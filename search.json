[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para Ciência de Dados (2ª edição)",
    "section": "",
    "text": "✅ Boas-vindas\nEste é o website para a tradução em Português da 2ª edição do livro “R for Data Science”. Este livro vai te ensinar como fazer ciência de dados com R: você irá aprender como importar os seus dados para o R, arrumá-los em uma estrutura mais útil, transformá-los e visualizá-los.\nNeste livro, você vai encontrar um conjunto de habilidades para a ciência de dados. Assim como estudantes de química aprendem a limpar tubos de ensaio e montar um laboratório, você vai aprender a limpar dados e fazer gráficos – além de muitas outras coisas. Essas são as habilidades que fazem a ciência de dados acontecer, e aqui você vai encontrar as melhores práticas para fazer cada uma dessas coisas com o R. Você vai aprender a usar a gramática dos gráficos, programação letrada (literate programming) e pesquisa reprodutível para economizar tempo. Você também vai aprender a gerenciar recursos cognitivos para facilitar descobertas ao lidar com, visualizar e explorar dados.\nEste site é e sempre será gratuito, licenciado sob a Licença CC BY-NC-ND 3.0. Se você gostaria de ter uma cópia física do livro, você pode comprar a versão em Inglês na Amazon. Se você aprecia ler o livro gratuitamente e gostaria de retribuir, por favor faça uma doação para a Kākāpō Recovery: o kākāpō (que aparece na capa do livro) é uma espécie de papagaio nativa da Nova Zelândia que está criticamente ameaçada de extinção; restam apenas 248 espécimes.\nVocê pode encontrar respostas sugeridas para exercícios no livro em https://mine-cetinkaya-rundel.github.io/r4ds-solutions.\nPor favor, note que o R4DS utiliza um Código de Conduta de Contribuidores. Ao contribuir para este livro, você concorda em seguir seus termos.\nSe você fala outra língua, pode se interessar pelas traduções gratuitas da primeira edição do livro:\nPor favor, note que o R4DS usa um Código de Conduta para Contribuidores. Ao contribuir para este livro, você concorda em seguir estes termos.",
    "crumbs": [
      "✅ Boas-vindas"
    ]
  },
  {
    "objectID": "index.html#agradecimentos",
    "href": "index.html#agradecimentos",
    "title": "R para Ciência de Dados (2ª edição)",
    "section": "Agradecimentos",
    "text": "Agradecimentos\nA versão original do livro (em Inglês) é hospedada pela https://www.netlify.com como parte de seu apoio ao software e às comunidades open source.",
    "crumbs": [
      "✅ Boas-vindas"
    ]
  },
  {
    "objectID": "preface-2e.html",
    "href": "preface-2e.html",
    "title": "✅ Prefácio da segunda edição",
    "section": "",
    "text": "Boas vindas à segunda edição do livro “R para Ciência de Dados”! Esta é uma revisão importante da primeira edição, removendo material que não consideramos mais útil, adicionando material que gostaríamos de ter incluído na primeira edição e atualizando o texto e o código de acordo com as melhores práticas. Também estamos muito animados em dar as boas-vindas a uma nova co-autora: Mine Çetinkaya-Rundel, uma renomada educadora em ciência de dados e uma de nossas colegas na Posit (conhecida anteriormente como RStudio).\nSegue abaixo um breve resumo das maiores mudanças nesta edição:\n\nA primeira parte do livro foi renomeada para “Visão geral”. O objetivo desta seção é fornecer a você os detalhes aproximados da “visão geral” da ciência de dados antes de nos aprofundarmos nos detalhes.\nA segunda parte do livro é chamada “Visualizar”. Esta parte oferece uma cobertura mais abrangente das ferramentas e práticas recomendadas de visualização de dados em comparação à primeira edição. O melhor lugar para obter todos os detalhes ainda é o livro do ggplot2, mas agora o R4DS aborda de forma mais abrangente as técnicas importantes.\nA terceira parte do livro agora é chamada de “Transformar” e inclui novos capítulos sobre números, vetores lógicos e valores faltantes (missing values - NA). Esses tópicos eram anteriormente parte do capítulo de transformação de dados, mas precisavam de mais espaço para cobrir todos os detalhes.\nA quarta parte do livro é chamada de “Importar”. São novos capítulos que vão além da leitura de arquivos de texto simples para trabalhar com planilhas, importar dados de bancos de dados (databases), trabalhar com grandes conjuntos de dados (big data), converter dados hierárquicos em dados tabulares e extrair dados de sites da web (web scraping).\nA parte “Programar” permanece, mas foi reescrita do zero para se concentrar nas partes mais importantes da escrita de funções e iteração. Agora, a escrita de funções inclui detalhes sobre como criar funções no estilo tidy (lidando com os desafios de avaliação tidy (tidy evaluation)), uma vez que isso se tornou muito mais fácil e importante nos últimos anos. Adicionamos um novo capítulo sobre funções importantes do R base que você provavelmente encontrará em códigos em R por aí.\nA parte de modelagem foi removida. Nunca tivemos espaço suficiente para fazer justiça à modelagem e agora existem recursos muito melhores disponíveis. Geralmente, recomendamos o uso do pacote tidymodels e a leitura do livro Tidy Modeling with R escrito por Max Kuhn e Julia Silge.\nA parte de “Comunicar” permanece, mas foi atualizada em detalhes para apresentar o Quarto em vez do R Markdown. Esta edição do livro foi escrita no Quarto e ele claramente é a ferramenta do futuro.",
    "crumbs": [
      "✅ Prefácio da segunda edição"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "✅ Introdução",
    "section": "",
    "text": "O que você aprenderá\nA ciência de dados é um campo vasto, e não é possível dominá-la lendo apenas um único livro. Este livro tem como objetivo fornecer a você uma base sólida nas ferramentas mais importantes e conhecimento suficiente para encontrar os recursos necessários para aprender mais quando for preciso. Nosso modelo das etapas de um projeto típico de ciência de dados se parece com Figura Em nosso modelo do processo de ciência de dados, você começa com a importação e organização dos dados. Em seguida, você entende seus dados por meio de um ciclo iterativo de transformação, visualização e modelagem. Você finaliza o ciclo comunicando seus resultados para outras pessoas..\nFigura 1: Em nosso modelo do processo de ciência de dados, você começa com a importação e organização dos dados. Em seguida, você entende seus dados por meio de um ciclo iterativo de transformação, visualização e modelagem. Você finaliza o ciclo comunicando seus resultados para outras pessoas.\nPrimeiro, você deve importar seus dados para o R. Isso geralmente significa que você pega dados armazenados em um arquivo, um banco de dados ou uma API (interface de programação de aplicação, ou Application Programming Interface em inglês) da web e importa em uma tabela (data frame) no R. Se você não conseguir importar seus dados para o R, não poderá fazer ciência de dados com eles!\nDepois de importar seus dados, é uma boa ideia organizá-los .\nOrganizar seus dados significa armazená-los em uma forma consistente que corresponda à semântica do conjunto de dados com a forma como ele é armazenado. Em resumo, quando seus dados estão organizados no formato tidy1, cada coluna é uma variável e cada linha é uma observação.\nDados no formato tidy (tidy data) são importantes porque a estrutura consistente permite que você concentre seus esforços em responder perguntas sobre os dados, em vez de lutar para colocar os dados na forma correta para usar diferentes funções. Depois de ter dados organizados, normalmente o próximo passo é transformá-los. A transformação inclui focar em observações de interesse (como todas as pessoas em uma cidade ou todos os dados do último ano), criar novas variáveis que são funções de variáveis existentes (como calcular a velocidade a partir da distância e do tempo) e calcular um conjunto de estatísticas resumidas (como contagens ou médias). Juntos, organizar e transformar são chamados de manipulação de dados2.\nUma vez que você tenha dados organizados e com as variáveis de que precisa, existem duas principais fontes de geração de conhecimento: visualização e modelagem. Essas têm pontos fortes e fracos complementares, portanto, qualquer análise de dados real irá iterar entre elas muitas vezes.\nVisualização é uma atividade fundamentalmente humana. Uma boa visualização mostrará coisas que você não esperava ou levantará novas questões sobre os dados. Uma boa visualização também pode sugerir que você está fazendo a pergunta errada ou que precisa coletar dados diferentes. As visualizações podem surpreender você, mas não escalam particularmente bem porque exigem que um ser humano as interprete.\nModelos são ferramentas complementares à visualização. Depois de tornar suas perguntas suficientemente precisas, você pode usar um modelo para respondê-las. Os modelos são fundamentalmente ferramentas matemáticas ou computacionais, então geralmente escalam bem. Mesmo quando não o fazem, geralmente é mais barato comprar mais computadores do que comprar mais cérebros! No entanto, cada modelo faz suposições, e, por sua própria natureza, um modelo não pode questionar suas próprias suposições. Isso significa que um modelo não pode, fundamentalmente, surpreendê-lo.\nA última etapa da ciência de dados é a comunicação, uma parte absolutamente crítica de qualquer projeto de análise de dados. Não importa o quão bem seus modelos e visualizações tenham ajudado você a entender os dados, a menos que você também possa comunicar seus resultados para outras pessoas.\nEm torno de todas essas ferramentas está a programação. A programação é uma ferramenta abrangente que é usada em quase todas as partes de um projeto de ciência de dados. Não é necessário ser uma pessoa especialista em programação para ter sucesso na ciência de dados, mas aprender mais sobre programação compensa, pois se tornar melhor em programação permite automatizar tarefas comuns e resolver novos problemas com maior facilidade.\nVocê usará essas ferramentas em todos os projetos de ciência de dados, mas para a maioria deles, elas não são suficientes. Há uma regra aproximada de 80/20 em jogo: você pode abordar cerca de 80% de cada projeto usando as ferramentas que aprenderá neste livro, mas precisará de outras ferramentas para lidar com os 20% restantes. Ao longo deste livro, indicaremos recursos onde você pode aprender mais.",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#como-este-livro-está-organizado",
    "href": "intro.html#como-este-livro-está-organizado",
    "title": "✅ Introdução",
    "section": "Como este livro está organizado",
    "text": "Como este livro está organizado\nA descrição anterior das ferramentas da ciência de dados está organizada aproximadamente de acordo com a ordem em que você as utiliza em uma análise (embora, é claro, você vá iterar por elas várias vezes). Em nossa experiência, no entanto, aprender primeiro a importação e organização de dados não é a melhor escolha, porque essas tarefas são, 80% do tempo, rotineiras e entediantes, e nos outros 20% do tempo, são estranhas e frustrantes. Esse não é um bom ponto de partida para aprender um novo assunto! Em vez disso, começaremos com a visualização e transformação de dados que já foram importados e organizados. Dessa forma, quando você importar e organizar seus próprios dados, sua motivação permanecerá alta, porque você sabe que o esforço vale a pena.\nDentro de cada capítulo, procuramos seguir um padrão consistente: começar com alguns exemplos motivadores para que você possa entender o panorama geral e, em seguida, aprofundar nos detalhes. Cada seção do livro é acompanhada de exercícios para ajudar você a praticar o que aprendeu. Embora possa ser tentador pular os exercícios, a melhor maneira de aprender é praticando com problemas reais.",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#o-que-você-não-aprenderá",
    "href": "intro.html#o-que-você-não-aprenderá",
    "title": "✅ Introdução",
    "section": "O que você não aprenderá",
    "text": "O que você não aprenderá\nExistem vários tópicos importantes que este livro não aborda. Acreditamos que é importante manter um foco rigoroso no essencial para que você possa começar o mais rápido possível. Isso significa que não é possível, neste livro, abordar todos os tópicos importantes.\nModelagem\nA modelagem é extremamente importante para a ciência de dados, mas é um tópico amplo e, infelizmente, não temos espaço suficiente para abordá-lo adequadamente aqui. Para aprender mais sobre modelagem, recomendamos fortemente o livro Tidy Modeling with R, escrito por nossos colegas Max Kuhn e Julia Silge. O livro Tidy Modeling with R ensinará a você a família de pacotes tidymodels, que, como você pode imaginar pelo nome, compartilha muitas convenções com os pacotes do tidyverse que usamos neste livro.\nBig data\nEste livro orgulhosamente e principalmente foca em conjuntos de dados pequenos e que cabem na memória3 (in-memory).\nEste é o lugar certo para começar, porque você não poderá lidar com big data a menos que já tenha experiência com bases de dados pequenas. As ferramentas que você aprenderá ao longo da maior parte deste livro lidarão facilmente com centenas de megabytes de dados e, com um pouco de cuidado, você geralmente poderá usá-las para trabalhar com alguns gigabytes de dados. Também mostraremos como obter dados de bancos de dados e arquivos parquet, ambos frequentemente usados para armazenar big data. Você não necessariamente conseguirá trabalhar com o conjunto de dados inteiro, mas isso nem sempre é um problema, pois, em muitos casos, você só precisa de um subconjunto ou uma amostra para responder à pergunta que te interessa.\nSe você está rotineiramente lidando com dados maiores (digamos, de 10 a 100 GB), recomendamos aprender mais sobre o pacote data.table. Não o ensinamos aqui porque ele usa uma interface diferente do tidyverse e requer que você aprenda algumas convenções diferentes. No entanto, ele é incrivelmente mais rápido, e o retorno no desempenho compensa o tempo investido para aprender a usá-lo, se você estiver trabalhando com big data.\nPython, Julia e outros\nNeste livro, você não aprenderá nada sobre Python, Julia ou qualquer outra linguagem de programação útil para a ciência de dados. Isso não é porque achamos que essas ferramentas são ruins. Elas não são! E, na prática, a maioria das equipes de ciência de dados usa uma combinação de linguagens, muitas vezes pelo menos R e Python. Mas acreditamos firmemente que é melhor dominar uma ferramenta de cada vez, e R é um ótimo ponto de partida.",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#pré-requisitos",
    "href": "intro.html#pré-requisitos",
    "title": "✅ Introdução",
    "section": "Pré-requisitos",
    "text": "Pré-requisitos\nFizemos algumas suposições sobre o que você já deveria saber para aproveitar ao máximo este livro. Você deve ter uma compreensão geral de matemática e é útil se você já tiver alguma experiência básica em programação. Se você nunca programou antes, pode achar o livro Hands on Programming with R, escrito por Garrett, um recurso valioso para complementar este livro.\nVocê precisará de quatro coisas para executar os códigos deste livro: R, RStudio, um conjunto de pacotes R chamado tidyverse e alguns outros pacotes. Pacotes são as unidades fundamentais de código R reprodutível. Eles incluem funções reutilizáveis, documentação que descreve como usá-los e dados de exemplo.\nR\nPara baixar o R, acesse o CRAN, o comprehensive R archive network, em https://cloud.r-project.org. Uma nova versão principal do R é lançada anualmente, e há 2-3 lançamentos menores a cada ano. É uma boa ideia atualizar regularmente. A atualização pode ser um pouco complicada, especialmente para as versões principais que exigem que você reinstale todos os seus pacotes, mas adiá-la só torna as coisas piores. Recomendamos o R 4.2.0 ou posterior para este livro.\nRStudio\nO RStudio é uma IDE (ambiente de desenvolvimento integrado), para programação em R, que você pode baixar em https://posit.co/download/rstudio-desktop/. O RStudio é atualizado algumas vezes por ano e ele o informará automaticamente quando uma nova versão estiver disponível, portanto, não é necessário verificar periodicamente. É uma boa ideia atualizar regularmente para aproveitar os recursos mais recentes e melhorados. Para este livro, certifique-se de ter pelo menos o RStudio 2022.02.0.\nQuando você inicia o RStudio, Figura O RStudio possui duas partes principais: digite o código em R no Console à esquerda e procure o painel Plots dentro do painel Output à direita., você verá duas partes principais na interface: o painel de console (Console) e o painel de saída (Output). Por enquanto, tudo o que você precisa saber é que você digita o código R no Console e pressiona Enter para executá-lo. Você aprenderá mais à medida que avançarmos!4\n\n\n\n\n\n\n\nFigura 2: O RStudio possui duas partes principais: digite o código em R no Console à esquerda e procure o painel Plots dentro do painel Output à direita.\n\n\n\n\nO tidyverse\nVocê também precisará instalar alguns pacotes do R. Um pacote do R é uma coleção de funções, dados e documentação que estende as capacidades do R base. O uso de pacotes é fundamental para o uso bem-sucedido do R. A maioria dos pacotes que você aprenderá neste livro faz parte do chamado tidyverse. Todos os pacotes no tidyverse compartilham uma filosofia comum de dados e programação em R e são projetados para funcionar juntos.\nVocê pode instalar o tidyverse completo com uma única linha de código:\n\ninstall.packages(\"tidyverse\")\n\nEm seu computador, digite essa linha de código no console e pressione Enter para executá-la. O R fará o download dos pacotes do CRAN e os instalará em seu computador.\nVocê não poderá usar as funções, objetos ou arquivos de ajuda de um pacote até carregá-lo com library(). Depois de instalar um pacote, você pode carregá-lo usando a função library():\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4.9000     ✔ readr     2.1.5     \n#&gt; ✔ forcats   1.0.0          ✔ stringr   1.5.1     \n#&gt; ✔ ggplot2   3.5.0          ✔ tibble    3.2.1     \n#&gt; ✔ lubridate 1.9.3          ✔ tidyr     1.3.1     \n#&gt; ✔ purrr     1.0.2          \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nIsso informa que o tidyverse carrega nove pacotes: dplyr, forcats, ggplot2, lubridate, purrr, readr, stringr, tibble, tidyr. Esses são considerados o núcleo do tidyverse porque você os usará em quase todas as análises.\nOs pacotes do tidyverse mudam com bastante frequência. Você pode verificar se há atualizações disponíveis executando tidyverse_update().\nOutros pacotes\nExistem muitos outros pacotes excelentes que não fazem parte do tidyverse porque resolvem problemas em um domínio diferente ou são projetados com um conjunto diferente de princípios subjacentes. Isso não os torna melhores ou piores; apenas os torna diferentes. Em outras palavras, o complemento ao tidyverse não é o messyverse5, mas muitos outros universos de pacotes inter-relacionados.\nConforme você enfrenta mais projetos de ciência de dados com R, aprenderá novos pacotes e novas formas de pensar sobre dados.\nUsaremos muitos pacotes de fora do tidyverse neste livro. Por exemplo, usaremos os seguintes pacotes porque eles fornecem conjuntos de dados interessantes para trabalharmos no processo de aprendizado do R:\n\ninstall.packages(\n  c(\"arrow\", \"curl\", \"remotes\", \"duckdb\",\n    \"ggrepel\", \"ggridges\", \"ggthemes\", \"hexbin\", \"janitor\",  \n    \"leaflet\", \"maps\", \"openxlsx\", \n    \"repurrrsive\", \"tidymodels\", \"writexl\")\n  )\n\n# Instalar o pacote de dados\nremotes::install_github(\"cienciadedatos/dados\")\n\nTambém usaremos uma seleção de outros pacotes para exemplos isolados. Você não precisa instalá-los agora, apenas lembre-se de que sempre que vir um erro como este:\n\nlibrary(ggrepel)\n#&gt; Error in library(ggrepel) : there is no package called ‘ggrepel’\n\nVocê precisará executar install.packages(\"ggrepel\") para instalar o pacote.",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#executando-código-em-r",
    "href": "intro.html#executando-código-em-r",
    "title": "✅ Introdução",
    "section": "Executando código em R",
    "text": "Executando código em R\nA seção anterior mostrou vários exemplos de execução de código em R. O código no livro parece assim:\n\n1 + 2\n#&gt; [1] 3\n\nSe você executar o mesmo código no seu console, ele parecerá assim:\n&gt; 1 + 2\n[1] 3\nExistem duas diferenças principais. No seu console, você digita após o &gt;, chamado de prompt; não mostramos o prompt no livro. No livro, a saída é comentada com #&gt;; no seu console, ela aparece diretamente após o código. Essas duas diferenças significam que se você estiver trabalhando com uma versão online do livro, poderá copiar facilmente o código do livro e colá-lo no console.\nAo longo do livro, usamos um conjunto consistente de convenções para se referir ao código:\n\nFunções são exibidas em uma fonte de código e seguidas por parênteses, como sum() ou mean().\nOutros objetos R (como dados ou argumentos de função) estão em uma fonte de código, sem parênteses, como voos ou x.\nÀs vezes, para deixar claro de qual pacote um objeto vem, usaremos o nome do pacote seguido por quatro-pontos ::, como dplyr::mutate() ou dados::voos. Isso também é código em R válido.",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#agradecimentos",
    "href": "intro.html#agradecimentos",
    "title": "✅ Introdução",
    "section": "Agradecimentos",
    "text": "Agradecimentos\nEste livro não é apenas o produto de Hadley, Mine e Garrett, mas é o resultado de muitas conversas (pessoalmente e online) que tivemos com muitas pessoas na comunidade R. Estamos incrivelmente gratos por todas as conversas que tivemos com todos vocês; muito obrigado!\nEste livro foi escrito de forma colaborativa e muitas pessoas contribuíram por meio de pull requests. Um agradecimento especial a todas as 259 pessoas que contribuíram com melhorias por meio de pull requests no GitHub (em ordem alfabética pelo nome de usuário): @a-rosenberg, Tim Becker (@a2800276), Abinash Satapathy (@Abinashbunty), Adam Gruer (@adam-gruer), adi pradhan (@adidoit), A. s. (@Adrianzo), Aep Hidyatuloh (@aephidayatuloh), Andrea Gilardi (@agila5), Ajay Deonarine (@ajay-d), @AlanFeder, Daihe Sui (@alansuidaihe), @alberto-agudo, @AlbertRapp, @aleloi, pete (@alonzi), Alex (@ALShum), Andrew M. (@amacfarland), Andrew Landgraf (@andland), @andyhuynh92, Angela Li (@angela-li), Antti Rask (@AnttiRask), LOU Xun (@aquarhead), @ariespirgel, @august-18, Michael Henry (@aviast), Azza Ahmed (@azzaea), Steven Moran (@bambooforest), Brian G. Barkley (@BarkleyBG), Mara Averick (@batpigandme), Oluwafemi OYEDELE (@BB1464), Brent Brewington (@bbrewington), Bill Behrman (@behrman), Ben Herbertson (@benherbertson), Ben Marwick (@benmarwick), Ben Steinberg (@bensteinberg), Benjamin Yeh (@bentyeh), Betul Turkoglu (@betulturkoglu), Brandon Greenwell (@bgreenwell), Bianca Peterson (@BinxiePeterson), Birger Niklas (@BirgerNi), Brett Klamer (@bklamer), @boardtc, Christian (@c-hoh), Caddy (@caddycarine), Camille V Leonard (@camillevleonard), @canovasjm, Cedric Batailler (@cedricbatailler), Christina Wei (@christina-wei), Christian Mongeau (@chrMongeau), Cooper Morris (@coopermor), Colin Gillespie (@csgillespie), Rademeyer Vermaak (@csrvermaak), Chloe Thierstein (@cthierst), Chris Saunders (@ctsa), Abhinav Singh (@curious-abhinav), Curtis Alexander (@curtisalexander), Christian G. Warden (@cwarden), Charlotte Wickham (@cwickham), Kenny Darrell (@darrkj), David Kane (@davidkane9), David (@davidrsch), David Rubinger (@davidrubinger), David Clark (@DDClark), Derwin McGeary (@derwinmcgeary), Daniel Gromer (@dgromer), @Divider85, @djbirke, Danielle Navarro (@djnavarro), Russell Shean (@DOH-RPS1303), Zhuoer Dong (@dongzhuoer), Devin Pastoor (@dpastoor), @DSGeoff, Devarshi Thakkar (@dthakkar09), Julian During (@duju211), Dylan Cashman (@dylancashman), Dirk Eddelbuettel (@eddelbuettel), Edwin Thoen (@EdwinTh), Ahmed El-Gabbas (@elgabbas), Henry Webel (@enryH), Ercan Karadas (@ercan7), Eric Kitaif (@EricKit), Eric Watt (@ericwatt), Erik Erhardt (@erikerhardt), Etienne B. Racine (@etiennebr), Everett Robinson (@evjrob), @fellennert, Flemming Miguel (@flemmingmiguel), Floris Vanderhaeghe (@florisvdh), @funkybluehen, @gabrivera, Garrick Aden-Buie (@gadenbuie), Peter Ganong (@ganong123), Gerome Meyer (@GeroVanMi), Gleb Ebert (@gl-eb), Josh Goldberg (@GoldbergData), bahadir cankardes (@gridgrad), Gustav W Delius (@gustavdelius), Hao Chen (@hao-trivago), Harris McGehee (@harrismcgehee), @hendrikweisser, Hengni Cai (@hengnicai), Iain (@Iain-S), Ian Sealy (@iansealy), Ian Lyttle (@ijlyttle), Ivan Krukov (@ivan-krukov), Jacob Kaplan (@jacobkap), Jazz Weisman (@jazzlw), John Blischak (@jdblischak), John D. Storey (@jdstorey), Gregory Jefferis (@jefferis), Jeffrey Stevens (@JeffreyRStevens), 蒋雨蒙 (@JeldorPKU), Jennifer (Jenny) Bryan (@jennybc), Jen Ren (@jenren), Jeroen Janssens (@jeroenjanssens), @jeromecholewa, Janet Wesner (@jilmun), Jim Hester (@jimhester), JJ Chen (@jjchern), Jacek Kolacz (@jkolacz), Joanne Jang (@joannejang), @johannes4998, John Sears (@johnsears), @jonathanflint, Jon Calder (@jonmcalder), Jonathan Page (@jonpage), Jon Harmon (@jonthegeek), JooYoung Seo (@jooyoungseo), Justinas Petuchovas (@jpetuchovas), Jordan (@jrdnbradford), Jeffrey Arnold (@jrnold), Jose Roberto Ayala Solares (@jroberayalas), Joyce Robbins (@jtr13), @juandering, Julia Stewart Lowndes (@jules32), Sonja (@kaetschap), Kara Woo (@karawoo), Katrin Leinweber (@katrinleinweber), Karandeep Singh (@kdpsingh), Kevin Perese (@kevinxperese), Kevin Ferris (@kferris10), Kirill Sevastyanenko (@kirillseva), Jonathan Kitt (@KittJonathan), @koalabearski, Kirill Müller (@krlmlr), Rafał Kucharski (@kucharsky), Kevin Wright (@kwstat), Noah Landesberg (@landesbergn), Lawrence Wu (@lawwu), @lindbrook, Luke W Johnston (@lwjohnst86), Kara de la Marck (@MarckK), Kunal Marwaha (@marwahaha), Matan Hakim (@matanhakim), Matthias Liew (@MatthiasLiew), Matt Wittbrodt (@MattWittbrodt), Mauro Lepore (@maurolepore), Mark Beveridge (@mbeveridge), @mcewenkhundi, mcsnowface, PhD (@mcsnowface), Matt Herman (@mfherman), Michael Boerman (@michaelboerman), Mitsuo Shiota (@mitsuoxv), Matthew Hendrickson (@mjhendrickson), @MJMarshall, Misty Knight-Finley (@mkfin7), Mohammed Hamdy (@mmhamdy), Maxim Nazarov (@mnazarov), Maria Paula Caldas (@mpaulacaldas), Mustafa Ascha (@mustafaascha), Nelson Areal (@nareal), Nate Olson (@nate-d-olson), Nathanael (@nateaff), @nattalides, Ned Western (@NedJWestern), Nick Clark (@nickclark1000), @nickelas, Nirmal Patel (@nirmalpatel), Nischal Shrestha (@nischalshrestha), Nicholas Tierney (@njtierney), Jakub Nowosad (@Nowosad), Nick Pullen (@nstjhp), @olivier6088, Olivier Cailloux (@oliviercailloux), Robin Penfold (@p0bs), Pablo E. Garcia (@pabloedug), Paul Adamson (@padamson), Penelope Y (@penelopeysm), Peter Hurford (@peterhurford), Peter Baumgartner (@petzi53), Patrick Kennedy (@pkq), Pooya Taherkhani (@pooyataher), Y. Yu (@PursuitOfDataScience), Radu Grosu (@radugrosu), Ranae Dietzel (@Ranae), Ralph Straumann (@rastrau), Rayna M Harris (@raynamharris), @ReeceGoding, Robin Gertenbach (@rgertenbach), Jajo (@RIngyao), Riva Quiroga (@rivaquiroga), Richard Knight (@RJHKnight), Richard Zijdeman (@rlzijdeman), @robertchu03, Robin Kohrs (@RobinKohrs), Robin (@Robinlovelace), Emily Robinson (@robinsones), Rob Tenorio (@robtenorio), Rod Mazloomi (@RodAli), Rohan Alexander (@RohanAlexander), Romero Morais (@RomeroBarata), Albert Y. Kim (@rudeboybert), Saghir (@saghirb), Hojjat Salmasian (@salmasian), Jonas (@sauercrowd), Vebash Naidoo (@sciencificity), Seamus McKinsey (@seamus-mckinsey), @seanpwilliams, Luke Smith (@seasmith), Matthew Sedaghatfar (@sedaghatfar), Sebastian Kraus (@sekR4), Sam Firke (@sfirke), Shannon Ellis (@ShanEllis), @shoili, Christian Heinrich (@Shurakai), S’busiso Mkhondwane (@sibusiso16), SM Raiyyan (@sm-raiyyan), Jakob Krigovsky (@sonicdoe), Stephan Koenig (@stephan-koenig), Stephen Balogun (@stephenbalogun), Steven M. Mortimer (@StevenMMortimer), Stéphane Guillou (@stragu), Sulgi Kim (@sulgik), Sergiusz Bleja (@svenski), Tal Galili (@talgalili), Alec Fisher (@Taurenamo), Todd Gerarden (@tgerarden), Tom Godfrey (@thomasggodfrey), Tim Broderick (@timbroderick), Tim Waterhouse (@timwaterhouse), TJ Mahr (@tjmahr), Thomas Klebel (@tklebel), Tom Prior (@tomjamesprior), Terence Teo (@tteo), @twgardner2, Ulrik Lyngs (@ulyngs), Shinya Uryu (@uribo), Martin Van der Linden (@vanderlindenma), Walter Somerville (@waltersom), @werkstattcodes, Will Beasley (@wibeasley), Yihui Xie (@yihui), Yiming (Paul) Li (@yimingli), @yingxingwu, Hiroaki Yutani (@yutannihilation), Yu Yu Aung (@yuyu-aung), Zach Bogart (@zachbogart), @zeal626, Zeki Akyol (@zekiakyol).",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#considerações-finais",
    "href": "intro.html#considerações-finais",
    "title": "✅ Introdução",
    "section": "Considerações Finais",
    "text": "Considerações Finais\nA versão online deste livro está disponível em https://cienciadedatos.github.io/pt-r4ds/. O código fonte do livro está disponível em https://github.com/cienciadedatos/pt-r4ds. O livro é gerado pelo Quarto, que facilita a escrita de livros que combinam texto e código executável.",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "✅ Introdução",
    "section": "",
    "text": "Nota de tradução: tidy é um verbo em inglês que quer dizer “arrumar/organizar”. Tidy data é uma forma de organizar os dados, que será abordado no capítulo 5  ✅ Organizando os dados (data tidying).↩︎\nNota de tradução: Manipulação de dados é chamado em inglês de data wrangling, porque colocar seus dados em uma forma natural de trabalhar frequentemente parece uma luta (wrangle)!↩︎\nNota de tradução: “Caber na memória” se refere à memória RAM (random access memory) do computador, cuja função é guardar temporariamente toda a informação que o computador precisa (por exemplo, as bases de dados importadas).↩︎\nSe você deseja uma visão abrangente de todos os recursos do RStudio, consulte o Guia de uso do RStudio em https://docs.posit.co/ide/user.↩︎\nNota de tradução: tidyverse é a união das palavras tidy (arrumado) e universe (universo), sendo então a ideia de um “universo arrumado”. messy quer dizer desarrumado, e messyverse seria a ideia de um universo desarrumado.↩︎",
    "crumbs": [
      "✅ Introdução"
    ]
  },
  {
    "objectID": "whole-game.html",
    "href": "whole-game.html",
    "title": "✅ Visão geral",
    "section": "",
    "text": "O nosso objetivo nesta parte do livro é oferecer uma visão geral rápida das principais ferramentas da ciência de dados: importação, organização, transformação e visualização de dados, como mostrado na Figura Nesta parte do livro, você aprenderá como importar, organizar, transformar e visualizar dados.. Queremos apresentar para você uma visão geral da ciência de dados, fornecendo apenas o suficiente de todos os principais elementos para que você possa lidar com conjuntos de dados reais, ainda que simples. As partes posteriores do livro abordarão cada um desses tópicos com mais profundidade, ampliando o leque de desafios da ciência de dados que você pode enfrentar.\n\n\n\n\n\n\n\nFigura 1: Nesta parte do livro, você aprenderá como importar, organizar, transformar e visualizar dados.\n\n\n\n\nQuatro capítulos se concentram nas ferramentas da ciência de dados:\n\nA visualização é um ótimo ponto de partida para a programação em R, porque os resultados são claros: você pode criar gráficos elegantes e informativos que te ajudam a entender os dados. No 1  ✅ Visualização de dados, você mergulhará na visualização, aprendendo a estrutura básica de um gráfico ggplot2 e técnicas poderosas para transformar dados em gráficos.\nGeralmente, apenas a visualização não é suficiente. Portanto, no 3  Data transformation, você aprenderá os principais verbos que permitem selecionar variáveis importantes, filtrar observações essenciais, criar novas variáveis e fazer sumarizações.\nNo 5  ✅ Organizando os dados (data tidying), você aprenderá sobre dados organizados (tidy data), uma maneira consistente de armazenar seus dados que facilita a transformação, visualização e modelagem. Você aprenderá os princípios de tidy data e como deixar seus dados neste formato.\nAntes de poder transformar e visualizar seus dados, você precisa primeiro importá-los para o R. No 7  Data import, você aprenderá o básico de como importar arquivos .csv para o R.\n\nEntre esses capítulos, há outros quatro capítulos que se concentram no fluxo de trabalho no R. Em 2  ✅ Fluxo de Trabalho: básico, 4  ✅ Fluxo de trabalho: estilo de código e 6  ✅ Fluxo de trabalho: scripts e projetos, você aprenderá boas práticas de fluxo de trabalho para escrever e organizar seu código R. Isso te preparará para o sucesso a longo prazo, pois fornecerá as ferramentas necessárias para manter a organização ao enfrentar projetos reais. Por fim, no 8  ✅ Fluxo de trabalho: obtendo ajuda, você aprenderá como obter ajuda e continuar aprendendo.",
    "crumbs": [
      "✅ Visão geral"
    ]
  },
  {
    "objectID": "data-visualize.html",
    "href": "data-visualize.html",
    "title": "1  ✅ Visualização de dados",
    "section": "",
    "text": "1.1 Introdução\nO R possui diversos sistemas para construir gráficos, mas o ggplot2 é um dos mais elegantes e versáteis. O ggplot2 implementa a gramática dos gráficos, um sistema coerente para descrever e construir gráficos. Com o ggplot2 você pode fazer mais, e mais rápido, ao aprender um sistema e aplicá-lo em muitos lugares.\nEste capítulo irá te ensinar como visualizar seus dados usando o ggplot2. Nós vamos começar criando um gráfico de dispersão simples e usá-lo para introduzir o mapeamento de atributos estéticos (aesthetic) e geometrias – os blocos fundamentais na construção do ggplot2. Nós vamos então te orientar na visualização de distribuições de variáveis individuais, bem como na visualização de relações entre duas ou mais variáveis. Terminaremos salvando seus gráficos e com dicas de resolução de problemas.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#introdução",
    "href": "data-visualize.html#introdução",
    "title": "1  ✅ Visualização de dados",
    "section": "",
    "text": "“O gráfico simples trouxe mais informações à mente dos analistas de dados do que qualquer outro dispositivo.” — John Tukey\n\n\n\n\n1.1.1 Pré-requisitos\nEste capítulo tem foco no ggplot2, um dos principais pacotes do tidyverse. Para acessar os bancos de dados, páginas de ajuda e funções utilizadas neste capítulo, você deve carregar o tidyverse executando o comando:\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4.9000     ✔ readr     2.1.5     \n#&gt; ✔ forcats   1.0.0          ✔ stringr   1.5.1     \n#&gt; ✔ ggplot2   3.5.0          ✔ tibble    3.2.1     \n#&gt; ✔ lubridate 1.9.3          ✔ tidyr     1.3.1     \n#&gt; ✔ purrr     1.0.2          \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nEssa única linha de código carrega os pacotes essenciais do tidyverse, que você irá utilizar em quase toda análise de dados. Ela também te diz quais funções do tidyverse possuem conflitos com as função do R base (ou de outro pacote que você tenha carregado)1.\nSe você rodar este código e receber a mensagem de erro there is no package called 'tidyverse', você precisará instalar o pacote antes usando a função install.packages() ou a interface de instalação do RStudio, e então rodar library() novamente.\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nVocê só precisa instalar um pacote uma vez, mas precisa carregá-lo sempre que iniciar uma nova sessão.\nAlém do tidyverse, nós também usaremos o pacote dados, que contém várias bases de dados, incluindo uma com medidas corporais de pinguins de três ilhas do Arquipélago Palmer, junto do pacote ggthemes, que fornece uma paleta de cores segura para pessoas com daltonismo.\n\nlibrary(dados)\nlibrary(ggthemes)",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#primeiros-passos",
    "href": "data-visualize.html#primeiros-passos",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.2 Primeiros passos",
    "text": "1.2 Primeiros passos\nOs pinguins com nadadeiras mais compridas pesam mais ou menos que pinguins com nadadeiras curtas? Você provavelmente já tem uma resposta, mas tente torná-la mais precisa. Como é a relação entre o comprimento da nadadeira e massa corporal? Ela é positiva? Negativa? Linear? Não linear? A relação varia com a espécie do pinguim? E quanto à ilha onde o pinguim vive? Vamos criar visualizações que podemos usar para responder essas perguntas.\n\n1.2.1 O data frame pinguins\n\nVocê pode testar suas respostas à essas questões usando o data frame pinguins encontrado no pacote dados (usando dados::pinguins). Um data frame é uma coleção tabular (formato de tabela) de variáveis (nas colunas) e observações (nas linhas). pinguins contém 344 observações coletadas e disponibilizadas pela Dra. Kristen Gorman e pelo PELD Estação Palmer, Antártica2.\nPara facilitar a discussão, vamos definir alguns termos:\n\nUma variável é uma quantidade, qualidade ou propriedade que você pode medir.\nUm valor é o estado de uma variável quando você a mede. O valor de uma variável pode mudar de medição para medição.\nUma observação é um conjunto de medições feitas em condições semelhantes (geralmente todas as medições em uma observação são feitas ao mesmo tempo e no mesmo objeto). Uma observação conterá vários valores, cada um associado a uma variável diferente. Às vezes, vamos nos referir a uma observação como um ponto de dados.\nDados tabulares são um conjunto de valores, cada um associado a uma variável e uma observação. Os dados tabulares estarão no formato tidy (arrumado) se cada valor estiver em sua própria “célula”, cada variável em sua própria coluna e cada observação em sua própria linha.\n\nNeste contexto, uma variável refere-se a um atributo de todos os pinguins, e uma observação refere-se a todos os atributos de um único pinguim.\nDigite o nome do data frame no console e o R mostrará uma visualização de seu conteúdo. Observe que aparece escrito tibble no topo desta visualização. No tidyverse, usamos data frames especiais chamados tibbles, dos quais você aprenderá mais em breve.\n\npinguins\n#&gt; # A tibble: 344 × 8\n#&gt;   especie           ilha      comprimento_bico profundidade_bico\n#&gt;   &lt;fct&gt;             &lt;fct&gt;                &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Pinguim-de-adélia Torgersen             39.1              18.7\n#&gt; 2 Pinguim-de-adélia Torgersen             39.5              17.4\n#&gt; 3 Pinguim-de-adélia Torgersen             40.3              18  \n#&gt; 4 Pinguim-de-adélia Torgersen             NA                NA  \n#&gt; 5 Pinguim-de-adélia Torgersen             36.7              19.3\n#&gt; 6 Pinguim-de-adélia Torgersen             39.3              20.6\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 4 more variables: comprimento_nadadeira &lt;int&gt;, massa_corporal &lt;int&gt;, …\n\nEste data frame contém 8 colunas. Para uma visualização alternativa, onde você pode ver todas as variáveis e as primeiras observações de cada variável, use glimpse(). Ou, se você estiver no RStudio, execute View(pinguins) para abrir um visualizador de dados interativo.\n\nglimpse(pinguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ especie               &lt;fct&gt; Pinguim-de-adélia, Pinguim-de-adélia, Pinguim…\n#&gt; $ ilha                  &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, T…\n#&gt; $ comprimento_bico      &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2,…\n#&gt; $ profundidade_bico     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6,…\n#&gt; $ comprimento_nadadeira &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 1…\n#&gt; $ massa_corporal        &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675,…\n#&gt; $ sexo                  &lt;fct&gt; macho, fêmea, fêmea, NA, fêmea, macho, fêmea,…\n#&gt; $ ano                   &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 200…\n\nEntre as variáveis em pinguins estão:\n\nespecie: a espécie de um pinguim (Pinguim-de-adélia, Pinguim-de-barbicha e Pinguim-gentoo).\ncomprimento_nadadeira: comprimento da nadadeira de um pinguim, em milímetros.\nmassa_corporal: massa corporal de um pinguim, em gramas.\n\nPara saber mais sobre pinguins, abra sua página de ajuda executando ?pinguins.\n\n1.2.2 Objetivo final\nNosso objetivo final neste capítulo é recriar a seguinte visualização que exibe a relação entre o comprimento da nadadeira e a massa corporal desses pinguins, levando em consideração a espécie do pinguim.\n\n\n\n\n\n\n\n\n\n1.2.3 Criando um gráfico ggplot\nVamos recriar esse gráfico passo a passo.\nNo ggplot2, você inicia um gráfico com a função ggplot(), definindo um objeto de gráfico ao qual você adiciona camadas. O primeiro argumento da função ggplot() é o conjunto de dados a ser usado no gráfico e, portanto, ggplot(data = pinguins) cria um gráfico vazio que está preparado para exibir os dados dos pinguins, mas, como ainda não dissemos como fazer a visualização, por enquanto ele está vazio. Esse não é um gráfico muito interessante, mas você pode pensar nele como uma tela vazia na qual você pintará as camadas restantes do seu gráfico.\n\nggplot(data = pinguins)\n\n\n\n\n\n\n\nEm seguida, precisamos informar ao ggplot() como as informações dos nossos dados serão representadas visualmente. O argumento mapping (mapeamento) da função ggplot() define como as variáveis em seu conjunto de dados são mapeadas para as propriedades visuais (estética) do gráfico. O argumento mapping é sempre definido na função aes(), e os argumentos x e y de aes() especificam quais variáveis devem ser mapeadas nos eixos x e y. Por enquanto, mapearemos apenas o comprimento da nadadeira para o atributo estético x e a massa corporal para o atributo y. O ggplot2 procura as variáveis mapeadas no argumento data, nesse caso, pinguins.\nO gráfico a seguir mostra o resultado da adição desses mapeamentos.\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n)\n\n\n\n\n\n\n\nNossa tela vazia agora está mais estruturada: está claro onde os comprimentos das nadadeiras serão exibidos (no eixo x) e onde as massas corporais serão exibidas (no eixo y). Mas os pinguins em si ainda não estão no gráfico. Isso ocorre porque ainda não definimos, em nosso código, como representar as observações de nosso data frame em nosso gráfico.\nPara isso, precisamos definir um geom: A geometria que um gráfico usa para representar os dados. Essas geometrias são disponibilizados no ggplot2 com funções que começam com geom_. As pessoas geralmente descrevem os gráficos pelo tipo de geom que o gráfico usa. Por exemplo, os gráficos de barras usam geometrias de barras (geom_bar()), os gráficos de linhas usam geometrias de linhas (geom_line()), os boxplots usam geometrias de boxplot (geom_boxplot()), os gráficos de dispersão usam geometrias de pontos (geom_point()) e assim por diante.\nA função geom_point() adiciona uma camada de pontos ao seu gráfico, o que cria um gráfico de dispersão. O ggplot2 vem com muitas funções de geometria, cada uma adicionando um tipo diferente de camada a um gráfico. Você aprenderá várias geometrias ao longo do livro, principalmente em Capítulo 9.\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n) +\n  geom_point()\n#&gt; Warning: Removed 2 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\nAgora temos algo que se parece com o que poderíamos chamar de “gráfico de dispersão”. Ele ainda não corresponde ao nosso gráfico mostrado no início da seção “objetivo final”, mas, usando esse gráfico, podemos começar a responder à pergunta que motivou nossa exploração: “Como é a relação entre o comprimento da nadadeira e a massa corporal?” A relação parece ser positiva (à medida que o comprimento da nadadeira aumenta, a massa corporal também aumenta), razoavelmente linear (os pontos estão agrupados em torno de uma linha em vez de uma curva) e moderadamente forte (não há muita dispersão em torno dessa linha). Os pinguins com nadadeiras mais longas geralmente são maiores em termos de massa corporal.\nAntes de adicionarmos mais camadas a esse gráfico, vamos parar por um momento e revisar a mensagem de aviso que recebemos:\n\nRemoved 2 rows containing missing values (geom_point()).\n\nEstamos vendo essa mensagem porque há dois pinguins em nosso conjunto de dados com valores faltantes (missing values - NA*) de massa corporal e/ou comprimento da nadadeira e o ggplot2 não tem como representá-los no gráfico sem esses dois valores. Assim como o R, o ggplot2 adota a filosofia de que os valores faltantes nunca devem desaparecer silenciosamente. Esse tipo de aviso é provavelmente um dos tipos mais comuns de avisos que você verá ao trabalhar com dados reais - os valores faltantes são um problema muito comum e você aprenderá mais sobre eles ao longo do livro, especialmente em Capítulo 18. Nos demais gráficos deste capítulo, vamos suprimir esse aviso para que ele não seja mostrado em cada gráfico que fizermos.\n\n1.2.4 Adicionando atributos estéticos e camadas\nGráficos de dispersão são úteis para exibir a relação entre duas variáveis numéricas, mas é sempre uma boa ideia ter uma postura cética em relação a qualquer relação aparente entre duas variáveis e perguntar se pode haver outras variáveis que expliquem ou mudem a natureza dessa relação aparente. Por exemplo, a relação entre o comprimento das nadadeira e a massa corporal difere de acordo com a espécie? Vamos incluir as espécies em nosso gráfico e ver se isso revela alguma ideia adicional sobre a relação aparente entre essas variáveis. Faremos isso representando as espécies com pontos de cores diferentes.\nPara conseguir isso, precisaremos modificar o atributo estético ou a geometria? Se você pensou “no mapeamento estético, dentro de aes()”, você já está pegando o jeito de criar visualizações de dados com o ggplot2! Caso contrário, não se preocupe. Ao longo do livro, você criará muito mais visualizações com ggplot e terá muito mais oportunidades de verificar sua intuição.\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal, color = especie)\n) +\n  geom_point()\n\n\n\n\n\n\n\nQuando uma variável categórica é mapeada a um atributo estético, o ggplot2 atribui automaticamente um valor único da estética (aqui uma cor única) a cada nível único da variável (cada uma das três espécies), um processo conhecido como dimensionamento. O ggplot2 também adicionará uma legenda que explica quais valores correspondem a quais níveis.\nAgora vamos adicionar mais uma camada: uma curva suave que exibe a relação entre a massa corporal e o comprimento das nadadeiras. Antes de prosseguir, consulte o código acima e pense em como podemos adicionar isso ao nosso gráfico existente.\nComo essa é uma nova geometria que representa nossos dados, adicionaremos uma nova geometria como uma camada sobre o nossa geometria de pontos: geom_smooth(). E especificaremos que queremos desenhar a linha de melhor ajuste com base em um modelo linear (linear model em inglês) com method = \"lm\".\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal, color = especie)\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nAdicionamos linhas com sucesso, mas esse gráfico não se parece com o gráfico do Seção 1.2.2, que tem apenas uma linha para todo o conjunto de dados, em vez de linhas separadas para cada espécie de pinguim.\nQuando os mapeamentos estéticos são definidos em ggplot(), no nível global, eles são passados para cada uma das camadas de geometria (geom) subsequentes do gráfico. Entretanto, cada função geom no ggplot2 também pode receber um argumento mapping, que permite mapeamentos estéticos em nível local que são adicionados àqueles herdados do nível global. Como queremos que os pontos sejam coloridos com base na espécie, mas não queremos que as linhas sejam separadas para eles, devemos especificar color = especie somente para geom_point().\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n) +\n  geom_point(mapping = aes(color = especie)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nPronto! Temos algo que se parece muito com nosso objetivo final, embora ainda não esteja perfeito. Ainda precisamos usar formas diferentes para cada espécie de pinguim e melhorar os rótulos.\nGeralmente, não é uma boa ideia representar informações usando apenas cores em um gráfico, pois as pessoas percebem as cores de forma diferente devido ao daltonismo ou a outras diferenças de visão de cores. Portanto, além da cor, também podemos mapear especie para a estética shape (forma).\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n) +\n  geom_point(mapping = aes(color = especie, shape = especie)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\nObserve que a legenda também é atualizada automaticamente para refletir as diferentes formas dos pontos.\nE, finalmente, podemos melhorar os rótulos do nosso gráfico usando a função labs() em uma nova camada. Alguns dos argumentos de labs() podem ser autoexplicativos: title adiciona um título e subtitle adiciona um subtítulo ao gráfico. Outros argumentos correspondem aos mapeamentos estéticos, x é o rótulo do eixo x, y é o rótulo do eixo y e color e shape definem o rótulo da legenda. Além disso, podemos aprimorar a paleta de cores para que seja segura para pessoas com daltonismo com a função scale_color_colorblind() do pacote ggthemes.\n\nggplot(pinguins, aes(x = comprimento_nadadeira, y = massa_corporal)) +\n  geom_point(aes(color = especie, shape = especie)) +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Massa corporal e comprimento da nadadeira\",\n    subtitle = \"Medidas para Pinguim-de-adélia, Pinguim-de-barbicha e Pinguim-gentoo\",\n    x = \"Comprimento da nadadeira (mm)\",\n    y = \"Massa corporal (g)\",\n    color = \"Espécie\",\n    shape = \"Espécie\"\n  ) +\n  scale_color_colorblind()\n\n\n\n\n\n\n\nFinalmente temos um gráfico que corresponde perfeitamente ao nosso “objetivo final”!\n\n1.2.5 Exercícios\n\nQuantas linhas existem em pinguins? E quantas colunas?\nO que a variável profundidade_bico no data frame pinguins descreve? Leia a documentação da base pinguins para descobrir, utilizando o comando ?pinguins .\nFaça um gráfico de dispersão de profundidade_bico em função de comprimento_bico. Ou seja, faça um gráfico de dispersão com profundidade_bico no eixo y e comprimento_bico no eixo x. Descreva a relação entre essas duas variáveis.\nO que acontece se você fizer um gráfico de dispersão de especie em função de profundidade_bico? Qual seria uma melhor escolha de geometria (geom)?\nPor que o seguinte erro ocorre e como você poderia corrigi-lo?\n\n\nggplot(data = pinguins) + \n  geom_point()\n\n\nO que o argumento na.rm faz em geom_point()? Qual é o valor padrão do argumento? Crie um gráfico de dispersão em que você use esse argumento definido como TRUE (verdadeiro).\nAdicione a seguinte legenda ao gráfico que você criou no exercício anterior: “Os dados são provenientes do pacote dados”. Dica: dê uma olhada na documentação da função labs().\nRecrie a visualização a seguir. Para qual atributo estético profundidade_bico deve ser mapeada? E ela deve ser mapeada no nível global ou no nível da geometria?\n\n\n\n\n\n\n\n\n\n\nExecute esse código em sua mente e preveja como será o resultado. Em seguida, execute o código no R e verifique suas previsões.\n\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal, color = ilha)\n) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\nEsses dois gráficos serão diferentes? Por que sim ou por que não?\n\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n) +\n  geom_point() +\n  geom_smooth()\n\nggplot() +\n  geom_point(\n    data = pinguins,\n    mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n  ) +\n  geom_smooth(\n    data = pinguins,\n    mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n  )",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggplot2-calls",
    "href": "data-visualize.html#sec-ggplot2-calls",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.3 Chamadas ggplot2",
    "text": "1.3 Chamadas ggplot2\nÀ medida que passarmos dessas seções introdutórias, faremos a transição para uma expressão mais concisa do código do ggplot2. Até agora, temos sido muito explícitos, o que é útil quando se está aprendendo:\n\nggplot(\n  data = pinguins,\n  mapping = aes(x = comprimento_nadadeira, y = massa_corporal)\n) +\n  geom_point()\n\nNormalmente, o primeiro ou os dois primeiros argumentos de uma função são tão importantes que você logo saberá usar eles de cor. Os dois primeiros argumentos de ggplot() são data e mapping; no restante do livro, não escreveremos esses nomes. Isso economiza digitação e, ao reduzir a quantidade de texto extra, facilita a visualização das diferenças entre os gráficos. Essa é uma preocupação de programação realmente importante, à qual voltaremos em Capítulo 25.\nReescrevendo o gráfico anterior de forma mais concisa, temos:\n\nggplot(pinguins, aes(x = comprimento_nadadeira, y = massa_corporal)) +\n  geom_point()\n\nNo futuro, você também aprenderá sobre o pipe (encadeamento), |&gt;, que permitirá que você crie esse gráfico com a seguinte sintaxe:\n\npinguins |&gt; \n  ggplot(aes(x = comprimento_nadadeira, y = massa_corporal)) + \n  geom_point()",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#visualizando-distribuições",
    "href": "data-visualize.html#visualizando-distribuições",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.4 Visualizando distribuições",
    "text": "1.4 Visualizando distribuições\nA forma como você visualiza a distribuição de uma variável depende do tipo de variável: categórica ou numérica.\n\n1.4.1 Uma variável categórica\nUma variável é categórica se puder assumir apenas um valor de um pequeno conjunto de valores. Para examinar a distribuição de uma variável categórica, você pode usar um gráfico de barras. A altura das barras exibe quantas observações ocorreram com cada valor x.\n\nggplot(pinguins, aes(x = especie)) +\n  geom_bar()\n\n\n\n\n\n\n\nEm gráficos de barras de variáveis categóricas com níveis não ordenados, como a especie de pinguim acima, geralmente é preferível reordenar as barras com base em suas frequências. Para isso, é necessário transformar a variável em um fator (como o R lida com dados categóricos) e, em seguida, reordenar os níveis desse fator.\n\nggplot(pinguins, aes(x = fct_infreq(especie))) +\n  geom_bar()\n\n\n\n\n\n\n\nVocê aprenderá mais sobre fatores e funções para lidar com fatores (como fct_infreq() mostrado acima) em Capítulo 16.\n\n1.4.2 Uma variável numérica\nUma variável é numérica (ou quantitativa) se puder assumir uma ampla gama de valores numéricos e se for possível adicionar, subtrair ou calcular médias com esses valores. As variáveis numéricas podem ser contínuas ou discretas.\nUma visualização comumente usada para distribuições de variáveis contínuas é um histograma.\n\nggplot(pinguins, aes(x = massa_corporal)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\n\n\n\nUm histograma divide o eixo x em intervalos igualmente espaçados e, em seguida, usa a altura de uma barra para exibir o número de observações que se enquadram em cada intervalo. No gráfico acima, a barra mais alta mostra que 39 observações têm um valor massa_corporal entre 3500 e 3700 gramas, que são as bordas esquerda e direita da barra.\nVocê pode definir a largura dos intervalos em um histograma com o argumento binwidth (largura do intervalo), que é medido nas unidades da variável x. Você deve sempre explorar uma variedade de larguras de intervalos ao trabalhar com histogramas, pois diferentes larguras de intervalos podem revelar padrões diferentes. Nos gráficos abaixo, uma largura de intervalo de 20 é muito estreita, resultando em muitas barras, o que dificulta a determinação da forma da distribuição. Da mesma forma, uma largura de intervalo de 2000 é muito alta, resultando em todos os dados sendo agrupados em apenas três barras, o que também dificulta a determinação da forma da distribuição. Uma largura de intervalo de 200 proporciona um balanço mais adequado.\nggplot(pinguins, aes(x = massa_corporal)) +\n  geom_histogram(binwidth = 20)\nggplot(pinguins, aes(x = massa_corporal)) +\n  geom_histogram(binwidth = 2000)\n\n\n\n\n\n\n\n\n\n\nUma visualização alternativa para distribuições de variáveis numéricas é um gráfico de densidade. Um gráfico de densidade é uma versão suavizada de um histograma e uma alternativa prática, especialmente para dados contínuos provenientes de uma distribuição suavizada subjacente. Não entraremos em detalhes sobre como geom_density() estima a densidade (você pode ler mais sobre isso na documentação da função), mas vamos explicar como a curva de densidade é desenhada com uma analogia. Imagine um histograma feito de blocos de madeira. Em seguida, imagine que você jogue um fio de espaguete cozido sobre ele. A forma que o espaguete assumirá sobre os blocos pode ser considerada como a forma da curva de densidade. Ela mostra menos detalhes do que um histograma, mas pode facilitar a obtenção rápida da forma da distribuição, principalmente com relação à moda (valor que ocorre com maior frequência) e à assimetria.\n\nggplot(pinguins, aes(x = massa_corporal)) +\n  geom_density()\n#&gt; Warning: Removed 2 rows containing non-finite outside the scale range\n#&gt; (`stat_density()`).\n\n\n\n\n\n\n\n\n1.4.3 Exercícios\n\nFaça um gráfico de barras de especie de pinguins, no qual você atribui especie ao atributo estético y. Como esse gráfico é diferente?\nComo os dois gráficos a seguir são diferentes? Qual atributo estético, color ou fill, é mais útil para alterar a cor das barras?\n\n\nggplot(pinguins, aes(x = especie)) +\n  geom_bar(color = \"red\")\n\nggplot(pinguins, aes(x = especie)) +\n  geom_bar(fill = \"red\")\n\n\nO que o argumento bins em geom_histogram() faz?\nFaça um histograma da variável quilate no conjunto de dados diamante que está disponível quando você carrega o pacote dados. Faça experiências com diferentes larguras de intervalo (binwidth). Qual largura de intervalo revela os padrões mais interessantes?",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#visualizando-relações",
    "href": "data-visualize.html#visualizando-relações",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.5 Visualizando relações",
    "text": "1.5 Visualizando relações\nPara visualizar uma relação, precisamos ter pelo menos duas variáveis mapeadas para os atributos estéticos de um gráfico. Nas seções a seguir, você aprenderá sobre os gráficos comumente usados para visualizar relações entre duas ou mais variáveis e as geometrias usados para criá-los.\n\n1.5.1 Uma variável numérica e uma variável categórica\nPara visualizar a relação entre uma variável numérica e uma variável categórica, podemos usar diagramas de caixa (chamados boxplots) lado a lado. Um boxplot é um tipo de abreviação visual para medidas de posição (percentis) que descrevem uma distribuição. Também é útil para identificar possíveis outliers. Conforme mostrado em Figura 1.1, cada boxplot consiste em:\n\nUma caixa que indica o intervalo da metade intermediária dos dados, uma distância conhecida como intervalo interquartil (IIQ), que se estende do 25º percentil da distribuição até o 75º percentil. No meio da caixa há uma linha que exibe a mediana, ou seja, o 50º percentil, da distribuição. Essas três linhas lhe dão uma noção da dispersão da distribuição e se a distribuição é ou não simétrica em relação à mediana ou inclinada para um lado.\nPontos que apresentam observações com valores maiores que 1,5 vezes o IIQ de qualquer borda da caixa. Esses pontos discrepantes são incomuns e, por isso, são plotados individualmente.\nUma linha que se estende de cada extremidade da caixa e vai até o ponto mais distante (sem considerar os valores discrepantes - outliers) na distribuição.\n\n\n\n\n\n\n\n\nFigura 1.1: Diagrama mostrando como um boxplot é criado.\n\n\n\n\nVamos dar uma olhada na distribuição da massa corporal por espécie usando geom_boxplot():\n\nggplot(pinguins, aes(x = especie, y = massa_corporal)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nComo alternativa, podemos criar gráficos de densidade com geom_density().\n\nggplot(pinguins, aes(x = massa_corporal, color = especie)) +\n  geom_density(linewidth = 0.75)\n\n\n\n\n\n\n\nTambém personalizamos a espessura das linhas usando o argumento linewidth para que elas se destaquem um pouco mais contra o plano de fundo.\nAlém disso, podemos mapear especie para os atributos estéticos color e fill e usar o atributo alpha para adicionar transparência às curvas de densidade preenchidas. Esse atributo assume valores entre 0 (completamente transparente) e 1 (completamente opaco). No gráfico a seguir, ela está definida como 0.5.\n\nggplot(pinguins, aes(x = massa_corporal, color = especie, fill = especie)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\nObserve a terminologia que usamos aqui:\n\nNós mapeamos variáveis para atributos estéticos se quisermos que o atributo visual representado por esse atributo varie de acordo com os valores dessa variável.\nCaso contrário, nós definimos o valor de um atributo estético.\n\n1.5.2 Duas variáveis categóricas\nPodemos usar gráficos de barras empilhadas para visualizar a relação entre duas variáveis categóricas. Por exemplo, os dois gráficos de barras empilhadas a seguir exibem a relação entre ilha e espécie ou, especificamente, a visualização da distribuição de espécie em cada ilha.\nO primeiro gráfico mostra as frequências de cada espécie de pinguim em cada ilha. O gráfico de frequências mostra que há um número igual de Pinguim-de-adélia em cada ilha. Mas não temos uma boa noção do equilíbrio percentual em cada ilha.\n\nggplot(pinguins, aes(x = ilha, fill = especie)) +\n  geom_bar()\n\n\n\n\n\n\n\nO segundo gráfico é um gráfico de frequência relativa, criado pela definição de position = \"fill\" na geometria, que é mais útil para comparar as distribuições de espécies entre as ilhas, pois não é afetado pelo número desigual de pinguins entre as ilhas. Usando esse gráfico, podemos ver que todos os Pinguim-gentoo vivem na ilha Biscoe e constituem aproximadamente 75% dos pinguins dessa ilha, todos os Pinguim-de-barbicha vivem na ilha Dream e constituem aproximadamente 50% dos pinguins dessa ilha, e os Pinguim-de-adélia vivem nas três ilhas e constituem todos os pinguins da ilha Torgersen.\n\nggplot(pinguins, aes(x = ilha, fill = especie)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nAo criar esses gráficos de barras, mapeamos a variável que será separada em barras para o atributo estético x e a variável que mudará as cores dentro das barras para a estética fill.\n\n1.5.3 Duas variáveis numéricas\nAté agora, você aprendeu sobre gráficos de dispersão (criados com geom_point()) e curvas suaves (criadas com geom_smooth()) para visualizar a relação entre duas variáveis numéricas. Um gráfico de dispersão é provavelmente o gráfico mais usado para visualizar a relação entre duas variáveis numéricas.\n\nggplot(pinguins, aes(x = comprimento_nadadeira, y = massa_corporal)) +\n  geom_point()\n\n\n\n\n\n\n\n\n1.5.4 Três ou mais variáveis\nComo vimos em Seção 1.2.4, podemos incorporar mais variáveis em um gráfico mapeando-as para atributos estéticos adicionais. Por exemplo, no gráfico de dispersão a seguir, as cores dos pontos (color) representam espécies e as formas dos pontos (shape) representam ilhas.\n\nggplot(pinguins, aes(x = comprimento_nadadeira, y = massa_corporal)) +\n  geom_point(aes(color = especie, shape = ilha))\n\n\n\n\n\n\n\nNo entanto, mapear muitos atributos estéticos a um gráfico faz com que ele fique desordenado e difícil de entender. Outra maneira, que é particularmente útil para variáveis categóricas, é dividir seu gráfico em facetas (facets), subdivisões ou janelas que exibem um subconjunto dos dados cada uma.\nPara separar seu gráfico em facetas por uma única variável, use facet_wrap(). O primeiro argumento de facet_wrap() é uma fórmula3, que você cria com ~ seguido do nome de uma variável. A variável que você passa para facet_wrap() deve ser categórica.\n\nggplot(pinguins, aes(x = comprimento_nadadeira, y = massa_corporal)) +\n  geom_point(aes(color = especie, shape = especie)) +\n  facet_wrap(~ilha)\n\n\n\n\n\n\n\nVocê vai aprender sobre muitas outras geometrias para visualizar distribuições de variáveis e relações entre elas em Capítulo 9.\n\n1.5.5 Exercícios\n\nO data frame milhas que acompanha o pacote dados contém observações 234 coletadas pela Agência de Proteção Ambiental dos EUA em modelos de 38 carros. Quais variáveis em milhas são categóricas? Quais variáveis são numéricas? (Dica: digite ?milhas para ler a documentação do conjunto de dados.) Como você pode ver essas informações ao executar milhas?\nFaça um gráfico de dispersão de rodovia (Milhas rodoviárias por galão) em função de cilindrada usando o data frame milhas. Em seguida, mapeie uma terceira variável numérica para color (cor), depois size (tamanho), depois igualmente para color e size e, por fim, shape (forma). Como esses atributos estéticos se comportam de forma diferente para variáveis categóricas e numéricas?\nNo gráfico de dispersão de rodovia vs. cilindrada, o que acontece se você mapear uma terceira variável para linewidth (espessura da linha)?\nO que acontece se você mapear a mesma variável para várias atributos estéticos?\nFaça um gráfico de dispersão de profundidade_bico vs. comprimento_bico e pinte os pontos por especie. O que a adição da coloração por especie revela sobre a relação entre essas duas variáveis? E quanto à separação em facetas por especie?\nPor que o seguinte código produz duas legendas separadas? Como você corrigiria isso para combinar as duas legendas?\n\n\nggplot(\n  data = pinguins,\n  mapping = aes(\n    x = comprimento_bico, y = profundidade_bico, \n    color = especie, shape = especie\n  )\n) +\n  geom_point() +\n  labs(color = \"Especies\")\n\n\nCrie os dois gráficos de barras empilhadas a seguir. Que pergunta você pode responder com o primeiro? Que pergunta você pode responder com o segundo?\n\n\nggplot(pinguins, aes(x = ilha, fill = especie)) +\n  geom_bar(position = \"fill\")\nggplot(pinguins, aes(x = especie, fill = ilha)) +\n  geom_bar(position = \"fill\")",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#sec-ggsave",
    "href": "data-visualize.html#sec-ggsave",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.6 Salvando seus gráficos",
    "text": "1.6 Salvando seus gráficos\nDepois de criar um gráfico, talvez você queira tirá-lo do R salvando-o como uma imagem que possa ser usada em outro lugar. Esse é o objetivo da função ggsave(), que salvará no computador o gráfico criado mais recentemente:\n\nggplot(pinguins, aes(x = comprimento_nadadeira, y = massa_corporal)) +\n  geom_point()\nggsave(filename = \"penguin-plot.png\")\n\nIsso salvará o gráfico no seu diretório de trabalho, um conceito sobre o qual você aprenderá mais em Capítulo 6.\nSe você não especificar a largura width e a altura height, elas serão tiradas das dimensões do dispositivo de plotagem atual. Para obter um código reprodutível, você deverá especificá-los. Você pode obter mais informações sobre a função ggsave() na documentação.\nDe modo geral, entretanto, recomendamos que você monte seus relatórios finais usando o Quarto, um sistema de escrita reprodutível que permite intercalar seu código e sua escrita e incluir automaticamente seus gráficos em seus relatórios. Você aprenderá mais sobre o Quarto em Capítulo 28.\n\n1.6.1 Exercícios\n\nExecute as seguintes linhas de código. Qual dos dois gráficos é salvo como grafico-milhas.png? Por quê?\n\n\nggplot(milhas, aes(x = classe)) +\n  geom_bar()\nggplot(milhas, aes(x = cidade, y = rodovia)) +\n  geom_point()\nggsave(\"grafico-milhas.png\")\n\n\nO que você precisa alterar no código acima para salvar o gráfico como PDF em vez de PNG? Como você poderia descobrir quais tipos de arquivos de imagem funcionariam em ggsave()?",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#problemas-comuns",
    "href": "data-visualize.html#problemas-comuns",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.7 Problemas comuns",
    "text": "1.7 Problemas comuns\nAo começar a executar o código em R, é provável que você encontre problemas. Não se preocupe, isso acontece com todo mundo. Todos nós estamos escrevendo código em R há anos, mas todos os dias ainda escrevemos códigos que não funcionam na primeira tentativa!\nComece comparando cuidadosamente o código que está executando com o código do livro. O R é extremamente exigente, e um caractere mal colocado pode fazer toda a diferença. Certifique-se de que cada ( seja combinado com um ) e que cada \" seja combinado com outra \". Às vezes, você executará o código e nada acontecerá. Verifique o lado esquerdo do console: se houver um +, isso significa que o R acha que você não digitou uma expressão completa e está esperando que você a termine. Nesse caso, geralmente é fácil começar do zero novamente pressionando Esc para interromper o processamento do comando atual.\nUm problema comum ao criar gráficos ggplot2 é colocar o + no lugar errado: ele deve vir no final da linha, não no início. Em outras palavras, certifique-se de não ter escrito acidentalmente um código como este:\n\nggplot(data = milhas) \n+ geom_point(mapping = aes(x = cilindrada, y = rodovia))\n\nSe você ainda estiver com dificuldades, tente a ajuda (painel Help). Você pode obter ajuda sobre qualquer função do R executando ?nome_da_função no console ou selecionando o nome da função e pressionando F1 no RStudio. Não se preocupe se a ajuda não parecer muito útil - em vez disso, pule para os exemplos e procure um código que corresponda ao que você está tentando fazer.\nSe isso não ajudar, leia atentamente a mensagem de erro. Às vezes, a resposta estará escondida lá! Mas quando você é iniciante no R, mesmo que a resposta esteja na mensagem de erro, talvez você ainda não saiba como entendê-la. Outra ferramenta excelente é o Google: tente pesquisar a mensagem de erro no Google, pois é provável que outra pessoa tenha tido o mesmo problema e tenha obtido ajuda on-line.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#resumo",
    "href": "data-visualize.html#resumo",
    "title": "1  ✅ Visualização de dados",
    "section": "\n1.8 Resumo",
    "text": "1.8 Resumo\nNeste capítulo, você aprendeu os fundamentos da visualização de dados com o ggplot2. Começamos com a ideia básica que sustenta o ggplot2: uma visualização é um mapeamento de variáveis em seus dados para atributos estéticos como posição (position), cor (color), tamanho (size) e forma (shape). Em seguida, você aprendeu a aumentar a complexidade e melhorar a apresentação de seus gráficos camada por camada. Você também aprendeu sobre gráficos comumente usados para visualizar a distribuição de uma única variável, bem como para visualizar relações entre duas ou mais variáveis ao utilizar mapeamentos de atributos estéticos adicionais e/ou dividindo seu gráfico em pequenos gráficos usando facetas.\nUsaremos as visualizações repetidamente ao longo deste livro, introduzindo novas técnicas à medida que precisarmos delas, além de nos aprofundarmos na criação de visualizações com o ggplot2 em Capítulo 9 por meio da Capítulo 11.\nCom as noções básicas de visualização em seu currículo, no próximo capítulo mudaremos um pouco a direção e daremos algumas orientações práticas sobre o fluxo de trabalho. Intercalamos conselhos sobre fluxo de trabalho com ferramentas de ciência de dados ao longo desta parte do livro, pois isso te ajudará a manter a organização à medida que você escreve quantidades cada vez maiores de código em R.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "data-visualize.html#footnotes",
    "href": "data-visualize.html#footnotes",
    "title": "1  ✅ Visualização de dados",
    "section": "",
    "text": "Você pode eliminar essa mensagem e forçar com que a resolução de conflitos aconteça sob demanda utilizando o pacote conflicted, que se torna mais importante à medida que carrega mais pacotes. Você pode ler mais sobre o pacote conflicted no endereço https://conflicted.r-lib.org.↩︎\nHorst AM, Hill AP, Gorman KB (2020). palmerpinguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpinguins/. doi: 10.5281/zenodo.3960218.↩︎\nAqui “fórmula” é o nome da coisa criada por ~, não um sinônimo de “equação”.↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>✅ Visualização de dados</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html",
    "href": "workflow-basics.html",
    "title": "2  ✅ Fluxo de Trabalho: básico",
    "section": "",
    "text": "2.1 Princípios básicos de programação\nVamos revisar alguns conceitos básicos que omitimos até agora, no interesse de fazer você plotar gráficos o mais rápido possível. Você pode usar o R para fazer cálculos matemáticos básicos:\n1 / 200 * 30\n#&gt; [1] 0.15\n(59 + 73 + 2) / 3\n#&gt; [1] 44.66667\nsin(pi / 2)\n#&gt; [1] 1\nVocê pode criar novos objetos com o operador de atribuição &lt;-:\nx &lt;- 3 * 4\nNote que o valor de x não é impresso, ele é apenas armazenado. Se você quiser ver o valor, digite x no console.\nVocê pode combinar vários elementos em um vetor com c():\nprimos &lt;- c(2, 3, 5, 7, 11, 13)\nE a aritmética básica em vetores é aplicada a cada elemento do vetor:\nprimos * 2\n#&gt; [1]  4  6 10 14 22 26\nprimos - 1\n#&gt; [1]  1  2  4  6 10 12\nTodos os comandos em R onde que você cria objetos, comandos de atribuição, têm a mesma forma:\nnome_objeto &lt;- valor\nQuando ler esse código, diga “nome do objeto recebe valor” na sua cabeça.\nVocê fará muitas atribuições, e &lt;- não é simples de digitar. Você pode economizar algum tempo com o atalho do teclado do RStudio: Alt + - (o sinal de menos). Observe que o RStudio automaticamente coloca espaços em torno de &lt;-, o que é uma boa prática de formatação de código. Ler código pode ser desafiador até mesmo nos seus melhores dias, então dê um descanso para seus olhos e utilize espaços.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✅ Fluxo de Trabalho: básico</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#comentários",
    "href": "workflow-basics.html#comentários",
    "title": "2  ✅ Fluxo de Trabalho: básico",
    "section": "\n2.2 Comentários",
    "text": "2.2 Comentários\nO R ignorará qualquer texto após # em uma linha. Isso permite que você escreva comentários, que são textos que são ignorados pelo R, mas que podem ser lidos por outros humanos. Às vezes, incluiremos comentários nos exemplos explicando o que está acontecendo com o código.\nComentários podem ser úteis para descrever brevemente o que o código a seguir faz.\n\n# cria um vetor de números primos\nprimos &lt;- c(2, 3, 5, 7, 11, 13)\n\n# multiplica primos por 2\nprimos * 2\n#&gt; [1]  4  6 10 14 22 26\n\nEm pequenos trechos de código como este, deixar um comentário para cada linha de código pode não ser necessário. Mas, à medida que o código que você está escrevendo fica mais complexo, os comentários podem economizar muito tempo seu (e das pessoas que colaboram com você) para descobrir o que foi feito no código.\nUse comentários para explicar o porquê do seu código, não o como ou o o quê. O o quê e o como do seu código são sempre possíveis de descobrir lendo-os cuidadosamente, mesmo que isso possa ser chato. Se você descrever cada etapa nos comentários e, em seguida alterar o código, terá que se lembrar de atualizar os comentários também, caso contrário, será confuso quando você retornar ao seu código no futuro.\nDescobrir por que algo foi feito é muito mais difícil, senão impossível. Por exemplo, geom_smooth() tem um argumento chamado span, que controla a suavidade da curva (smoothness), com valores maiores produzindo uma curva mais suave. Suponha que você decida alterar o valor de span de seu padrão de 0.75 para 0.9: é fácil para alguém que está lendo no futuro entender o que está acontecendo, mas a menos que você anote seu pensamento em um comentário, ninguém entenderá o por que de você ter alterado o padrão.\nPara código de análise de dados, use comentários para explicar sua abordagem estratégica e registrar informações importantes à medida que as encontrar. Não há como recuperar esse conhecimento do próprio código sem comentários.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✅ Fluxo de Trabalho: básico</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#sec-whats-in-a-name",
    "href": "workflow-basics.html#sec-whats-in-a-name",
    "title": "2  ✅ Fluxo de Trabalho: básico",
    "section": "\n2.3 A importância dos nomes",
    "text": "2.3 A importância dos nomes\nNomes de objetos devem começar com uma letra e só podem conter letras, números, _ e .. Você quer que os nomes dos seus objetos sejam descritivos, então você precisará adotar uma convenção para várias palavras. Recomendamos snake_case, onde você separa palavras minúsculas com _.\n\neu_uso_snake_case\noutrasPessoasUsamCamelCase\nalgumas.pessoas.usam.pontos\nE_aLgumas.Pessoas_nAoUsamConvencao\n\nVamos voltar aos nomes quando discutirmos o estilo de código no Capítulo 4.\nVocê pode ver o conteúdo de um objeto (chamaremos isso de inspecionar) digitando seu nome:\n\nx\n#&gt; [1] 12\n\nFazendo outra atribuição:\n\nesse_e_um_nome_bem_longo &lt;- 2.5\n\nPara inspecionar esse objeto, experimente o recurso de autocompletar (autocomplete) do RStudio: digite “esse”, pressione TAB, adicione caracteres até ter um prefixo único e pressione enter.\nVamos supor que você cometeu um erro e que o valor de esse_e_um_nome_bem_longo deveria ser 3.5, não 2.5. Você pode usar outro atalho de teclado para te ajudar a corrigi-lo. Por exemplo, você pode pressionar ↑ para recuperar o último comando que você digitou e editá-lo. Ou, digite “esse” e pressione Cmd/Ctrl + ↑ para listar todos os comandos que você digitou que começam com essas letras. Use as setas para navegar e, em seguida, pressione enter para digitar novamente o comando. Altere 2.5 para 3.5 e execute novamente.\nFazendo mais uma atribuição:\n\nr_rocks &lt;- 2^3\n\nVamos tentar inspecioná-lo:\n\nr_rock\n#&gt; Error: object 'r_rock' not found\nR_rocks\n#&gt; Error: object 'R_rocks' not found\n\nIsso ilustra o contrato implícito entre você e o R: o R fará os cálculos chatos para você, mas em troca, você deve ser escrever suas instruções de forma precisa. Se não, você provavelmente receberá um erro que diz que o objeto que você está procurando não foi encontrado. Erros de digitação importam; o R não pode ler sua mente e dizer: “ah, você provavelmente quis dizer r_rocks quando digitou r_rock”. A caixa alta (letras maiúsculas) importa; da mesma forma, o R não pode ler sua mente e dizer: “ah, você provavelmente quis dizer r_rocks quando digitou R_rocks”.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✅ Fluxo de Trabalho: básico</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#chamando-funções",
    "href": "workflow-basics.html#chamando-funções",
    "title": "2  ✅ Fluxo de Trabalho: básico",
    "section": "\n2.4 Chamando funções",
    "text": "2.4 Chamando funções\nO R tem uma grande coleção de funções embutidas que são chamadas assim:\n\nnome_da_funcao(argumento1 = valor1, argumento2 = valor2, ...)\n\nVamos tentar usar seq(), que faz sequências regulares de números, e enquanto fazemos nisso, vamos aprender mais sobre os recursos do RStudio. Digite se e pressione TAB. Uma janela pop-up mostra as possíveis formas de completar o código. Especifique seq() digitando mais (um q) para especificar ou usando as setas ↑/↓ para selecionar. Observe a janelinha que aparece, mostrando os argumentos e o objetivo da função. Se você quiser mais ajuda, pressione F1 para obter todos os detalhes no painel ajuda (Help) na parte inferior direita.\nQuando você selecionar a função que deseja, pressione TAB novamente. O RStudio adicionará os parênteses de abertura (() e fechamento ()) correspondentes para você automaticamente. Digite o nome do primeiro argumento, from, e defina-o como 1. Em seguida, digite o nome do segundo argumento, to, e defina-o como 10. Por último, pressione enter.\n\nseq(from = 1, to = 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nNormalmente omitimos os nomes dos primeiros argumentos em chamadas de função, assim podemos reescrever isso da seguinte forma:\n\nseq(1, 10)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\nDigite o código a seguir e veja que o RStudio fornece assistência semelhante com as aspas em pares:\n\nx &lt;- \"olá mundo\"\n\nAs aspas e parênteses devem sempre vir em pares. O RStudio faz o melhor para te ajudar, mas ainda é possível cometer um erro e acabar com aspas não fechadas. Se isso acontecer, o console do R mostrará o caractere de continuação “+”:\n&gt; x &lt;- \"olá\n+\nO + indica que o R está esperando mais alguma entrada (input); ele acha que você ainda não terminou de digitar. Normalmente, isso significa que você esqueceu de adicionar um \" ou um ). Adicione o par que está faltando ou pressione ESCAPE (ou ESC) para cancelar a expressão e tentar novamente.\nObserve que o painel ambiente (Environment) no painel superior direito exibe todos os objetos que você criou:",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✅ Fluxo de Trabalho: básico</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#exercícios",
    "href": "workflow-basics.html#exercícios",
    "title": "2  ✅ Fluxo de Trabalho: básico",
    "section": "\n2.5 Exercícios",
    "text": "2.5 Exercícios\n\n\nPor que esse código não funciona?\n\nminha_variavel &lt;- 10\nminha_varıavel\n#&gt; Error in eval(expr, envir, enclos): object 'minha_varıavel' not found\n\nOlhe com atenção! (Isso pode parecer um exercício sem sentido, mas treinar seu cérebro para notar até a menor diferença valerá a pena quando você estiver programando.)\n\n\nAltere cada um dos seguintes comandos R para que eles sejam executados corretamente:\n\nlibary(todyverse)\nlibary(dados)\n\nggplot(dTA = milhas) + \n  geom_point(maping = aes(x = cilindrada y = rodovia)) +\n  geom_smooth(method = \"lm)\n\n\nPressione Option + Shift + K / Alt + Shift + K. O que acontece? Como você pode chegar ao mesmo lugar usando os menus?\n\nVamos revisitar um exercício da Seção 1.6. Rode as seguintes linhas de código. Qual dos dois gráficos é salvo como mpg-plot.png? Por quê?\n\nmeu_grafico_de_barras &lt;- ggplot(milhas, aes(x = classe)) +\n  geom_bar()\nmeu_grafico_de_dispersao &lt;- ggplot(milhas, aes(x = cidade, y = rodovia)) +\n  geom_point()\nggsave(filename = \"milhas-plot.png\", plot = meu_grafico_de_barras)",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✅ Fluxo de Trabalho: básico</span>"
    ]
  },
  {
    "objectID": "workflow-basics.html#sumário",
    "href": "workflow-basics.html#sumário",
    "title": "2  ✅ Fluxo de Trabalho: básico",
    "section": "\n2.6 Sumário",
    "text": "2.6 Sumário\nNesse capítulo você aprendeu um pouco mais sobre como o código R funciona e algumas dicas para te ajudar a entender seu código quando você voltar a ele no futuro. No próximo capítulo, continuaremos sua jornada de ciência de dados, ensinando-o sobre o dplyr, o pacote tidyverse que ajuda você a transformar dados, seja selecionando variáveis importantes, filtrando as linhas de interesse ou calculando estatísticas resumidas.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>✅ Fluxo de Trabalho: básico</span>"
    ]
  },
  {
    "objectID": "data-transform.html",
    "href": "data-transform.html",
    "title": "3  Data transformation",
    "section": "",
    "text": "3.1 Introduction\nVisualization is an important tool for generating insight, but it’s rare that you get the data in exactly the right form you need to make the graph you want. Often you’ll need to create some new variables or summaries to answer your questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with. You’ll learn how to do all that (and more!) in this chapter, which will introduce you to data transformation using the dplyr package and a new dataset on flights that departed from New York City in 2013.\nThe goal of this chapter is to give you an overview of all the key tools for transforming a data frame. We’ll start with functions that operate on rows and then columns of a data frame, then circle back to talk more about the pipe, an important tool that you use to combine verbs. We will then introduce the ability to work with groups. We will end the chapter with a case study that showcases these functions in action and we’ll come back to the functions in more detail in later chapters, as we start to dig into specific types of data (e.g., numbers, strings, dates).",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#introduction",
    "href": "data-transform.html#introduction",
    "title": "3  Data transformation",
    "section": "",
    "text": "3.1.1 Prerequisites\nIn this chapter we’ll focus on the dplyr package, another core member of the tidyverse. We’ll illustrate the key ideas using data from the nycflights13 package, and use ggplot2 to help us understand the data.\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4.9000     ✔ readr     2.1.5     \n#&gt; ✔ forcats   1.0.0          ✔ stringr   1.5.1     \n#&gt; ✔ ggplot2   3.5.0          ✔ tibble    3.2.1     \n#&gt; ✔ lubridate 1.9.3          ✔ tidyr     1.3.1     \n#&gt; ✔ purrr     1.0.2          \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nTake careful note of the conflicts message that’s printed when you load the tidyverse. It tells you that dplyr overwrites some functions in base R. If you want to use the base version of these functions after loading dplyr, you’ll need to use their full names: stats::filter() and stats::lag(). So far we’ve mostly ignored which package a function comes from because most of the time it doesn’t matter. However, knowing the package can help you find help and find related functions, so when we need to be precise about which package a function comes from, we’ll use the same syntax as R: packagename::functionname().\n\n3.1.2 nycflights13\nTo explore the basic dplyr verbs, we’re going to use nycflights13::flights. This dataset contains all 336,776 flights that departed from New York City in 2013. The data comes from the US Bureau of Transportation Statistics, and is documented in ?flights.\n\nflights\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights is a tibble, a special type of data frame used by the tidyverse to avoid some common gotchas. The most important difference between tibbles and data frames is the way tibbles print; they are designed for large datasets, so they only show the first few rows and only the columns that fit on one screen. There are a few options to see everything. If you’re using RStudio, the most convenient is probably View(flights), which will open an interactive scrollable and filterable view. Otherwise you can use print(flights, width = Inf) to show all columns, or use glimpse():\n\nglimpse(flights)\n#&gt; Rows: 336,776\n#&gt; Columns: 19\n#&gt; $ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n#&gt; $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 55…\n#&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 60…\n#&gt; $ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2,…\n#&gt; $ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 8…\n#&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 8…\n#&gt; $ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7,…\n#&gt; $ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\"…\n#&gt; $ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301…\n#&gt; $ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N…\n#&gt; $ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LG…\n#&gt; $ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IA…\n#&gt; $ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149…\n#&gt; $ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 73…\n#&gt; $ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6…\n#&gt; $ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59…\n#&gt; $ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-0…\n\nIn both views, the variables names are followed by abbreviations that tell you the type of each variable: &lt;int&gt; is short for integer, &lt;dbl&gt; is short for double (aka real numbers), &lt;chr&gt; for character (aka strings), and &lt;dttm&gt; for date-time. These are important because the operations you can perform on a column depend so much on its “type”.\n\n3.1.3 dplyr basics\nYou’re about to learn the primary dplyr verbs (functions) which will allow you to solve the vast majority of your data manipulation challenges. But before we discuss their individual differences, it’s worth stating what they have in common:\n\nThe first argument is always a data frame.\nThe subsequent arguments typically describe which columns to operate on, using the variable names (without quotes).\nThe output is always a new data frame.\n\nBecause each verb does one thing well, solving complex problems will usually require combining multiple verbs, and we’ll do so with the pipe, |&gt;. We’ll discuss the pipe more in Seção 3.4, but in brief, the pipe takes the thing on its left and passes it along to the function on its right so that x |&gt; f(y) is equivalent to f(x, y), and x |&gt; f(y) |&gt; g(z) is equivalent to g(f(x, y), z). The easiest way to pronounce the pipe is “then”. That makes it possible to get a sense of the following code even though you haven’t yet learned the details:\n\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\ndplyr’s verbs are organized into four groups based on what they operate on: rows, columns, groups, or tables. In the following sections you’ll learn the most important verbs for rows, columns, and groups, then we’ll come back to the join verbs that work on tables in Capítulo 19. Let’s dive in!",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#rows",
    "href": "data-transform.html#rows",
    "title": "3  Data transformation",
    "section": "\n3.2 Rows",
    "text": "3.2 Rows\nThe most important verbs that operate on rows of a dataset are filter(), which changes which rows are present without changing their order, and arrange(), which changes the order of the rows without changing which are present. Both functions only affect the rows, and the columns are left unchanged. We’ll also discuss distinct() which finds rows with unique values but unlike arrange() and filter() it can also optionally modify the columns.\n\n3.2.1 filter()\n\nfilter() allows you to keep rows based on the values of the columns1. The first argument is the data frame. The second and subsequent arguments are the conditions that must be true to keep the row. For example, we could find all flights that departed more than 120 minutes (two hours) late:\n\nflights |&gt; \n  filter(dep_delay &gt; 120)\n#&gt; # A tibble: 9,723 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      848           1835       853     1001           1950\n#&gt; 2  2013     1     1      957            733       144     1056            853\n#&gt; 3  2013     1     1     1114            900       134     1447           1222\n#&gt; 4  2013     1     1     1540           1338       122     2020           1825\n#&gt; 5  2013     1     1     1815           1325       290     2120           1542\n#&gt; 6  2013     1     1     1842           1422       260     1958           1535\n#&gt; # ℹ 9,717 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nAs well as &gt; (greater than), you can use &gt;= (greater than or equal to), &lt; (less than), &lt;= (less than or equal to), == (equal to), and != (not equal to). You can also combine conditions with & or , to indicate “and” (check for both conditions) or with | to indicate “or” (check for either condition):\n\n# Flights that departed on January 1\nflights |&gt; \n  filter(month == 1 & day == 1)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# Flights that departed in January or February\nflights |&gt; \n  filter(month == 1 | month == 2)\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nThere’s a useful shortcut when you’re combining | and ==: %in%. It keeps rows where the variable equals one of the values on the right:\n\n# A shorter way to select flights that departed in January or February\nflights |&gt; \n  filter(month %in% c(1, 2))\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nWe’ll come back to these comparisons and logical operators in more detail in Capítulo 12.\nWhen you run filter() dplyr executes the filtering operation, creating a new data frame, and then prints it. It doesn’t modify the existing flights dataset because dplyr functions never modify their inputs. To save the result, you need to use the assignment operator, &lt;-:\n\njan1 &lt;- flights |&gt; \n  filter(month == 1 & day == 1)\n\n\n3.2.2 Common mistakes\nWhen you’re starting out with R, the easiest mistake to make is to use = instead of == when testing for equality. filter() will let you know when this happens:\n\nflights |&gt; \n  filter(month = 1)\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; ℹ This usually means that you've used `=` instead of `==`.\n#&gt; ℹ Did you mean `month == 1`?\n\nAnother mistakes is you write “or” statements like you would in English:\n\nflights |&gt; \n  filter(month == 1 | 2)\n\nThis “works”, in the sense that it doesn’t throw an error, but it doesn’t do what you want because | first checks the condition month == 1 and then checks the condition 2, which is not a sensible condition to check. We’ll learn more about what’s happening here and why in Seção 15.6.2.\n\n3.2.3 arrange()\n\narrange() changes the order of the rows based on the value of the columns. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns. For example, the following code sorts by the departure time, which is spread over four columns. We get the earliest years first, then within a year the earliest months, etc.\n\nflights |&gt; \n  arrange(year, month, day, dep_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nYou can use desc() on a column inside of arrange() to re-order the data frame based on that column in descending (big-to-small) order. For example, this code orders flights from most to least delayed:\n\nflights |&gt; \n  arrange(desc(dep_delay))\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     9      641            900      1301     1242           1530\n#&gt; 2  2013     6    15     1432           1935      1137     1607           2120\n#&gt; 3  2013     1    10     1121           1635      1126     1239           1810\n#&gt; 4  2013     9    20     1139           1845      1014     1457           2210\n#&gt; 5  2013     7    22      845           1600      1005     1044           1815\n#&gt; 6  2013     4    10     1100           1900       960     1342           2211\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nNote that the number of rows has not changed – we’re only arranging the data, we’re not filtering it.\n\n3.2.4 distinct()\n\ndistinct() finds all the unique rows in a dataset, so in a technical sense, it primarily operates on the rows. Most of the time, however, you’ll want the distinct combination of some variables, so you can also optionally supply column names:\n\n# Remove duplicate rows, if any\nflights |&gt; \n  distinct()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# Find all unique origin and destination pairs\nflights |&gt; \n  distinct(origin, dest)\n#&gt; # A tibble: 224 × 2\n#&gt;   origin dest \n#&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 EWR    IAH  \n#&gt; 2 LGA    IAH  \n#&gt; 3 JFK    MIA  \n#&gt; 4 JFK    BQN  \n#&gt; 5 LGA    ATL  \n#&gt; 6 EWR    ORD  \n#&gt; # ℹ 218 more rows\n\nAlternatively, if you want to the keep other columns when filtering for unique rows, you can use the .keep_all = TRUE option.\n\nflights |&gt; \n  distinct(origin, dest, .keep_all = TRUE)\n#&gt; # A tibble: 224 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 218 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nIt’s not a coincidence that all of these distinct flights are on January 1: distinct() will find the first occurrence of a unique row in the dataset and discard the rest.\nIf you want to find the number of occurrences instead, you’re better off swapping distinct() for count(), and with the sort = TRUE argument you can arrange them in descending order of number of occurrences. You’ll learn more about count in Seção 13.3.\n\nflights |&gt;\n  count(origin, dest, sort = TRUE)\n#&gt; # A tibble: 224 × 3\n#&gt;   origin dest      n\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 JFK    LAX   11262\n#&gt; 2 LGA    ATL   10263\n#&gt; 3 LGA    ORD    8857\n#&gt; 4 JFK    SFO    8204\n#&gt; 5 LGA    CLT    6168\n#&gt; 6 EWR    ORD    6100\n#&gt; # ℹ 218 more rows\n\n\n3.2.5 Exercises\n\n\nIn a single pipeline for each condition, find all flights that meet the condition:\n\nHad an arrival delay of two or more hours\nFlew to Houston (IAH or HOU)\nWere operated by United, American, or Delta\nDeparted in summer (July, August, and September)\nArrived more than two hours late, but didn’t leave late\nWere delayed by at least an hour, but made up over 30 minutes in flight\n\n\nSort flights to find the flights with longest departure delays. Find the flights that left earliest in the morning.\nSort flights to find the fastest flights. (Hint: Try including a math calculation inside of your function.)\nWas there a flight on every day of 2013?\nWhich flights traveled the farthest distance? Which traveled the least distance?\nDoes it matter what order you used filter() and arrange() if you’re using both? Why/why not? Think about the results and how much work the functions would have to do.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#columns",
    "href": "data-transform.html#columns",
    "title": "3  Data transformation",
    "section": "\n3.3 Columns",
    "text": "3.3 Columns\nThere are four important verbs that affect the columns without changing the rows: mutate() creates new columns that are derived from the existing columns, select() changes which columns are present, rename() changes the names of the columns, and relocate() changes the positions of the columns.\n\n3.3.1 mutate()\n\nThe job of mutate() is to add new columns that are calculated from the existing columns. In the transform chapters, you’ll learn a large set of functions that you can use to manipulate different types of variables. For now, we’ll stick with basic algebra, which allows us to compute the gain, how much time a delayed flight made up in the air, and the speed in miles per hour:\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60\n  )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nBy default, mutate() adds new columns on the right hand side of your dataset, which makes it difficult to see what’s happening here. We can use the .before argument to instead add the variables to the left hand side2:\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .before = 1\n  )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    gain speed  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    -9  370.  2013     1     1      517            515         2      830\n#&gt; 2   -16  374.  2013     1     1      533            529         4      850\n#&gt; 3   -31  408.  2013     1     1      542            540         2      923\n#&gt; 4    17  517.  2013     1     1      544            545        -1     1004\n#&gt; 5    19  394.  2013     1     1      554            600        -6      812\n#&gt; 6   -16  288.  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\nThe . is a sign that .before is an argument to the function, not the name of a third new variable we are creating. You can also use .after to add after a variable, and in both .before and .after you can use the variable name instead of a position. For example, we could add the new variables after day:\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .after = day\n  )\n\nAlternatively, you can control which variables are kept with the .keep argument. A particularly useful argument is \"used\" which specifies that we only keep the columns that were involved or created in the mutate() step. For example, the following output will contain only the variables dep_delay, arr_delay, air_time, gain, hours, and gain_per_hour.\n\nflights |&gt; \n  mutate(\n    gain = dep_delay - arr_delay,\n    hours = air_time / 60,\n    gain_per_hour = gain / hours,\n    .keep = \"used\"\n  )\n\nNote that since we haven’t assigned the result of the above computation back to flights, the new variables gain, hours, and gain_per_hour will only be printed but will not be stored in a data frame. And if we want them to be available in a data frame for future use, we should think carefully about whether we want the result to be assigned back to flights, overwriting the original data frame with many more variables, or to a new object. Often, the right answer is a new object that is named informatively to indicate its contents, e.g., delay_gain, but you might also have good reasons for overwriting flights.\n\n3.3.2 select()\n\nIt’s not uncommon to get datasets with hundreds or even thousands of variables. In this situation, the first challenge is often just focusing on the variables you’re interested in. select() allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:\n\n\nSelect columns by name:\n\nflights |&gt; \n  select(year, month, day)\n\n\n\nSelect all columns between year and day (inclusive):\n\nflights |&gt; \n  select(year:day)\n\n\n\nSelect all columns except those from year to day (inclusive):\n\nflights |&gt; \n  select(!year:day)\n\nHistorically this operation was done with - instead of !, so you’re likely to see that in the wild. These two operators serve the same purpose but with subtle differences in behavior. We recommend using ! because it reads as “not” and combines well with & and |.\n\n\nSelect all columns that are characters:\n\nflights |&gt; \n  select(where(is.character))\n\n\n\nThere are a number of helper functions you can use within select():\n\n\nstarts_with(\"abc\"): matches names that begin with “abc”.\n\nends_with(\"xyz\"): matches names that end with “xyz”.\n\ncontains(\"ijk\"): matches names that contain “ijk”.\n\nnum_range(\"x\", 1:3): matches x1, x2 and x3.\n\nSee ?select for more details. Once you know regular expressions (the topic of Capítulo 15) you’ll also be able to use matches() to select variables that match a pattern.\nYou can rename variables as you select() them by using =. The new name appears on the left hand side of the =, and the old variable appears on the right hand side:\n\nflights |&gt; \n  select(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 1\n#&gt;   tail_num\n#&gt;   &lt;chr&gt;   \n#&gt; 1 N14228  \n#&gt; 2 N24211  \n#&gt; 3 N619AA  \n#&gt; 4 N804JB  \n#&gt; 5 N668DN  \n#&gt; 6 N39463  \n#&gt; # ℹ 336,770 more rows\n\n\n3.3.3 rename()\n\nIf you want to keep all the existing variables and just want to rename a few, you can use rename() instead of select():\n\nflights |&gt; \n  rename(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nIf you have a bunch of inconsistently named columns and it would be painful to fix them all by hand, check out janitor::clean_names() which provides some useful automated cleaning.\n\n3.3.4 relocate()\n\nUse relocate() to move variables around. You might want to collect related variables together or move important variables to the front. By default relocate() moves variables to the front:\n\nflights |&gt; \n  relocate(time_hour, air_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;   time_hour           air_time  year month   day dep_time sched_dep_time\n#&gt;   &lt;dttm&gt;                 &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n#&gt; 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n#&gt; 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n#&gt; 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n#&gt; 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n#&gt; 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\nYou can also specify where to put them using the .before and .after arguments, just like in mutate():\n\nflights |&gt; \n  relocate(year:dep_time, .after = time_hour)\nflights |&gt; \n  relocate(starts_with(\"arr\"), .before = dep_time)\n\n\n3.3.5 Exercises\n\nCompare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?\nBrainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.\nWhat happens if you specify the name of the same variable multiple times in a select() call?\n\nWhat does the any_of() function do? Why might it be helpful in conjunction with this vector?\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\n\n\nDoes the result of running the following code surprise you? How do the select helpers deal with upper and lower case by default? How can you change that default?\n\nflights |&gt; select(contains(\"TIME\"))\n\n\nRename air_time to air_time_min to indicate units of measurement and move it to the beginning of the data frame.\n\nWhy doesn’t the following work, and what does the error mean?\n\nflights |&gt; \n  select(tailnum) |&gt; \n  arrange(arr_delay)\n#&gt; Error in `arrange()`:\n#&gt; ℹ In argument: `..1 = arr_delay`.\n#&gt; Caused by error:\n#&gt; ! object 'arr_delay' not found",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-the-pipe",
    "href": "data-transform.html#sec-the-pipe",
    "title": "3  Data transformation",
    "section": "\n3.4 The pipe",
    "text": "3.4 The pipe\nWe’ve shown you simple examples of the pipe above, but its real power arises when you start to combine multiple verbs. For example, imagine that you wanted to find the fast flights to Houston’s IAH airport: you need to combine filter(), mutate(), select(), and arrange():\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  mutate(speed = distance / air_time * 60) |&gt; \n  select(year:day, dep_time, carrier, flight, speed) |&gt; \n  arrange(desc(speed))\n#&gt; # A tibble: 7,198 × 7\n#&gt;    year month   day dep_time carrier flight speed\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt; 1  2013     7     9      707 UA         226  522.\n#&gt; 2  2013     8    27     1850 UA        1128  521.\n#&gt; 3  2013     8    28      902 UA        1711  519.\n#&gt; 4  2013     8    28     2122 UA        1022  519.\n#&gt; 5  2013     6    11     1628 UA        1178  515.\n#&gt; 6  2013     8    27     1017 UA         333  515.\n#&gt; # ℹ 7,192 more rows\n\nEven though this pipeline has four steps, it’s easy to skim because the verbs come at the start of each line: start with the flights data, then filter, then mutate, then select, then arrange.\nWhat would happen if we didn’t have the pipe? We could nest each function call inside the previous call:\n\narrange(\n  select(\n    mutate(\n      filter(\n        flights, \n        dest == \"IAH\"\n      ),\n      speed = distance / air_time * 60\n    ),\n    year:day, dep_time, carrier, flight, speed\n  ),\n  desc(speed)\n)\n\nOr we could use a bunch of intermediate objects:\n\nflights1 &lt;- filter(flights, dest == \"IAH\")\nflights2 &lt;- mutate(flights1, speed = distance / air_time * 60)\nflights3 &lt;- select(flights2, year:day, dep_time, carrier, flight, speed)\narrange(flights3, desc(speed))\n\nWhile both forms have their time and place, the pipe generally produces data analysis code that is easier to write and read.\nTo add the pipe to your code, we recommend using the built-in keyboard shortcut Ctrl/Cmd + Shift + M. You’ll need to make one change to your RStudio options to use |&gt; instead of %&gt;% as shown in Figura 3.1; more on %&gt;% shortly.\n\n\n\n\n\n\n\nFigura 3.1: To insert |&gt;, make sure the “Use native pipe operator” option is checked.\n\n\n\n\n\n\n\n\n\n\nmagrittr\n\n\n\nIf you’ve been using the tidyverse for a while, you might be familiar with the %&gt;% pipe provided by the magrittr package. The magrittr package is included in the core tidyverse, so you can use %&gt;% whenever you load the tidyverse:\n\nlibrary(tidyverse)\n\nmtcars %&gt;% \n  group_by(cyl) %&gt;%\n  summarize(n = n())\n\nFor simple cases, |&gt; and %&gt;% behave identically. So why do we recommend the base pipe? Firstly, because it’s part of base R, it’s always available for you to use, even when you’re not using the tidyverse. Secondly, |&gt; is quite a bit simpler than %&gt;%: in the time between the invention of %&gt;% in 2014 and the inclusion of |&gt; in R 4.1.0 in 2021, we gained a better understanding of the pipe. This allowed the base implementation to jettison infrequently used and less important features.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#groups",
    "href": "data-transform.html#groups",
    "title": "3  Data transformation",
    "section": "\n3.5 Groups",
    "text": "3.5 Groups\nSo far you’ve learned about functions that work with rows and columns. dplyr gets even more powerful when you add in the ability to work with groups. In this section, we’ll focus on the most important functions: group_by(), summarize(), and the slice family of functions.\n\n3.5.1 group_by()\n\nUse group_by() to divide your dataset into groups meaningful for your analysis:\n\nflights |&gt; \n  group_by(month)\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   month [12]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\ngroup_by() doesn’t change the data but, if you look closely at the output, you’ll notice that the output indicates that it is “grouped by” month (Groups: month [12]). This means subsequent operations will now work “by month”. group_by() adds this grouped feature (referred to as class) to the data frame, which changes the behavior of the subsequent verbs applied to the data.\n\n3.5.2 summarize()\n\nThe most important grouped operation is a summary, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group. In dplyr, this operation is performed by summarize()3, as shown by the following example, which computes the average departure delay by month:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay)\n  )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1        NA\n#&gt; 2     2        NA\n#&gt; 3     3        NA\n#&gt; 4     4        NA\n#&gt; 5     5        NA\n#&gt; 6     6        NA\n#&gt; # ℹ 6 more rows\n\nUhoh! Something has gone wrong and all of our results are NAs (pronounced “N-A”), R’s symbol for missing value. This happened because some of the observed flights had missing data in the delay column, and so when we calculated the mean including those values, we got an NA result. We’ll come back to discuss missing values in detail in Capítulo 18, but for now we’ll tell the mean() function to ignore all missing values by setting the argument na.rm to TRUE:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 12 × 2\n#&gt;   month delay\n#&gt;   &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1  10.0\n#&gt; 2     2  10.8\n#&gt; 3     3  13.2\n#&gt; 4     4  13.9\n#&gt; 5     5  13.0\n#&gt; 6     6  20.8\n#&gt; # ℹ 6 more rows\n\nYou can create any number of summaries in a single call to summarize(). You’ll learn various useful summaries in the upcoming chapters, but one very useful summary is n(), which returns the number of rows in each group:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n()\n  )\n#&gt; # A tibble: 12 × 3\n#&gt;   month delay     n\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     1  10.0 27004\n#&gt; 2     2  10.8 24951\n#&gt; 3     3  13.2 28834\n#&gt; 4     4  13.9 28330\n#&gt; 5     5  13.0 28796\n#&gt; 6     6  20.8 28243\n#&gt; # ℹ 6 more rows\n\nMeans and counts can get you a surprisingly long way in data science!\n\n3.5.3 The slice_ functions\nThere are five handy functions that allow you extract specific rows within each group:\n\n\ndf |&gt; slice_head(n = 1) takes the first row from each group.\n\ndf |&gt; slice_tail(n = 1) takes the last row in each group.\n\ndf |&gt; slice_min(x, n = 1) takes the row with the smallest value of column x.\n\ndf |&gt; slice_max(x, n = 1) takes the row with the largest value of column x.\n\ndf |&gt; slice_sample(n = 1) takes one random row.\n\nYou can vary n to select more than one row, or instead of n =, you can use prop = 0.1 to select (e.g.) 10% of the rows in each group. For example, the following code finds the flights that are most delayed upon arrival at each destination:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  slice_max(arr_delay, n = 1) |&gt;\n  relocate(dest)\n#&gt; # A tibble: 108 × 19\n#&gt; # Groups:   dest [105]\n#&gt;   dest   year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 ABQ    2013     7    22     2145           2007        98      132\n#&gt; 2 ACK    2013     7    23     1139            800       219     1250\n#&gt; 3 ALB    2013     1    25      123           2000       323      229\n#&gt; 4 ANC    2013     8    17     1740           1625        75     2042\n#&gt; 5 ATL    2013     7    22     2257            759       898      121\n#&gt; 6 AUS    2013     7    10     2056           1505       351     2347\n#&gt; # ℹ 102 more rows\n#&gt; # ℹ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\nNote that there are 105 destinations but we get 108 rows here. What’s up? slice_min() and slice_max() keep tied values so n = 1 means give us all rows with the highest value. If you want exactly one row per group you can set with_ties = FALSE.\nThis is similar to computing the max delay with summarize(), but you get the whole corresponding row (or rows if there’s a tie) instead of the single summary statistic.\n\n3.5.4 Grouping by multiple variables\nYou can create groups using more than one variable. For example, we could make a group for each date.\n\ndaily &lt;- flights |&gt;  \n  group_by(year, month, day)\ndaily\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nWhen you summarize a tibble grouped by more than one variable, each summary peels off the last group. In hindsight, this wasn’t a great way to make this function work, but it’s difficult to change without breaking existing code. To make it obvious what’s happening, dplyr displays a message that tells you how you can change this behavior:\n\ndaily_flights &lt;- daily |&gt; \n  summarize(n = n())\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n\nIf you’re happy with this behavior, you can explicitly request it in order to suppress the message:\n\ndaily_flights &lt;- daily |&gt; \n  summarize(\n    n = n(), \n    .groups = \"drop_last\"\n  )\n\nAlternatively, change the default behavior by setting a different value, e.g., \"drop\" to drop all grouping or \"keep\" to preserve the same groups.\n\n3.5.5 Ungrouping\nYou might also want to remove grouping from a data frame without using summarize(). You can do this with ungroup().\n\ndaily |&gt; \n  ungroup()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nNow let’s see what happens when you summarize an ungrouped data frame.\n\ndaily |&gt; \n  ungroup() |&gt;\n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  )\n#&gt; # A tibble: 1 × 2\n#&gt;   avg_delay flights\n#&gt;       &lt;dbl&gt;   &lt;int&gt;\n#&gt; 1      12.6  336776\n\nYou get a single row back because dplyr treats all the rows in an ungrouped data frame as belonging to one group.\n\n3.5.6 .by\n\ndplyr 1.1.0 includes a new, experimental, syntax for per-operation grouping, the .by argument. group_by() and ungroup() aren’t going away, but you can now also use the .by argument to group within a single operation:\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = month\n  )\n\nOr if you want to group by multiple variables:\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = c(origin, dest)\n  )\n\n.by works with all verbs and has the advantage that you don’t need to use the .groups argument to suppress the grouping message or ungroup() when you’re done.\nWe didn’t focus on this syntax in this chapter because it was very new when we wrote the book. We did want to mention it because we think it has a lot of promise and it’s likely to be quite popular. You can learn more about it in the dplyr 1.1.0 blog post.\n\n3.5.7 Exercises\n\nWhich carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights |&gt; group_by(carrier, dest) |&gt; summarize(n()))\nFind the flights that are most delayed upon departure from each destination.\nHow do delays vary over the course of the day. Illustrate your answer with a plot.\nWhat happens if you supply a negative n to slice_min() and friends?\nExplain what count() does in terms of the dplyr verbs you just learned. What does the sort argument to count() do?\n\nSuppose we have the following tiny data frame:\n\ndf &lt;- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what group_by() does.\n\ndf |&gt;\n  group_by(y)\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what arrange() does. Also comment on how it’s different from the group_by() in part (a)?\n\ndf |&gt;\n  arrange(y)\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does.\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does. Then, comment on what the message says.\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does. How is the output different from the one in part (d).\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\n\n\nWrite down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  mutate(mean_x = mean(x))",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#sec-sample-size",
    "href": "data-transform.html#sec-sample-size",
    "title": "3  Data transformation",
    "section": "\n3.6 Case study: aggregates and sample size",
    "text": "3.6 Case study: aggregates and sample size\nWhenever you do any aggregation, it’s always a good idea to include a count (n()). That way, you can ensure that you’re not drawing conclusions based on very small amounts of data. We’ll demonstrate this with some baseball data from the Lahman package. Specifically, we will compare what proportion of times a player gets a hit (H) vs. the number of times they try to put the ball in play (AB):\n\nbatters &lt;- Lahman::Batting |&gt; \n  group_by(playerID) |&gt; \n  summarize(\n    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n    n = sum(AB, na.rm = TRUE)\n  )\nbatters\n#&gt; # A tibble: 20,469 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 aardsda01      0          4\n#&gt; 2 aaronha01      0.305  12364\n#&gt; 3 aaronto01      0.229    944\n#&gt; 4 aasedo01       0          5\n#&gt; 5 abadan01       0.0952    21\n#&gt; 6 abadfe01       0.111      9\n#&gt; # ℹ 20,463 more rows\n\nWhen we plot the skill of the batter (measured by the batting average, performance) against the number of opportunities to hit the ball (measured by times at bat, n), you see two patterns:\n\nThe variation in performance is larger among players with fewer at-bats. The shape of this plot is very characteristic: whenever you plot a mean (or other summary statistics) vs. group size, you’ll see that the variation decreases as the sample size increases4.\nThere’s a positive correlation between skill (performance) and opportunities to hit the ball (n) because teams want to give their best batters the most opportunities to hit the ball.\n\n\nbatters |&gt; \n  filter(n &gt; 100) |&gt; \n  ggplot(aes(x = n, y = performance)) +\n  geom_point(alpha = 1 / 10) + \n  geom_smooth(se = FALSE)\n\n\n\n\n\n\n\nNote the handy pattern for combining ggplot2 and dplyr. You just have to remember to switch from |&gt;, for dataset processing, to + for adding layers to your plot.\nThis also has important implications for ranking. If you naively sort on desc(performance), the people with the best batting averages are clearly the ones who tried to put the ball in play very few times and happened to get a hit, they’re not necessarily the most skilled players:\n\nbatters |&gt; \n  arrange(desc(performance))\n#&gt; # A tibble: 20,469 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 abramge01           1     1\n#&gt; 2 alberan01           1     1\n#&gt; 3 banisje01           1     1\n#&gt; 4 bartocl01           1     1\n#&gt; 5 bassdo01            1     1\n#&gt; 6 birasst01           1     2\n#&gt; # ℹ 20,463 more rows\n\nYou can find a good explanation of this problem and how to overcome it at http://varianceexplained.org/r/empirical_bayes_baseball/ and https://www.evanmiller.org/how-not-to-sort-by-average-rating.html.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#summary",
    "href": "data-transform.html#summary",
    "title": "3  Data transformation",
    "section": "\n3.7 Summary",
    "text": "3.7 Summary\nIn this chapter, you’ve learned the tools that dplyr provides for working with data frames. The tools are roughly grouped into three categories: those that manipulate the rows (like filter() and arrange(), those that manipulate the columns (like select() and mutate()), and those that manipulate groups (like group_by() and summarize()). In this chapter, we’ve focused on these “whole data frame” tools, but you haven’t yet learned much about what you can do with the individual variable. We’ll come back to that in the Transform part of the book, where each chapter will give you tools for a specific type of variable.\nIn the next chapter, we’ll pivot back to workflow to discuss the importance of code style, keeping your code well organized in order to make it easy for you and others to read and understand your code.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data-transform.html#footnotes",
    "href": "data-transform.html#footnotes",
    "title": "3  Data transformation",
    "section": "",
    "text": "Later, you’ll learn about the slice_*() family which allows you to choose rows based on their positions.↩︎\nRemember that in RStudio, the easiest way to see a dataset with many columns is View().↩︎\nOr summarise(), if you prefer British English.↩︎\n*cough* the law of large numbers *cough*.↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "workflow-style.html",
    "href": "workflow-style.html",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "",
    "text": "4.1 Nomes\nFalamos um pouco sobre nomes em Seção 2.3. Lembre-se de que os nomes de variáveis (aqueles criados por &lt;- e aqueles criados por mutate()) devem usar apenas letras minúsculas, números e _. Use _ para separar palavras dentro de um nome.\n# Tente escrever assim:\nvoos_curtos &lt;- voos |&gt; filter(tempo_voo &lt; 60)\n\n# Evite escrever assim:\nVOOSCURTOS &lt;- voos |&gt; filter(tempo_voo &lt; 60)\nComo regra geral, é melhor usar nomes longos, descritivos e que sejam fáceis de entender, do que nomes curtos só pela rapidez para digitar. Os nomes curtos economizam relativamente pouco tempo ao escrever o código (especialmente porque o recurso de autocompletar (autocomplete) ajuda a terminar de digitá-los), mas isso pode te atrasar depois, quando voltar ao código antigo e precisar decifrar uma abreviação bem difícil de entender.\nSe você tem um monte de nomes para coisas que estão relacionadas entre si, faça o possível para ser consistente. É fácil surgirem inconsistências quando você esquece uma convenção anterior, então não se sinta mal se você tiver que voltar e renomear as coisas. Em geral se você tem um monte de variáveis que são uma variação de um tema específico, é melhor dar a elas um prefixo comum em vez de um sufixo comum, porque o recurso de autocompletar funciona melhor no início de uma variável.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#espaços",
    "href": "workflow-style.html#espaços",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "\n4.2 Espaços",
    "text": "4.2 Espaços\nUse espaços em ambos os lados dos operadores matemáticos, exceto ^ (operadores: +, -, ==, &lt;, …), e em torno do operador de atribuição (&lt;-).\n\n# Tente escrever assim:\nz &lt;- (a + b)^2 / d\n\n# Evite escrever assim:\nz&lt;-( a + b ) ^ 2/d\n\nNão coloque espaços dentro ou fora de parênteses para chamadas de funções normais. Sempre coloque um espaço depois de uma vírgula, assim como escrevemos em português.\n\n# Tente escrever assim:\nmean(x, na.rm = TRUE)\n\n# Evite escrever assim:\nmean (x ,na.rm=TRUE)\n\nTudo bem adicionar espaços extras se isso melhorar o alinhamento. Por exemplo, se você estiver criando várias variáveis com um mutate(), você pode querer adicionar espaços para que todos os sinais de = fiquem alinhados.1 Isso facilita a leitura do código.\n\nvoos |&gt; \n  mutate(\n    velocidade     = distancia / tempo_voo,\n    hora_saida     = horario_saida %/% 100,\n    minuto_saida   = horario_saida %%  100\n  )",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#sec-pipes",
    "href": "workflow-style.html#sec-pipes",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "\n4.3 Pipes (Encadeamento)",
    "text": "4.3 Pipes (Encadeamento)\nO |&gt; (chamado de pipe) deve sempre ter um espaço antes dele e deve ser sempre a última coisa em uma linha. Isso torna mais fácil adicionar novas etapas, reorganizar etapas existentes, modificar elementos dentro de uma etapa e obter uma visão geral do código ao passar os olhos sobre os verbos no lado esquerdo.\n\n# Tente escrever assim:\nvoos |&gt;  \n  filter(!is.na(atraso_saida), !is.na(cauda)) |&gt; \n  count(destino)\n\n# Evite escrever assim:\nvoos|&gt;filter(!is.na(atraso_saida), !is.na(cauda))|&gt;count(destino)\n\nSe a função para a qual você está encadeando tem argumentos nomeados (como mutate() ou summarize()), coloque cada argumento em uma nova linha. Se a função não tiver argumentos nomeados (como select() ou filter()), mantenha tudo em uma linha, caso caiba. Caso não caiba, você deve colocar cada argumento em sua própria linha.\n\n# Tente escrever assim:\nvoos |&gt;  \n  group_by(cauda) |&gt; \n  summarize(\n    atraso = mean(atraso_chegada, na.rm = TRUE),\n    n = n()\n  )\n\n# Evite escrever assim:\nvoos |&gt;\n  group_by(\n    cauda\n  ) |&gt; \n  summarize(atraso = mean(atraso_chegada, na.rm = TRUE), n = n())\n\nDepois da primeira etapa do encadeamento, recue cada linha (indente) em dois espaços. O RStudio colocará automaticamente os espaços para você após a quebra de linha feita logo depois do pipe |&gt;. Se você estiver colocando cada argumento em sua própria linha, recue em mais dois espaços. Certifique-se de que o ) (fechamento de parêntesis) esteja em sua própria linha e não recuada para corresponder à posição horizontal do nome da função.\n\n# Tente escrever assim:\nvoos |&gt;  \n  group_by(cauda) |&gt; \n  summarize(\n    atraso = mean(atraso_chegada, na.rm = TRUE),\n    n = n()\n  )\n\n# Evite escrever assim:\nvoos|&gt;\n  group_by(cauda) |&gt; \n  summarize(\n             atraso = mean(atraso_chegada, na.rm = TRUE), \n             n = n()\n           )\n\n# Evite escrever assim:\nvoos|&gt;\n  group_by(cauda) |&gt; \n  summarize(\n  atraso = mean(atraso_chegada, na.rm = TRUE), \n  n = n()\n  )\n\nTudo bem ignorar algumas dessas regras se as etapas de seu encadeamento (pipeline) se encaixar facilmente em uma linha. Mas, em nossa experiência coletiva, é comum que pequenos trechos de código cresçam, então você vai acabar economizando tempo no longo prazo começando com todo o espaço vertical de que precisa.\n\n# Isso se encaixa bem em uma linha:\ndf |&gt; mutate(y = x + 1)\n\n# Enquanto isso ocupa 4x mais linhas, é facilmente estendido para\n# mais variáveis e mais etapas no futuro:\ndf |&gt; \n  mutate(\n    y = x + 1\n  )\n\nPor último, tenha cuidado ao escrever pipelines muito longos, com mais de 10-15 linhas, por exemplo. Tente dividir o pipeline em subtarefas menores, dando a cada tarefa um nome que informe o objetivo daquela etapa. Os nomes ajudarão quem está lendo a entender o que está acontecendo e torna mais fácil de verificar se os resultados intermediários estão como o esperado.\nDê nomes informativos sempre que puder. Por exemplo, quando você alterar a estrutura dos dados em seu nível básico, como após pivotar ou sumarizar. Não espere acertar na primeira tentativa! Isso significa que você tem que dividir os encadeamentos longos se houver estados intermediários que possam receber bons nomes.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#ggplot2",
    "href": "workflow-style.html#ggplot2",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "\n4.4 ggplot2",
    "text": "4.4 ggplot2\nAs mesmas regras básicas que se aplicam ao pipe também se aplicam ao ggplot2; você deve tratar o + da mesma forma que o |&gt;.\n\nvoos |&gt; \n  group_by(mes) |&gt; \n  summarize(\n    atraso = mean(atraso_chegada, na.rm = TRUE)\n  ) |&gt; \n  ggplot(aes(x = mes, y = atraso)) +\n  geom_point() + \n  geom_line()\n\nLembre-se, se você não puder colocar todos os argumentos de uma função em uma única linha, coloque cada argumento em sua própria linha:\n\nvoos |&gt; \n  group_by(destino) |&gt; \n  summarize(\n    distancia = mean(distancia),\n    velocidade = mean(distancia / tempo_voo, na.rm = TRUE)\n  ) |&gt; \n  ggplot(aes(x = distancia, y = velocidade)) +\n  geom_smooth(\n    method = \"loess\",\n    span = 0.5,\n    se = FALSE, \n    color = \"white\", \n    linewidth = 4\n  ) +\n  geom_point()\n\nPreste atenção quando mudar do |&gt; para o + no encademanto do código. Gostaríamos que essa transição não fosse necessária, mas infelizmente, o ggplot2 foi escrito antes do pipe ser descoberto.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#comentários-de-seção",
    "href": "workflow-style.html#comentários-de-seção",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "\n4.5 Comentários de seção",
    "text": "4.5 Comentários de seção\nConforme seus scripts ficam mais longos, você pode usar comentários de seção para dividir seu arquivo em partes gerenciáveis:\n\n# Carregar os dados --------------------------------------\n\n# Plotar os dados   --------------------------------------\n\nO RStudio fornece um atalho de teclado para criar esses cabeçalhos (Cmd/Ctrl + Shift + R), e os exibe no menu de navegação de código na parte inferior esquerda do editor, como mostrado na Figura 4.2.\n\n\n\n\n\n\n\nFigura 4.2: Depois de adicionar comentários de seção ao seu script, você pode navegar facilmente por eles usando a ferramenta de navegação de código na parte inferior esquerda do editor de scripts.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#exercícios",
    "href": "workflow-style.html#exercícios",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "\n4.6 Exercícios",
    "text": "4.6 Exercícios\n\nAplique as boas normas de formatação aos seguintes pipelines seguindo as diretrizes apresentadas neste capítulo.\n\n\n    voos|&gt;filter(destino==\"IAH\")|&gt;group_by(ano,mes,dia)|&gt;summarize(n=n(),\n    atraso=mean(atraso_chegada,na.rm=TRUE))|&gt;filter(n&gt;10)\n\n    voos|&gt;filter(companhia_aerea==\"UA\",destino%in%c(\"IAH\",\"HOU\"),saida_programada&gt;\n    0900,chegada_prevista&lt;2000)|&gt;group_by(voo)|&gt;summarize(atraso=mean(\n    atraso_chegada,na.rm=TRUE),cancelado=sum(is.na(atraso_chegada)),n=n())|&gt;filter(n&gt;10)",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#sumário",
    "href": "workflow-style.html#sumário",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "\n4.7 Sumário",
    "text": "4.7 Sumário\nNeste capítulo, você aprendeu os princípios mais importantes da convenção de estilo de código. Essa convenção pode parecer um conjunto de regras arbitrárias (porque são!), mas com o tempo, à medida que você escreve mais código e compartilha código com mais pessoas, você verá como é importante ter um código fácil de ser lido e entendido. E não se esqueça do pacote styler: é uma ótima maneira de melhorar de forma rápida a qualidade do código mal formatado.\nNo próximo capítulo, voltamos às ferramentas de ciência de dados, aprendendo sobre tidy data (dados organizados). Tidy data é uma maneira consistente (convenção) de organizar seus conjuntos de dados que é usada em todo o tidyverse. Essa consistência torna sua vida mais fácil porque, uma vez que você tem dados organizados de acordo com os conceitos de tidy data, eles irão funcionar com a grande maioria das funções do tidyverse. Claro, a vida nunca é fácil, e a maioria dos conjuntos de dados que você encontrará na vida real não serão tidy. Por esse motivo, também ensinaremos como usar o pacote tidyr para organizar seus dados desorganizados.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "workflow-style.html#footnotes",
    "href": "workflow-style.html#footnotes",
    "title": "4  ✅ Fluxo de trabalho: estilo de código",
    "section": "",
    "text": "Como horario_saida está no formato HMM ou HHMM, fazemos uma divisão do número inteiro (%/%) para obter a hora e o resto (também conhecido como módulo, %%) para obter o minuto.↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>✅ Fluxo de trabalho: estilo de código</span>"
    ]
  },
  {
    "objectID": "data-tidy.html",
    "href": "data-tidy.html",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "",
    "text": "5.1 Introdução\nNeste capítulo, você vai aprender uma forma consistente de organizar seus dados no R utilizando um sistema chamado tidy data. Colocar seus dados nesse formato requer alguma preparação, mas esse é um trabalho que se paga ao longo prazo. Uma vez que você tenha os dados organizados (tidy) e as ferramentas do pacote tidyverse, você irá gastar muito menos tempo transformando-os entre uma representação e outra, permitindo que você gaste mais tempo nas questões que realmente te importam.\nNeste capítulo, você primeiro vai aprender sobre a definição do formato tidy e vê-lo sendo aplicado em um conjunto de dados de exemplo. Em seguida, você vai mergulhar na principal ferramenta que utilizará para organizar os dados: a pivotagem (pivoting). Pivotar lhe permite mudar a forma dos dados sem modificar nenhum de seus valores.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#introdução",
    "href": "data-tidy.html#introdução",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "",
    "text": "“Todas as famílias felizes se parecem, cada família infeliz é infeliz à sua maneira.”\n— Leo Tolstoy\n\n\n“Todos os conjuntos de dados organizados se parecem, cada conjunto de dados bagunçados são bagunçados à sua maneira.”\n— Hadley Wickham\n\n\n\n\n5.1.1 Pré-requisitos\nNeste capítulo, vamos focar no tidyr, um pacote que disponibliza uma variedade de ferramentas para te ajudar a organizar seus conjuntos de dados bagunçados. tidyr faz parte do grupo de pacotes mais importantes do tidyverse (conhecidos como core tidyverse).\n\nlibrary(tidyverse)\nlibrary(dados)\n\nDeste capítulo em diante, vamos suprimir a mensagem de carregamento library(tidyverse).",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-tidy-data",
    "href": "data-tidy.html#sec-tidy-data",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "\n5.2 Dados organizados (tidy data)",
    "text": "5.2 Dados organizados (tidy data)\nÉ possível representar os mesmos dados de diversas formas. O exemplo abaixo mostra os mesmos dados organizados de três formas diferentes. Cada conjunto de dados mostra os mesmos valores de quatro variáveis: país, ano, população, e o número de casos documentados de tuberculose. No entanto, cada conjunto de dados organiza os valores de uma forma diferente.\n\ntabela1\n\n# A tibble: 6 × 4\n  pais          ano  casos  populacao\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afeganistão  1999    745   19987071\n2 Afeganistão  2000   2666   20595360\n3 Brasil       1999  37737  172006362\n4 Brasil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\ntabela2\n\n# A tibble: 12 × 4\n   pais          ano tipo        contagem\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1 Afeganistão  1999 casos            745\n 2 Afeganistão  1999 população   19987071\n 3 Afeganistão  2000 casos           2666\n 4 Afeganistão  2000 população   20595360\n 5 Brasil       1999 casos          37737\n 6 Brasil       1999 população  172006362\n 7 Brasil       2000 casos          80488\n 8 Brasil       2000 população  174504898\n 9 China        1999 casos         212258\n10 China        1999 população 1272915272\n11 China        2000 casos         213766\n12 China        2000 população 1280428583\n\ntabela3\n\n# A tibble: 6 × 3\n  pais          ano taxa             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afeganistão  1999 745/19987071     \n2 Afeganistão  2000 2666/20595360    \n3 Brasil       1999 37737/172006362  \n4 Brasil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\nTodas essas são representações dos mesmos dados. Mas nem todas são igualmente fáceis de se utilizar. Uma delas, tabela1, será muito mais fácil de trabalhar dentro do tidyverse porque está no formato tidy.\nExistem três regras interrelacionadas que fazem com que um conjunto de dados seja considerado tidy:\n\nCada variável é uma coluna; cada coluna é uma variável.\nCada observação é uma linha; cada linha é uma observação.\nCada valor é uma célula; cada célula é um único valor.\n\nFigura 5.1 mostra essas regras visualmente.\n\n\n\n\n\n\n\nFigura 5.1: As seguintes três regras tornam um conjunto de dados tidy: variáveis são colunas, observações são linhas e valores são células.\n\n\n\n\nPor que garantir que seus dados estão no formato tidy? Existem duas principais vantagens:\n\nHá uma vantagem generalizada em escolher uma forma consistente de armazenar os dados. Se você tiver uma estrutura de dados consistente, é mais fácil compreender as ferramentas adequadas a ela, pois ela terá uma uniformidade intrínseca.\nHá uma vantagem específica em colocar as variáveis em colunas porque isso permite que a natureza vetorial do R possa brilhar. Como você aprendeu em Seção 3.3.1 e Seção 3.5.2, a maioria das funções nativas do R trabalham com vetores de valores. Isso torna natural as transformações sobre dados no formato tidy.\n\ndplyr, ggplot2, e todos os demais pacotes do tidyverse foram pensados para trabalhar com dados tidy. Aqui estão alguns pequenos exemplos mostrando como é possível trabalhar com tabela1.\n\n# Calcular a taxa (_rate_) por 10.000\ntabela1 |&gt;\n  mutate(taxa = casos / populacao * 10000)\n\n# A tibble: 6 × 5\n  pais          ano  casos  populacao  taxa\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Afeganistão  1999    745   19987071 0.373\n2 Afeganistão  2000   2666   20595360 1.29 \n3 Brasil       1999  37737  172006362 2.19 \n4 Brasil       2000  80488  174504898 4.61 \n5 China        1999 212258 1272915272 1.67 \n6 China        2000 213766 1280428583 1.67 \n\n# Calcular o total de casos por ano \ntabela1 |&gt; \n  group_by(ano) |&gt; \n  summarize(total_casos = sum(casos))\n\n# A tibble: 2 × 2\n    ano total_casos\n  &lt;dbl&gt;       &lt;dbl&gt;\n1  1999      250740\n2  2000      296920\n\n# Visualizar mudanças ao longo do tempo\nggplot(tabela1, aes(x = ano, y = casos)) +\n  geom_line(aes(group = pais), color = \"grey50\") +\n  geom_point(aes(color = pais, shape = pais)) +\n  scale_x_continuous(breaks = c(1999, 2000)) # quebras (breaks) no eixo-x em 1999 e 2000\n\n\n\n\n\n\n\n\n5.2.1 Exercícios\n\nPara cada uma das tabelas do exemplo, descreva o que cada observação e cada coluna representa.\n\nFaça um esboço do processo que você usaria para calcular taxa para a tabela2 e tabela3. Você precisará executar quatro operações:\n\nExtrair o número de casos de tuberculose por país por ano.\nExtrair a população correspondente por país por ano.\nDividir os casos pela população e multiplicar por 10000.\nArmazenar de volta no local apropriado.\n\nVocê ainda não aprendeu todas as funções necessárias para, de fato, executar essas operações, mas ainda assim você deve ser capaz de pensar sobre as transformações que você precisaria.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#sec-pivoting",
    "href": "data-tidy.html#sec-pivoting",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "\n5.3 Alongando os dados",
    "text": "5.3 Alongando os dados\nOs princípios do formato tidy parecem ser tão óbvios que você deve estar se perguntando se algum dia vai encontrar algum cojunto de dados que não esteja nesse formato. Infelizmente, porém, a maioria dos dados reais não estão nesse formato. Existem dois motivos principais:\n\nGeralmente os dados estão organizados para facilitar algum outro objetivo além da análise. Por exemplo, é comum os dados estarem estruturados para facilitar a entrada de novos dados e não a análise dos mesmos.\nA maioria das pessoas não está familiarizada com os princípios do formato tidy e é difícil derivá-lo espontaneamente a menos que já se tenha trabalhado com dados por muito tempo.\n\nIsso significa que a maioria das análises reais vai demandar pelo menos alguma adaptação para o formato tidy. Você vai começar descobrindo quais são as variáveis e observações presentes. Algumas vezes isso é fácil, em outras você precisará consultar as pessoas que geraram os dados originalmente. Em seguida, você irá *pivotar** seus dados para o formato tidy, com as variáveis nas colunas e as observações nas linhas.\ntidyr disponibiliza duas funções para pivotar os dados: pivot_longer() e pivot_wider(). Começaremos com pivot_longer() pois é o caso mais comum. Vamos nos aprofundar em alguns exemplos.\n\n5.3.1 Dados nos nomes das colunas\nO conjunto de dados top100musicas marca a posição das músicas na billboard no ano 2000:\n\ntop100musicas\n\n# A tibble: 317 × 79\n   artista        musica data.adicionada semana1 semana2 semana3 semana4 semana5\n   &lt;chr&gt;          &lt;chr&gt;  &lt;date&gt;            &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2 Pac          Baby … 2000-02-26           87      82      72      77      87\n 2 2Ge+her        The H… 2000-09-02           91      87      92      NA      NA\n 3 3 Doors Down   Krypt… 2000-04-08           81      70      68      67      66\n 4 3 Doors Down   Loser  2000-10-21           76      76      72      69      67\n 5 504 Boyz       Wobbl… 2000-04-15           57      34      25      17      17\n 6 98^0           Give … 2000-08-19           51      39      34      26      26\n 7 A*Teens        Danci… 2000-07-08           97      97      96      95     100\n 8 Aaliyah        I Don… 2000-01-29           84      62      51      41      38\n 9 Aaliyah        Try A… 2000-03-18           59      53      38      28      21\n10 Adams, Yolanda Open … 2000-08-26           76      76      74      69      68\n# ℹ 307 more rows\n# ℹ 71 more variables: semana6 &lt;dbl&gt;, semana7 &lt;dbl&gt;, semana8 &lt;dbl&gt;,\n#   semana9 &lt;dbl&gt;, semana10 &lt;dbl&gt;, semana11 &lt;dbl&gt;, semana12 &lt;dbl&gt;,\n#   semana13 &lt;dbl&gt;, semana14 &lt;dbl&gt;, semana15 &lt;dbl&gt;, semana16 &lt;dbl&gt;,\n#   semana17 &lt;dbl&gt;, semana18 &lt;dbl&gt;, semana19 &lt;dbl&gt;, semana20 &lt;dbl&gt;,\n#   semana21 &lt;dbl&gt;, semana22 &lt;dbl&gt;, semana23 &lt;dbl&gt;, semana24 &lt;dbl&gt;,\n#   semana25 &lt;dbl&gt;, semana26 &lt;dbl&gt;, semana27 &lt;dbl&gt;, semana28 &lt;dbl&gt;, …\n\n\nNesse conjunto de dados, cada observação é uma música. As três primeiras colunas (artista, musica e data.adicionada) são variáveis que descrevem a música. Em seguida, temos 76 colunas (semana1-semana76) que descrevem a posição da música em cada semana1. Aqui, o nome das colunas é uma variável (a semana) e o valor da célula é outra (a posicao).\nPara transformar esses dados em tidy, vamos usar pivot_longer():\n\ntop100musicas|&gt;\n  pivot_longer(\n    cols = starts_with(\"semana\"), \n    names_to = \"semana\", \n    values_to = \"posicao\"\n  )\n\n# A tibble: 24,092 × 5\n   artista musica                  data.adicionada semana   posicao\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;          &lt;chr&gt;      &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana1       87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana2       82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana3       72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana4       77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana5       87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana6       94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana7       99\n 8 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana8       NA\n 9 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana9       NA\n10 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana10      NA\n# ℹ 24,082 more rows\n\n\nNa função, são três argumentos principais, após os dados:\n\n\ncols especifica quais colunas precisarão ser pivotadas, ou seja, quais colunas ainda não são variáveis. Esse argumento usa a mesma sintaxe que a função select() então aqui poderíamos usar !c(artista, musica, data.adicionada) ou starts_with(\"semana\").\n\nnames_to nomeia a variável armazenada nos nomes das colunas, nós nomeamos aquela variável como semana.\n\nvalues_to nomeia a variável armazenada nos valores das células, nós nomeamos aquela variável como posicao.\n\nNote que os códigos \"semana\" e \"posicao\" estão entre aspas porque essas são novas variáveis que estamos criando, elas ainda não existem nos dados quando a gente faz a chamada à pivot_longer().\nAgora voltaremos nossa atenção ao data frame resultante, em um formato mais longo. O que acontece se uma música fica no top 100 por menos que 76 semanas? Vejamos “Baby Don’t Cry” do 2 Pac, por exemplo. A saída acima sugere que ela ficou apenas 7 semanas no top 100, e todas as demais semanas foram preenchidas por valores ausentes. Esses NAs, na verdade, não representam observações desconhecidas; eles foram forçadas a existir pela estrutura do conjunto de dados 2, então podemos pedir para a pivot_longer() se livrar deles por meio do parâmetro values_drop_na = TRUE:\n\ntop100musicas|&gt; \n  pivot_longer(\n    cols = starts_with(\"semana\"), \n    names_to = \"semana\", \n    values_to = \"posicao\",\n    values_drop_na = TRUE\n  )\n\n# A tibble: 5,307 × 5\n   artista musica                  data.adicionada semana  posicao\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;          &lt;chr&gt;     &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana1      87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana2      82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana3      72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana4      77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana5      87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana6      94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26      semana7      99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02      semana1      91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02      semana2      87\n10 2Ge+her The Hardest Part Of ... 2000-09-02      semana3      92\n# ℹ 5,297 more rows\n\n\nO número de linhas agora é muito menor, indicando que várias linhas que continham apenas NAs foram removidas.\nVocê também poderia estar se perguntando: o que aconteceria caso a música ficasse no top 100 por mais que 76 semanas? Não é possível dizer apenas com esses dados, mas você poderia imaginar que colunas adicionais semana77, semana78, … seriam incluídas no conjunto de dados.\nEsses dados agora estão no formato tidy, mas nós ainda podemos facilitar cálculos futuros ao converter os valores da coluna semana de caracteres para números utilizando mutate() e readr::parse_number(). parse_number() é uma função bem útil que irá extrair o primeiro número de uma sequência de caracteres (string) e vai ignorar todo o resto.\n\ntop100musicas_longo &lt;- top100musicas |&gt; \n  pivot_longer(\n    cols = starts_with(\"semana\"), \n    names_to = \"semana\", \n    values_to = \"posicao\",\n    values_drop_na = TRUE\n  ) |&gt; \n  mutate(\n    semana = parse_number(semana)\n  )\ntop100musicas_longo\n\n# A tibble: 5,307 × 5\n   artista musica                  data.adicionada semana posicao\n   &lt;chr&gt;   &lt;chr&gt;                   &lt;date&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26           1      87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26           2      82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26           3      72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26           4      77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26           5      87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26           6      94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26           7      99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02           1      91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02           2      87\n10 2Ge+her The Hardest Part Of ... 2000-09-02           3      92\n# ℹ 5,297 more rows\n\n\nAgora que temos todos os números das semanas em uma única variável e todas as posições em outra, é um bom ponto para visualizar como a posição das músicas varia ao longo do tempo. O código é mostrado abaixo e o resultado está em Figura 5.2. Nós podemos ver que muito poucas músicas permanecem no top 100 por mais de 20 semanas.\n\ntop100musicas_longo|&gt; \n  ggplot(aes(x = semana, y = posicao, group = posicao)) + \n  geom_line(alpha = 0.25) + \n  scale_y_reverse()\n\n\n\n\n\n\nFigura 5.2: Um gráfico de linhas mostrando como as posições de uma música muda ao longo do tempo.\n\n\n\n\n\n5.3.2 Como a pivotagem funciona?\nAgora que você já viu como usar a pivotagem para mudar a forma de nossos dados, vamos tomar um tempinho para ganhar alguma intuição sobre o que a pivotagem faz com os dados. Vamos começar com um conjunto de dados bem simples para enxergamos com mais facilidade o que está acontecendo. Suponha que temos três pacientes com ids A, B e C, e fazemos a medição da pressão sanguínea duas vezes para cadas paciente. Vamos criar os dados com tribble(), uma função útil para construir pequenos conjuntos de dados (tibbles) manualmente:\n\n# ps - \"pressão sanguínea\"\ndf &lt;- tribble(\n  ~id,  ~ps1, ~ps2,\n   \"A\",  100,  120,\n   \"B\",  140,  115,\n   \"C\",  120,  125\n)\n\nNós queremos que nosso conjunto de dados tenham três variáveis: id (já existe), medicao (o nome das colunas), e valor (valor das células). Para obter essa forma, precisamos pivotar df para um formato mais longo:\n\ndf |&gt; \n  pivot_longer(\n    cols = ps1:ps2,\n    names_to = \"medicao\",\n    values_to = \"valor\"\n  )\n\n# A tibble: 6 × 3\n  id    medicao valor\n  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 A     ps1       100\n2 A     ps2       120\n3 B     ps1       140\n4 B     ps2       115\n5 C     ps1       120\n6 C     ps2       125\n\n\nComo funciona essa mudança de formato? É mais fácil de ver se pensarmos coluna por coluna. Como mostrado em Figura 5.3, os valores de uma coluna que já eram uma variável nos dados originais (id) precisam ser repetidos uma vez para cada coluna que foi pivotada.\n\n\n\n\n\n\n\nFigura 5.3: Colunas que já são variáveis precisam ser repetidas uma vez para cada coluna que é pivotada.\n\n\n\n\nOs nomes das colunas se tornam valores em uma nova variável, cujo nome foi definido pelo parâmetro names_to, conforme mostrado em Figura 5.4. Eles precisam ser repetidos uma vez para cada linha dos dados originais.\n\n\n\n\n\n\n\nFigura 5.4: Os nomes das colunas pivotadas se tornam valores em uma nova coluna. Os valores precisam ser reptidos uma vez para cada linha dos dados originais.\n\n\n\n\nOs valores das células também se tornam valores em uma nova variável, com o nome definido por values_to. Eles são “desenrolados” linha a linha. Figura 5.5 ilustra o processo.\n\n\n\n\n\n\n\nFigura 5.5: O número de valores é preservado (não repetidos), mas “desenrolado” linha-a-linha.\n\n\n\n\n\n5.3.3 Muitas variáveis nos nomes de colunas\nUma situação mais desafiadora ocorre quando tem-se muitas partes de informação aglomeradas nos nomes das colunas, e você gostaria de armazená-las em variáveis separadas. Por exemplo, pegue o conjunto de dados who2, que é a fonte da tabela1 e outros amigos que você viu acima:\n\nwho2\n\n# A tibble: 7,240 × 58\n   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554 sp_m_5564\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan  1980       NA        NA        NA        NA        NA        NA\n 2 Afghanistan  1981       NA        NA        NA        NA        NA        NA\n 3 Afghanistan  1982       NA        NA        NA        NA        NA        NA\n 4 Afghanistan  1983       NA        NA        NA        NA        NA        NA\n 5 Afghanistan  1984       NA        NA        NA        NA        NA        NA\n 6 Afghanistan  1985       NA        NA        NA        NA        NA        NA\n 7 Afghanistan  1986       NA        NA        NA        NA        NA        NA\n 8 Afghanistan  1987       NA        NA        NA        NA        NA        NA\n 9 Afghanistan  1988       NA        NA        NA        NA        NA        NA\n10 Afghanistan  1989       NA        NA        NA        NA        NA        NA\n# ℹ 7,230 more rows\n# ℹ 50 more variables: sp_m_65 &lt;dbl&gt;, sp_f_014 &lt;dbl&gt;, sp_f_1524 &lt;dbl&gt;,\n#   sp_f_2534 &lt;dbl&gt;, sp_f_3544 &lt;dbl&gt;, sp_f_4554 &lt;dbl&gt;, sp_f_5564 &lt;dbl&gt;,\n#   sp_f_65 &lt;dbl&gt;, sn_m_014 &lt;dbl&gt;, sn_m_1524 &lt;dbl&gt;, sn_m_2534 &lt;dbl&gt;,\n#   sn_m_3544 &lt;dbl&gt;, sn_m_4554 &lt;dbl&gt;, sn_m_5564 &lt;dbl&gt;, sn_m_65 &lt;dbl&gt;,\n#   sn_f_014 &lt;dbl&gt;, sn_f_1524 &lt;dbl&gt;, sn_f_2534 &lt;dbl&gt;, sn_f_3544 &lt;dbl&gt;,\n#   sn_f_4554 &lt;dbl&gt;, sn_f_5564 &lt;dbl&gt;, sn_f_65 &lt;dbl&gt;, ep_m_014 &lt;dbl&gt;, …\n\n\nEsse conjunto de dados, coletado pela Organização Mundial da Saúde (OMS)3, armazena informações sobre diagnósticos de tuberculose. Existem duas colunas que já são variáveis e parecem fáceis de interpretar: country e year. Em seguida vêm outras 56 colunas tais como sp_m_014, ep_m_4554 e rel_m_3544. Se você olhar com cuidado para essas colunas por tempo suficiente, verá que há um padrão. Cada nome de coluna é composto por três partes separadas por _. A primeira parte, sp/rel/ep, descreve o método utilizado para o diagnóstico, a segunda parte, m/f é o gênero - gender (codificado como uma variável binária nesse conjunto de dados), e a terceira parte, 014/1524/2534/3544/4554/5564/65 é o intervalo de idade - age (014 representa 0-14, por exemplo).\nEntão, nesse caso temos seis partes de informação registrados em who2: o país (country) e o ano (year) (já nas colunas); o método diagnóstico, a categoria do gênero, e a categoria do intervalo de idade (contido nos outros nomes de colunas); e a contagem dos pacientes em naquela categoria (valores das células). Para organizar essas seis partes de informação em seis colunas separadas, utilizaremos pivot_longer() passando um vetor de nomes de colunas para o parâmetro names_to, instruções para separar, nas partes, os nomes originais das variáveis para o parâmetro names_sep e um nome de coluna para values_to:\n\nwho2 |&gt; \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\",\n    values_to = \"count\"\n  )\n\n# A tibble: 405,440 × 6\n   country      year diagnosis gender age   count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n 1 Afghanistan  1980 sp        m      014      NA\n 2 Afghanistan  1980 sp        m      1524     NA\n 3 Afghanistan  1980 sp        m      2534     NA\n 4 Afghanistan  1980 sp        m      3544     NA\n 5 Afghanistan  1980 sp        m      4554     NA\n 6 Afghanistan  1980 sp        m      5564     NA\n 7 Afghanistan  1980 sp        m      65       NA\n 8 Afghanistan  1980 sp        f      014      NA\n 9 Afghanistan  1980 sp        f      1524     NA\n10 Afghanistan  1980 sp        f      2534     NA\n# ℹ 405,430 more rows\n\n\nUma alternativa a names_sep é names_pattern, que você pode usar para extrair variáveis em nomenclaturas mais complicadas, desde que você já tenha aprendido a usar expressões regulares Capítulo 15.\nConceitualmente, essa seria só uma pequena variação desse caso mais simples que você acabou de ver. Figura 5.6 mostra a ideia básica: agora, em vez da coluna de nomes pivotar para uma única coluna, ela pivota para múltiplas colunas. Você pode imaginar isso acontecendo em dois passos (primeiro pivotando e depois separando) mas no fundo, tudo ocorre em um único passo porque é mais rápido.\n\n\n\n\n\n\n\nFigura 5.6: Pivotar colunas com múltiplas partes de informação nos nomes significa que cada nome agora vai preencher valores em múltiplas colunas como saída.\n\n\n\n\n\n5.3.4 Dados e nomes de variáveis nos cabeçalhos das colunas\nO próximo degrau em complexidade é quando os nomes das colunas incluem uma mistura de nomes e valores das variáveis. Por exemplo, vamos pegar o conjunto de dados nucleo_familiar:\n\nnucleo_familiar\n\n# A tibble: 5 × 5\n  familia datanascimento_crianca1 datanascimento_crianca2 nome_crianca1\n    &lt;int&gt; &lt;date&gt;                  &lt;date&gt;                  &lt;chr&gt;        \n1       1 1998-11-26              2000-01-29              Susan        \n2       2 1996-06-22              NA                      Mark         \n3       3 2002-07-11              2004-04-05              Sam          \n4       4 2004-10-10              2009-08-27              Craig        \n5       5 2000-12-05              2005-02-28              Parker       \n# ℹ 1 more variable: nome_crianca2 &lt;chr&gt;\n\n\nNesse conjunto temos dados de cinco famílias, com nomes e datas de nascimento de até duas crianças. O novo desafio é que nesses dados os nomes das colunas contêm os nomes de duas variáveis (data_nascimento, nome) e os valores de outra (criança - crianca, com valores 1 ou 2). Para resolver esse problema, novamente precisamods passar um vetor para names_to, mas dessa vamos vamos passar um parâmetro especial \".value\" (chamado de sentinel); esse parâmetro não é o nome de uma variável, mas um valor único que diz ao pivot_longer() para fazer algo diferente com ele. Isso sobrepõe o argumento values_to normal em favor do primeiro componente do nome da coluna pivotada, utilizado como nome da variável na saída da função.\n\nnucleo_familiar |&gt;\n  pivot_longer(\n    cols = !familia,\n    names_to = c(\".value\", \"crianca\"),\n    names_sep = \"_\",\n    values_drop_na = TRUE\n  )\n\n# A tibble: 9 × 4\n  familia crianca  datanascimento nome  \n    &lt;int&gt; &lt;chr&gt;    &lt;date&gt;         &lt;chr&gt; \n1       1 crianca1 1998-11-26     Susan \n2       1 crianca2 2000-01-29     Jose  \n3       2 crianca1 1996-06-22     Mark  \n4       3 crianca1 2002-07-11     Sam   \n5       3 crianca2 2004-04-05     Seth  \n6       4 crianca1 2004-10-10     Craig \n7       4 crianca2 2009-08-27     Khai  \n8       5 crianca1 2000-12-05     Parker\n9       5 crianca2 2005-02-28     Gracie\n\n\nNovamente utilizaremos values_drop_na = TRUE, uma vez que a forma da entrada força a criação de variáveis ausentes explícitas (ex: para famílias com apenas um filho).\nFigura 5.7 ilustra a ideia básica em um exemplo mais simples. Quando você utiliza \".value\" em names_to, a coluna de nomes dos dados de entrada contribui tanto para os valores quanto para os nomes das variáveis na saída.\n\n\n\n\n\n\n\nFigura 5.7: Pivotar com names_to = c(\".value\", \"num\") divide os nomes das colunas em dois componentes: a primeira parte determina o nome da coluna da saída, (x ou y), e a segunda parte determina o valore da coluna num.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#transformando-os-dados-para-o-formato-largo-widening-data",
    "href": "data-tidy.html#transformando-os-dados-para-o-formato-largo-widening-data",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "\n5.4 Transformando os dados para o formato largo (Widening data)",
    "text": "5.4 Transformando os dados para o formato largo (Widening data)\nAté então, utilizamos pivot_longer() para resolver um tipo comum de problemas no qual os valores foram movidos para os nomes de colunas. Agora vamos pivotar (HA HA) para pivot_wider(), que vai tornar o conjunto de dados mais largo (wider) ao aumentar o número de colunas e diminuir o número de linhas, auxiliando quando uma informação está espalhada em múltiplas linhas. Isso tende a aparecer menos na vida real, mas parece ser comum quando estamos lidando com dados governamentais.\nComeçaremos dando uma olhada em cms_paciente_experiencia, um conjunto de dados de serviços do Centers of Medicare and Medicaid que coleta dados sobre as experiências dos pacientes:\n\ncms_paciente_experiencia\n\n# A tibble: 500 × 5\n   organizacao_id organizacao_nome  medida_codigo medida_titulo taxa_performance\n   &lt;chr&gt;          &lt;chr&gt;             &lt;chr&gt;         &lt;chr&gt;                    &lt;dbl&gt;\n 1 0446157747     USC CARE MEDICAL… CAHPS_GRP_1   Obtenção de …               63\n 2 0446157747     USC CARE MEDICAL… CAHPS_GRP_2   O quão bem o…               87\n 3 0446157747     USC CARE MEDICAL… CAHPS_GRP_3   CAHPS for MI…               86\n 4 0446157747     USC CARE MEDICAL… CAHPS_GRP_5   Promoção e e…               57\n 5 0446157747     USC CARE MEDICAL… CAHPS_GRP_8   Equipe do co…               85\n 6 0446157747     USC CARE MEDICAL… CAHPS_GRP_12  Administraçã…               24\n 7 0446162697     ASSOCIATION OF U… CAHPS_GRP_1   Obtenção de …               59\n 8 0446162697     ASSOCIATION OF U… CAHPS_GRP_2   O quão bem o…               85\n 9 0446162697     ASSOCIATION OF U… CAHPS_GRP_3   CAHPS for MI…               83\n10 0446162697     ASSOCIATION OF U… CAHPS_GRP_5   Promoção e e…               63\n# ℹ 490 more rows\n\n\nA unidade principal sendo estudada é a organização, mas cada organização está espalhada em seis linhas, com uma linha para cada medição feita pela pesquisa. Nós podemos ver o conjunto completo dos valores de medida_codigo e medida_titulo utilizando a função distinct():\n\ncms_paciente_experiencia |&gt; \n  distinct(medida_codigo, medida_titulo)\n\n# A tibble: 6 × 2\n  medida_codigo medida_titulo                                                 \n  &lt;chr&gt;         &lt;chr&gt;                                                         \n1 CAHPS_GRP_1   Obtenção de cuidados, consultas e informações no momento certo\n2 CAHPS_GRP_2   O quão bem os provedores se comunicam                         \n3 CAHPS_GRP_3   CAHPS for MIPS SSM: Patient's Rating of Provider              \n4 CAHPS_GRP_5   Promoção e educação em saúde                                  \n5 CAHPS_GRP_8   Equipe do consultório cortês e prestativa                     \n6 CAHPS_GRP_12  Administração dos recursos do paciente                        \n\n\nNenhuma dessas colunas irá gerar nomes espetaculares: medida_codigo não dá nenhuma pista quanto ao significado da variável e medida_titulo é uma longa frase, com espaços, Por enquanto, nós utilizaremos medida_codigo como a fonte de nossa nova coluna de nomes, mas em uma análise real você deveria considerar seu próprio nome de variável, que deve ser curto e informativo.\npivot_wider() tem a interface oposta à pivot_longer(): em vez de escolher o novo nome das colunas, nós precisamos fornecer as colunas existentes que definem os valores de (values_from) e o nome da coluna (names_from):\n\ncms_paciente_experiencia |&gt; \n  pivot_wider(\n    names_from = medida_codigo,\n    values_from = taxa_performance\n  )\n\n# A tibble: 500 × 9\n   organizacao_id organizacao_nome         medida_titulo CAHPS_GRP_1 CAHPS_GRP_2\n   &lt;chr&gt;          &lt;chr&gt;                    &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt;\n 1 0446157747     USC CARE MEDICAL GROUP … Obtenção de …          63          NA\n 2 0446157747     USC CARE MEDICAL GROUP … O quão bem o…          NA          87\n 3 0446157747     USC CARE MEDICAL GROUP … CAHPS for MI…          NA          NA\n 4 0446157747     USC CARE MEDICAL GROUP … Promoção e e…          NA          NA\n 5 0446157747     USC CARE MEDICAL GROUP … Equipe do co…          NA          NA\n 6 0446157747     USC CARE MEDICAL GROUP … Administraçã…          NA          NA\n 7 0446162697     ASSOCIATION OF UNIVERSI… Obtenção de …          59          NA\n 8 0446162697     ASSOCIATION OF UNIVERSI… O quão bem o…          NA          85\n 9 0446162697     ASSOCIATION OF UNIVERSI… CAHPS for MI…          NA          NA\n10 0446162697     ASSOCIATION OF UNIVERSI… Promoção e e…          NA          NA\n# ℹ 490 more rows\n# ℹ 4 more variables: CAHPS_GRP_3 &lt;dbl&gt;, CAHPS_GRP_5 &lt;dbl&gt;, CAHPS_GRP_8 &lt;dbl&gt;,\n#   CAHPS_GRP_12 &lt;dbl&gt;\n\n\nA saída ainda não parece muito correta; parece que ainda precisamos de múltiplas linhas para cada organização. Isso é por que também precisamos dizer à pivot_wider() qual a coluna ou colunas têm valores que identificam cada linha de forma única; nesse caso são as variáveis que começam com \"org\":\n\ncms_paciente_experiencia |&gt; \n  pivot_wider(\n    id_cols = starts_with(\"organizacao\"),\n    names_from = medida_codigo,\n    values_from = taxa_performance\n  )\n\n# A tibble: 95 × 8\n   organizacao_id organizacao_nome           CAHPS_GRP_1 CAHPS_GRP_2 CAHPS_GRP_3\n   &lt;chr&gt;          &lt;chr&gt;                            &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 0446157747     USC CARE MEDICAL GROUP INC          63          87          86\n 2 0446162697     ASSOCIATION OF UNIVERSITY…          59          85          83\n 3 0547164295     BEAVER MEDICAL GROUP PC             49          NA          75\n 4 0749333730     CAPE PHYSICIANS ASSOCIATE…          67          84          85\n 5 0840104360     ALLIANCE PHYSICIANS INC             66          87          87\n 6 0840109864     REX HOSPITAL INC                    73          87          84\n 7 0840513552     SCL HEALTH MEDICAL GROUP …          58          83          76\n 8 0941545784     GRITMAN MEDICAL CENTER INC          46          86          81\n 9 1052612785     COMMUNITY MEDICAL GROUP L…          65          84          80\n10 1254237779     OUR LADY OF LOURDES MEMOR…          61          NA          NA\n# ℹ 85 more rows\n# ℹ 3 more variables: CAHPS_GRP_5 &lt;dbl&gt;, CAHPS_GRP_8 &lt;dbl&gt;, CAHPS_GRP_12 &lt;dbl&gt;\n\n\nIsso gera a saída que estávamos esperando.\n\n5.4.1 Como funciona a função pivot_wider()?\nPara entender como a função pivot_wider() funciona, vamos novamente começar com um conjunto de dados bem simples. Agora temos dois pacientes com ids A e B, e temos três medições de pressão sanguínea para o paciente A e duas para o paciente B:\n\ndf &lt;- tribble(\n  ~id, ~medida, ~valor,\n  \"A\",        \"ps1\",    100,\n  \"B\",        \"ps1\",    140,\n  \"B\",        \"ps2\",    115, \n  \"A\",        \"ps2\",    120,\n  \"A\",        \"ps3\",    105\n)\n\nVamos pegar os valores da coluna valor e os nomes da coluna medida:\n\ndf |&gt;\n  pivot_wider(\n    names_from = medida,\n    values_from = valor\n  )\n\n# A tibble: 2 × 4\n  id      ps1   ps2   ps3\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 A       100   120   105\n2 B       140   115    NA\n\n\nPara iniciar o processo, a função pivot_wider() precisa primeiramente entender o que será distribuído para as linhas e colunas. Os novos nomes de coluna serão os valores únicos de medida.\n\ndf |&gt; \n  distinct(medida) |&gt; \n  pull()\n\n[1] \"ps1\" \"ps2\" \"ps3\"\n\n\nPor padrão, as linhas da saída são determinadas por todas as demais variáveis que não estão indo para os novos nomes ou valores. Essas são chamadas id_cols. Aqui temos apenas uma coluna, mas em geral, pode haver qualquer número delas.\n\ndf |&gt; \n  select(-medida, -valor) |&gt; \n  distinct()\n\n# A tibble: 2 × 1\n  id   \n  &lt;chr&gt;\n1 A    \n2 B    \n\n\nA função pivot_wider() então combina esses resultados para gerar um data frame vazio:\n\ndf |&gt; \n  select(-medida, -valor) |&gt; \n  distinct() |&gt; \n  mutate(x = NA, y = NA, z = NA)\n\n# A tibble: 2 × 4\n  id    x     y     z    \n  &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n1 A     NA    NA    NA   \n2 B     NA    NA    NA   \n\n\nE em seguida, preenche todos os valores ausentes com os dados de entrada. Nesse caso, nem todas as células da saída possuem um valor correspondente na entrada visto que não temos a terceira medição de pressão para o paciente B, então aquela célula permanecerá vazia. Voltaremos a essa ideia de que a pivot_wider() pode “produzir” valores ausentes em Capítulo 18.\nVocê pode também estar se perguntando se há várias linhas na entrada que correspondem a apenas uma célula na saída. O exemplo abaixo, possui duas linhas que correspondem ao id “A” à medida “ps1”:\n\ndf &lt;- tribble(\n  ~id, ~medida, ~valor,\n  \"A\",        \"ps1\",    100,\n  \"A\",        \"ps1\",    102,\n  \"A\",        \"ps2\",    120,\n  \"B\",        \"ps1\",    140, \n  \"B\",        \"ps2\",    115\n)\n\nSe tentarmos pivotar essa tabela teremos uma saída que contém estruturas chamadas colunas de listas (list-columns), sobre as quais você aprenderá mais em Capítulo 23:\n\ndf |&gt;\n  pivot_wider(\n    names_from = medida,\n    values_from = valor\n  )\n\nWarning: Values from `valor` are not uniquely identified; output will contain list-cols.\n• Use `values_fn = list` to suppress this warning.\n• Use `values_fn = {summary_fun}` to summarise duplicates.\n• Use the following dplyr code to identify duplicates.\n  {data} |&gt;\n  dplyr::summarise(n = dplyr::n(), .by = c(id, medida)) |&gt;\n  dplyr::filter(n &gt; 1L)\n\n\n# A tibble: 2 × 3\n  id    ps1       ps2      \n  &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\n\nComo você ainda não sabe como trabalhar com esse tipo de estrutura, você deve seguir as dicas que aparecem na mensagem de alerta (warning) para entender onde está o problema:\n\ndf |&gt; \n  group_by(id, medida) |&gt; \n  summarize(n = n(), .groups = \"drop\") |&gt; \n  filter(n &gt; 1)\n\n# A tibble: 1 × 3\n  id    medida     n\n  &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;\n1 A     ps1        2\n\n\nAí então, você fica a cargo de entender o que deu de errado com os dados e ajustar os problemas já ocorridos ou utilizar suas habilidades de agrupar e resumir os dados originais para se certificar que que cada combinação dos valores de linhas e colunas estejam em apenas uma linha.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#resumo",
    "href": "data-tidy.html#resumo",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "\n5.5 Resumo",
    "text": "5.5 Resumo\nNesse capítulo você aprendeu sobre dados no formato tidy: dados que possuem variáveis nas colunas e observações nas linhas. Dados nesse formato facilitam o trabalho no tidyverse, pois sua estrutura consistente é entendida pela maioria das funções. O principal desafio, então, é transformar dados provenientes de quaisquer estruturas que você receber para o formato tidy. Para esse fim, você aprendeu sobre pivot_longer() e pivot_wider() que permitem a organização de vários conjuntos de dados que ainda não estejam no formato tidy. Os exemplos apresentados aqui são uma seleção dos vários presentes em vignette(\"pivot\", package = \"tidyr\"), então, se você encontrar algum problema com o qual esse capítulo ainda não é capaz de te ajudar, é uma boa ideia checar nessa vignette.\nUm outro desafio é o fato de que para certos conjuntos de dados, pode ser impossível especificar se a versão longa (long) ou larga (wide) é a versão tidy. Isso é, em parte, um reflexo da nossa definição de dados tidy, em que dizemos que cada coluna deve conter uma variável, mas não definimos, de fato, o que é uma variável (e fazer isso é surpreendentemente difícil.) É totalmente aceitável dizer, de uma forma pragmática, que uma variável é qualquer coisa que facilite sua análise. Então, se tiver difícil descobrir como fazer algum tipo de cálculo ou análise, considere alterar a forma como seus dados estão organizados; não tenha medo de voltar para um formato untidy, transformá-lo e depois reorganizá-lo conforme necessário!\nSe você gostou desse capítulo e quiser saber mais sobre a teoria por trás dele, você pode se aprofundar sobre a história e os fundamentos teóricos no artigo Tidy Data publicado no Journal of Statistical Software.\nE agora que você já está escrevendo uma quantidade considerável de código em R, é a hora de aprender um pouco mais sobre como organizar o seu código em arquivos e diretórios. No próximo capítulo, você irá aprender sobre todas as vantagens dos scripts e projetos, e algumas das várias ferramentas que eles disponibilizam para tornar sua vida mais fácil.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "data-tidy.html#footnotes",
    "href": "data-tidy.html#footnotes",
    "title": "5  ✅ Organizando os dados (data tidying)",
    "section": "",
    "text": "A música será incluída aos dados desde que tenha estado no top 100 em algum momento do ano 2000, e então será monitorada por até 72 semanas após a primeira aparição.↩︎\nVoltaremos a essas ideias em Capítulo 18.↩︎\nNota de tradução: do inglês World Health Organisation - WHO que é nome do conjunto de dados.↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>✅ Organizando os dados (*data tidying*)</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html",
    "href": "workflow-scripts.html",
    "title": "6  ✅ Fluxo de trabalho: scripts e projetos",
    "section": "",
    "text": "6.1 Scripts\nAté agora você usou o console para executar códigos. O console é um ótimo lugar para começar, mas com o tempo você perceberá que ele vai ficando apertado à medida que criamos gráficos mais complexos com ggplot2 e pipelines mais longas com dplyr. Para ter mais espaço para trabalhar, use o editor de scripts. Abra-o clicando no menu Arquivo, selecionando Novo Arquivo e depois R script, ou usando o atalho de teclado Cmd/Ctrl + Shift + N. Agora você verá quatro painéis, como na Figura 6.1. O editor de scripts é um ótimo lugar para experimentar com seu código. Quando você quiser mudar algo, não precisa reescrever tudo, pode apenas editar o script e executá-lo novamente. E uma vez que você tenha escrito um código que funcione e faça o que você quer, pode salvá-lo como um arquivo de script para retornar a ele facilmente mais tarde.\nFigura 6.1: Abrir o editor de script adiciona um novo painel no canto superior esquerdo da interface de usuário do RStudio.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>✅ Fluxo de trabalho: scripts e projetos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#scripts",
    "href": "workflow-scripts.html#scripts",
    "title": "6  ✅ Fluxo de trabalho: scripts e projetos",
    "section": "",
    "text": "6.1.1 Rodando código\nO editor de scripts é um excelente lugar para construir gráficos complexos com ggplot2 ou sequências longas de manipulações com dplyr. O segredo para usar o editor de scripts de forma eficaz é memorizar um dos atalhos de teclado mais importantes: Cmd/Ctrl + Enter. Isso executa o trecho de código atual no console. Por exemplo, veja o código abaixo.\n\nlibrary(dplyr)\nlibrary(dados)\n\nnao_cancelado &lt;- voos %&gt;% \n  filter(!is.na(atraso_saida)█, !is.na(atraso_chegada))\n\nnao_cancelado %&gt;% \n  group_by(ano, mes, dia) %&gt;% \n  summarize(media = mean(atraso_saida))\n\nSe o seu cursor estiver em █, pressionar Cmd/Ctrl + Enter executará o comando completo que gera nao_cancelado. Também moverá o cursor para a declaração seguinte (começando com nao_cancelado |&gt;). Isso torna fácil percorrer o script completo pressionando repetidamente Cmd/Ctrl + Enter.\nEm vez de executar seu código expressão por expressão, você também pode executar o script completo em um único passo com Cmd/Ctrl + Shift + S. Fazer isso regularmente é uma ótima maneira de garantir que você capturou todas as partes importantes do seu código no script.\nRecomendamos que você sempre comece seu script carregando os pacotes de que precisa. Dessa forma, se você compartilhar seu código com outras pessoas, elas poderão ver facilmente quais pacotes precisam instalar. Observe, no entanto, que você nunca deve incluir install.packages() em um script que compartilha. É imprudente passar adiante um script que fará alterações no computador de alguém considerando que a pessoa pode não estar atenta ao que está fazendo!\nAo trabalhar nos próximos capítulos, recomendamos fortemente que você comece no editor de scripts e pratique seus atalhos de teclado. Com o tempo, enviar código para o console dessa maneira se tornará tão natural que você nem pensará sobre isso.\n\n6.1.2 Diagnosticando problemas no código\nNo editor de scripts, o RStudio destacará erros de sintaxe com uma linha ondulada vermelha e um X na barra lateral:\n\n\n\n\n\n\n\n\nPara saber mais sobre o problema, passe o mouse sobre o X:\n\n\n\n\n\n\n\n\nO RStudio também informará sobre problemas em potencial:\n\n\n\n\n\n\n\n\n\n6.1.3 Salvando e nomeando\nO RStudio salva automaticamente o conteúdo do editor de scripts quando você sai e recarrega automaticamente quando você reabre. Contudo, é altamente recomendável evitar os nomes como Untitled1, Untitled2, Untitled3, etc, que são o padrão para arquivos não nomeados. Salve seus scripts e atribua a eles nomes que façam sentido.\nPode ser tentador nomear seus arquivos codigo.R ou meuscript.R, mas você deve pensar um pouco mais antes de escolher um nome para seu arquivo. Três princípios importantes para nomear arquivos são os seguintes:\n\nOs nomes dos arquivos devem ser legíveis por máquina: evite espaços, símbolos e caracteres especiais. Não confie na sensibilidade a maiúsculas e minúsculas para distinguir arquivos.\nOs nomes dos arquivos devem ser legíveis por humanos: use nomes de arquivos para descrever o que está no arquivo.\nOs nomes dos arquivos devem se dar bem com a ordenação padrão: comece os nomes dos arquivos com números para que a ordenação alfabética os coloque na ordem em que são usados.\n\nPor exemplo, suponha que você tenha os seguintes arquivos em uma pasta de projeto.\nmodelo alternativo.R\ncodigo para analise exploratoria.r\nrelatoriofinal.qmd\nRelatorioFinal.qmd\nfig 1.png\nFigura_02.png\nprimeira_tentativa_modelo.R\nexecutar-primeiro.r\ntemporario.txt\nExistem vários problemas aqui: é difícil encontrar qual arquivo executar primeiro, os nomes dos arquivos contêm espaços, existem dois arquivos com o mesmo nome, um com caixa alta na primeira letra e outro sem (relatoriofinal vs. RelatorioFinal1), e alguns nomes não descrevem seu conteúdo (executar-primeiro e temporario).\nAqui está uma maneira melhor de nomear e organizar o mesmo conjunto de arquivos:\n01-carregar-dados.R\n02-analise-exploratoria.R\n03-modelo-abordagem-1.R\n04-modelo-abordagem-2.R\nfig-01.png\nfig-02.png\nrelatorio-2022-03-20.qmd\nrelatorio-2022-04-02.qmd\nnotas-rascunho-relatorio.txt\nNumerar os scripts principais torna óbvio a ordem em que devem ser executados e um esquema de nomenclatura consistente facilita a visualização do que varia. Além disso, as figuras são rotuladas de maneira semelhante, os relatórios são distinguidos por datas incluídas nos nomes dos arquivos, e temporario é renomeado para notas-rascunho-relatorio para descrever melhor seu conteúdo. Se você tem muitos arquivos em um diretório, é recomendado levar a organização um passo adiante e colocar diferentes tipos de arquivos (scripts, figuras, etc.) em diretórios diferentes.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>✅ Fluxo de trabalho: scripts e projetos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#projetos",
    "href": "workflow-scripts.html#projetos",
    "title": "6  ✅ Fluxo de trabalho: scripts e projetos",
    "section": "\n6.2 Projetos",
    "text": "6.2 Projetos\nUm dia, você precisará sair do R, fazer outra coisa e voltar para a sua análise mais tarde. Um dia, você estará trabalhando em várias análises simultaneamente e vai querer mantê-las separadas. Um dia, você precisará trazer dados do mundo externo para o R e enviar resultados numéricos e figuras do R para o mundo externo.\nPara lidar com essas situações da vida real, você precisa tomar duas decisões:\n\nQual é a fonte da verdade? O que você vai salvar como seu registro final do que aconteceu?\nOnde é o lar da sua análise?\n\n\n6.2.1 Qual é a fonte da verdade?\nComo iniciante, é aceitável confiar no seu Ambiente (Environment) atual para guardar todos os objetos que você criou durante sua análise. No entanto, para facilitar o trabalho em projetos maiores ou colaborar com outros, sua fonte da verdade deveriam ser os scripts R. Com seus scripts R (e seus arquivos de dados), você pode recriar o ambiente (Environment). Com apenas o seu ambiente, é muito mais difícil recriar seus scripts R: você terá que digitar novamente muito código de memória (inevitavelmente cometendo erros ao longo do caminho) ou terá que cuidadosamente extrair seu histórico R.\nPara ajudar a manter seus scripts R como a fonte da verdade para sua análise, recomendamos fortemente que você instrua o RStudio a não preservar seu espaço de trabalho (workspace) entre as sessões. Você pode fazer isso executando usethis::use_blank_slate()2 ou imitando as opções mostradas na Figura 6.2. Isso causará alguma dor a curto prazo, porque agora, quando você reiniciar o RStudio, ele não se lembrará do código que você executou na última vez, nem os objetos que você criou ou os conjuntos de dados que você leu estarão disponíveis para uso. Mas essa dor a curto prazo poupa-lhe agonia a longo prazo, pois força você a capturar todos os procedimentos importantes em seu código. Não há nada pior do que descobrir três meses depois que você só armazenou os resultados de um cálculo importante em seu ambiente, não o próprio cálculo em seu código.\n\n\n\n\n\n\n\nFigura 6.2: Copie estas opções nas suas opções do RStudio para sempre iniciar sua sessão do RStudio com um ambiente (Environment) limpo.\n\n\n\n\nExiste um ótimo par de atalhos de teclado que trabalham juntos para garantir que você tenha capturado as partes importantes do seu código no editor:\n\nPressione Cmd/Ctrl + Shift + 0/F10 para reiniciar o R.\nPressione Cmd/Ctrl + Shift + S para executar novamente o script atual.\n\nNós usamos coletivamente este padrão centenas de vezes por semana.\nAlternativamente, se você não usa atalhos de teclado, você pode ir para Sessão &gt; Reiniciar R e então destacar e executar novamente o seu script atual.\n\n\n\n\n\n\nRStudio server\n\n\n\nSe você está usando o RStudio server, sua sessão R nunca é reiniciada por padrão. Quando você fecha a aba do seu RStudio server, pode parecer que você está fechando o R, mas o servidor na verdade continua rodando em segundo plano. Na próxima vez que você retornar, você estará exatamente no mesmo lugar que deixou. Isso torna ainda mais importante reiniciar regularmente o R para que você esteja começando com um ambiente limpo.\n\n\n\n6.2.2 Onde é o “lar” da sua análise?\nO R tem um poderoso conceito de diretório de trabalho. Este é o local onde o R procura por arquivos que você pede para carregar, e onde ele colocará quaisquer arquivos que você pedir para salvar. O RStudio mostra o seu diretório de trabalho atual no topo do console:\n\n\n\n\n\n\n\n\nE você pode imprimir isso em código R executando getwd():\n\ngetwd()\n#&gt; [1] \"/Users/hadley/Documents/r4ds\"\n\nNesta sessão R, o diretório de trabalho atual (pense nele como “casa”) está na pasta Documentos do Hadley, em uma subpasta chamada r4ds. Este código retornará um resultado diferente quando você executá-lo, porque a estrutura de diretórios do seu computador é diferente da do Hadley!\nComo um usuário iniciante de R, está tudo bem em deixar o seu diretório de trabalho ser o seu diretório inicial, diretório de documentos, ou qualquer outro diretório estranho no seu computador. Mas você já leu sete capítulos deste livro, e você não é mais um iniciante. Muito em breve, você deve evoluir para organizar seus projetos em diretórios e, ao trabalhar em um projeto, definir o diretório de trabalho do R para o diretório associado.\nVocê pode definir o diretório de trabalho a partir do próprio R, mas nós não recomendamos isso:\n\nsetwd(\"/caminho/para/meu/ProjetoLegal\")\n\nExiste uma maneira melhor; uma maneira que também te coloca no caminho para gerenciar seu trabalho em R como um especialista. Essa maneira é o projeto do RStudio.\n\n6.2.3 Projetos do RStudio\nManter todos os arquivos associados a um determinado projeto (dados de entrada, scripts R, resultados analíticos e figuras) juntos em um diretório é uma prática tão sábia e comum que o RStudio tem suporte integrado para isso através de projetos. Vamos criar um projeto para você usar enquanto trabalha no restante deste livro. Clique em Arquivo &gt; Novo Projeto, e então siga os passos mostrados em Figura 6.3.\n\n\n\n\n\n\n\nFigura 6.3: Para criar um novo projeto: (topo) primeiro clique em Novo Diretório, depois (meio) clique em Novo Projeto, então (abaixo) preencha o nome do diretório (projeto), escolha um bom subdiretório para ser o “lar” do seu projeto, e clique em Criar Projeto.\n\n\n\n\nNomeie seu projeto como r4ds e pense cuidadosamente sobre qual subdiretório você colocará o projeto. Se você não armazená-lo em algum lugar que faça sentido, será difícil encontrá-lo no futuro!\nUma vez que esse processo esteja completo, você terá um novo projeto RStudio apenas para este livro. Verifique se o “lar” do seu projeto é o diretório de trabalho atual:\n\ngetwd()\n#&gt; [1] /Users/hadley/Documents/r4ds\n\nAgora insira os seguintes comandos no editor de scripts e salve o arquivo, chamando-o de “diamantes.R”. Em seguida, crie uma nova pasta chamada “dados”. Você pode fazer isso clicando no botão “Nova Pasta” no painel de Arquivos no RStudio. Finalmente, execute o script completo, que salvará um arquivo PNG e CSV no diretório do seu projeto. Não se preocupe com os detalhes, você aprenderá mais tarde no livro.\n\nlibrary(dados)\n\nggplot(diamante, aes(x = quilate, y = preco)) + \n  geom_hex()\nggsave(\"diamantes.png\")\n\nwrite_csv(diamante, \"dados/diamantes.csv\")\n\nFeche o RStudio. Inspecione a pasta associada ao seu projeto - observe o arquivo .Rproj. Dê um duplo clique nesse arquivo para reabrir o projeto. Observe que você volta para onde parou: é o mesmo diretório de trabalho e histórico de comandos, e todos os arquivos em que você estava trabalhando ainda estão abertos. Porque você seguiu nossas instruções acima, você terá, no entanto, um ambiente completamente novo, garantindo que você está começando com uma folha em branco.\nDa maneira que preferir no seu sistema operacional, pesquise no seu computador por diamantes.png e você encontrará o PNG (sem surpresa) mas também o script que o criou (diamantes.R). Isso é ótimo! Um dia, você vai querer refazer uma figura ou apenas entender de onde ela veio. Se você rigorosamente salvar figuras em arquivos com código R e nunca com o mouse ou a área de transferência, você será capaz de reproduzir trabalhos antigos com facilidade!\n\n6.2.4 Caminhos relativos e absolutos\nUma vez que você está dentro de um projeto, você deve usar apenas caminhos relativos, não caminhos absolutos. Qual é a diferença? Um caminho relativo é relativo ao diretório de trabalho, ou seja, a “casa” do projeto. Quando Hadley escreveu dados/diamantes.csv acima, era um atalho para /Users/hadley/Documents/r4ds/data/diamantes.csv. Mas, importante, se a Mine executasse este código em seu computador, apontaria para /Users/Mine/Documents/r4ds/data/diamantes.csv. É por isso que os caminhos relativos são importantes: eles funcionarão independentemente de onde a pasta do projeto R terminar.\nOs caminhos absolutos apontam para o mesmo lugar, independentemente do seu diretório de trabalho. Eles parecem um pouco diferentes dependendo do seu sistema operacional. No Windows, eles começam com uma letra de unidade (por exemplo, C:) ou duas barras invertidas (por exemplo, \\\\servername) e no Mac/Linux eles começam com uma barra “/” (por exemplo, /users/hadley). Você nunca deve usar caminhos absolutos em seus scripts, porque eles dificultam o compartilhamento: ninguém mais terá exatamente a mesma configuração de diretório que você.\nHá outra diferença importante entre os sistemas operacionais: como você separa os componentes do caminho. Mac e Linux usam barras (por exemplo, dados/diamantes.csv) e o Windows usa barras invertidas (por exemplo, dados\\diamantes.csv). O R pode trabalhar com qualquer tipo (não importa a plataforma que você está usando atualmente), mas infelizmente, barras invertidas significam algo especial para o R, e para obter uma única barra invertida no caminho, você precisa digitar duas barras invertidas! Isso pode te frustrar, então recomendamos sempre usar o estilo do Linux/Mac com barras normais.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>✅ Fluxo de trabalho: scripts e projetos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#exercícios",
    "href": "workflow-scripts.html#exercícios",
    "title": "6  ✅ Fluxo de trabalho: scripts e projetos",
    "section": "\n6.3 Exercícios",
    "text": "6.3 Exercícios\n\nAcesse a conta do Twitter RStudio Tips (em inglês), https://twitter.com/rstudiotips e encontre uma dica que pareça interessante. Pratique usá-la!\nQuais outros erros comuns o diagnóstico do RStudio irá reportar? Leia (em inglês) https://support.posit.co/hc/en-us/articles/205753617-Code-Diagnostics para descobrir.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>✅ Fluxo de trabalho: scripts e projetos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#sumário",
    "href": "workflow-scripts.html#sumário",
    "title": "6  ✅ Fluxo de trabalho: scripts e projetos",
    "section": "\n6.4 Sumário",
    "text": "6.4 Sumário\nNeste capítulo, você aprendeu como organizar seu código R em scripts (arquivos) e projetos (diretórios). Assim como o estilo de código, isso pode parecer trabalho desnecessário no início. Mas à medida que você acumula mais código em vários projetos, você aprenderá a apreciar como uma pequena organização inicial pode economizar muito tempo no futuro.\nEm resumo, scripts e projetos fornecem um fluxo de trabalho sólido que te servirá bem no futuro:\n\nCrie um projeto RStudio para cada projeto de análise de dados.\nSalve seus scripts (com nomes informativos) no projeto, edite-os, execute-os em partes ou como um todo. Reinicie o R frequentemente para garantir que você capturou tudo em seus scripts.\nUse apenas caminhos relativos, nunca caminhos absolutos.\n\nEntão tudo que você precisa está em um lugar e claramente separado de todos os outros projetos em que você está trabalhando.\nAté agora, trabalhamos com conjuntos de dados incluídos em pacotes R. Isso facilita a prática em dados pré-preparados, mas obviamente seus dados não estarão disponíveis desta forma. Então, no próximo capítulo, você vai aprender como carregar dados do computador para a sua sessão R usando o pacote readr.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>✅ Fluxo de trabalho: scripts e projetos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#footnotes",
    "href": "workflow-scripts.html#footnotes",
    "title": "6  ✅ Fluxo de trabalho: scripts e projetos",
    "section": "",
    "text": "Sem mencionar que você está flertando com o azar ao usar “final” no nome 😆 A tirinha Piled Higher and Deeper tem uma divertida historinha sobre isso.↩︎\nSe você não tem o pacote usethis instalado, você pode instalá-lo com install.packages(\"usethis\").↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>✅ Fluxo de trabalho: scripts e projetos</span>"
    ]
  },
  {
    "objectID": "data-import.html",
    "href": "data-import.html",
    "title": "7  Data import",
    "section": "",
    "text": "7.1 Introduction\nWorking with data provided by R packages is a great way to learn data science tools, but you want to apply what you’ve learned to your own data at some point. In this chapter, you’ll learn the basics of reading data files into R.\nSpecifically, this chapter will focus on reading plain-text rectangular files. We’ll start with practical advice for handling features like column names, types, and missing data. You will then learn about reading data from multiple files at once and writing data from R to a file. Finally, you’ll learn how to handcraft data frames in R.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#introduction",
    "href": "data-import.html#introduction",
    "title": "7  Data import",
    "section": "",
    "text": "7.1.1 Prerequisites\nIn this chapter, you’ll learn how to load flat files in R with the readr package, which is part of the core tidyverse.\n\nlibrary(tidyverse)",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#reading-data-from-a-file",
    "href": "data-import.html#reading-data-from-a-file",
    "title": "7  Data import",
    "section": "\n7.2 Reading data from a file",
    "text": "7.2 Reading data from a file\nTo begin, we’ll focus on the most common rectangular data file type: CSV, which is short for comma-separated values. Here is what a simple CSV file looks like. The first row, commonly called the header row, gives the column names, and the following six rows provide the data. The columns are separated, aka delimited, by commas.\n\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,Güvenç Attila,Ice cream,Lunch only,6\n\nTabela 7.1 shows a representation of the same data as a table.\n\n\n\nTabela 7.1: Data from the students.csv file as a table.\n\n\n\n\n\n\n\n\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\n\n1\nSunil Huffmann\nStrawberry yoghurt\nLunch only\n4\n\n\n2\nBarclay Lynn\nFrench fries\nLunch only\n5\n\n\n3\nJayendra Lyne\nN/A\nBreakfast and lunch\n7\n\n\n4\nLeon Rossini\nAnchovies\nLunch only\nNA\n\n\n5\nChidiegwu Dunkel\nPizza\nBreakfast and lunch\nfive\n\n\n6\nGüvenç Attila\nIce cream\nLunch only\n6\n\n\n\n\n\n\n\n\nWe can read this file into R using read_csv(). The first argument is the most important: the path to the file. You can think about the path as the address of the file: the file is called students.csv and that it lives in the data folder.\n\nstudents &lt;- read_csv(\"data/students.csv\")\n#&gt; Rows: 6 Columns: 5\n#&gt; ── Column specification ─────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr (4): Full Name, favourite.food, mealPlan, AGE\n#&gt; dbl (1): Student ID\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThe code above will work if you have the students.csv file in a data folder in your project. You can download the students.csv file from https://pos.it/r4ds-students-csv or you can read it directly from that URL with:\n\nstudents &lt;- read_csv(\"https://pos.it/r4ds-students-csv\")\n\nWhen you run read_csv(), it prints out a message telling you the number of rows and columns of data, the delimiter that was used, and the column specifications (names of columns organized by the type of data the column contains). It also prints out some information about retrieving the full column specification and how to quiet this message. This message is an integral part of readr, and we’ll return to it in Seção 7.3.\n\n7.2.1 Practical advice\nOnce you read data in, the first step usually involves transforming it in some way to make it easier to work with in the rest of your analysis. Let’s take another look at the students data with that in mind.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\nIn the favourite.food column, there are a bunch of food items, and then the character string N/A, which should have been a real NA that R will recognize as “not available”. This is something we can address using the na argument. By default, read_csv() only recognizes empty strings (\"\") in this dataset as NAs, we want it to also recognize the character string \"N/A\".\n\nstudents &lt;- read_csv(\"data/students.csv\", na = c(\"N/A\", \"\"))\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\nYou might also notice that the Student ID and Full Name columns are surrounded by backticks. That’s because they contain spaces, breaking R’s usual rules for variable names; they’re non-syntactic names. To refer to these variables, you need to surround them with backticks, `:\n\nstudents |&gt; \n  rename(\n    student_id = `Student ID`,\n    full_name = `Full Name`\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite.food     mealPlan            AGE  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\nAn alternative approach is to use janitor::clean_names() to use some heuristics to turn them all into snake case at once1.\n\nstudents |&gt; janitor::clean_names()\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\nAnother common task after reading in data is to consider variable types. For example, meal_plan is a categorical variable with a known set of possible values, which in R should be represented as a factor:\n\nstudents |&gt;\n  janitor::clean_names() |&gt;\n  mutate(meal_plan = factor(meal_plan))\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\nNote that the values in the meal_plan variable have stayed the same, but the type of variable denoted underneath the variable name has changed from character (&lt;chr&gt;) to factor (&lt;fct&gt;). You’ll learn more about factors in Capítulo 16.\nBefore you analyze these data, you’ll probably want to fix the age and id columns. Currently, age is a character variable because one of the observations is typed out as five instead of a numeric 5. We discuss the details of fixing this issue in Capítulo 20.\n\nstudents &lt;- students |&gt;\n  janitor::clean_names() |&gt;\n  mutate(\n    meal_plan = factor(meal_plan),\n    age = parse_number(if_else(age == \"five\", \"5\", age))\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\nA new function here is if_else(), which has three arguments. The first argument test should be a logical vector. The result will contain the value of the second argument, yes, when test is TRUE, and the value of the third argument, no, when it is FALSE. Here we’re saying if age is the character string \"five\", make it \"5\", and if not leave it as age. You will learn more about if_else() and logical vectors in Capítulo 12.\n\n7.2.2 Other arguments\nThere are a couple of other important arguments that we need to mention, and they’ll be easier to demonstrate if we first show you a handy trick: read_csv() can read text strings that you’ve created and formatted like a CSV file:\n\nread_csv(\n  \"a,b,c\n  1,2,3\n  4,5,6\"\n)\n#&gt; # A tibble: 2 × 3\n#&gt;       a     b     c\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\nUsually, read_csv() uses the first line of the data for the column names, which is a very common convention. But it’s not uncommon for a few lines of metadata to be included at the top of the file. You can use skip = n to skip the first n lines or use comment = \"#\" to drop all lines that start with (e.g.) #:\n\nread_csv(\n  \"The first line of metadata\n  The second line of metadata\n  x,y,z\n  1,2,3\",\n  skip = 2\n)\n#&gt; # A tibble: 1 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\nread_csv(\n  \"# A comment I want to skip\n  x,y,z\n  1,2,3\",\n  comment = \"#\"\n)\n#&gt; # A tibble: 1 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n\nIn other cases, the data might not have column names. You can use col_names = FALSE to tell read_csv() not to treat the first row as headings and instead label them sequentially from X1 to Xn:\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = FALSE\n)\n#&gt; # A tibble: 2 × 3\n#&gt;      X1    X2    X3\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\nAlternatively, you can pass col_names a character vector which will be used as the column names:\n\nread_csv(\n  \"1,2,3\n  4,5,6\",\n  col_names = c(\"x\", \"y\", \"z\")\n)\n#&gt; # A tibble: 2 × 3\n#&gt;       x     y     z\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2     3\n#&gt; 2     4     5     6\n\nThese arguments are all you need to know to read the majority of CSV files that you’ll encounter in practice. (For the rest, you’ll need to carefully inspect your .csv file and read the documentation for read_csv()’s many other arguments.)\n\n7.2.3 Other file types\nOnce you’ve mastered read_csv(), using readr’s other functions is straightforward; it’s just a matter of knowing which function to reach for:\n\nread_csv2() reads semicolon-separated files. These use ; instead of , to separate fields and are common in countries that use , as the decimal marker.\nread_tsv() reads tab-delimited files.\nread_delim() reads in files with any delimiter, attempting to automatically guess the delimiter if you don’t specify it.\nread_fwf() reads fixed-width files. You can specify fields by their widths with fwf_widths() or by their positions with fwf_positions().\nread_table() reads a common variation of fixed-width files where columns are separated by white space.\nread_log() reads Apache-style log files.\n\n7.2.4 Exercises\n\nWhat function would you use to read a file where fields were separated with “|”?\nApart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common?\nWhat are the most important arguments to read_fwf()?\n\nSometimes strings in a CSV file contain commas. To prevent them from causing problems, they need to be surrounded by a quoting character, like \" or '. By default, read_csv() assumes that the quoting character will be \". To read the following text into a data frame, what argument to read_csv() do you need to specify?\n\n\"x,y\\n1,'a,b'\"\n\n\n\nIdentify what is wrong with each of the following inline CSV files. What happens when you run the code?\n\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\nread_csv(\"a,b\\n\\\"1\")\nread_csv(\"a,b\\n1,2\\na,b\")\nread_csv(\"a;b\\n1;3\")\n\n\n\nPractice referring to non-syntactic names in the following data frame by:\n\nExtracting the variable called 1.\nPlotting a scatterplot of 1 vs. 2.\nCreating a new column called 3, which is 2 divided by 1.\nRenaming the columns to one, two, and three.\n\n\nannoying &lt;- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-col-types",
    "href": "data-import.html#sec-col-types",
    "title": "7  Data import",
    "section": "\n7.3 Controlling column types",
    "text": "7.3 Controlling column types\nA CSV file doesn’t contain any information about the type of each variable (i.e. whether it’s a logical, number, string, etc.), so readr will try to guess the type. This section describes how the guessing process works, how to resolve some common problems that cause it to fail, and, if needed, how to supply the column types yourself. Finally, we’ll mention a few general strategies that are useful if readr is failing catastrophically and you need to get more insight into the structure of your file.\n\n7.3.1 Guessing types\nreadr uses a heuristic to figure out the column types. For each column, it pulls the values of 1,0002 rows spaced evenly from the first row to the last, ignoring missing values. It then works through the following questions:\n\nDoes it contain only F, T, FALSE, or TRUE (ignoring case)? If so, it’s a logical.\nDoes it contain only numbers (e.g., 1, -4.5, 5e6, Inf)? If so, it’s a number.\nDoes it match the ISO8601 standard? If so, it’s a date or date-time. (We’ll return to date-times in more detail in Seção 17.2).\nOtherwise, it must be a string.\n\nYou can see that behavior in action in this simple example:\n\nread_csv(\"\n  logical,numeric,date,string\n  TRUE,1,2021-01-15,abc\n  false,4.5,2021-02-15,def\n  T,Inf,2021-02-16,ghi\n\")\n#&gt; # A tibble: 3 × 4\n#&gt;   logical numeric date       string\n#&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt; \n#&gt; 1 TRUE        1   2021-01-15 abc   \n#&gt; 2 FALSE       4.5 2021-02-15 def   \n#&gt; 3 TRUE      Inf   2021-02-16 ghi\n\nThis heuristic works well if you have a clean dataset, but in real life, you’ll encounter a selection of weird and beautiful failures.\n\n7.3.2 Missing values, column types, and problems\nThe most common way column detection fails is that a column contains unexpected values, and you get a character column instead of a more specific type. One of the most common causes for this is a missing value, recorded using something other than the NA that readr expects.\nTake this simple 1 column CSV file as an example:\n\nsimple_csv &lt;- \"\n  x\n  10\n  .\n  20\n  30\"\n\nIf we read it without any additional arguments, x becomes a character column:\n\nread_csv(simple_csv)\n#&gt; # A tibble: 4 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 10   \n#&gt; 2 .    \n#&gt; 3 20   \n#&gt; 4 30\n\nIn this very small case, you can easily see the missing value .. But what happens if you have thousands of rows with only a few missing values represented by .s sprinkled among them? One approach is to tell readr that x is a numeric column, and then see where it fails. You can do that with the col_types argument, which takes a named list where the names match the column names in the CSV file:\n\ndf &lt;- read_csv(\n  simple_csv, \n  col_types = list(x = col_double())\n)\n#&gt; Warning: One or more parsing issues, call `problems()` on your data frame for\n#&gt; details, e.g.:\n#&gt;   dat &lt;- vroom(...)\n#&gt;   problems(dat)\n\nNow read_csv() reports that there was a problem, and tells us we can find out more with problems():\n\nproblems(df)\n#&gt; # A tibble: 1 × 5\n#&gt;     row   col expected actual file                                           \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;                                          \n#&gt; 1     3     1 a double .      /private/var/folders/st/0346cszj61928zc133bfr8…\n\nThis tells us that there was a problem in row 3, col 1 where readr expected a double but got a .. That suggests this dataset uses . for missing values. So then we set na = \".\", the automatic guessing succeeds, giving us the numeric column that we want:\n\nread_csv(simple_csv, na = \".\")\n#&gt; # A tibble: 4 × 1\n#&gt;       x\n#&gt;   &lt;dbl&gt;\n#&gt; 1    10\n#&gt; 2    NA\n#&gt; 3    20\n#&gt; 4    30\n\n\n7.3.3 Column types\nreadr provides a total of nine column types for you to use:\n\n\ncol_logical() and col_double() read logicals and real numbers. They’re relatively rarely needed (except as above), since readr will usually guess them for you.\n\ncol_integer() reads integers. We seldom distinguish integers and doubles in this book because they’re functionally equivalent, but reading integers explicitly can occasionally be useful because they occupy half the memory of doubles.\n\ncol_character() reads strings. This can be useful to specify explicitly when you have a column that is a numeric identifier, i.e., long series of digits that identifies an object but doesn’t make sense to apply mathematical operations to. Examples include phone numbers, social security numbers, credit card numbers, etc.\n\ncol_factor(), col_date(), and col_datetime() create factors, dates, and date-times respectively; you’ll learn more about those when we get to those data types in Capítulo 16 and Capítulo 17.\n\ncol_number() is a permissive numeric parser that will ignore non-numeric components, and is particularly useful for currencies. You’ll learn more about it in Capítulo 13.\n\ncol_skip() skips a column so it’s not included in the result, which can be useful for speeding up reading the data if you have a large CSV file and you only want to use some of the columns.\n\nIt’s also possible to override the default column by switching from list() to cols() and specifying .default:\n\nanother_csv &lt;- \"\nx,y,z\n1,2,3\"\n\nread_csv(\n  another_csv, \n  col_types = cols(.default = col_character())\n)\n#&gt; # A tibble: 1 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     2     3\n\nAnother useful helper is cols_only() which will read in only the columns you specify:\n\nread_csv(\n  another_csv,\n  col_types = cols_only(x = col_character())\n)\n#&gt; # A tibble: 1 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-readr-directory",
    "href": "data-import.html#sec-readr-directory",
    "title": "7  Data import",
    "section": "\n7.4 Reading data from multiple files",
    "text": "7.4 Reading data from multiple files\nSometimes your data is split across multiple files instead of being contained in a single file. For example, you might have sales data for multiple months, with each month’s data in a separate file: 01-sales.csv for January, 02-sales.csv for February, and 03-sales.csv for March. With read_csv() you can read these data in at once and stack them on top of each other in a single data frame.\n\nsales_files &lt;- c(\"data/01-sales.csv\", \"data/02-sales.csv\", \"data/03-sales.csv\")\nread_csv(sales_files, id = \"file\")\n#&gt; # A tibble: 19 × 6\n#&gt;   file              month    year brand  item     n\n#&gt;   &lt;chr&gt;             &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 data/01-sales.csv January  2019     1  1234     3\n#&gt; 2 data/01-sales.csv January  2019     1  8721     9\n#&gt; 3 data/01-sales.csv January  2019     1  1822     2\n#&gt; 4 data/01-sales.csv January  2019     2  3333     1\n#&gt; 5 data/01-sales.csv January  2019     2  2156     9\n#&gt; 6 data/01-sales.csv January  2019     2  3987     6\n#&gt; # ℹ 13 more rows\n\nOnce again, the code above will work if you have the CSV files in a data folder in your project. You can download these files from https://pos.it/r4ds-01-sales, https://pos.it/r4ds-02-sales, and https://pos.it/r4ds-03-sales or you can read them directly with:\n\nsales_files &lt;- c(\n  \"https://pos.it/r4ds-01-sales\",\n  \"https://pos.it/r4ds-02-sales\",\n  \"https://pos.it/r4ds-03-sales\"\n)\nread_csv(sales_files, id = \"file\")\n\nThe id argument adds a new column called file to the resulting data frame that identifies the file the data come from. This is especially helpful in circumstances where the files you’re reading in do not have an identifying column that can help you trace the observations back to their original sources.\nIf you have many files you want to read in, it can get cumbersome to write out their names as a list. Instead, you can use the base list.files() function to find the files for you by matching a pattern in the file names. You’ll learn more about these patterns in Capítulo 15.\n\nsales_files &lt;- list.files(\"data\", pattern = \"sales\\\\.csv$\", full.names = TRUE)\nsales_files\n#&gt; [1] \"data/01-sales.csv\" \"data/02-sales.csv\" \"data/03-sales.csv\"",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#sec-writing-to-a-file",
    "href": "data-import.html#sec-writing-to-a-file",
    "title": "7  Data import",
    "section": "\n7.5 Writing to a file",
    "text": "7.5 Writing to a file\nreadr also comes with two useful functions for writing data back to disk: write_csv() and write_tsv(). The most important arguments to these functions are x (the data frame to save) and file (the location to save it). You can also specify how missing values are written with na, and if you want to append to an existing file.\n\nwrite_csv(students, \"students.csv\")\n\nNow let’s read that csv file back in. Note that the variable type information that you just set up is lost when you save to CSV because you’re starting over with reading from a plain text file again:\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\nwrite_csv(students, \"students-2.csv\")\nread_csv(\"students-2.csv\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\nThis makes CSVs a little unreliable for caching interim results—you need to recreate the column specification every time you load in. There are two main alternatives:\n\n\nwrite_rds() and read_rds() are uniform wrappers around the base functions readRDS() and saveRDS(). These store data in R’s custom binary format called RDS. This means that when you reload the object, you are loading the exact same R object that you stored.\n\nwrite_rds(students, \"students.rds\")\nread_rds(\"students.rds\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\nThe arrow package allows you to read and write parquet files, a fast binary file format that can be shared across programming languages. We’ll return to arrow in more depth in Capítulo 22.\n\nlibrary(arrow)\nwrite_parquet(students, \"students.parquet\")\nread_parquet(\"students.parquet\")\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;fct&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    NA                 Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\nParquet tends to be much faster than RDS and is usable outside of R, but does require the arrow package.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#data-entry",
    "href": "data-import.html#data-entry",
    "title": "7  Data import",
    "section": "\n7.6 Data entry",
    "text": "7.6 Data entry\nSometimes you’ll need to assemble a tibble “by hand” doing a little data entry in your R script. There are two useful functions to help you do this which differ in whether you layout the tibble by columns or by rows. tibble() works by column:\n\ntibble(\n  x = c(1, 2, 5), \n  y = c(\"h\", \"m\", \"g\"),\n  z = c(0.08, 0.83, 0.60)\n)\n#&gt; # A tibble: 3 × 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6\n\nLaying out the data by column can make it hard to see how the rows are related, so an alternative is tribble(), short for transposed tibble, which lets you lay out your data row by row. tribble() is customized for data entry in code: column headings start with ~ and entries are separated by commas. This makes it possible to lay out small amounts of data in an easy to read form:\n\ntribble(\n  ~x, ~y, ~z,\n  1, \"h\", 0.08,\n  2, \"m\", 0.83,\n  5, \"g\", 0.60\n)\n#&gt; # A tibble: 3 × 3\n#&gt;       x y         z\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     1 h      0.08\n#&gt; 2     2 m      0.83\n#&gt; 3     5 g      0.6",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#summary",
    "href": "data-import.html#summary",
    "title": "7  Data import",
    "section": "\n7.7 Summary",
    "text": "7.7 Summary\nIn this chapter, you’ve learned how to load CSV files with read_csv() and to do your own data entry with tibble() and tribble(). You’ve learned how csv files work, some of the problems you might encounter, and how to overcome them. We’ll come to data import a few times in this book: Capítulo 20 from Excel and Google Sheets, Capítulo 21 will show you how to load data from databases, Capítulo 22 from parquet files, Capítulo 23 from JSON, and Capítulo 24 from websites.\nWe’re just about at the end of this section of the book, but there’s one important last topic to cover: how to get help. So in the next chapter, you’ll learn some good places to look for help, how to create a reprex to maximize your chances of getting good help, and some general advice on keeping up with the world of R.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "data-import.html#footnotes",
    "href": "data-import.html#footnotes",
    "title": "7  Data import",
    "section": "",
    "text": "The janitor package is not part of the tidyverse, but it offers handy functions for data cleaning and works well within data pipelines that use |&gt;.↩︎\nYou can override the default of 1000 with the guess_max argument.↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data import</span>"
    ]
  },
  {
    "objectID": "workflow-help.html",
    "href": "workflow-help.html",
    "title": "8  ✅ Fluxo de trabalho: obtendo ajuda",
    "section": "",
    "text": "8.1 O Google é seu amigo\nSe você travar, começe com o Google. Tipicamente colocando “R” em uma busca é o suficiente para restringi-la para resultados relevantes: se a busca não for útil, geralmente significa que não existem muitos resultados específicos. Além do mais, adicionando na busca nomes de pacotes como “tidyverse” ou “ggplot2” irá ajudar a direcionar os resultados ao seu código de maneira mais familiar a você, por exemplo: “como fazer um boxplot no R com ggplot2” ao invés de “como fazer um boxplot no R”. Particularmente, o Google é muito bom com mensagens de erro. Se você tiver uma mensagem de erro e não tem ideia do que ela significa, dê um Google com a mensagem! Há chances de que outras pessoas também tenham ficado confusas com o erro anteriormente e em algum lugar da web você terá ajuda. (Se a mensagem de erro não estiver em inglês, execute Sys.setenv(LANGUAGE = \"en\") e execute novamente o código; provavelmente encontrará ajuda com mensagens de erro em inglês.)\nSe o Google não ajudar tente o Stack Overflow. Comece reservando tempo para buscar uma resposta já existente, incluindo [R] para restringir sua busca por perguntas e respostas que usem R.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>✅ Fluxo de trabalho: obtendo ajuda</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#criando-um-exemplo-reprodutível-reprex",
    "href": "workflow-help.html#criando-um-exemplo-reprodutível-reprex",
    "title": "8  ✅ Fluxo de trabalho: obtendo ajuda",
    "section": "\n8.2 Criando um exemplo reprodutível (reprex)",
    "text": "8.2 Criando um exemplo reprodutível (reprex)\nSe a sua busca no Google não retornar nenhuma resposta satisfatória, é uma boa ideia preparar um reprex, termo para exemplo reprodutível (do inglês: reproducible example). Um bom reprex facilita para que outras pessoas possam te ajudar, e geralmente você poderá resolver o problema durante a criação dele. Existem duas partes na criação de um reprex:\n\nPrimeiro, você precisa permitir a reprodução do seu código. Isto é, significa que você precisa copiar tudo, isto é, incluir qualquer comando library() e criar todos os objetos necessários. A maneira mais fácil de fazer isto é usando o pacote reprex.\nSegundo, você precisa ser minimalista. Exclua tudo que não for relacionado ao seu código. Usualmente isto envolve a criação de um objeto R menor e mais simples do que aquele que você está criando de verdade ou até mesmo usar dados internos1.\n\nIsto parece muito trabalhoso! E pode ser, mas tem um grande retorno:\n\nEm 80% dos casos, a criação de um excelente reprex mostrará a raiz do seu problema. É incrível como o processo de escrever um exemplo pequeno e auto-suficiente ajuda você a responder sua própria dúvida.\nNos 20% restantes, você terá entendido a essência do seu problema de uma maneira que é fácil para os outros entenderem. Isto aumenta consideravelmente suas chances de obter ajuda!\n\nAo criar um reprex manualmente, é fácil esquecer de algo por acidente, o que significa que seu código pode não ser executado no computador de outra pessoa. Evite esse problema utilizando o pacote reprex, que é instalado como parte do tidyverse. Digamos que você copie este código na sua área de transferência (ou no RStudio Server ou Cloud, selecionando):\n\ny &lt;- 1:4\nmean(y)\n\nEntão execute reprex(), onde a saída padrão está formatada para o GitHub:\nreprex::reprex()\nUm HTML bem formatado irá aparecer no RStudio Viewer (se estiver usando RStudio) ou em seu navegador padrão. O reprex é automaticamente copiado para sua área de transferência (no RStudio Server ou Cloud você mesmo precisa copiar):\n``` r\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n```\nO texto é formatado em uma forma especial chamado de Markdown, que pode ser copiado para sites como StackOverflow ou Github que irão automaticamente formatar para se parecer com código. Abaixo está a provável saída do Markdown formatado para o Github:\n\ny &lt;- 1:4\nmean(y)\n#&gt; [1] 2.5\n\nQualquer pessoa poderá copiar, colar e rodar isto imediatamente.\nExistem três coisas que você precisa incluir para tornar seu exemplo reprodutível: pacotes necessários, dados e código.\n\nPacotes devem ser carregados no início do script para facilitar a visualização de quais são necessários. Este é um bom momento para você verificar que está usando a última versão dos pacotes; você poder ter encontado um bug que foi resolvido desde a sua última atualização dos pacotes. Para pacotes do tidyverse, a maneira mais fácil de atualizar é com o comando tidyverse_update().\n\nA maneira mais fácil para incluir os dados é usar dput() para gerar o código em R necessário para recriar os dados. Por exemplo, para recriar o dataset mtcars no R execute os seguintes comandos:\n\nExecute dput(mtcars) no R\nCopie o resultado\nNo reprex, digite mtcars &lt;- e então cole o resultado copiado no passo anterior.\n\nTente usar a menor parte dos seus dados que ainda gera o erro.\n\n\nDedique um pouco de tempo para se certificar de que seu código é de fácil leitura por todos:\n\nEsteja certo de que usou espaços e suas variáveis são concisas, porém objetivas;\nUse comentários para indicar onde está o problema;\nFaça seu melhor para excluir tudo que não é relacionado com o problema.\n\nQuanto mais sucinto o código, mais fácil é para entender e mais fácil ainda para arrumar.\n\n\nTermine verificando que você fez um exemplo possível de ser reproduzido por meio de uma nova sessão do R, copiando e colando seu script.\nA criação de exemplos reprodutíveis (reprex) não é trivial e exige alguma prática para aprender a criar exemplos reprodutíveis bons e que contenham o mínimo de código e dados possível. Contudo, aprender a fazer perguntas que incluem o código e dedicando algum tempo para fazer ele ser reprodutível será um aprendizado de longo prazo enquanto você aprender e aprimorar suas habilidades com o R.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>✅ Fluxo de trabalho: obtendo ajuda</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#invista-em-você",
    "href": "workflow-help.html#invista-em-você",
    "title": "8  ✅ Fluxo de trabalho: obtendo ajuda",
    "section": "\n8.3 Invista em você",
    "text": "8.3 Invista em você\nVocê também deve dedicar algum tempo se preparando para resolver problemas antes que eles ocorram. Investir um pouco de tempo para aprender R a cada dia terá sua recompensa no longo prazo. Uma maneira é seguir o que a equipe do tidyverse está fazendo no blog do tidyverse (https://www.tidyverse.org/blog/). Para acompanhar de forma mais ampla a comunidade do R, recomendamos a leitura do R weekly (https://rweekly.org): é um esforço da comunidade em agregar as notícias mais interessantes sobre o R a cada semana.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>✅ Fluxo de trabalho: obtendo ajuda</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#sumário",
    "href": "workflow-help.html#sumário",
    "title": "8  ✅ Fluxo de trabalho: obtendo ajuda",
    "section": "\n8.4 Sumário",
    "text": "8.4 Sumário\nEste capítulo encerra a parte “Visão geral” deste livro. Você viu até agora as partes mais importantes do processo em ciência de dados: visualização, transformação, organização e importação. Agora você tem uma visão abrangente do processo como um todo e começamos a entrar nos detalhes.\nA próxima parte do livro, Visualização, é um aprofundamento na estrutura dos gráficos e criação de visualização de dados com o ggplot2, exemplos de como usar as ferramentas que aprendeu até agora para construir uma análise exploratória de dados e também introduzir boas práticas na criação de gráficos para comunicação.",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>✅ Fluxo de trabalho: obtendo ajuda</span>"
    ]
  },
  {
    "objectID": "workflow-help.html#footnotes",
    "href": "workflow-help.html#footnotes",
    "title": "8  ✅ Fluxo de trabalho: obtendo ajuda",
    "section": "",
    "text": "Nota de tradução: São dados que estão sempre disponíveis no R (ex. mtcars), e são bastante utilizados em exemplos, aulas, tutoriais, entre outros. Outra opção interessante é utilizar dados do pacote dados para criar exemplos reprodutíveis.↩︎",
    "crumbs": [
      "✅ Visão geral",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>✅ Fluxo de trabalho: obtendo ajuda</span>"
    ]
  },
  {
    "objectID": "visualize.html",
    "href": "visualize.html",
    "title": "✅ Visualizar",
    "section": "",
    "text": "Depois de ler a primeira parte do livro, você compreende (pelo menos superficialmente) as ferramentas mais importantes para fazer ciência de dados. Agora é hora de começar a se aprofundar nos detalhes. Nesta parte do livro, você aprenderá a visualizar dados com mais detalhes.\n\n\n\n\n\n\n\nFigura 1: A visualização de dados geralmente é o primeiro passo na exploração de dados.\n\n\n\n\nCada capítulo aborda um ou mais aspectos da criação de uma visualização de dados.\n\nNo 9  ✅ Camadas, você irá conhecer a gramática dos gráficos.\nNo 10  Exploratory data analysis, você irá combinar a visualização com a sua curiosidade e ceticismo para fazer e responder perguntas interessantes sobre os dados.\nPor fim, no 11  Communication, você irá aprender a usar seus gráficos exploratórios, melhorá-los e transformá-los em gráficos expositivos, gráficos que ajudam o recém-chegado à sua análise a entender o que está acontecendo da maneira mais rápida e fácil possível.\n\nEstes três capítulos te permitem iniciar no mundo da visualização, mas há muito mais para aprender. O melhor lugar para aprender mais é o livro sobre o ggplot2: ggplot2: Elegant graphics for data analysis. Este livro aprofunda muito mais a teoria subjacente e tem muitos exemplos de como combinar as diversas funções do pacote para resolver problemas práticos. Outro grande recurso é a galeria de extensões do ggplot2 https://exts.ggplot2.tidyverse.org/gallery/. Este site lista diversos pacotes que expandem o ggplot2 com novas geometrias e escalas. É um ótimo lugar para começar se estiver tentando fazer algo que parece difícil com o ggplot2.",
    "crumbs": [
      "✅ Visualizar"
    ]
  },
  {
    "objectID": "layers.html",
    "href": "layers.html",
    "title": "9  ✅ Camadas",
    "section": "",
    "text": "9.1 Introdução\nNo Capítulo 1, você aprendeu muito mais do que apenas criar gráficos de dispersão, gráficos de barras e boxplots. Você aprendeu uma base que você pode usar para criar qualquer tipo de gráfico com o ggplot2.\nNesse capítulo, você irá expandir essa base conforme for aprendendo sobre a gramática dos gráficos baseada em camadas. Vamos começar explorando mais profundamente o mapeamento estético, as geometrias e as facetas. Em seguida, você aprenderá sobre as transformações estatísticas que acontecem nos bastidores quando o ggplot2 cria um gráfico. Essas transformações são usadas para calcular novos valores a serem plotados, como as alturas das barras em um gráfico de barras, ou as medianas em um boxplot. Você também irá aprender sobre ajustes de posição, os quais modificam como as geometrias são exibidas nos seus gráficos. Por fim, introduziremos brevemente o sistema de coordenadas.\nNão iremos abordar todas as funções e opções para cada uma dessas camadas, mas guiaremos você pelas funcionalidades mais importantes e comumente utilizadas que são fornecidas pelo ggplot2. Além disso, apresentaremos a você pacotes que estendem as funcionalidades do ggplot2.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#introdução",
    "href": "layers.html#introdução",
    "title": "9  ✅ Camadas",
    "section": "",
    "text": "9.1.1 Pré-requisitos\nEsse capítulo foca no ggplot2. Para acessar as páginas de ajuda e as funções utilizadas nesse capítulo, carregue o pacote tidyverse. Para acessar as bases de dados, carregaremos também o pacote dados. Ao rodar o código abaixo, esses dois pacotes serão carregados:\n\nlibrary(tidyverse)\nlibrary(dados)",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#mapeamento-estético",
    "href": "layers.html#mapeamento-estético",
    "title": "9  ✅ Camadas",
    "section": "\n9.2 Mapeamento estético",
    "text": "9.2 Mapeamento estético\n\n“O maior valor de uma imagem está em quando ela nos força a perceber o que não esperávamos ver.” — John Tukey\n\nLembre-se de que a base de dados milhas incluída no pacote dados contém 234 observações de 38 modelos de carros.\n\nmilhas\n#&gt; # A tibble: 234 × 11\n#&gt;   fabricante modelo cilindrada   ano cilindros transmissao tracao cidade\n#&gt;   &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;     &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;   &lt;int&gt;\n#&gt; 1 audi       a4            1.8  1999         4 auto(l5)    d          18\n#&gt; 2 audi       a4            1.8  1999         4 manual(m5)  d          21\n#&gt; 3 audi       a4            2    2008         4 manual(m6)  d          20\n#&gt; 4 audi       a4            2    2008         4 auto(av)    d          21\n#&gt; 5 audi       a4            2.8  1999         6 auto(l5)    d          16\n#&gt; 6 audi       a4            2.8  1999         6 manual(m5)  d          18\n#&gt; # ℹ 228 more rows\n#&gt; # ℹ 3 more variables: rodovia &lt;int&gt;, combustivel &lt;chr&gt;, classe &lt;chr&gt;\n\nEntre as variáveis da base milhas estão:\n\ncilindrada: O tamanho do motor de um carro, em litros. Uma variável numérica.\nrodovia: A eficiência de combustível do carro na rodovia, em milhas por galão (milhas). Um carro com baixa eficiência de combustível consome mais combustível do que um carro com alta eficiência, ao percorrerem a mesma distância. Uma variável numérica.\nclasse: Tipo do carro. Uma variável categórica.\n\nVamos começar visualizando a relação entre cilindrada e rodovia para várias classes de carros. Podemos fazer isso com um gráfico de dispersão no qual as variáveis numéricas são mapeadas nos atributos estéticos x e y e a variável categórica é mapeada em um atributo estético como color (cor) ou shape (forma).\n# Esquerda\nggplot(milhas, aes(x = cilindrada, y = rodovia, color = classe)) +\n  geom_point()\n\n# Direita\nggplot(milhas, aes(x = cilindrada, y = rodovia, shape = classe)) +\n  geom_point()\n#&gt; Warning: The shape palette can deal with a maximum of 6 discrete values because more\n#&gt; than 6 becomes difficult to discriminate\n#&gt; ℹ you have requested 7 values. Consider specifying shapes manually if you\n#&gt;   need that many have them.\n#&gt; Warning: Removed 62 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nQuando classe é mapeada no atributo estético shape (forma), recebemos dois avisos:\n\n1: The shape palette can deal with a maximum of 6 discrete values because more than 6 becomes difficult to discriminate; you have 7. Consider specifying shapes manually if you must have them.\n2: Removed 62 rows containing missing values (geom_point()).\n\nOu seja:\n\n1: A paleta de formas pode lidar com no máximo 6 valores discretos, porque acima de 6 torna-se difícil discriminá-los; você tem 7. Considere especificar as formas manualmente caso elas sejam de fato necessárias.\n2: 62 linhas contendo valores ausentes foram removidas (geom_point()).\n\nUma vez que o ggplot2, por padrão, usa apenas seis formas por vez, grupos que ultrapassem essa quantidade não serão plotados quando você usar o atributo estético shape (forma). O segundo aviso está relacionado a esse primeiro: há 62 SUVs na base de dados e elas não foram plotadas.\nDe forma semelhante, podemos também mapear a variável classe nos atributos estéticos size (tamanho) ou alpha (transparência), as quais controlarão o tamanho e a transparência dos pontos, respectivamente.\n# Esquerda\nggplot(milhas, aes(x = cilindrada, y = rodovia, size = classe)) +\n  geom_point()\n#&gt; Warning: Using size for a discrete variable is not advised.\n\n# Direita\nggplot(milhas, aes(x = cilindrada, y = rodovia, alpha = classe)) +\n  geom_point()\n#&gt; Warning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\nEsses dois gráficos também produzem um aviso:\n\nUsing alpha for a discrete variable is not advised.\n\nOu seja:\n\nNão é recomendado usar o atributo estético alpha (transparência) para uma variável discreta.\n\nMapear uma variável discreta não ordenada (categórica), classe, em um atributo estético ordenado (size ou alpha) em geral não é uma boa ideia, porque implica em uma ordenação que não existe de fato.\nUma vez que você seleciona o atributo estético do mapeamento, o ggplot2 cuida do resto. Ele seleciona uma escala adequada para ser utilizada com esse atributo e constrói uma legenda que explica a relação entre as categorias e os valores. Para os atributos estéticos x e y, o ggplot2 não cria uma legenda, mas cria uma linha de eixo com marcas de escala e rótulos. Essa linha de eixo fornece a mesma informação que uma legenda: explica a correspondência entre as posições e os valores.\nVocê também pode definir manualmente as propriedades visuais da sua geometria ao incluí-las como um argumento da função geom (fora do aes()), ao invés de depender do mapeamento de uma variável para definir essa aparência. Por exemplo, podemos tornar todos os pontos do nosso gráfico azuis:\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point(color = \"blue\")\n\n\n\n\n\n\n\nAqui, a cor não traz informações sobre uma variável, apenas modifica a aparência do gráfico. Você vai precisar selecionar um valor que faça sentido para aquele atributo estético:\n\nO nome de uma cor como uma sequência de caracteres (texto) em inglês, por exemplo, color = \"blue\"\n\nO tamanho de um ponto em mm, por exemplo, size = 1\n\nO formato de um ponto como um número, por exemplo, shape = 1, como mostrado na Figura 9.1.\n\n\n\n\n\n\n\n\nFigura 9.1: O R apresenta 25 formas que são identificadas por números. Algumas podem parecer duplicadas: por exemplo, 0, 15 e 22 são todas quadrados. A diferença entre elas vem da interação das estéticas color (cor) e fill (preenchimento). As formas vazadas (0–14) têm uma borda cuja cor é determinada pelo argumento color; as formas sólidas (15–20) são preenchidas com a cor definida em color; as formas preenchidas (21–24) têm a cor da sua borda definida por color e o seu preenchimento definido por fill. As figuras foram alinhadas de forma a manter formas semelhantes próximas umas das outras.\n\n\n\n\nAté o momento, nós discutimos os atributos estéticos que podem ser mapeados em um gráfico de dispersão ao usarmos uma geometria de ponto (geom_point). Você pode aprender mais sobre todas as possibilidades de mapeamentos estéticos na vinheta de especificações estéticas (em inglês): https://ggplot2.tidyverse.org/articles/ggplot2-specs.html.\nOs atributos estéticos específicos que você pode usar em um gráfico dependem da geometria que você está utilizando para representar os dados. Na próxima seção, exploraremos mais a fundo as geometrias.\n\n9.2.1 Exercícios\n\nCrie um gráfico de dispersão de rodovia vs. cilindrada no qual os pontos sejam triângulos preenchidos em cor-de-rosa (pink).\n\nPor que o código abaixo não resultou em um gráfico com pontos em azul?\n\nggplot(milhas) + \n  geom_point(aes(x = cilindrada, y = rodovia, color = \"blue\"))\n\n\nO que o atributo estético stroke faz? Com quais formas esse atributo estético funciona? (Dica: use ?geom_point)\nO que acontece se você mapear um atributo estético para algo que não seja o nome de uma variável, como aes(color = cilindrada &lt; 5)? Observe que você também precisará definir os atributos estéticos x e y.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#sec-geometric-objects",
    "href": "layers.html#sec-geometric-objects",
    "title": "9  ✅ Camadas",
    "section": "\n9.3 Geometrias",
    "text": "9.3 Geometrias\nQual a semelhança entre esses dois gráficos?\n\n\n\n\n\n\n\n\n\n\n\n\n\nOs dois gráficos contém a mesma variável x, a mesma variável y e descrevem os mesmos dados. Mas os gráficos não são idênticos. Cada um desses gráficos usa uma geom diferente para representar esses dados. O gráfico à esquerda usa a geometria de ponto (point), enquanto o gráfico à direita usa a geometria de suavização (smooth) e inclui uma linha suavizada ajustada aos dados.\nPara alterar a geometria do seu gráfico, basta mudar a função geom adicionada ao ggplot(). Por exemplo, para criar os gráficos acima você pode usar o seguinte código:\n\n# Esquerda\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point()\n\n# Direita\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_smooth()\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nCada função geom no ggplot2 recebe um argumento mapping, que pode ser definido tanto localmente, na camada geom, quanto globalmente, na camada ggplot(). No entanto, nem todos os atributos estéticos irão funcionar com todas as geometrias. Você pode definir o formato (shape) de um ponto, mas não pode definir o “formato” de uma linha. Se você tentar fazer isso, o ggplot2 ignorará silenciosamente esse mapeamento estético. Por outro lado, você pode definir o tipo de linha (linetype) de uma linha. A função geom_smooth() irá desenhar uma linha diferente, com um tipo diferente de linha, para cada valor da variável que for mapeada em linetype.\n# Esquerda\nggplot(milhas, aes(x = cilindrada, y = rodovia, shape = tracao)) + \n  geom_smooth()\n\n# Direita\nggplot(milhas, aes(x = cilindrada, y = rodovia, linetype = tracao)) + \n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\nAqui, o geom_smooth() separa os carros em três linhas com base na categoria de tracao à qual pertencem. Uma linha descreve todos os pontos pertencentes à categoria 4, outra linha descreve os pontos pertencentes à categoria d, e uma terceira linha descreve todos os pontos pertencentes à categoria t. Aqui, 4 corresponde a tração nas quatro rodas, d corresponde a tração nas rodas dianteiras e t corresponde a tração nas rodas traseiras.\nSe isso não fez muito sentido, podemos tornar essa relação mais óbvia ao sobrepor as linhas aos dados brutos e então colorir tudo de acordo com a tracao.\n\nggplot(milhas, aes(x = cilindrada, y = rodovia, color = tracao)) + \n  geom_point() +\n  geom_smooth(aes(linetype = tracao))\n\n\n\n\n\n\n\nObserve que esse gráfico contém duas geometrias no mesmo gráfico.\nMuitas geometrias, como o geom_smooth(), usam uma única geometria para representar várias linhas de dados. Para essas geometrias, você pode mapear o atributo estético group (grupo) a uma variável categórica para desenhar várias geometrias. O ggplot2 irá desenhar uma geometria separada para cada valor único da variável de agrupamento. Na prática, o ggplot2 agrupará automaticamente os dados para essas geometrias sempre que você mapear um atributo estético a uma variável discreta (como no exemplo com linetype). É conveniente contar com esse recurso porque o atributo estético group, por si só, não adiciona às geoms uma legenda ou características que permitam distinguir os grupos.\n# Esquerda\nggplot(milhas, aes(x = cilindrada, y = rodovia)) +\n  geom_smooth()\n\n# Middle\nggplot(milhas, aes(x = cilindrada, y = rodovia)) +\n  geom_smooth(aes(group = tracao))\n\n# Direita\nggplot(milhas, aes(x = cilindrada, y = rodovia)) +\n  geom_smooth(aes(color = tracao), show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe você incluir mapeamentos em uma função geom, o ggplot2 irá tratá-los como mapeamentos locais para aquela camada. Ele usará esses mapeamentos para estender ou substituir mapeamentos globais apenas para aquela camada. Isso torna possível representar atributos estéticos diferentes em diferentes camadas.\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point(aes(color = classe)) + \n  geom_smooth()\n\n\n\n\n\n\n\nVocê pode usar essa mesma ideia para especificar dados (data) diferentes para cada camada. Aqui, nós utilizamos pontos vermelhos e círculos vazados para destacar carros com dois assentos. O argumento data, definido localmente na camada geom_point(), substitui - apenas para essa camada - o argumento data definido globalmente na camada ggplot().\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point() + \n  geom_point(\n    data = milhas |&gt; filter(classe == \"2 assentos\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = milhas |&gt; filter(classe == \"2 assentos\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\n\n\n\nAs geometrias são os blocos de construção base do ggplot2. Você pode transformar completamente a aparência do seu gráfico ao alterar as geometrias que o compõem, e geoms diferentes podem mostrar diferentes características dos seus dados. Por exemplo, o histograma e o gráfico de densidade abaixo mostram que a distribuição de eficiência de combustível na rodovia é bimodal e assimétrica à direita, enquanto o boxplot mostra que há dois possíveis outliers (valores atípicos).\n# Esquerda\nggplot(milhas, aes(x = rodovia)) +\n  geom_histogram(binwidth = 2)\n\n# Middle\nggplot(milhas, aes(x = rodovia)) +\n  geom_density()\n\n# Direita\nggplot(milhas, aes(x = rodovia)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nO ggplot2 oferece mais de 40 geoms, mas essas não cobrem todas as possibilidades de criação de gráficos. Se você precisar de uma geometria diferente, recomendamos procurá-la em pacotes de extensão, para ver se outra pessoa já a implementou (veja uma amostra em https://exts.ggplot2.tidyverse.org/gallery/). Por exemplo, o pacote ggridges (https://wilkelab.org/ggridges) é útil para construir ridgeline plots (gráficos de densidade sobrepostos), os quais podem ser úteis para visualizar as curvas de densidade de uma variável numérica para diferentes categorias de uma variável categórica. No gráfico a seguir, nós não apenas utilizamos uma nova geometria (geom_density_ridges()), mas também mapeamos a mesma variável a múltiplos atributos estéticos (tracao foi mapeada em y, fill e color), além de definirmos um atributo estético (alpha = 0.5) para tornar as curvas de densidade transparentes.\n\nlibrary(ggridges)\n\nggplot(milhas, aes(x = rodovia, y = tracao, fill = tracao, color = tracao)) +\n  geom_density_ridges(alpha = 0.5, show.legend = FALSE)\n#&gt; Picking joint bandwidth of 1.28\n\n\n\n\n\n\n\nO melhor lugar para obter uma visão abrangente de todas as geometrias oferecidas pelo ggplot2, assim como de todas as funções do pacote, é a página de referência: https://ggplot2.tidyverse.org/reference. Para aprender mais sobre uma geometria específica, use a ajuda (por exemplo, ?geom_smooth).\n\n9.3.1 Exercícios\n\nQual geom você usaria para construir um gráfico de linha? E um boxplot? E um histograma? E um gráfico de área?\n\nAnteriormente nesse capítulo nós utilizamos o argumento show.legend sem explicá-lo:\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) +\n  geom_smooth(aes(color = tracao), show.legend = FALSE)\n\n\n\nO que o argumento `show.legend = FALSE` faz nesse gráfico?\nO que acontece se você o remove?\nPor que você acha que o utilizamos anteriomente?\n\nO que o argumento se da geometria geom_smooth() faz?\n\nRecrie o código em R necessário para gerar os gráficos abaixo. Observe que sempre que uma variável categórica é utilizada no gráfico, trata-se da variável tracao.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#facetas",
    "href": "layers.html#facetas",
    "title": "9  ✅ Camadas",
    "section": "\n9.4 Facetas",
    "text": "9.4 Facetas\nNo capítulo Capítulo 1 você aprendeu sobre a criação de facetas com a função facet_wrap(), que divide um gráfico em “subgráficos”, os quais exibem um subconjunto dos dados com base em uma variável categórica.\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point() + \n  facet_wrap(~cilindros)\n\n\n\n\n\n\n\nPara que as facetas do seu gráfico sejam criadas com base em duas variáveis, troque a função facet_wrap() pela função facet_grid(). O primeiro argumento de facet_grid() também é uma fórmula, mas agora é uma fórmula com o seguinte formato: linhas ~ colunas.\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point() + \n  facet_grid(tracao ~ cilindros)\n\n\n\n\n\n\n\nPor padrão, cada uma dessas facetas compartilha a mesma escala e intervalo para os eixos x e y. Isso é útil quando você quer comparar os dados de facetas diferentes, mas pode ser limitante quando você quer visualizar melhor a relação entre as variáveis dentro de cada faceta. Definir, em uma função que cria facetas, o argumento scales como \"free\" permitirá escalas de diferentes nos eixos tanto das linhas quanto das colunas. Já \"free_x\" permitirá escalas diferentes apenas nas linhas e \"free_y\" permitirá escalas diferentes apenas nas colunas.\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point() + \n  facet_grid(tracao ~ cilindros, scales = \"free_y\")\n\n\n\n\n\n\n\n\n9.4.1 Exercícios\n\nO que acontece se você criar facetas com uma variável contínua?\n\nO que significam essas células vazias no gráfico acima com facet_grid(tracao ~ cilindros)? Execute o código a seguir. Como elas se relacionam com o gráfico que resulta desse código?\n\nggplot(milhas) + \n  geom_point(aes(x = tracao, y = cilindros))\n\n\n\nQuais gráficos o código a seguir cria? O que o . faz?\n\nggplot(milhas) + \n  geom_point(aes(x = cilindrada, y = rodovia)) +\n  facet_grid(tracao ~ .)\n\nggplot(milhas) + \n  geom_point(aes(x = cilindrada, y = rodovia)) +\n  facet_grid(. ~ cilindros)\n\n\n\nObserve o primeiro gráfico criado por faceta abaixo:\n\nggplot(milhas) + \n  geom_point(aes(x = cilindrada, y = rodovia)) + \n  facet_wrap(~ classe, nrow = 2)\n\nQuais são as vantagens de usar facetas ao invés do atributo estético color? Quais são as desvantagens? Como essas vantagens e desvantagens mudariam se você tivesse uma base de dados maior?\n\nLeia ?facet_wrap. O que o argumento nrow faz? O que o argumento ncol faz? Quais outras opções controlam o layout dos paineis individuais? Por que a função facet_grid() não tem os argumentos nrow e ncol?\n\nQual dos gráficos abaixo facilita a comparação do tamanho do motor (cilindrada) entre carros com diferentes tipos de tração? O que isso diz sobre quando colocar uma variável para criar facetas nas linhas ou colunas?\n\nggplot(milhas, aes(x = cilindrada)) + \n  geom_histogram() + \n  facet_grid(tracao ~ .)\n\nggplot(milhas, aes(x = cilindrada)) + \n  geom_histogram() +\n  facet_grid(. ~ tracao)\n\n\n\nRecrie o gráfico abaixo usando facet_wrap() ao invés de facet_grid(). Como as posições dos rótulos das facetas mudam?\n\nggplot(milhas) + \n  geom_point(aes(x = cilindrada, y = rodovia)) +\n  facet_grid(tracao ~ .)",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#transformações-estatísticas",
    "href": "layers.html#transformações-estatísticas",
    "title": "9  ✅ Camadas",
    "section": "\n9.5 Transformações estatísticas",
    "text": "9.5 Transformações estatísticas\nConsidere um gráfico de barras simples, construído com geom_bar() ou geom_col(). O gráfico abaixo mostra a quantidade total de diamantes na base de dados diamante, agrupados por corte. A base de dados diamante, do pacote dados, contém informações de ~54.000 diamantes, incluindo preco, quilate, cor, transparencia e corte de cada diamante. O gráfico mostra que há mais diamantes disponíveis com cortes de alta qualidade do que com cortes de baixa qualidade.\n\nggplot(diamante, aes(x = corte)) + \n  geom_bar()\n\n\n\n\n\n\n\nNo eixo x, o gráfico mostra a variável corte, uma variável da base de dados diamante. No eixo y, ele mostra a contagem (em inglês, count), mas contagem não é uma variável contida em diamante! De onde vem essa contagem? Muitos gráficos, como os gráficos de dispersão, representam os valores brutos da sua base de dados. Outros gráficos, como os gráficos de barras, calculam novos valores para serem representados no gráfico:\n\nGráficos de barras, histogramas e polígonos de frequência agrupam seus dados em intervalos e então representam no gráfico a contagem do intervalo, ou seja, a quantidade de observações contida em cada intervalo.\nSmoothers (suavizadores) ajustam um modelo aos seus dados e, em seguida, representam as predições deste modelo.\nGráficos boxplot calculam cinco medidas resumo da distribuição e então mostram esses valores como uma caixa com um formato específico.\n\nO algoritmo usado para calcular novos valores para um gráfico recebe o nome de stat, uma abreviação para o termo em inglês statistical transformation (ou seja, transformação estatística). Figura 9.2 mostra como esse processo funciona com o geom_bar().\n\n\n\n\n\n\n\nFigura 9.2: Ao criarmos um gráfico de barras, começamos com os dados brutos. Então, os agregamos para contar a quantidade de observações em cada barra. Finalmente, essa variável calculada (a contagem) é mapeada para o atributo estético do gráfico.\n\n\n\n\nVocê pode descobrir qual stat uma geometria usa ao inspecionar o valor padrão do argumento stat. Por exemplo, ?geom_bar() mostra que o valor padrão para stat é “count” (contagem), o que significa que geom_bar() usa stat_count(). stat_count() está documentada na mesma página que geom_bar(). Se você rolar a página, a seção chamada “Computed variables” (Variáveis calculadas) explica que ela calcula duas novas variáveis: count e prop.\nToda geometria tem uma stat padrão; e toda stat tem uma geometria padrão. Isso significa que você, em geral, pode usar geometrias sem se preocupar com a transformação estatística subjacente. No entanto, há três razões pelas quais você pode precisar usar uma stat explicitamente:\n\n\nVocê pode querer substituir a stat padrão. No código abaixo, nós mudamos a stat da geom_bar() de “count” (o padrão) para “identity”. Isso nos deixa mapear a altura das barras para os valores brutos de uma variável y.\n\ndiamante |&gt;\n  count(corte) |&gt;\n  ggplot(aes(x = corte, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\nVocê pode querer substituir o mapeamento padrão de variáveis transformadas para o atributo estético. Por exemplo, você pode querer mostrar um gráfico de barras com proporções, ao invés de contagens:\n\nggplot(diamante, aes(x = corte, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\n\n\n\nPara descobrir quais variáveis podem ser calculadas por stat, procure pela seção “computed variables” (“variáveis calculadas”) na ajuda do geom_bar().\n\n\nVocê pode querer chamar atenção, no seu código, para a transformação estatística utilizada. Por exemplo, você pode usar stat_summary(), que cria uma medida resumo dos valores de y para cada valor único de x, para destacar a medida resumo que você está calculando:\n\nggplot(diamante) + \n  stat_summary(\n    aes(x = corte, y = profundidade),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )\n\n\n\n\n\n\n\n\n\nO ggplot2 oferece mais de 20 stats para você utilizar. Cada stat é uma função, então você pode obter ajuda da maneira usual, por exemplo, ?stat_bin.\n\n9.5.1 Exercícios\n\nQual é a geometria associada ao stat_summary() por padrão? Como você poderia reescrever o código para gerar o gráfico anterior usando uma função geom ao invés da função stat?\nO que a função geom_col() faz? No que ela difere da função geom_bar()?\nA maioria dos geoms e stats vêm em pares que quase sempre são usados em conjunto. Faça uma lista de todos os pares. O que eles têm em comum? (Dica: Leia a documentação.)\nQuais variáveis o stat_smooth() calcula? Quais argumentos controlam o comportamento dessa função?\n\nNo nosso gráfico de barras de proporção, precisamos definir group = 1. Por que? Em outras palavras, qual é o problema com esses dois gráficos?\n\nggplot(diamante, aes(x = corte, y = after_stat(prop))) + \n  geom_bar()\nggplot(diamante, aes(x = corte, fill = cor, y = after_stat(prop))) + \n  geom_bar()",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#ajustes-de-posição",
    "href": "layers.html#ajustes-de-posição",
    "title": "9  ✅ Camadas",
    "section": "\n9.6 Ajustes de posição",
    "text": "9.6 Ajustes de posição\nHá mais um elemento mágico associado aos gráficos de barras. Você pode colorir um gráfico de barras usando o atributo estético color ou, de maneira mais útil, o atributo estético fill:\n# Esquerda\nggplot(milhas, aes(x = tracao, color = tracao)) + \n  geom_bar()\n\n# Direita\nggplot(milhas, aes(x = tracao, fill = tracao)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nObserve o que acontece se você mapear o atributo estético de preenchimento (fill) para outra variável, como classe: as barras são empilhadas automaticamente. Cada retângulo colorido representa uma combinação de tracao e classe.\n\nggplot(milhas, aes(x = tracao, fill = classe)) + \n  geom_bar()\n\n\n\n\n\n\n\nO empilhamento é realizado automaticamente usando o ajuste de posição especificado pelo argumento position. Se você não quer um gráfico de barras empilhadas, você pode usar uma das outras três opções: \"identity\", \"dodge\" ou \"fill\".\n\n\nposition = \"identity\" irá colocar cada objeto exatamente onde ele se encontra no contexto do gráfico. Essa opção não é muito útil para barras, porque elas se sobrepõem. Para visualizar essa sobreposição, precisamos tornar as barras ligeiramente transparentes, definindo alpha igual a um valor pequeno, ou completamente transparentes, definindo fill = NA.\n# Esquerda\nggplot(milhas, aes(x = tracao, fill = classe)) + \n  geom_bar(alpha = 1/5, position = \"identity\")\n\n# Direita\nggplot(milhas, aes(x = tracao, color = classe)) + \n  geom_bar(fill = NA, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\nO ajuste de posição “identity” é mais útil para geoms 2D, como pontos (geom_point()), na qual esse ajuste é o padrão.\n\nposition = \"fill\" funciona como position = \"stacked\", mas faz com que cada conjunto de barras empilhadas tenha a mesma altura. Isso facilita a comparação de proporções entre grupos.\n\nposition = \"dodge\" coloca objetos sobrepostos diretamente ao lado um do outro. Isso facilita a comparação de valores individuais.\n# Esquerda\nggplot(milhas, aes(x = tracao, fill = classe)) + \n  geom_bar(position = \"fill\")\n\n# Direita\nggplot(milhas, aes(x = tracao, fill = classe)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\nHá um outro tipo de ajuste que não é útil para gráficos de barras, mas pode ser muito útil para gráficos de dispersão. Lembre-se do nosso primeiro gráfico de dispersão. Você notou que o gráfico mostra apenas 126 pontos, mesmo que haja 234 observações no conjunto de dados?\n\n\n\n\n\n\n\n\nOs valores de rodovia e cilindrada são arredondados, então os pontos aparecem em uma grade e muitos pontos se sobrepõem. Esse problema é conhecido como sobreposição excessiva (em inglês, overplotting). Essa disposição dos pontos torna difícil visualizar a distribuição dos dados. Os pontos estão distribuídos de forma similiar ao longo do gráfico, ou há uma combinação especial de rodovia e cilindrada que contém 109 valores?\nVocê pode evitar essa sobreposição configurando o ajuste de posição para “jitter”. position = \"jitter\" adiciona uma pequena quantidade de ruído aleatório a cada ponto. Isso espalha os pontos porque é improvável que dois pontos recebam a mesma quantidade de ruído aleatório.\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) + \n  geom_point(position = \"jitter\")\n\n\n\n\n\n\n\nAdicionar aleatoriedade pode parecer uma maneira estranha de melhorar seu gráfico, mas ainda que isso torne o gráfico menos preciso em escalas pequenas, o torna mais revelador em grandes escalas. Já que essa é uma operação tão útil, o ggplot2 possui uma forma simplificada para geom_point(position = \"jitter\"): geom_jitter().\nPara aprender mais sobre ajustes de posição, veja a página de ajuda referente a cada tipo de ajuste: ?position_dodge, ?position_fill, ?position_identity, ?position_jitter e ?position_stack.\n\n9.6.1 Exercícios\n\n\nQual o problema com o gráfico abaixo? Como você poderia melhorá-lo?\n\nggplot(milhas, aes(x = cidade, y = rodovia)) + \n  geom_point()\n\n\n\nQual, caso exista, é a diferença entre os dois gráficos abaixo? Por que?\n\nggplot(milhas, aes(x = cilindrada, y = rodovia)) +\n  geom_point()\nggplot(milhas, aes(x = cilindrada, y = rodovia)) +\n  geom_point(position = \"identity\")\n\n\nQuais parâmetros do geom_jitter() controlam a quantidade de “jittering” (ruído aleatório adicionado a cada ponto)?\nCompare e aponte as diferenças entre geom_jitter() e geom_count().\nQual é o ajuste de posição padrão para o geom_boxplot()? Crie uma visualização com a base de dados milhas que demonstre isso.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#sistema-de-coordenadas",
    "href": "layers.html#sistema-de-coordenadas",
    "title": "9  ✅ Camadas",
    "section": "\n9.7 Sistema de coordenadas",
    "text": "9.7 Sistema de coordenadas\nOs sistemas de coordenadas são, provavelmente, a parte mais complicada do ggplot2. O sistema de coordenadas padrão é o sistema cartesiano, no qual as posições x e y atuam de forma independente para determinar a localização de cada ponto. Há outros dois sistemas de coordenadas que, ocasionalmente, são úteis.\n\n\ncoord_quickmap() ajusta corretamente a proporção entre os eixos para mapas geográficos. Isso é muito importante se você estiver plotando dados espaciais com o ggplot2. Não temos espaço para discutir mapas neste livro, mas você pode aprender mais no capítulo de Mapas do livro ggplot2: Elegant graphics for data analysis.\nnz &lt;- map_data(\"nz\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\") +\n  coord_quickmap()\n\n\n\n\n\n\n\n\n\n\n\n\ncoord_polar() usa coordenadas polares. As coordenadas polares revelam uma conexão interessante entre um gráfico de barras e um gráfico de rosa-dos-ventos (em inglês, Coxcomb).\nbar &lt;- ggplot(data = diamante) + \n  geom_bar(\n    mapping = aes(x = transparencia, fill = transparencia), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1)\n\nbar + coord_flip()\nbar + coord_polar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.7.1 Exercícios\n\nTransforme um gráfico de barras empilhadas em um gráfico de pizza usando coord_polar().\nQual a diferença entre coord_quickmap() e coord_map()?\n\nO que o gráfico abaixo te diz sobre a relação entre as variáveis cidade e rodovia? Por que coord_fixed() é importante? O que o geom_abline() faz?\n\nggplot(data = milhas, mapping = aes(x = cidade, y = rodovia)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#a-gramática-dos-gráficos-baseada-em-camadas",
    "href": "layers.html#a-gramática-dos-gráficos-baseada-em-camadas",
    "title": "9  ✅ Camadas",
    "section": "\n9.8 A gramática dos gráficos baseada em camadas",
    "text": "9.8 A gramática dos gráficos baseada em camadas\nNós podemos expandir o template para criação de um gráfico, que você aprendeu em Seção 1.3, ao adicionar ajustes de posição, transformações estatísticas, sistemas de coordenadas e facetas:\nggplot(data = &lt;DADOS&gt;) + \n  &lt;GEOM_FUNCTION&gt;(\n     mapping = aes(&lt;MAPPINGS&gt;),\n     stat = &lt;STAT&gt;, \n     position = &lt;POSITION&gt;\n  ) +\n  &lt;COORDINATE_FUNCTION&gt; +\n  &lt;FACET_FUNCTION&gt;\nNosso novo template recebe sete parâmetros, as palavras entre &lt; &gt; que aparecerem no template. Na prática, raramente será necessário fornecer esses sete parâmetros para construir um gráfico, porque o ggplot2 fornecerá valores padrão úteis para todos esses parâmetros, exceto os dados, o mapeamento estético e a função geom.\nOs sete parâmetros do template compõem a gramática dos gráficos, um sistema formal para construir gráficos. A gramática dos gráficos é baseada na ideia de que é possível descrever, de forma única, qualquer gráfico como uma combinação de: um conjunto de dados, uma geometria, um mapeamento estético, uma transformação estatística, um ajuste de posição, um sistema de coordenadas, um esquema de facetas e um tema.\nPara entender como isso funciona, considere como você poderia construir um gráfico básico do zero: você poderia começar com um conjunto de dados e, em seguida, transformá-lo nas informações que deseja mostrar (com uma transformação estatística). Em seguida, você poderia escolher uma geometria para representar cada observação dos dados transformados. Você poderia então usar os atributos estéticos das geometrias para representar variáveis presentes nesses dados. Você mapearia os valores de cada variável para cada mapeamento estético. Essas etapas estão ilustradas em Figura 9.3. Em seguida, você selecionaria um sistema de coordenadas para posicionar as geometrias, usando a localização dos objetos (que é em si um atributo estético) para exibir os valores das variáveis x e y.\n\n\n\n\n\n\n\nFigura 9.3: Etapas para ir de dados brutos a uma tabela de frequências e então a um gráfico de barras no qual a altura das barras representa as frequências.\n\n\n\n\nA essa altura, você teria um gráfico completo, mas poderia ir além e ajustar as posições das geoms no sistema de coordenadas (com ajustes de posição) ou dividir o gráfico em subgráficos (criando facetas). Você também poderia adicionar informações ao gráfico ao adicionar uma ou mais camadas. Cada camada adicional usará uma base de dados, uma geometria, um conjunto de mapeamentos estéticos, uma transformação estatística e um ajuste de posição.\nVocê pode usar esse método para construir qualquer gráfico que imaginar. Em outras palavras, você pode usar o template de código que aprendeu neste capítulo para construir centenas de milhares de gráficos distintos.\nCaso queira aprender mais sobre os fundamentos teóricos do ggplot2, você pode ler “The Layered Grammar of Graphics”, o artigo científico que descreve detalhadamente a teoria do ggplot2.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "layers.html#resumo",
    "href": "layers.html#resumo",
    "title": "9  ✅ Camadas",
    "section": "\n9.9 Resumo",
    "text": "9.9 Resumo\nNeste capítulo você aprendeu sobre a gramática dos gráficos baseada em camadas, começando com atributos estéticos e geometrias para construir um gráfico simples, facetas para dividir o gráfico em subgráficos, transformações estatísticas para entender como as geometrias são calculadas, ajustes de posição para controlar de forma precisa essas posições quando as geometrias se sobrepõem e sistemas de coordenadas que permitem modificar o que x e y significam. Uma camada que ainda não abordamos é o tema (theme), que será introduzida em Seção 11.5.\nDois recursos muito úteis para ter uma visão geral do funcionamento completo do ggplot2 são: a cheatsheet do ggplot2 (que você encontra, em inglês, em https://posit.co/resources/cheatsheets) e o site do pacote ggplot2, também em inglês (https://ggplot2.tidyverse.org).\nUma lição importante que você deve tirar deste capítulo é que, quando sentir a necessidade de uma geometria que não é fornecida pelo ggplot2, é sempre uma boa ideia verificar se alguém já resolveu seu problema criando um pacote de extensão do ggplot2 que ofereça essa geometria.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>✅ Camadas</span>"
    ]
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "10  Exploratory data analysis",
    "section": "",
    "text": "10.1 Introduction\nThis chapter will show you how to use visualization and transformation to explore your data in a systematic way, a task that statisticians call exploratory data analysis, or EDA for short. EDA is an iterative cycle. You:\nEDA is not a formal process with a strict set of rules. More than anything, EDA is a state of mind. During the initial phases of EDA you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will home in on a few particularly productive insights that you’ll eventually write up and communicate to others.\nEDA is an important part of any data analysis, even if the primary research questions are handed to you on a platter, because you always need to investigate the quality of your data. Data cleaning is just one application of EDA: you ask questions about whether your data meets your expectations or not. To do data cleaning, you’ll need to deploy all the tools of EDA: visualization, transformation, and modelling.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "10  Exploratory data analysis",
    "section": "",
    "text": "Generate questions about your data.\nSearch for answers by visualizing, transforming, and modelling your data.\nUse what you learn to refine your questions and/or generate new questions.\n\n\n\n\n10.1.1 Prerequisites\nIn this chapter we’ll combine what you’ve learned about dplyr and ggplot2 to interactively ask questions, answer them with data, and then ask new questions.\n\nlibrary(tidyverse)",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#questions",
    "href": "EDA.html#questions",
    "title": "10  Exploratory data analysis",
    "section": "\n10.2 Questions",
    "text": "10.2 Questions\n\n“There are no routine statistical questions, only questionable statistical routines.” — Sir David Cox\n\n\n“Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” — John Tukey\n\nYour goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.\nEDA is fundamentally a creative process. And like most creative processes, the key to asking quality questions is to generate a large quantity of questions. It is difficult to ask revealing questions at the start of your analysis because you do not know what insights can be gleaned from your dataset. On the other hand, each new question that you ask will expose you to a new aspect of your data and increase your chance of making a discovery. You can quickly drill down into the most interesting parts of your data—and develop a set of thought-provoking questions—if you follow up each question with a new question based on what you find.\nThere is no rule about which questions you should ask to guide your research. However, two types of questions will always be useful for making discoveries within your data. You can loosely word these questions as:\n\nWhat type of variation occurs within my variables?\nWhat type of covariation occurs between my variables?\n\nThe rest of this chapter will look at these two questions. We’ll explain what variation and covariation are, and we’ll show you several ways to answer each question.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#variation",
    "href": "EDA.html#variation",
    "title": "10  Exploratory data analysis",
    "section": "\n10.3 Variation",
    "text": "10.3 Variation\nVariation is the tendency of the values of a variable to change from measurement to measurement. You can see variation easily in real life; if you measure any continuous variable twice, you will get two different results. This is true even if you measure quantities that are constant, like the speed of light. Each of your measurements will include a small amount of error that varies from measurement to measurement. Variables can also vary if you measure across different subjects (e.g., the eye colors of different people) or at different times (e.g., the energy levels of an electron at different moments). Every variable has its own pattern of variation, which can reveal interesting information about how that it varies between measurements on the same observation as well as across observations. The best way to understand that pattern is to visualize the distribution of the variable’s values, which you’ve learned about in Capítulo 1.\nWe’ll start our exploration by visualizing the distribution of weights (carat) of ~54,000 diamonds from the diamonds dataset. Since carat is a numerical variable, we can use a histogram:\n\nggplot(diamonds, aes(x = carat)) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\nNow that you can visualize variation, what should you look for in your plots? And what type of follow-up questions should you ask? We’ve put together a list below of the most useful types of information that you will find in your graphs, along with some follow-up questions for each type of information. The key to asking good follow-up questions will be to rely on your curiosity (What do you want to learn more about?) as well as your skepticism (How could this be misleading?).\n\n10.3.1 Typical values\nIn both bar charts and histograms, tall bars show the common values of a variable, and shorter bars show less-common values. Places that do not have bars reveal values that were not seen in your data. To turn this information into useful questions, look for anything unexpected:\n\nWhich values are the most common? Why?\nWhich values are rare? Why? Does that match your expectations?\nCan you see any unusual patterns? What might explain them?\n\nLet’s take a look at the distribution of carat for smaller diamonds.\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt; 3)\n\nggplot(smaller, aes(x = carat)) +\n  geom_histogram(binwidth = 0.01)\n\n\n\n\n\n\n\nThis histogram suggests several interesting questions:\n\nWhy are there more diamonds at whole carats and common fractions of carats?\nWhy are there more diamonds slightly to the right of each peak than there are slightly to the left of each peak?\n\nVisualizations can also reveal clusters, which suggest that subgroups exist in your data. To understand the subgroups, ask:\n\nHow are the observations within each subgroup similar to each other?\nHow are the observations in separate clusters different from each other?\nHow can you explain or describe the clusters?\nWhy might the appearance of clusters be misleading?\n\nSome of these questions can be answered with the data while some will require domain expertise about the data. Many of them will prompt you to explore a relationship between variables, for example, to see if the values of one variable can explain the behavior of another variable. We’ll get to that shortly.\n\n10.3.2 Unusual values\nOutliers are observations that are unusual; data points that don’t seem to fit the pattern. Sometimes outliers are data entry errors, sometimes they are simply values at the extremes that happened to be observed in this data collection, and other times they suggest important new discoveries. When you have a lot of data, outliers are sometimes difficult to see in a histogram. For example, take the distribution of the y variable from the diamonds dataset. The only evidence of outliers is the unusually wide limits on the x-axis.\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\nThere are so many observations in the common bins that the rare bins are very short, making it very difficult to see them (although maybe if you stare intently at 0 you’ll spot something). To make it easy to see the unusual values, we need to zoom to small values of the y-axis with coord_cartesian():\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5) +\n  coord_cartesian(ylim = c(0, 50))\n\n\n\n\n\n\n\ncoord_cartesian() also has an xlim() argument for when you need to zoom into the x-axis. ggplot2 also has xlim() and ylim() functions that work slightly differently: they throw away the data outside the limits.\nThis allows us to see that there are three unusual values: 0, ~30, and ~60. We pluck them out with dplyr:\n\nunusual &lt;- diamonds |&gt; \n  filter(y &lt; 3 | y &gt; 20) |&gt; \n  select(price, x, y, z) |&gt;\n  arrange(y)\nunusual\n#&gt; # A tibble: 9 × 4\n#&gt;   price     x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  5139  0      0    0   \n#&gt; 2  6381  0      0    0   \n#&gt; 3 12800  0      0    0   \n#&gt; 4 15686  0      0    0   \n#&gt; 5 18034  0      0    0   \n#&gt; 6  2130  0      0    0   \n#&gt; 7  2130  0      0    0   \n#&gt; 8  2075  5.15  31.8  5.12\n#&gt; 9 12210  8.09  58.9  8.06\n\nThe y variable measures one of the three dimensions of these diamonds, in mm. We know that diamonds can’t have a width of 0mm, so these values must be incorrect. By doing EDA, we have discovered missing data that was coded as 0, which we never would have found by simply searching for NAs. Going forward we might choose to re-code these values as NAs in order to prevent misleading calculations. We might also suspect that measurements of 32mm and 59mm are implausible: those diamonds are over an inch long, but don’t cost hundreds of thousands of dollars!\nIt’s good practice to repeat your analysis with and without the outliers. If they have minimal effect on the results, and you can’t figure out why they’re there, it’s reasonable to omit them, and move on. However, if they have a substantial effect on your results, you shouldn’t drop them without justification. You’ll need to figure out what caused them (e.g., a data entry error) and disclose that you removed them in your write-up.\n\n10.3.3 Exercises\n\nExplore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.\nExplore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)\nHow many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?\nCompare and contrast coord_cartesian() vs. xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#sec-unusual-values-eda",
    "href": "EDA.html#sec-unusual-values-eda",
    "title": "10  Exploratory data analysis",
    "section": "\n10.4 Unusual values",
    "text": "10.4 Unusual values\nIf you’ve encountered unusual values in your dataset, and simply want to move on to the rest of your analysis, you have two options.\n\n\nDrop the entire row with the strange values:\n\ndiamonds2 &lt;- diamonds |&gt; \n  filter(between(y, 3, 20))\n\nWe don’t recommend this option because one invalid value doesn’t imply that all the other values for that observation are also invalid. Additionally, if you have low quality data, by the time that you’ve applied this approach to every variable you might find that you don’t have any data left!\n\n\nInstead, we recommend replacing the unusual values with missing values. The easiest way to do this is to use mutate() to replace the variable with a modified copy. You can use the if_else() function to replace unusual values with NA:\n\ndiamonds2 &lt;- diamonds |&gt; \n  mutate(y = if_else(y &lt; 3 | y &gt; 20, NA, y))\n\n\n\nIt’s not obvious where you should plot missing values, so ggplot2 doesn’t include them in the plot, but it does warn that they’ve been removed:\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point()\n#&gt; Warning: Removed 9 rows containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\nTo suppress that warning, set na.rm = TRUE:\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point(na.rm = TRUE)\n\nOther times you want to understand what makes observations with missing values different to observations with recorded values. For example, in nycflights13::flights1, missing values in the dep_time variable indicate that the flight was cancelled. So you might want to compare the scheduled departure times for cancelled and non-cancelled times. You can do this by making a new variable, using is.na() to check if dep_time is missing.\n\nnycflights13::flights |&gt; \n  mutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + (sched_min / 60)\n  ) |&gt; \n  ggplot(aes(x = sched_dep_time)) + \n  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)\n\n\n\n\n\n\n\nHowever this plot isn’t great because there are many more non-cancelled flights than cancelled flights. In the next section we’ll explore some techniques for improving this comparison.\n\n10.4.1 Exercises\n\nWhat happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference in how missing values are handled in histograms and bar charts?\nWhat does na.rm = TRUE do in mean() and sum()?\nRecreate the frequency plot of scheduled_dep_time colored by whether the flight was cancelled or not. Also facet by the cancelled variable. Experiment with different values of the scales variable in the faceting function to mitigate the effect of more non-cancelled flights than cancelled flights.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#covariation",
    "href": "EDA.html#covariation",
    "title": "10  Exploratory data analysis",
    "section": "\n10.5 Covariation",
    "text": "10.5 Covariation\nIf variation describes the behavior within a variable, covariation describes the behavior between variables. Covariation is the tendency for the values of two or more variables to vary together in a related way. The best way to spot covariation is to visualize the relationship between two or more variables.\n\n10.5.1 A categorical and a numerical variable\nFor example, let’s explore how the price of a diamond varies with its quality (measured by cut) using geom_freqpoly():\n\nggplot(diamonds, aes(x = price)) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\nNote that ggplot2 uses an ordered color scale for cut because it’s defined as an ordered factor variable in the data. You’ll learn more about these in Seção 16.6.\nThe default appearance of geom_freqpoly() is not that useful here because the height, determined by the overall count, differs so much across cuts, making it hard to see the differences in the shapes of their distributions.\nTo make the comparison easier we need to swap what is displayed on the y-axis. Instead of displaying count, we’ll display the density, which is the count standardized so that the area under each frequency polygon is one.\n\nggplot(diamonds, aes(x = price, y = after_stat(density))) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\n\n\n\nNote that we’re mapping the density to y, but since density is not a variable in the diamonds dataset, we need to first calculate it. We use the after_stat() function to do so.\nThere’s something rather surprising about this plot - it appears that fair diamonds (the lowest quality) have the highest average price! But maybe that’s because frequency polygons are a little hard to interpret - there’s a lot going on in this plot.\nA visually simpler plot for exploring this relationship is using side-by-side boxplots.\n\nggplot(diamonds, aes(x = cut, y = price)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nWe see much less information about the distribution, but the boxplots are much more compact so we can more easily compare them (and fit more on one plot). It supports the counter-intuitive finding that better quality diamonds are typically cheaper! In the exercises, you’ll be challenged to figure out why.\ncut is an ordered factor: fair is worse than good, which is worse than very good and so on. Many categorical variables don’t have such an intrinsic order, so you might want to reorder them to make a more informative display. One way to do that is with fct_reorder(). You’ll learn more about that function in Seção 16.4, but we want to give you a quick preview here because it’s so useful. For example, take the class variable in the mpg dataset. You might be interested to know how highway mileage varies across classes:\n\nggplot(mpg, aes(x = class, y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nTo make the trend easier to see, we can reorder class based on the median value of hwy:\n\nggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\nIf you have long variable names, geom_boxplot() will work better if you flip it 90°. You can do that by exchanging the x and y aesthetic mappings.\n\nggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n10.5.1.1 Exercises\n\nUse what you’ve learned to improve the visualization of the departure times of cancelled vs. non-cancelled flights.\nBased on EDA, what variable in the diamonds dataset appears to be most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?\nInstead of exchanging the x and y variables, add coord_flip() as a new layer to the vertical boxplot to create a horizontal one. How does this compare to exchanging the variables?\nOne problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs. cut. What do you learn? How do you interpret the plots?\nCreate a visualization of diamond prices vs. a categorical variable from the diamonds dataset using geom_violin(), then a faceted geom_histogram(), then a colored geom_freqpoly(), and then a colored geom_density(). Compare and contrast the four plots. What are the pros and cons of each method of visualizing the distribution of a numerical variable based on the levels of a categorical variable?\nIf you have a small dataset, it’s sometimes useful to use geom_jitter() to avoid overplotting to more easily see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.\n\n10.5.2 Two categorical variables\nTo visualize the covariation between categorical variables, you’ll need to count the number of observations for each combination of levels of these categorical variables. One way to do that is to rely on the built-in geom_count():\n\nggplot(diamonds, aes(x = cut, y = color)) +\n  geom_count()\n\n\n\n\n\n\n\nThe size of each circle in the plot displays how many observations occurred at each combination of values. Covariation will appear as a strong correlation between specific x values and specific y values.\nAnother approach for exploring the relationship between these variables is computing the counts with dplyr:\n\ndiamonds |&gt; \n  count(color, cut)\n#&gt; # A tibble: 35 × 3\n#&gt;   color cut           n\n#&gt;   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;\n#&gt; 1 D     Fair        163\n#&gt; 2 D     Good        662\n#&gt; 3 D     Very Good  1513\n#&gt; 4 D     Premium    1603\n#&gt; 5 D     Ideal      2834\n#&gt; 6 E     Fair        224\n#&gt; # ℹ 29 more rows\n\nThen visualize with geom_tile() and the fill aesthetic:\n\ndiamonds |&gt; \n  count(color, cut) |&gt;  \n  ggplot(aes(x = color, y = cut)) +\n  geom_tile(aes(fill = n))\n\n\n\n\n\n\n\nIf the categorical variables are unordered, you might want to use the seriation package to simultaneously reorder the rows and columns in order to more clearly reveal interesting patterns. For larger plots, you might want to try the heatmaply package, which creates interactive plots.\n\n10.5.2.1 Exercises\n\nHow could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?\nWhat different data insights do you get with a segmented bar chart if color is mapped to the x aesthetic and cut is mapped to the fill aesthetic? Calculate the counts that fall into each of the segments.\nUse geom_tile() together with dplyr to explore how average flight departure delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?\n\n10.5.3 Two numerical variables\nYou’ve already seen one great way to visualize the covariation between two numerical variables: draw a scatterplot with geom_point(). You can see covariation as a pattern in the points. For example, you can see a positive relationship between the carat size and price of a diamond: diamonds with more carats have a higher price. The relationship is exponential.\n\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n(In this section we’ll use the smaller dataset to stay focused on the bulk of the diamonds that are smaller than 3 carats)\nScatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black, making it hard to judge differences in the density of the data across the 2-dimensional space as well as making it hard to spot the trend. You’ve already seen one way to fix the problem: using the alpha aesthetic to add transparency.\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_point(alpha = 1 / 100)\n\n\n\n\n\n\n\nBut using transparency can be challenging for very large datasets. Another solution is to use bin. Previously you used geom_histogram() and geom_freqpoly() to bin in one dimension. Now you’ll learn how to use geom_bin2d() and geom_hex() to bin in two dimensions.\ngeom_bin2d() and geom_hex() divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin. geom_bin2d() creates rectangular bins. geom_hex() creates hexagonal bins. You will need to install the hexbin package to use geom_hex().\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_bin2d()\n\n# install.packages(\"hexbin\")\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_hex()\n\n\n\n\n\n\n\n\n\n\nAnother option is to bin one continuous variable so it acts like a categorical variable. Then you can use one of the techniques for visualizing the combination of a categorical and a continuous variable that you learned about. For example, you could bin carat and then for each group, display a boxplot:\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_width(carat, 0.1)))\n\n\n\n\n\n\n\ncut_width(x, width), as used above, divides x into bins of width width. By default, boxplots look roughly the same (apart from number of outliers) regardless of how many observations there are, so it’s difficult to tell that each boxplot summaries a different number of points. One way to show that is to make the width of the boxplot proportional to the number of points with varwidth = TRUE.\n\n10.5.3.1 Exercises\n\nInstead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs. cut_number()? How does that impact a visualization of the 2d distribution of carat and price?\nVisualize the distribution of carat, partitioned by price.\nHow does the price distribution of very large diamonds compare to small diamonds? Is it as you expect, or does it surprise you?\nCombine two of the techniques you’ve learned to visualize the combined distribution of cut, carat, and price.\n\nTwo dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the following plot have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately. Why is a scatterplot a better display than a binned plot for this case?\n\ndiamonds |&gt; \n  filter(x &gt;= 4) |&gt; \n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))\n\n\n\nInstead of creating boxes of equal width with cut_width(), we could create boxes that contain roughly equal number of points with cut_number(). What are the advantages and disadvantages of this approach?\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_number(carat, 20)))",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#patterns-and-models",
    "href": "EDA.html#patterns-and-models",
    "title": "10  Exploratory data analysis",
    "section": "\n10.6 Patterns and models",
    "text": "10.6 Patterns and models\nIf a systematic relationship exists between two variables it will appear as a pattern in the data. If you spot a pattern, ask yourself:\n\nCould this pattern be due to coincidence (i.e. random chance)?\nHow can you describe the relationship implied by the pattern?\nHow strong is the relationship implied by the pattern?\nWhat other variables might affect the relationship?\nDoes the relationship change if you look at individual subgroups of the data?\n\nPatterns in your data provide clues about relationships, i.e., they reveal covariation. If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it. If two variables covary, you can use the values of one variable to make better predictions about the values of the second. If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.\nModels are a tool for extracting patterns out of data. For example, consider the diamonds data. It’s hard to understand the relationship between cut and price, because cut and carat, and carat and price are tightly related. It’s possible to use a model to remove the very strong relationship between price and carat so we can explore the subtleties that remain. The following code fits a model that predicts price from carat and then computes the residuals (the difference between the predicted value and the actual value). The residuals give us a view of the price of the diamond, once the effect of carat has been removed. Note that instead of using the raw values of price and carat, we log transform them first, and fit a model to the log-transformed values. Then, we exponentiate the residuals to put them back in the scale of raw prices.\n\nlibrary(tidymodels)\n\ndiamonds &lt;- diamonds |&gt;\n  mutate(\n    log_price = log(price),\n    log_carat = log(carat)\n  )\n\ndiamonds_fit &lt;- linear_reg() |&gt;\n  fit(log_price ~ log_carat, data = diamonds)\n\ndiamonds_aug &lt;- augment(diamonds_fit, new_data = diamonds) |&gt;\n  mutate(.resid = exp(.resid))\n\nggplot(diamonds_aug, aes(x = carat, y = .resid)) + \n  geom_point()\n\n\n\n\n\n\n\nOnce you’ve removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive.\n\nggplot(diamonds_aug, aes(x = cut, y = .resid)) + \n  geom_boxplot()\n\n\n\n\n\n\n\nWe’re not discussing modelling in this book because understanding what models are and how they work is easiest once you have tools of data wrangling and programming in hand.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#summary",
    "href": "EDA.html#summary",
    "title": "10  Exploratory data analysis",
    "section": "\n10.7 Summary",
    "text": "10.7 Summary\nIn this chapter you’ve learned a variety of tools to help you understand the variation within your data. You’ve seen techniques that work with a single variable at a time and with a pair of variables. This might seem painfully restrictive if you have tens or hundreds of variables in your data, but they’re the foundation upon which all other techniques are built.\nIn the next chapter, we’ll focus on the tools we can use to communicate our results.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "EDA.html#footnotes",
    "href": "EDA.html#footnotes",
    "title": "10  Exploratory data analysis",
    "section": "",
    "text": "Remember that when we need to be explicit about where a function (or dataset) comes from, we’ll use the special form package::function() or package::dataset.↩︎",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Exploratory data analysis</span>"
    ]
  },
  {
    "objectID": "communication.html",
    "href": "communication.html",
    "title": "11  Communication",
    "section": "",
    "text": "11.1 Introduction\nIn Capítulo 10, you learned how to use plots as tools for exploration. When you make exploratory plots, you know—even before looking—which variables the plot will display. You made each plot for a purpose, could quickly look at it, and then move on to the next plot. In the course of most analyses, you’ll produce tens or hundreds of plots, most of which are immediately thrown away.\nNow that you understand your data, you need to communicate your understanding to others. Your audience will likely not share your background knowledge and will not be deeply invested in the data. To help others quickly build up a good mental model of the data, you will need to invest considerable effort in making your plots as self-explanatory as possible. In this chapter, you’ll learn some of the tools that ggplot2 provides to do so.\nThis chapter focuses on the tools you need to create good graphics. We assume that you know what you want, and just need to know how to do it. For that reason, we highly recommend pairing this chapter with a good general visualization book. We particularly like The Truthful Art, by Albert Cairo. It doesn’t teach the mechanics of creating visualizations, but instead focuses on what you need to think about in order to create effective graphics.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#introduction",
    "href": "communication.html#introduction",
    "title": "11  Communication",
    "section": "",
    "text": "11.1.1 Prerequisites\nIn this chapter, we’ll focus once again on ggplot2. We’ll also use a little dplyr for data manipulation, scales to override the default breaks, labels, transformations and palettes, and a few ggplot2 extension packages, including ggrepel (https://ggrepel.slowkow.com) by Kamil Slowikowski and patchwork (https://patchwork.data-imaginist.com) by Thomas Lin Pedersen. Don’t forget that you’ll need to install those packages with install.packages() if you don’t already have them.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggrepel)\nlibrary(patchwork)",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#labels",
    "href": "communication.html#labels",
    "title": "11  Communication",
    "section": "\n11.2 Labels",
    "text": "11.2 Labels\nThe easiest place to start when turning an exploratory graphic into an expository graphic is with good labels. You add labels with the labs() function.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Engine displacement (L)\",\n    y = \"Highway fuel economy (mpg)\",\n    color = \"Car type\",\n    title = \"Fuel efficiency generally decreases with engine size\",\n    subtitle = \"Two seaters (sports cars) are an exception because of their light weight\",\n    caption = \"Data from fueleconomy.gov\"\n  )\n\n\n\n\n\n\n\nThe purpose of a plot title is to summarize the main finding. Avoid titles that just describe what the plot is, e.g., “A scatterplot of engine displacement vs. fuel economy”.\nIf you need to add more text, there are two other useful labels: subtitle adds additional detail in a smaller font beneath the title and caption adds text at the bottom right of the plot, often used to describe the source of the data. You can also use labs() to replace the axis and legend titles. It’s usually a good idea to replace short variable names with more detailed descriptions, and to include the units.\nIt’s possible to use mathematical equations instead of text strings. Just switch \"\" out for quote() and read about the available options in ?plotmath:\n\ndf &lt;- tibble(\n  x = 1:10,\n  y = cumsum(x^2)\n)\n\nggplot(df, aes(x, y)) +\n  geom_point() +\n  labs(\n    x = quote(x[i]),\n    y = quote(sum(x[i] ^ 2, i == 1, n))\n  )\n\n\n\n\n\n\n\n\n11.2.1 Exercises\n\nCreate one plot on the fuel economy data with customized title, subtitle, caption, x, y, and color labels.\n\nRecreate the following plot using the fuel economy data. Note that both the colors and shapes of points vary by type of drive train.\n\n\n\n\n\n\n\n\n\nTake an exploratory graphic that you’ve created in the last month, and add informative titles to make it easier for others to understand.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#annotations",
    "href": "communication.html#annotations",
    "title": "11  Communication",
    "section": "\n11.3 Annotations",
    "text": "11.3 Annotations\nIn addition to labelling major components of your plot, it’s often useful to label individual observations or groups of observations. The first tool you have at your disposal is geom_text(). geom_text() is similar to geom_point(), but it has an additional aesthetic: label. This makes it possible to add textual labels to your plots.\nThere are two possible sources of labels. First, you might have a tibble that provides labels. In the following plot we pull out the cars with the highest engine size in each drive type and save their information as a new data frame called label_info.\n\nlabel_info &lt;- mpg |&gt;\n  group_by(drv) |&gt;\n  arrange(desc(displ)) |&gt;\n  slice_head(n = 1) |&gt;\n  mutate(\n    drive_type = case_when(\n      drv == \"f\" ~ \"front-wheel drive\",\n      drv == \"r\" ~ \"rear-wheel drive\",\n      drv == \"4\" ~ \"4-wheel drive\"\n    )\n  ) |&gt;\n  select(displ, hwy, drv, drive_type)\n\nlabel_info\n#&gt; # A tibble: 3 × 4\n#&gt; # Groups:   drv [3]\n#&gt;   displ   hwy drv   drive_type       \n#&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;            \n#&gt; 1   6.5    17 4     4-wheel drive    \n#&gt; 2   5.3    25 f     front-wheel drive\n#&gt; 3   7      24 r     rear-wheel drive\n\nThen, we use this new data frame to directly label the three groups to replace the legend with labels placed directly on the plot. Using the fontface and size arguments we can customize the look of the text labels. They’re larger than the rest of the text on the plot and bolded. (theme(legend.position = \"none\") turns all the legends off — we’ll talk about it more shortly.)\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_text(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, hjust = \"right\", vjust = \"bottom\"\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nNote the use of hjust (horizontal justification) and vjust (vertical justification) to control the alignment of the label.\nHowever the annotated plot we made above is hard to read because the labels overlap with each other, and with the points. We can use the geom_label_repel() function from the ggrepel package to address both of these issues. This useful package will automatically adjust labels so that they don’t overlap:\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE) +\n  geom_label_repel(\n    data = label_info, \n    aes(x = displ, y = hwy, label = drive_type),\n    fontface = \"bold\", size = 5, nudge_y = 2\n  ) +\n  theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nYou can also use the same idea to highlight certain points on a plot with geom_text_repel() from the ggrepel package. Note another handy technique used here: we added a second layer of large, hollow points to further highlight the labelled points.\n\npotential_outliers &lt;- mpg |&gt;\n  filter(hwy &gt; 40 | (hwy &gt; 20 & displ &gt; 5))\n  \nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_text_repel(data = potential_outliers, aes(label = model)) +\n  geom_point(data = potential_outliers, color = \"red\") +\n  geom_point(\n    data = potential_outliers,\n    color = \"red\", size = 3, shape = \"circle open\"\n  )\n\n\n\n\n\n\n\nRemember, in addition to geom_text() and geom_label(), you have many other geoms in ggplot2 available to help annotate your plot. A couple ideas:\n\nUse geom_hline() and geom_vline() to add reference lines. We often make them thick (linewidth = 2) and white (color = white), and draw them underneath the primary data layer. That makes them easy to see, without drawing attention away from the data.\nUse geom_rect() to draw a rectangle around points of interest. The boundaries of the rectangle are defined by aesthetics xmin, xmax, ymin, ymax. Alternatively, look into the ggforce package, specifically geom_mark_hull(), which allows you to annotate subsets of points with hulls.\nUse geom_segment() with the arrow argument to draw attention to a point with an arrow. Use aesthetics x and y to define the starting location, and xend and yend to define the end location.\n\nAnother handy function for adding annotations to plots is annotate(). As a rule of thumb, geoms are generally useful for highlighting a subset of the data while annotate() is useful for adding one or few annotation elements to a plot.\nTo demonstrate using annotate(), let’s create some text to add to our plot. The text is a bit long, so we’ll use stringr::str_wrap() to automatically add line breaks to it given the number of characters you want per line:\n\ntrend_text &lt;- \"Larger engine sizes tend to have lower fuel economy.\" |&gt;\n  str_wrap(width = 30)\ntrend_text\n#&gt; [1] \"Larger engine sizes tend to\\nhave lower fuel economy.\"\n\nThen, we add two layers of annotation: one with a label geom and the other with a segment geom. The x and y aesthetics in both define where the annotation should start, and the xend and yend aesthetics in the segment annotation define the end location of the segment. Note also that the segment is styled as an arrow.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point() +\n  annotate(\n    geom = \"label\", x = 3.5, y = 38,\n    label = trend_text,\n    hjust = \"left\", color = \"red\"\n  ) +\n  annotate(\n    geom = \"segment\",\n    x = 3, y = 35, xend = 5, yend = 25, color = \"red\",\n    arrow = arrow(type = \"closed\")\n  )\n\n\n\n\n\n\n\nAnnotation is a powerful tool for communicating main takeaways and interesting features of your visualizations. The only limit is your imagination (and your patience with positioning annotations to be aesthetically pleasing)!\n\n11.3.1 Exercises\n\nUse geom_text() with infinite positions to place text at the four corners of the plot.\nUse annotate() to add a point geom in the middle of your last plot without having to create a tibble. Customize the shape, size, or color of the point.\nHow do labels with geom_text() interact with faceting? How can you add a label to a single facet? How can you put a different label in each facet? (Hint: Think about the dataset that is being passed to geom_text().)\nWhat arguments to geom_label() control the appearance of the background box?\nWhat are the four arguments to arrow()? How do they work? Create a series of plots that demonstrate the most important options.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#scales",
    "href": "communication.html#scales",
    "title": "11  Communication",
    "section": "\n11.4 Scales",
    "text": "11.4 Scales\nThe third way you can make your plot better for communication is to adjust the scales. Scales control how the aesthetic mappings manifest visually.\n\n11.4.1 Default scales\nNormally, ggplot2 automatically adds scales for you. For example, when you type:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nggplot2 automatically adds default scales behind the scenes:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_color_discrete()\n\nNote the naming scheme for scales: scale_ followed by the name of the aesthetic, then _, then the name of the scale. The default scales are named according to the type of variable they align with: continuous, discrete, datetime, or date. scale_x_continuous() puts the numeric values from displ on a continuous number line on the x-axis, scale_color_discrete() chooses colors for each of the class of car, etc. There are lots of non-default scales which you’ll learn about below.\nThe default scales have been carefully chosen to do a good job for a wide range of inputs. Nevertheless, you might want to override the defaults for two reasons:\n\nYou might want to tweak some of the parameters of the default scale. This allows you to do things like change the breaks on the axes, or the key labels on the legend.\nYou might want to replace the scale altogether, and use a completely different algorithm. Often you can do better than the default because you know more about the data.\n\n11.4.2 Axis ticks and legend keys\nCollectively axes and legends are called guides. Axes are used for x and y aesthetics; legends are used for everything else.\nThere are two primary arguments that affect the appearance of the ticks on the axes and the keys on the legend: breaks and labels. Breaks controls the position of the ticks, or the values associated with the keys. Labels controls the text label associated with each tick/key. The most common use of breaks is to override the default choice:\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(15, 40, by = 5)) \n\n\n\n\n\n\n\nYou can use labels in the same way (a character vector the same length as breaks), but you can also set it to NULL to suppress the labels altogether. This can be useful for maps, or for publishing plots where you can’t share the absolute numbers. You can also use breaks and labels to control the appearance of legends. For discrete scales for categorical variables, labels can be a named list of the existing levels names and the desired labels for them.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  scale_x_continuous(labels = NULL) +\n  scale_y_continuous(labels = NULL) +\n  scale_color_discrete(labels = c(\"4\" = \"4-wheel\", \"f\" = \"front\", \"r\" = \"rear\"))\n\n\n\n\n\n\n\nThe labels argument coupled with labelling functions from the scales package is also useful for formatting numbers as currency, percent, etc. The plot on the left shows default labelling with label_dollar(), which adds a dollar sign as well as a thousand separator comma. The plot on the right adds further customization by dividing dollar values by 1,000 and adding a suffix “K” (for “thousands”) as well as adding custom breaks. Note that breaks is in the original scale of the data.\n# Left\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(labels = label_dollar())\n\n# Right\nggplot(diamonds, aes(x = price, y = cut)) +\n  geom_boxplot(alpha = 0.05) +\n  scale_x_continuous(\n    labels = label_dollar(scale = 1/1000, suffix = \"K\"), \n    breaks = seq(1000, 19000, by = 6000)\n  )\n\n\n\n\n\n\n\n\n\n\nAnother handy label function is label_percent():\n\nggplot(diamonds, aes(x = cut, fill = clarity)) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(name = \"Percentage\", labels = label_percent())\n\n\n\n\n\n\n\nAnother use of breaks is when you have relatively few data points and want to highlight exactly where the observations occur. For example, take this plot that shows when each US president started and ended their term.\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_x_date(name = NULL, breaks = presidential$start, date_labels = \"'%y\")\n\n\n\n\n\n\n\nNote that for the breaks argument we pulled out the start variable as a vector with presidential$start because we can’t do an aesthetic mapping for this argument. Also note that the specification of breaks and labels for date and datetime scales is a little different:\n\ndate_labels takes a format specification, in the same form as parse_datetime().\ndate_breaks (not shown here), takes a string like “2 days” or “1 month”.\n\n11.4.3 Legend layout\nYou will most often use breaks and labels to tweak the axes. While they both also work for legends, there are a few other techniques you are more likely to use.\nTo control the overall position of the legend, you need to use a theme() setting. We’ll come back to themes at the end of the chapter, but in brief, they control the non-data parts of the plot. The theme setting legend.position controls where the legend is drawn:\nbase &lt;- ggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class))\n\nbase + theme(legend.position = \"right\") # the default\nbase + theme(legend.position = \"left\")\nbase + \n  theme(legend.position = \"top\") +\n  guides(color = guide_legend(nrow = 3))\nbase + \n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf your plot is short and wide, place the legend at the top or bottom, and if it’s tall and narrow, place the legend at the left or right. You can also use legend.position = \"none\" to suppress the display of the legend altogether.\nTo control the display of individual legends, use guides() along with guide_legend() or guide_colorbar(). The following example shows two important settings: controlling the number of rows the legend uses with nrow, and overriding one of the aesthetics to make the points bigger. This is particularly useful if you have used a low alpha to display many points on a plot.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2, override.aes = list(size = 4)))\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nNote that the name of the argument in guides() matches the name of the aesthetic, just like in labs().\n\n11.4.4 Replacing a scale\nInstead of just tweaking the details a little, you can instead replace the scale altogether. There are two types of scales you’re mostly likely to want to switch out: continuous position scales and color scales. Fortunately, the same principles apply to all the other aesthetics, so once you’ve mastered position and color, you’ll be able to quickly pick up other scale replacements.\nIt’s very useful to plot transformations of your variable. For example, it’s easier to see the precise relationship between carat and price if we log transform them:\n# Left\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d()\n\n# Right\nggplot(diamonds, aes(x = log10(carat), y = log10(price))) +\n  geom_bin2d()\n\n\n\n\n\n\n\n\n\n\nHowever, the disadvantage of this transformation is that the axes are now labelled with the transformed values, making it hard to interpret the plot. Instead of doing the transformation in the aesthetic mapping, we can instead do it with the scale. This is visually identical, except the axes are labelled on the original data scale.\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_bin2d() + \n  scale_x_log10() + \n  scale_y_log10()\n\n\n\n\n\n\n\nAnother scale that is frequently customized is color. The default categorical scale picks colors that are evenly spaced around the color wheel. Useful alternatives are the ColorBrewer scales which have been hand tuned to work better for people with common types of color blindness. The two plots below look similar, but there is enough difference in the shades of red and green that the dots on the right can be distinguished even by people with red-green color blindness.1\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv))\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\nDon’t forget simpler techniques for improving accessibility. If there are just a few colors, you can add a redundant shape mapping. This will also help ensure your plot is interpretable in black and white.\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv, shape = drv)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\nThe ColorBrewer scales are documented online at https://colorbrewer2.org/ and made available in R via the RColorBrewer package, by Erich Neuwirth. Figura 11.1 shows the complete list of all palettes. The sequential (top) and diverging (bottom) palettes are particularly useful if your categorical values are ordered, or have a “middle”. This often arises if you’ve used cut() to make a continuous variable into a categorical variable.\n\n\n\n\n\n\n\nFigura 11.1: All colorBrewer scales.\n\n\n\n\nWhen you have a predefined mapping between values and colors, use scale_color_manual(). For example, if we map presidential party to color, we want to use the standard mapping of red for Republicans and blue for Democrats. One approach for assigning these colors is using hex color codes:\n\npresidential |&gt;\n  mutate(id = 33 + row_number()) |&gt;\n  ggplot(aes(x = start, y = id, color = party)) +\n  geom_point() +\n  geom_segment(aes(xend = end, yend = id)) +\n  scale_color_manual(values = c(Republican = \"#E81B23\", Democratic = \"#00AEF3\"))\n\n\n\n\n\n\n\nFor continuous color, you can use the built-in scale_color_gradient() or scale_fill_gradient(). If you have a diverging scale, you can use scale_color_gradient2(). That allows you to give, for example, positive and negative values different colors. That’s sometimes also useful if you want to distinguish points above or below the mean.\nAnother option is to use the viridis color scales. The designers, Nathaniel Smith and Stéfan van der Walt, carefully tailored continuous color schemes that are perceptible to people with various forms of color blindness as well as perceptually uniform in both color and black and white. These scales are available as continuous (c), discrete (d), and binned (b) palettes in ggplot2.\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  labs(title = \"Default, continuous\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_c() +\n  labs(title = \"Viridis, continuous\", x = NULL, y = NULL)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed() +\n  scale_fill_viridis_b() +\n  labs(title = \"Viridis, binned\", x = NULL, y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that all color scales come in two varieties: scale_color_*() and scale_fill_*() for the color and fill aesthetics respectively (the color scales are available in both UK and US spellings).\n\n11.4.5 Zooming\nThere are three ways to control the plot limits:\n\nAdjusting what data are plotted.\nSetting the limits in each scale.\nSetting xlim and ylim in coord_cartesian().\n\nWe’ll demonstrate these options in a series of plots. The plot on the left shows the relationship between engine size and fuel efficiency, colored by type of drive train. The plot on the right shows the same variables, but subsets the data that are plotted. Subsetting the data has affected the x and y scales as well as the smooth curve.\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n# Right\nmpg |&gt;\n  filter(displ &gt;= 5 & displ &lt;= 6 & hwy &gt;= 10 & hwy &lt;= 25) |&gt;\n  ggplot(aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\nLet’s compare these to the two plots below where the plot on the left sets the limits on individual scales and the plot on the right sets them in coord_cartesian(). We can see that reducing the limits is equivalent to subsetting the data. Therefore, to zoom in on a region of the plot, it’s generally best to use coord_cartesian().\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  scale_x_continuous(limits = c(5, 6)) +\n  scale_y_continuous(limits = c(10, 25))\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = drv)) +\n  geom_smooth() +\n  coord_cartesian(xlim = c(5, 6), ylim = c(10, 25))\n\n\n\n\n\n\n\n\n\n\nOn the other hand, setting the limits on individual scales is generally more useful if you want to expand the limits, e.g., to match scales across different plots. For example, if we extract two classes of cars and plot them separately, it’s difficult to compare the plots because all three scales (the x-axis, the y-axis, and the color aesthetic) have different ranges.\nsuv &lt;- mpg |&gt; filter(class == \"suv\")\ncompact &lt;- mpg |&gt; filter(class == \"compact\")\n\n# Left\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n# Right\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nOne way to overcome this problem is to share scales across multiple plots, training the scales with the limits of the full data.\nx_scale &lt;- scale_x_continuous(limits = range(mpg$displ))\ny_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))\ncol_scale &lt;- scale_color_discrete(limits = unique(mpg$drv))\n\n# Left\nggplot(suv, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n# Right\nggplot(compact, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n\n\n\n\n\n\n\n\n\nIn this particular case, you could have simply used faceting, but this technique is useful more generally, if for instance, you want to spread plots over multiple pages of a report.\n\n11.4.6 Exercises\n\n\nWhy doesn’t the following code override the default scale?\n\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  scale_color_gradient(low = \"white\", high = \"red\") +\n  coord_fixed()\n\n\nWhat is the first argument to every scale? How does it compare to labs()?\n\nChange the display of the presidential terms by:\n\nCombining the two variants that customize colors and x axis breaks.\nImproving the display of the y axis.\nLabelling each term with the name of the president.\nAdding informative plot labels.\nPlacing breaks every 4 years (this is trickier than it seems!).\n\n\n\nFirst, create the following plot. Then, modify the code using override.aes to make the legend easier to see.\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point(aes(color = cut), alpha = 1/20)",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#sec-themes",
    "href": "communication.html#sec-themes",
    "title": "11  Communication",
    "section": "\n11.5 Themes",
    "text": "11.5 Themes\nFinally, you can customize the non-data elements of your plot with a theme:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(aes(color = class)) +\n  geom_smooth(se = FALSE) +\n  theme_bw()\n\n\n\n\n\n\n\nggplot2 includes the eight themes shown in Figura 11.2, with theme_gray() as the default.2 Many more are included in add-on packages like ggthemes (https://jrnold.github.io/ggthemes), by Jeffrey Arnold. You can also create your own themes, if you are trying to match a particular corporate or journal style.\n\n\n\n\n\n\n\nFigura 11.2: The eight themes built-in to ggplot2.\n\n\n\n\nIt’s also possible to control individual components of each theme, like the size and color of the font used for the y axis. We’ve already seen that legend.position controls where the legend is drawn. There are many other aspects of the legend that can be customized with theme(). For example, in the plot below we change the direction of the legend as well as put a black border around it. Note that customization of the legend box and plot title elements of the theme are done with element_*() functions. These functions specify the styling of non-data components, e.g., the title text is bolded in the face argument of element_text() and the legend border color is defined in the color argument of element_rect(). The theme elements that control the position of the title and the caption are plot.title.position and plot.caption.position, respectively. In the following plot these are set to \"plot\" to indicate these elements are aligned to the entire plot area, instead of the plot panel (the default). A few other helpful theme() components are used to change the placement for format of the title and caption text.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) +\n  geom_point() +\n  labs(\n    title = \"Larger engine sizes tend to have lower fuel economy\",\n    caption = \"Source: https://fueleconomy.gov.\"\n  ) +\n  theme(\n    legend.position = c(0.6, 0.7),\n    legend.direction = \"horizontal\",\n    legend.box.background = element_rect(color = \"black\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.caption.position = \"plot\",\n    plot.caption = element_text(hjust = 0)\n  )\n#&gt; Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n#&gt; 3.5.0.\n#&gt; ℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\nFor an overview of all theme() components, see help with ?theme. The ggplot2 book is also a great place to go for the full details on theming.\n\n11.5.1 Exercises\n\nPick a theme offered by the ggthemes package and apply it to the last plot you made.\nMake the axis labels of your plot blue and bolded.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#layout",
    "href": "communication.html#layout",
    "title": "11  Communication",
    "section": "\n11.6 Layout",
    "text": "11.6 Layout\nSo far we talked about how to create and modify a single plot. What if you have multiple plots you want to lay out in a certain way? The patchwork package allows you to combine separate plots into the same graphic. We loaded this package earlier in the chapter.\nTo place two plots next to each other, you can simply add them to each other. Note that you first need to create the plots and save them as objects (in the following example they’re called p1 and p2). Then, you place them next to each other with +.\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"Plot 2\")\np1 + p2\n\n\n\n\n\n\n\nIt’s important to note that in the above code chunk we did not use a new function from the patchwork package. Instead, the package added a new functionality to the + operator.\nYou can also create complex plot layouts with patchwork. In the following, | places the p1 and p3 next to each other and / moves p2 to the next line.\n\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 3\")\n(p1 | p3) / p2\n\n\n\n\n\n\n\nAdditionally, patchwork allows you to collect legends from multiple plots into one common legend, customize the placement of the legend as well as dimensions of the plots, and add a common title, subtitle, caption, etc. to your plots. Below we create 5 plots. We have turned off the legends on the box plots and the scatterplot and collected the legends for the density plots at the top of the plot with & theme(legend.position = \"top\"). Note the use of the & operator here instead of the usual +. This is because we’re modifying the theme for the patchwork plot as opposed to the individual ggplots. The legend is placed on top, inside the guide_area(). Finally, we have also customized the heights of the various components of our patchwork – the guide has a height of 1, the box plots 3, density plots 2, and the faceted scatterplot 4. Patchwork divides up the area you have allotted for your plot using this scale and places the components accordingly.\n\np1 &lt;- ggplot(mpg, aes(x = drv, y = cty, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"Plot 1\")\n\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy, color = drv)) + \n  geom_boxplot(show.legend = FALSE) + \n  labs(title = \"Plot 2\")\n\np3 &lt;- ggplot(mpg, aes(x = cty, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"Plot 3\")\n\np4 &lt;- ggplot(mpg, aes(x = hwy, color = drv, fill = drv)) + \n  geom_density(alpha = 0.5) + \n  labs(title = \"Plot 4\")\n\np5 &lt;- ggplot(mpg, aes(x = cty, y = hwy, color = drv)) + \n  geom_point(show.legend = FALSE) + \n  facet_wrap(~drv) +\n  labs(title = \"Plot 5\")\n\n(guide_area() / (p1 + p2) / (p3 + p4) / p5) +\n  plot_annotation(\n    title = \"City and highway mileage for cars with different drive trains\",\n    caption = \"Source: https://fueleconomy.gov.\"\n  ) +\n  plot_layout(\n    guides = \"collect\",\n    heights = c(1, 3, 2, 4)\n    ) &\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\nIf you’d like to learn more about combining and layout out multiple plots with patchwork, we recommend looking through the guides on the package website: https://patchwork.data-imaginist.com.\n\n11.6.1 Exercises\n\n\nWhat happens if you omit the parentheses in the following plot layout. Can you explain why this happens?\n\np1 &lt;- ggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 1\")\np2 &lt;- ggplot(mpg, aes(x = drv, y = hwy)) + \n  geom_boxplot() + \n  labs(title = \"Plot 2\")\np3 &lt;- ggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  labs(title = \"Plot 3\")\n\n(p1 | p2) / p3\n\n\n\nUsing the three plots from the previous exercise, recreate the following patchwork.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#summary",
    "href": "communication.html#summary",
    "title": "11  Communication",
    "section": "\n11.7 Summary",
    "text": "11.7 Summary\nIn this chapter you’ve learned about adding plot labels such as title, subtitle, caption as well as modifying default axis labels, using annotation to add informational text to your plot or to highlight specific data points, customizing the axis scales, and changing the theme of your plot. You’ve also learned about combining multiple plots in a single graph using both simple and complex plot layouts.\nWhile you’ve so far learned about how to make many different types of plots and how to customize them using a variety of techniques, we’ve barely scratched the surface of what you can create with ggplot2. If you want to get a comprehensive understanding of ggplot2, we recommend reading the book, ggplot2: Elegant Graphics for Data Analysis. Other useful resources are the R Graphics Cookbook by Winston Chang and Fundamentals of Data Visualization by Claus Wilke.",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "communication.html#footnotes",
    "href": "communication.html#footnotes",
    "title": "11  Communication",
    "section": "",
    "text": "You can use a tool like SimDaltonism to simulate color blindness to test these images.↩︎\nMany people wonder why the default theme has a gray background. This was a deliberate choice because it puts the data forward while still making the grid lines visible. The white grid lines are visible (which is important because they significantly aid position judgments), but they have little visual impact and we can easily tune them out. The gray background gives the plot a similar typographic color to the text, ensuring that the graphics fit in with the flow of a document without jumping out with a bright white background. Finally, the gray background creates a continuous field of color which ensures that the plot is perceived as a single visual entity.↩︎",
    "crumbs": [
      "✅ Visualizar",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Communication</span>"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "✅ Transformar",
    "section": "",
    "text": "A segunda parte do livro abordou, com profundidade, a visualização de dados. Nesta parte do livro, você aprenderá sobre os tipos mais importantes de variáveis que você encontrará dentro de um data frame e conhecerá as ferramentas que pode usar para trabalhar com essas variáveis.\n\n\n\n\n\n\n\nFigura 1: As opções de transformação de dados dependem bastante do tipo de dados envolvidos, que é o foco desta parte do livro.\n\n\n\n\nVocê pode ler esses capítulos de acordo com a sua necessidade; eles foram escritos para serem independentes, permitindo que sejam lidos sem uma ordem específica.\n\nO 12  ✅ Vetores lógicos descreve os vetores lógicos. Estes são os tipos mais simples de vetores, porém são extremamente poderosos. Neste capítulo, você aprenderá a criar esses vetores lógicos por meio de comparações numéricas, a combiná-los utilizando álgebra booleana, a empregá-los para fazer sumarizações e a aplicá-los em transformações condicionais.\nO 13  ✅ Números explora ferramentas para vetores numéricos, a coluna vertebral da ciência de dados. Neste capítulo, você aprenderá mais sobre contagem e uma variedade de funções importantes de transformação e sumarização.\nO 14  Strings fornece as ferramentas necessárias para trabalhar com cadeias de caracteres (strings): você conseguirá extrair partes de uma string, separar uma string em vários caracteres e concatená-los para gerar uma string novamente. Este capítulo dá ênfase principalmente ao pacote stringr, mas também aborda algumas funções do tidyr voltadas para a extração de dados de strings.\nO 15  Regular expressions introduz as expressões regulares, uma ferramenta poderosa para manipular cadeias de caracteres (strings). Este capítulo fará com que você saia da fase de pensar que um um gato caminhou sobre o seu teclado e passe a ler e escrever com facilidade padrões complexos de strings.\nO 16  ✅ Fatores introduz os fatores: o tipo de dado que o R utiliza para armazenar dados categóricos. Você utiliza um fator quando uma variável possui um conjunto fixo de valores possíveis ou quando você deseja atribuir uma ordenação não alfabética a uma string.\nO 17  Dates and times fornece as principais ferramentas para trabalhar com datas e horários. Infelizmente, quanto mais você aprende sobre datas e horários, parece que o assunto se tornar mais complicado. No entanto, com a ajuda do pacote lubridate, você aprenderá a superar os desafios mais frequentes.\nO 18  ✅ Valores faltantes discute, em detalhes, os valores faltantes (missing values). Ao longo do livro, abordamos esse tema algumas vezes de forma isolada, mas agora é hora de uma análise mais abrangente que ajude você a distinguir valores ausentes implícitos de valores ausentes explícitos e a compreender como e por que você pode convertê-los.\nO 19  Joins encerra esta parte do livro sobre transformação, fornecendo ferramentas para unir dois (ou mais) data frames. Entender sobre uniões (joins) fará com que você assimile o conceito de chaves (keys) de banco de dados e pense sobre como identificar cada linha em um conjunto de dados.",
    "crumbs": [
      "✅ Transformar"
    ]
  },
  {
    "objectID": "logicals.html",
    "href": "logicals.html",
    "title": "12  ✅ Vetores lógicos",
    "section": "",
    "text": "12.1 Introdução\nNeste capítulo, você aprenderá ferramentas para trabalhar com vetores lógicos. Vetores lógicos são a forma mais simples de vetores, pois cada elemento pode ter apenas um dos três possíveis valores: TRUE, FALSE e NA. É relativamente raro encontrar vetores lógicos em seus dados brutos, mas você os criará e manipulará no decorrer de quase todas as análises.\nComeçaremos discutindo a forma mais comum de criar vetores lógicos: por meio de comparações numéricas. Em seguida, você aprenderá como usar a álgebra booleana para combinar diferentes vetores lógicos, bem como algumas sumarizações úteis. Terminaremos com if_else() e case_when(), duas funções úteis para fazer alterações condicionais alimentadas por vetores lógicos.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#introdução",
    "href": "logicals.html#introdução",
    "title": "12  ✅ Vetores lógicos",
    "section": "",
    "text": "12.1.1 Pré-requisitos\nA maioria das funções que você aprenderá neste capítulo são fornecidas pelo R base, então não precisamos do tidyverse, mas ainda assim iremos carregá-lo para que possamos usar mutate(), filter(), e demais funções para trabalhar com data frames. Também continuaremos a extrair exemplos do conjunto de dados dados::voos.\n\nlibrary(tidyverse)\nlibrary(dados)\n\nNo entanto, à medida que começamos a estudar novas ferramentas, nem sempre haverá um exemplo real perfeito. Então, começaremos a criar alguns dados fictícios com c():\n\nx &lt;- c(1, 2, 3, 5, 7, 11, 13)\nx * 2\n#&gt; [1]  2  4  6 10 14 22 26\n\nIsso facilita a explicação de funções individuais, ao custo de dificultar a visualização de como elas podem se aplicar aos seus problemas de dados. Apenas lembre-se de que qualquer transformação que fizermos em um vetor simples, você poderá fazer em uma variável dentro de data frame com mutate() e demais funções amigas.\n\ndf &lt;- tibble(x)\ndf |&gt; \n  mutate(y = x * 2)\n#&gt; # A tibble: 7 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2\n#&gt; 2     2     4\n#&gt; 3     3     6\n#&gt; 4     5    10\n#&gt; 5     7    14\n#&gt; 6    11    22\n#&gt; # ℹ 1 more row",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#comparações",
    "href": "logicals.html#comparações",
    "title": "12  ✅ Vetores lógicos",
    "section": "\n12.2 Comparações",
    "text": "12.2 Comparações\nUma forma muito comum de criar um vetor lógico é através de uma comparação numérica usando &lt;, &lt;=, &gt;, &gt;=, != e ==. Até agora, criamos principalmente variáveis ​​lógicas temporariamente dentro do filter() — elas são calculadas, usadas e depois jogadas fora. Por exemplo, o filtro abaixo encontra todo os voos que sairam durante o dia e chegaram aproximadamente no horário:\n\nvoos |&gt; \n  filter(horario_saida &gt; 600 & horario_saida &lt; 2000 & abs(atraso_chegada) &lt; 20)\n#&gt; # A tibble: 172,286 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1           601              600            1\n#&gt; 2  2013     1     1           602              610           -8\n#&gt; 3  2013     1     1           602              605           -3\n#&gt; 4  2013     1     1           606              610           -4\n#&gt; 5  2013     1     1           606              610           -4\n#&gt; 6  2013     1     1           607              607            0\n#&gt; # ℹ 172,280 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\nÉ útil saber que isto é apenas um atalho e você pode explicitamente criar a variável lógica intrínseca com mutate():\n\nvoos |&gt; \n  mutate(\n    diurno = horario_saida &gt; 600 & horario_saida &lt; 2000,\n    aprox_no_horario = abs(atraso_chegada) &lt; 20,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 4\n#&gt;   horario_saida atraso_chegada diurno aprox_no_horario\n#&gt;           &lt;int&gt;          &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt;           \n#&gt; 1           517             11 FALSE  TRUE            \n#&gt; 2           533             20 FALSE  FALSE           \n#&gt; 3           542             33 FALSE  FALSE           \n#&gt; 4           544            -18 FALSE  TRUE            \n#&gt; 5           554            -25 FALSE  FALSE           \n#&gt; 6           554             12 FALSE  TRUE            \n#&gt; # ℹ 336,770 more rows\n\nIsto é particularmente útil para lógicas mais complicadas, pois nomeando os passos intermediários, se torna mais fácil tanto ler o código quanto verificar se cada passo está sendo calculado corretamente.\nCom isto, o filtro inicial é equivalente a:\n\nvoos |&gt; \n  mutate(\n    diurno = horario_saida &gt; 600 & horario_saida &lt; 2000,\n    aprox_no_horario = abs(atraso_chegada) &lt; 20,\n  ) |&gt; \n  filter(diurno & aprox_no_horario)\n\n\n12.2.1 Comparações com ponto-flutuante (floating point)\nCuidado ao usar == com números. Por exemplo, parece que este vetor contém os números 1 e 2:\n\nx &lt;- c(1 / 49 * 49, sqrt(2) ^ 2)\nx\n#&gt; [1] 1 2\n\nMas se você fizer um teste de igualdade, você terá FALSE:\n\nx == c(1, 2)\n#&gt; [1] FALSE FALSE\n\nO que está acontecendo aqui? Os computadores armazenam números com um número fixo de casas decimais, então não há como representar exatamente 1/49 ou sqrt(2) e os cálculos subsequentes serão ligeiramente imprecisos. Podemos ver os valores exatos chamando print() com o argumento digits1:\n\nprint(x, digits = 16)\n#&gt; [1] 0.9999999999999999 2.0000000000000004\n\nVocê pode ver porque o R arrendonda estes números por padrão: eles são realmente muito próximos ao que você espera.\nAgora que você viu porque == falhou, o que você pode fazer a respeito? Uma opção é usar dplyr::near() que ignora pequenas diferenças:\n\nnear(x, c(1, 2))\n#&gt; [1] TRUE TRUE\n\n\n12.2.2 Valores faltantes (missing values)\nOs valores faltantes (missing values) representam o desconhecido, portanto são “contagiosos”: quase qualquer operação que envolva um valor desconhecido também será desconhecida:\n\nNA &gt; 5\n#&gt; [1] NA\n10 == NA\n#&gt; [1] NA\n\nO resultado mais confuso é este:\n\nNA == NA\n#&gt; [1] NA\n\nÉ mais fácil entender porque isto é verdadeiro se nós artificialmente fornecermos um pouco mais de contexto:\n\n# Não sabemos a idade de Maria\nidade_maria &lt;- NA\n\n# Não sabemos a idade de João\nidade_joao &lt;- NA\n\n# João e Maria tem a mesma idade?\nidade_maria == idade_joao\n#&gt; [1] NA\n# Não sabemos!\n\nPortanto, se você quiser encontrar todos os voos onde horario_saida está faltando, o código a seguir não funciona, pois horario_saida == NA retorna NA para cada linha e filter() ignora automaticamente valores faltantes:\n\nvoos |&gt; \n  filter(horario_saida == NA)\n#&gt; # A tibble: 0 × 19\n#&gt; # ℹ 19 variables: ano &lt;int&gt;, mes &lt;int&gt;, dia &lt;int&gt;, horario_saida &lt;int&gt;,\n#&gt; #   saida_programada &lt;int&gt;, atraso_saida &lt;dbl&gt;, horario_chegada &lt;int&gt;, …\n\nAo invés disso, vocè precisará de uma nova ferramenta: is.na().\n\n12.2.3 is.na()\n\nis.na(x) funciona com qualquer tipo de vetor e retorna TRUE para valores faltantes e FALSE para qualquer outra coisa:\n\nis.na(c(TRUE, NA, FALSE))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(1, NA, 3))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(\"a\", NA, \"b\"))\n#&gt; [1] FALSE  TRUE FALSE\n\nPodemos usar is.na() para encontrar todos os registros com horario_saida faltando:\n\nvoos |&gt; \n  filter(is.na(horario_saida))\n#&gt; # A tibble: 8,255 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1            NA             1630           NA\n#&gt; 2  2013     1     1            NA             1935           NA\n#&gt; 3  2013     1     1            NA             1500           NA\n#&gt; 4  2013     1     1            NA              600           NA\n#&gt; 5  2013     1     2            NA             1540           NA\n#&gt; 6  2013     1     2            NA             1620           NA\n#&gt; # ℹ 8,249 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\nis.na() também pode ser útil em arrange(). arrange() geralmente coloca todos os valores faltantes no final, mas você pode sobreescrever este padrão ordenando primeiro com is.na():\n\nvoos |&gt; \n  filter(mes == 1, dia == 1) |&gt; \n  arrange(horario_saida)\n#&gt; # A tibble: 842 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1           517              515            2\n#&gt; 2  2013     1     1           533              529            4\n#&gt; 3  2013     1     1           542              540            2\n#&gt; 4  2013     1     1           544              545           -1\n#&gt; 5  2013     1     1           554              600           -6\n#&gt; 6  2013     1     1           554              558           -4\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\nvoos |&gt; \n  filter(mes == 1, dia == 1) |&gt; \n  arrange(desc(is.na(horario_saida)), horario_saida)\n#&gt; # A tibble: 842 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1            NA             1630           NA\n#&gt; 2  2013     1     1            NA             1935           NA\n#&gt; 3  2013     1     1            NA             1500           NA\n#&gt; 4  2013     1     1            NA              600           NA\n#&gt; 5  2013     1     1           517              515            2\n#&gt; 6  2013     1     1           533              529            4\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\nVoltaremos a abordar mais detalhes sobre valores faltantes (missing values) no Capítulo 18.\n\n12.2.4 Exercício\n\nComo dplyr::near() funciona? Digite near para ver o código fonte. sqrt(2)^2 é próximo (near) a 2?\nUse mutate(), is.na() e count() juntos para descrever como os valores faltantes (missing values) em horario_saida, saida_programada e atraso_saida estão relacionados.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#álgebra-booleana",
    "href": "logicals.html#álgebra-booleana",
    "title": "12  ✅ Vetores lógicos",
    "section": "\n12.3 Álgebra booleana",
    "text": "12.3 Álgebra booleana\nQuando você tem múltiplos vetores lógicos, você pode combiná-los usando álgebra booleana. No R, & é “e”, | é “ou”, ! é “não” e xor() é ou exclusivo2. Por exemplo, df |&gt; filter(!is.na(x)) encontra todas as linhas onde x está faltando e df |&gt; filter(x &lt; -10 | x &gt; 0) encontra todas as linhas onde x é menor que -10 ou maior que 0. A Figura 12.1 mostra o conjunto completo de operações booleanas e como elas funcionam.\n\n\n\n\n\n\n\nFigura 12.1: O conjunto completo de operações booleanas. x é o círculo da esquerda , y é o círculo da direita e a região preenchida mostra qual parte cada operação seleciona.\n\n\n\n\nAlém de & e |, o R também possui && e ||. Não os use em funções dplyr! Eles são chamados de operadores de curto-circuito e retornam sempre apenas um único TRUE ou FALSE. Eles são importantes na programação, não em ciência de dados.\n\n12.3.1 Valores faltantes (missing values)\nAs regras para valores faltantes na álgebra booleana são um pouco complicadas de explicar porque parecem inconsistentes à primeira vista:\n\ndf &lt;- tibble(x = c(TRUE, FALSE, NA))\n\ndf |&gt; \n  mutate(\n    e = x & NA,\n    ou = x | NA\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   x     e     ou   \n#&gt;   &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 TRUE  NA    TRUE \n#&gt; 2 FALSE FALSE NA   \n#&gt; 3 NA    NA    NA\n\nPara entender o que está acontecendo aqui, pense em NA | TRUE (NA ou TRUE). Um valor faltante (missing value) em um vetor lógico significa que o valor poderia ser TRUE ou FALSE. TRUE | TRUE e FALSE | TRUE são ambos TRUE pois ao menos um dos termos é TRUE. NA | TRUE também deve ser TRUE pois NA pode ser TRUE ou FALSE. Entretanto, NA | FALSE é NA pois não sabemos se NA é TRUE ou FALSE. O mesmo se aplica com NA & FALSE.\n\n12.3.2 Ordem das operações\nObserve que a ordem das operações não funcionam como em Português. Veja o seguinte código que encontra todos os voos que saíram em novembro ou dezembro:\n\nvoos |&gt; \n   filter(mes == 11 | mes == 12)\n\nVocê pode estar tentado a escrevê-lo da forma que falaria em Português: “Encontre todos os voos que saíram em Novemebro e Dezembro.”:\n\nvoos |&gt; \n   filter(mes == 11 | 12)\n#&gt; # A tibble: 336,776 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1           517              515            2\n#&gt; 2  2013     1     1           533              529            4\n#&gt; 3  2013     1     1           542              540            2\n#&gt; 4  2013     1     1           544              545           -1\n#&gt; 5  2013     1     1           554              600           -6\n#&gt; 6  2013     1     1           554              558           -4\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\nEste código não gera erro, mas também não parece ter funcionado. O que acontece aqui? Neste caso, o R calcula mes == 11 criando um vetor lógico, o qual chamaremos de nov. Então calcula nov | 12. Quando usamos um número com um operador lógico, ele converte tudo exceto 0 para TRUE, o que é equivalente a nov | TRUE o que é sempre TRUE, então cada linha será selecionada:\n\nvoos |&gt; \n  mutate(\n    nov = mes == 11,\n    final = nov | 12,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;     mes nov   final\n#&gt;   &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1     1 FALSE TRUE \n#&gt; 2     1 FALSE TRUE \n#&gt; 3     1 FALSE TRUE \n#&gt; 4     1 FALSE TRUE \n#&gt; 5     1 FALSE TRUE \n#&gt; 6     1 FALSE TRUE \n#&gt; # ℹ 336,770 more rows\n\n\n12.3.3 %in%\n\nUm jeito fácil de evitar o problema de colocar ==s e |s na ordem correta é usar %in%. x %in% y retorna um vetor lógico de mesmo tamanho que x que é TRUE sempre que um valor em x está em qualquer lugar em y .\n\n1:12 %in% c(1, 5, 11)\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\nletters[1:10] %in% c(\"a\", \"e\", \"i\", \"o\", \"u\")\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\nPortanto, para encontrar todos os voos de novembro e dezembro, poderíamos escrever:\n\nvoos |&gt; \n  filter(mes %in% c(11, 12))\n\nNote que %in% possui diferentes regras do NA para ==, uma vez que NA %in% NA é TRUE.\n\nc(1, 2, NA) == NA\n#&gt; [1] NA NA NA\nc(1, 2, NA) %in% NA\n#&gt; [1] FALSE FALSE  TRUE\n\nIsto pode ser um atalho útil:\n\nvoos |&gt; \n  filter(horario_saida %in% c(NA, 0800))\n#&gt; # A tibble: 8,803 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1           800              800            0\n#&gt; 2  2013     1     1           800              810          -10\n#&gt; 3  2013     1     1            NA             1630           NA\n#&gt; 4  2013     1     1            NA             1935           NA\n#&gt; 5  2013     1     1            NA             1500           NA\n#&gt; 6  2013     1     1            NA              600           NA\n#&gt; # ℹ 8,797 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\n\n12.3.4 Exercícios\n\nEncontre todos os voos em que atraso_chegada está faltando (missing), mas atraso_saida não. Encontre todos os voos em que nem horario_chegada ou chegada_prevista estão faltando, mas atraso_chegada está.\nQuantos voos possuem horario_saida faltando? Quais outras variáveis possuem valores faltantes nestes registros? O que podem representar estas linhas?\nAssumindo que um valor faltante em horario_saida implica em um voo cancelado, olhe o número de voos cancelados por dia. Há algum padrão? Há alguma relação entre a proporção de voos cancelados e a média de atraso dos voos não cancelados?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#sec-logical-summaries",
    "href": "logicals.html#sec-logical-summaries",
    "title": "12  ✅ Vetores lógicos",
    "section": "\n12.4 Sumarização",
    "text": "12.4 Sumarização\nAs seções a seguir descrevem técnicas úteis para sumarização de vetores lógicos. Assim como funções que trabalham especificamente com vetores lógicos, você também pode usar funções que trabalham com vetores numéricos.\n\n12.4.1 Sumarizações lógicas\nExistem dois sumarizadores lógicos: any() e all(). any(x) é o equivalente ao |; retornará TRUE se houver algum TRUE em x. all(x) é o equivalente ao &; retornará TRUE somente se todos os valores de x forem TRUE. Assim como todas as funções de sumarização, elas retornarão NA se houver qualquer valor faltante (missing value) presente, e como de costume, você pode não considerá-los usando na.rm = TRUE.\nPor exemplo, poderíamos usar all() e any() para descobrir se todos os voos foram atrasados na partida por no máximo uma hora ou se algum voo atrasou na chegada por cinco horas ou mais. E usando group_by() podemos fazer isso para cada dia:\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt; \n  summarize(\n    todos_atrasados = all(atraso_saida &lt;= 60, na.rm = TRUE),\n    algum_atraso_longo = any(atraso_chegada &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;     ano   mes   dia todos_atrasados algum_atraso_longo\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;           &lt;lgl&gt;             \n#&gt; 1  2013     1     1 FALSE           TRUE              \n#&gt; 2  2013     1     2 FALSE           TRUE              \n#&gt; 3  2013     1     3 FALSE           FALSE             \n#&gt; 4  2013     1     4 FALSE           FALSE             \n#&gt; 5  2013     1     5 FALSE           TRUE              \n#&gt; 6  2013     1     6 FALSE           FALSE             \n#&gt; # ℹ 359 more rows\n\nNa maioria dos casos, entretanto, any() e all() são um tanto grosseiros, e seria bom poder obter mais detalhes sobre os valores TRUE ou FALSE. Isso nos leva aos sumarizadores numéricos.\n\n12.4.2 Sumarizações numéricas de vetores lógicos\nQuando você usa um vetor lógico em um contexto numérico, TRUE se torna 1 e FALSE se torna 0. Isto torna sum() e mean() muito úteis com vetores lógicos, pois sum(x) retorna o número de TRUEs e mean(x) retorna a proporção de TRUEs (pois mean() é sum() dividido por length()).\nIsto, por exemplo, nos permite ver a proporção de voos que tiveram atraso na saída em até uma hora e o número de voos que chegaram atrasados em cinco horas ou mais:\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt; \n  summarize(\n    todos_atrasados = mean(atraso_saida &lt;= 60, na.rm = TRUE),\n    algum_atraso_longo = sum(atraso_chegada &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;     ano   mes   dia todos_atrasados algum_atraso_longo\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;           &lt;dbl&gt;              &lt;int&gt;\n#&gt; 1  2013     1     1           0.939                  3\n#&gt; 2  2013     1     2           0.914                  3\n#&gt; 3  2013     1     3           0.941                  0\n#&gt; 4  2013     1     4           0.953                  0\n#&gt; 5  2013     1     5           0.964                  1\n#&gt; 6  2013     1     6           0.959                  0\n#&gt; # ℹ 359 more rows\n\n\n12.4.3 Subconjunto (subsetting) lógico\nExiste ainda um último uso de vetores lógicos em sumarizações: você pode usar um vetor lógico para filtrar uma única variável em um subconjunto (subset) de interesse. Isto faz uso do operador do R base [ (se pronuncia subset), o qual você aprenderá mais na Seção 27.2.\nImagine que gostaríamos de encontrar a média de atraso somente de voos que realmente estiveram atrasados. Uma forma de fazê-lo seria primeiro filtrar os voos e depois calcular a média de atraso:\n\nvoos |&gt; \n  filter(atraso_chegada &gt; 0) |&gt; \n  group_by(ano, mes, dia) |&gt; \n  summarize(\n    atraso_medio = mean(atraso_chegada),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;     ano   mes   dia atraso_medio     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1         32.5   461\n#&gt; 2  2013     1     2         32.0   535\n#&gt; 3  2013     1     3         27.7   460\n#&gt; 4  2013     1     4         28.3   297\n#&gt; 5  2013     1     5         22.6   238\n#&gt; 6  2013     1     6         24.4   381\n#&gt; # ℹ 359 more rows\n\nIsto funciona, mas e se você quisesse calcular o atraso médio também para voos que chegaram antecipadamente? Precisaríamos fazer um passo extra de filtro e então combinar os dois data frames3. Ao invés disso, você poderia usar [ para executar um filtro em linha (inline): atraso_chegada[atraso_chegada &gt; 0] irá retornar apenas os atrasos positivos na chegada.\nIsso leva a:\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt; \n  summarize(\n    atrasado = mean(atraso_chegada[atraso_chegada &gt; 0], na.rm = TRUE),\n    antecipado = mean(atraso_chegada[atraso_chegada &lt; 0], na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 6\n#&gt;     ano   mes   dia atrasado antecipado     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1     32.5      -12.5   842\n#&gt; 2  2013     1     2     32.0      -14.3   943\n#&gt; 3  2013     1     3     27.7      -18.2   914\n#&gt; 4  2013     1     4     28.3      -17.0   915\n#&gt; 5  2013     1     5     22.6      -14.0   720\n#&gt; 6  2013     1     6     24.4      -13.6   832\n#&gt; # ℹ 359 more rows\n\nObserve também a diferença no tamanho do grupo: no primeiro segmento n() tem o número de voos em atraso por dia, no segundo, n() retorna o número total de voos.\n\n12.4.4 Exercícios\n\nO que sum(is.na(x)) retorna? E mean(is.na(x))?\nO que prod() retorna quando aplicada a um vetor lógico? Qual função de sumarização lógica é equivalente? O que min() retorna quando aplicada a um vetor lógico? Qual função de sumarização lógica é equivalente? Leia a documentação e efetue alguns experimentos.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#transformações-condicionais",
    "href": "logicals.html#transformações-condicionais",
    "title": "12  ✅ Vetores lógicos",
    "section": "\n12.5 Transformações condicionais",
    "text": "12.5 Transformações condicionais\nUma das características mais poderosas de vetores lógico é seu uso em transformações condicionais, i.e. fazer alguma coisa em uma condição x, e alguma outra coisa diferente para a y. Existem duas funções importantes para isso: if_else() e case_when().\n\n12.5.1 if_else()\n\nSe você quiser usar um valor para quando a condição é TRUE e outro valor para quando a condição é FALSE, você pode usar dplyr::if_else()4. Você sempre usará os primeiros três argumentos de if_else(). O primeiro, condition, é um vetor lógico, o segundo, true, gera uma saída quando a condição é verdadeira, e o terceiro, false, gera uma saída quando a condição é falsa.\nVamos começar com um simples exemplo rotulando um vetor numérico como “+vo” (positivo) ou “-vo” (negativo):\n\nx &lt;- c(-3:3, NA)\nif_else(x &gt; 0, \"+vo\", \"-vo\")\n#&gt; [1] \"-vo\" \"-vo\" \"-vo\" \"-vo\" \"+vo\" \"+vo\" \"+vo\" NA\n\nHá um quarto argumento opcional, missing o qual pode ser usado se a entrada for um valor NA:\n\nif_else(x &gt; 0, \"+vo\", \"-vo\", \"???\")\n#&gt; [1] \"-vo\" \"-vo\" \"-vo\" \"-vo\" \"+vo\" \"+vo\" \"+vo\" \"???\"\n\nVocê também usar vetores para os argumentos true e false. Por exemplo, isto nos permite criar uma implementação mínima de abs():\n\nif_else(x &lt; 0, -x, x)\n#&gt; [1]  3  2  1  0  1  2  3 NA\n\nAté agora, todos os argumentos usaram os mesmos vetores, mas você pode misturar e combinar variáveis. Por exemplo, você pode implementar uma versão simples de coalesce() desta forma:\n\nx1 &lt;- c(NA, 1, 2, NA)\ny1 &lt;- c(3, NA, 4, 6)\nif_else(is.na(x1), y1, x1)\n#&gt; [1] 3 1 2 6\n\nVocê pode notar uma pequena infelicidade no nosso exemplo de rótulo acima: zero não é nem positivo nem negativo. Nós poderíamos resolver isso adicionando um novo if_else():\n\nif_else(x == 0, \"0\", if_else(x &lt; 0, \"-vo\", \"+vo\"), \"???\")\n#&gt; [1] \"-vo\" \"-vo\" \"-vo\" \"0\"   \"+vo\" \"+vo\" \"+vo\" \"???\"\n\nIsto já é um pouco difícil de ler, mas você pode imaginar como se tornaria mais difícil se você tiver ainda mais condições. Ao invés disso, você deve mudar para o dplyr::case_when().\n\n12.5.2 case_when()\n\nO case_when() do pacote dplyr é inspirado na declaração CASE do SQL e oferece uma forma flexível de efetuar diferentes cálculos para diferentes condições. Infelizmente, ele tem uma sintaxe que não se parece com nada que você usará no pacote tidyverse. Ele recebe pares que se parecem com condição ~ saída. condição deve ser um vetor lógico; quando for TRUE, saída será usada.\nIsto significa que poderíamos recriar nos if_else() aninhado desta forma:\n\nx &lt;- c(-3:3, NA)\ncase_when(\n  x == 0   ~ \"0\",\n  x &lt; 0    ~ \"-vo\", \n  x &gt; 0    ~ \"+vo\",\n  is.na(x) ~ \"???\"\n)\n#&gt; [1] \"-vo\" \"-vo\" \"-vo\" \"0\"   \"+vo\" \"+vo\" \"+vo\" \"???\"\n\nO código é maior, mas também é mais explícito.\nPara explicar com case_when() funciona, vamos explorar alguns casos mais simples. Se nenhum dos casos corresponder, a saída será NA:\n\ncase_when(\n  x &lt; 0 ~ \"-vo\",\n  x &gt; 0 ~ \"+vo\"\n)\n#&gt; [1] \"-vo\" \"-vo\" \"-vo\" NA    \"+vo\" \"+vo\" \"+vo\" NA\n\nUse o argumento .default se você quiser gerar um “padrão”/pegar todos os valores:\n\ncase_when(\n  x &lt; 0 ~ \"-vo\",\n  x &gt; 0 ~ \"+vo\",\n  .default = \"???\"\n)\n#&gt; [1] \"-vo\" \"-vo\" \"-vo\" \"???\" \"+vo\" \"+vo\" \"+vo\" \"???\"\n\nE observe que se várias condições corresponderem, apenas a primeira será usada:\n\ncase_when(\n  x &gt; 0 ~ \"+vo\",\n  x &gt; 2 ~ \"grande\"\n)\n#&gt; [1] NA    NA    NA    NA    \"+vo\" \"+vo\" \"+vo\" NA\n\nAssim como com if_else() você pode usar variáveis ​​em ambos os lados do ~ e pode misturar e combinar variáveis ​​conforme necessário para o seu problema. Por exemplo, poderíamos usar case_when() para fornecer alguns rótulos legíveis para o atraso de chegada:\n\nvoos |&gt; \n  mutate(\n    status = case_when(\n      is.na(atraso_chegada)      ~ \"cancelado\",\n      atraso_chegada &lt; -30       ~ \"muito antecipado\",\n      atraso_chegada &lt; -15       ~ \"antecipado\",\n      abs(atraso_chegada) &lt;= 15  ~ \"no horario\",\n      atraso_chegada &lt; 60        ~ \"atrasado\",\n      atraso_chegada &lt; Inf       ~ \"muito atrasdo\",\n    ),\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 2\n#&gt;   atraso_chegada status    \n#&gt;            &lt;dbl&gt; &lt;chr&gt;     \n#&gt; 1             11 no horario\n#&gt; 2             20 atrasado  \n#&gt; 3             33 atrasado  \n#&gt; 4            -18 antecipado\n#&gt; 5            -25 antecipado\n#&gt; 6             12 no horario\n#&gt; # ℹ 336,770 more rows\n\nTenha cuidado ao escrever esse tipo de instrução case_when() complexa; minhas duas primeiras tentativas usaram uma mistura de &lt; e &gt; e continuei criando acidentalmente condições sobrepostas.\n\n12.5.3 Tipos compatíveis\nObserve que if_else() e case_when() requerem tipos compatíveis na saída. Se eles não forem compatíveis, você verá erros como este:\n\nif_else(TRUE, \"a\", 1)\n#&gt; Error in `if_else()`:\n#&gt; ! Can't combine `true` &lt;character&gt; and `false` &lt;double&gt;.\n\ncase_when(\n  x &lt; -1 ~ TRUE,  \n  x &gt; 0  ~ now()\n)\n#&gt; Error in `case_when()`:\n#&gt; ! Can't combine `..1 (right)` &lt;logical&gt; and `..2 (right)` &lt;datetime&lt;local&gt;&gt;.\n\nNo geral, relativamente poucos tipos são compatíveis, porque a conversão automática de um tipo de vetor em outro é uma fonte comum de erros. Aqui estão os casos mais importantes que são compatíveis:\n\nVetores numéricos e lógicos são compatíveis, conforme discutimos na Seção 12.4.2.\nStrings e fatores (Capítulo 16) são compatíveis, porque você pode pensar em um fator como uma string com um conjunto restrito de valores.\nData e data-hora, que discutiremos no Capítulo 17, são compatíveis porque você pode pensar em uma data (date) como um caso especial de data-hora (datetime).\n\nNA, que é tecnicamente um vetor lógico, é compatível com tudo porque todo vetor tem alguma forma de representar um valor faltante (missing value).\n\nNão esperamos que você memorize essas regras, mas elas devem se tornar naturais com o tempo, porque são aplicadas de forma consistente em todo o tidyverse.\n\n12.5.4 Exercícios\n\nUm número é par se for divisível por dois, o que, no R, você pode descobrir com x %% 2 == 0. Use este fato e if_else() para determinar se cada número entre 0 e 20 é par ou ímpar.\nDado um vetor de dias como x &lt;- c(\"Segunda-feira\", \"Sábado\", \"Quarta-feira\"), use uma instrução ifelse() para rotulá-los como fins de semana ou dias de semana.\nUse ifelse() para calcular o valor absoluto de um vetor numérico chamado x.\nEscreva uma declaração case_when() que usa as colunas mes e dia de voos para rotular um conjunto de feriados importante dos Brasil (e.g., 7 de Setembro, Tiradentes, Carnaval e Natal5). Primeiro crie uma coluna lógica TRUE ou FALSE, e então uma coluna texto (character) que tenha o nome do feriado ou NA.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#resumo",
    "href": "logicals.html#resumo",
    "title": "12  ✅ Vetores lógicos",
    "section": "\n12.6 Resumo",
    "text": "12.6 Resumo\nA definição de vetor lógico é simples pois seu valor é TRUE, FALSE ou NA. Mas os vetores lógicos oferecem grande poder. Neste capítulo, você aprendeu a criar vetores lógicos com &gt;, &lt;, &lt;=, &gt;=, ==, != e is.na(), como combiná-los com !, & e |, e como sumarizá-los com any(), all(), sum() e mean(). Você também aprendeu as funções poderosas if_else() e case_when() que permitem você retornar valores dependendo do valor de um vetor lógico.\nVeremos vetores lógicos cada vez mais nos próximos capítulos. Por exemplo, no Capítulo 14 você vai aprender sobre str_detect(x, pattern) que retorna um vetor lógico que será TRUE para elementos de x que correnpondem ao pattern (padrão), e no Capítulo 17 você irá criar vetores lógicos a partir de comparações de datas e horários. Por ora, iremos para o próximo mais importante tipo de vetores: vetores numéricos.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#footnotes",
    "href": "logicals.html#footnotes",
    "title": "12  ✅ Vetores lógicos",
    "section": "",
    "text": "R normalmente chama print para você (ex. x é um atalho para print(x)), mas chamando-o explicitamente é útil se você quer fornecer outros argumentos.↩︎\nIsto é, xor(x, y) é verdadeiro se x for verdadeiro, ou y for verdadeiro, mas nunca ambos. Isto é como usamos “ou” em Português. “Ambos” geralmente não é uma resposta aceitável quando respondemos a pergunta “Você gostaria de sorvete ou bolo?”.↩︎\nIremos cobrir isto na Capítulo 19.↩︎\nA função if_else() do dplyr é muito similar a ifelse() do R base . Existem duas vantagens principais do if_else() sobre ifelse(): você pode escolher o que acontece com valor faltantes (missing values) e if_else() te retorna erros com mais sentido se sua variável possuir tipos incompatíveis.↩︎\nNota de tradução: Na versão original em inglês, os feriados são dos Estados Unidos.↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>✅ Vetores lógicos</span>"
    ]
  },
  {
    "objectID": "numbers.html",
    "href": "numbers.html",
    "title": "13  ✅ Números",
    "section": "",
    "text": "13.1 Introdução\nVetores numéricos são a espinha dorsal da ciência de dados e você já os usou muitas vezes anteriormente neste livro. Agora é hora de pesquisar sistematicamente o que você pode fazer com eles em R, garantindo que você esteja bem situado para resolver qualquer problema futuro envolvendo vetores numéricos.\nComeçaremos fornecendo algumas ferramentas para criar números se você tiver textos (strings) e depois entraremos em mais detalhes sobre count(). Em seguida, mergulharemos em várias transformações numéricas que combinam bem com mutate(), incluindo transformações mais gerais que podem ser aplicadas a outros tipos de vetores, mas são frequentemente usadas com vetores numéricos. Terminaremos abordando as funções de sumarização que combinam bem com summarize() e mostraremos como elas também podem ser usadas com mutate().",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#introdução",
    "href": "numbers.html#introdução",
    "title": "13  ✅ Números",
    "section": "",
    "text": "13.1.1 Pré-requisitos\nEste capítulo usa principalmente funções do R base que estão disponíveis sem precisarmos carregar nenhum pacote. Mas ainda iremos carregar o pacote tidyverse pois usaremos estas funções do R base dentro de funções do tidyverse como mutate() e filter(). Como no capítulo anterior, usaremos exemplos reais do pacote dados, bem como exemplos simples feitos com c() e tribble().\n\nlibrary(tidyverse)\nlibrary(dados)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#criando-números",
    "href": "numbers.html#criando-números",
    "title": "13  ✅ Números",
    "section": "\n13.2 Criando números",
    "text": "13.2 Criando números\nNa maioria dos casos, você obterá números já registrados em um dos dois tipos do R: inteiro (integer) ou ponto-flutuante (double), . Em alguns casos, você irá encontrá-los como textos (strings), possivelmente porque você os criou com pivotagem (pivoting) de algum cabeçalho de coluna ou porque algo deu errado em seu processo de importação.\nO pacote readr fornece duas funções úteis para transformar strings em números: parse_double() e parse_number(). Use parse_double() quando possuir números que foram escritos como strings:\n\nx &lt;- c(\"1.2\", \"5.6\", \"1e3\")\nparse_double(x)\n#&gt; [1]    1.2    5.6 1000.0\n\nUse parse_number() quando possuir strings que contenham textos não numéricos que você deseja ignorar. Isto é particularmente útil para dados de moedas e porcentagens:\n\nx &lt;- c(\"$1,234\", \"USD 3,513\", \"59%\")\nparse_number(x)\n#&gt; [1] 1234 3513   59",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#sec-counts",
    "href": "numbers.html#sec-counts",
    "title": "13  ✅ Números",
    "section": "\n13.3 Contagens",
    "text": "13.3 Contagens\nÉ uma supresa o quanto de ciência de dados você pode fazer somente com um pouco de contagem e aritmética básica, então o pacote dplyr torna a contagem o mais fácil possível com count(). Esta função é ótima para explorações rápidas e validações durante a análise:\n\nvoos |&gt; count(destino)\n#&gt; # A tibble: 105 × 2\n#&gt;   destino     n\n#&gt;   &lt;chr&gt;   &lt;int&gt;\n#&gt; 1 ABQ       254\n#&gt; 2 ACK       265\n#&gt; 3 ALB       439\n#&gt; 4 ANC         8\n#&gt; 5 ATL     17215\n#&gt; 6 AUS      2439\n#&gt; # ℹ 99 more rows\n\n(Independente do conselho no Capítulo 4, normalmente colocamos count() em uma única linha, pois é usado geralmente em linha de comando (console) para uma rápida verificação que um cálculo está funcionando como esperado.)\nSe você quiser os valores mais comuns, adicione sort = TRUE:\n\nvoos |&gt; count(destino, sort = TRUE)\n#&gt; # A tibble: 105 × 2\n#&gt;   destino     n\n#&gt;   &lt;chr&gt;   &lt;int&gt;\n#&gt; 1 ORD     17283\n#&gt; 2 ATL     17215\n#&gt; 3 LAX     16174\n#&gt; 4 BOS     15508\n#&gt; 5 MCO     14082\n#&gt; 6 CLT     14064\n#&gt; # ℹ 99 more rows\n\nE lembre-se que, se você quiser ver todos os valores, você pode usar |&gt; View() ou |&gt; print(n = Inf).\nVocê pode fazer o mesmo cálculo “na mão” com group_by(), summarize() e n(). Isto é útil pois permite que você faça outras sumarizações ao mesmo tempo:\n\nvoos |&gt; \n  group_by(destino) |&gt; \n  summarize(\n    n = n(),\n    atraso = mean(atraso_chegada, na.rm = TRUE)\n  )\n#&gt; # A tibble: 105 × 3\n#&gt;   destino     n atraso\n#&gt;   &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 ABQ       254   4.38\n#&gt; 2 ACK       265   4.85\n#&gt; 3 ALB       439  14.4 \n#&gt; 4 ANC         8  -2.5 \n#&gt; 5 ATL     17215  11.3 \n#&gt; 6 AUS      2439   6.02\n#&gt; # ℹ 99 more rows\n\nn() é uma função de sumarização especial que não recebe nenhum argumento, mas ao invés disso, acessa informação sobre o grupo “atual”. Isto significa que funciona apenas dentro de verbos dplyr:\n\nn()\n#&gt; Error in `n()`:\n#&gt; ! Must only be used inside data-masking verbs like `mutate()`,\n#&gt;   `filter()`, and `group_by()`.\n\nExistem algumas variações de n() e count() que você deve achar útil:\n\n\nn_distinct(x) conta o número de valores distintos (únicos) de uma ou mais variáveis. Por exemplo, poderíamos obter quais destinos são mais oferecidos por companhia aérea:\n\nvoos |&gt; \n  group_by(destino) |&gt; \n  summarize(companhia_aerea = n_distinct(companhia_aerea)) |&gt; \n  arrange(desc(companhia_aerea))\n#&gt; # A tibble: 105 × 2\n#&gt;   destino companhia_aerea\n#&gt;   &lt;chr&gt;             &lt;int&gt;\n#&gt; 1 ATL                   7\n#&gt; 2 BOS                   7\n#&gt; 3 CLT                   7\n#&gt; 4 ORD                   7\n#&gt; 5 TPA                   7\n#&gt; 6 AUS                   6\n#&gt; # ℹ 99 more rows\n\n\n\nUma contagem ponderada (weigthed count) é uma soma. Pode exemplo, você poderia “contar” o número de milhas que cada avião voou:\n\nvoos |&gt; \n  group_by(codigo_cauda) |&gt; \n  summarize(milhas = sum(distancia))\n#&gt; # A tibble: 4,044 × 2\n#&gt;   codigo_cauda milhas\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 D942DN         3418\n#&gt; 2 N0EGMQ       250866\n#&gt; 3 N10156       115966\n#&gt; 4 N102UW        25722\n#&gt; 5 N103US        24619\n#&gt; 6 N104UW        25157\n#&gt; # ℹ 4,038 more rows\n\nContagem ponderada é um problema tão comum que count() tem um argumento wt que faz a mesma coisa:\n\nvoos |&gt; count(codigo_cauda, wt = distancia)\n\n\n\nVocê pode contar valores faltantes (missing values) combinando sum() e is.na(). No conjunto de dados voos isto representa os voos cancelados:\n\nvoos |&gt; \n  group_by(destino) |&gt; \n  summarize(num_cancelados = sum(is.na(horario_saida))) \n#&gt; # A tibble: 105 × 2\n#&gt;   destino num_cancelados\n#&gt;   &lt;chr&gt;            &lt;int&gt;\n#&gt; 1 ABQ                  0\n#&gt; 2 ACK                  0\n#&gt; 3 ALB                 20\n#&gt; 4 ANC                  0\n#&gt; 5 ATL                317\n#&gt; 6 AUS                 21\n#&gt; # ℹ 99 more rows\n\n\n\n\n13.3.1 Exercícios\n\nComo você pode usar count() para contar o número de linhas com valores faltantes de uma determinada variável?\nExpanda as seguintes chamadas count() para usar group_by(), summarize() e arrange() ao invés de count():\n\nflights |&gt; count(dest, sort = TRUE)\nflights |&gt; count(tailnum, wt = distance)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#transformações-numéricas",
    "href": "numbers.html#transformações-numéricas",
    "title": "13  ✅ Números",
    "section": "\n13.4 Transformações numéricas",
    "text": "13.4 Transformações numéricas\nFunções de transformação trabalham bem com mutate() porque suas saídas são do mesmo tamanho que suas entradas. A grande maioria das funções de transformação já fazem parte do R base. É impraticável listar todas, portanto esta seção irá mostrar as mais úteis. Como um exemplo, enquanto o R fornece todas as funções trigonemétricas que você pode sonhar, não iremos listá-las aqui pois elas são raramente necessárias em ciência de dados.\n\n13.4.1 Regras aritméticas e de reciclagem\nIntroduzimos a base da aritmética (+, -, *, /, ^) no Capítulo 2 e desde então a temos usado muito. Estas funções não precisam de muitas explicações pois elas fazem o que você aprendeu na escola primária. Mas temos que falar brevemente sobre regras de reciclagem (recycling rules) que determinam o que ocorre quando os lados direito e esquerdo tem tamanhos diferentes. Isto é importante para operações como voos |&gt; mutate(tempo_voo = tempo_voo / 60) pois existem 336.776 números do lado esquerdo da / mas apenas um no lado direito.\nO R lida com tamanhos incompatíveis (mismatched lengths) com reciclagem ou repetição, do vetor menor. Podemos ver isso mais facilmente se criarmos vetores fora de um data frame:\n\nx &lt;- c(1, 2, 10, 20)\nx / 5\n#&gt; [1] 0.2 0.4 2.0 4.0\n# é um atalho para\nx / c(5, 5, 5, 5)\n#&gt; [1] 0.2 0.4 2.0 4.0\n\nGeralmente, você quer reciclar apenas números únicos (i.e. vetores de tamanho 1), mas o R irá reciclar qualquer vetor de menor tamanho. Em geral (mas nem sempre), o R te retorna uma mensagem de aviso se o vetor maior não é um múltiplo do menor:\n\nx * c(1, 2)\n#&gt; [1]  1  4 10 40\nx * c(1, 2, 3)\n#&gt; Warning in x * c(1, 2, 3): longer object length is not a multiple of shorter\n#&gt; object length\n#&gt; [1]  1  4 30 20\n\nEstas regras de reciclagem se aplicam também a comparações lógicas (==, &lt;, &lt;=, &gt;, &gt;=, !=) e podem levar à resultados surpreendentes se você acidentalmente usar == ao invés de %in% e o data frame tiver um número lamentável de linhas. Por exemplo, veja este código que tenta encontrar todos os voos de Janeiro e Fevereiro:\n\nvoos |&gt; \n  filter(mes == c(1, 2))\n#&gt; # A tibble: 25,977 × 19\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1           517              515            2\n#&gt; 2  2013     1     1           542              540            2\n#&gt; 3  2013     1     1           554              600           -6\n#&gt; 4  2013     1     1           555              600           -5\n#&gt; 5  2013     1     1           557              600           -3\n#&gt; 6  2013     1     1           558              600           -2\n#&gt; # ℹ 25,971 more rows\n#&gt; # ℹ 13 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\nO código é executado sem erros, mas não retorna o que você espera. Devido às regras de reciclagem, ele encontra um número ímpar de linhas que saíram em Janeiro e um número par de voos que saíram em Fevereiro. E infelizmente, não há aviso de erro, pois voos possui um número par de linhas.\nPara te proteger desse tipo de falha silenciosa, a maioria das funções do tidyverse usa um forma restrita de reciclagem que recicla apenas valores únicos. Infelizmente isto não ajuda aqui, ou em vários outros casos, pois o cálculo é feito pela função == do R base e não pela filter().\n\n13.4.2 Mínimo e máximo\nAs funções aritméticas trabalham com pares de variáveis. Duas funções intimamente relacionadas são pmin() e pmax(), que quando dadas duas ou mais variáveis ​​retornarão o menor ou maior valor em cada linha:\n\ndf &lt;- tribble(\n  ~x, ~y,\n  1,  3,\n  5,  2,\n  7, NA,\n)\n\ndf |&gt; \n  mutate(\n    min = pmin(x, y, na.rm = TRUE),\n    max = pmax(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     3\n#&gt; 2     5     2     2     5\n#&gt; 3     7    NA     7     7\n\nObserve que elas são diferentes das funções de sumarização min() e max() que recebem múltiplas observações e retornam um único valor. Você pode dizer quando usou a forma errada quando todos os mínimos e todos os máximos têm o mesmo valor:\n\ndf |&gt; \n  mutate(\n    min = min(x, y, na.rm = TRUE),\n    max = max(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     7\n#&gt; 2     5     2     1     7\n#&gt; 3     7    NA     1     7\n\n\n13.4.3 Aritmética modular\nArtitmética modular é o termo técnico para o tipo de matemática que você fez quando aprendeu sobre casas decimais, ex. divisão que retornam um valor inteiro e um resto. No R, %/% faz uma divisão inteira e %% calcula o resto:\n\n1:10 %/% 3\n#&gt;  [1] 0 0 1 1 1 2 2 2 3 3\n1:10 %% 3\n#&gt;  [1] 1 2 0 1 2 0 1 2 0 1\n\nAritmética modular é útil para o conjunto de dados voos, pois podemos usá-la para quebrar a variável saida_programada em hora e minuto:\n\nvoos |&gt; \n  mutate(\n    hora = saida_programada %/% 100,\n    minuto = saida_programada %% 100,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   saida_programada  hora minuto\n#&gt;              &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1              515     5     15\n#&gt; 2              529     5     29\n#&gt; 3              540     5     40\n#&gt; 4              545     5     45\n#&gt; 5              600     6      0\n#&gt; 6              558     5     58\n#&gt; # ℹ 336,770 more rows\n\nPodemos combinar isto com o truque mean(is.na(x)) da Seção 12.4 para ver como a proporção de voos cancelados varia ao longo do dia. Os resultados são mostrados na Figura 13.1.\n\nvoos |&gt; \n  group_by(hora = saida_programada %/% 100) |&gt; \n  summarize(prop_cancelados = mean(is.na(horario_saida)), n = n()) |&gt; \n  filter(hora &gt; 1) |&gt; \n  ggplot(aes(x = hora, y = prop_cancelados)) +\n  geom_line(color = \"grey50\") + \n  geom_point(aes(size = n))\n\n\n\n\n\n\nFigura 13.1: Um gráfico de linha com hora da saída programada no eixo-x e a proporção dos voos cancelados no eixo-y. Cancelamentos parecem se acumular ao longo do dia até as 20:00 horas, voos noturnos parecem ter muito menos chances de serem cancelados.\n\n\n\n\n\n13.4.4 Logaritmos\nLogaritmos são transformações incríveis para lidar com dados que variam em múltiplas ordens de magnitude e também para converter o crescimento exponencial em crescimento linear. No R, você tem escolha de três logaritmos: log() (o logaritmo natural, base e), log2() (base 2), e log10() (base 10). Recomendamos usar log2() ou log10(). log2() é fácil interpretar pois a diferença de 1 na escala logarítmica corresponde ao dobro na escalada original e a diferença de -1 corresponde à metade; e o log10() é de fácil transformação inversa (back-transform) (ex. 3 é 10^3 = 1000). O inverso de log() é exp(); para calcular o inverso de log2() ou log10() você precisará usar 2^ ou 10^.\n\n13.4.5 Arredondamento\nUse round(x) para arredondar um número para o inteiro mais próximo:\n\nround(123.456)\n#&gt; [1] 123\n\nVocê pode controlar a precisão do arredondamento usando o segundo argumento, digits. round(x, digits) arredonda para o próximo 10^-n então digits = 2 irá arredondar para o 0.01 mais próximo. Esta definição é útil, pois implica que round(x, -3) arredondará para o milésimo mais próximo, o que de fato acontece:\n\nround(123.456, 2)  # dois dígitos\n#&gt; [1] 123.46\nround(123.456, 1)  # um dígito\n#&gt; [1] 123.5\nround(123.456, -1) # arredonda para dezena mais próxima\n#&gt; [1] 120\nround(123.456, -2) # arredonda para a centena mais próxima\n#&gt; [1] 100\n\nHá algo de estranho com round() que parece uma surpresa à primeira vista:\n\nround(c(1.5, 2.5))\n#&gt; [1] 2 2\n\nround() usa o que é conhecido como “arredondamento da metade para o par” ou arredondamento do banqueiro: se um número estiver no meio do caminho entre dois inteiros, ele será arredondado para o inteiro par. Esta é uma boa estratégia porque mantém o arredondamento imparcial: metade de todos os 0,5 são arredondados para cima e a outra metade para baixo.\nround() é acompanhada por floor() que sempre arredonda para baixo e ceiling() que sempre arredonda para cima:\n\nx &lt;- 123.456\n\nfloor(x)\n#&gt; [1] 123\nceiling(x)\n#&gt; [1] 124\n\nEstas funções não possuem o argumento digits, portanto você deve escalar para baixo, arredondar e depois escalar para cima:\n\n# Arredonda para baixo para os dois dígitos mais próximos\nfloor(x / 0.01) * 0.01\n#&gt; [1] 123.45\n# Arredonda para cima para os dois dígitos mais próximos\nceiling(x / 0.01) * 0.01\n#&gt; [1] 123.46\n\nVocê pode usar a mesma técnica com round() para arredondar para múltiplos de algum número:\n\n# Arredonda para o múltiplo de 4 mais próximo\nround(x / 4) * 4\n#&gt; [1] 124\n\n# Arredonda para o 0.25 mais próximo\nround(x / 0.25) * 0.25\n#&gt; [1] 123.5\n\n\n13.4.6 Separando (cuttting) números em intervalos\nUse cut()1 para separar um vetor numérico em intervalos (também chamadas de bin) discretos:\n\nx &lt;- c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] (0,5]   (0,5]   (0,5]   (5,10]  (10,15] (15,20]\n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\nAs quebras (breaks) não precisam ser espaçadas igualmente:\n\ncut(x, breaks = c(0, 5, 10, 100))\n#&gt; [1] (0,5]    (0,5]    (0,5]    (5,10]   (10,100] (10,100]\n#&gt; Levels: (0,5] (5,10] (10,100]\n\nVocê pode, opcionalmente, definir seus próprios rótulos (labels). Note que deve haver um labels a menos que o número de breaks.\n\ncut(x, \n  breaks = c(0, 5, 10, 15, 20), \n  labels = c(\"sm\", \"md\", \"lg\", \"xl\")\n)\n#&gt; [1] sm sm sm md lg xl\n#&gt; Levels: sm md lg xl\n\nQualquer valor fora do intervalo de quebras, se torna automaticamente NA:\n\ny &lt;- c(NA, -10, 5, 10, 30)\ncut(y, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] &lt;NA&gt;   &lt;NA&gt;   (0,5]  (5,10] &lt;NA&gt;  \n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\nVeja a documentação para outros argumentos úteis como right e include.lowest, que controlam se os intervalos são [a, b) ou (a, b] e se o intervalor mais baixo deve ser [a, b].\n\n13.4.7 Agregadores cumulativos e rolantes (Cumulative and rolling aggregates)\nO R base oferece cumsum(), cumprod(), cummin(), cummax() para somas, produtos, mínimos e máximos contínuos ou cumulativos. dplyr oferece cummean() para média cumulativa (um tipo de média móvel). Somas acumuladas tendem a ser de maior uso na prática:\n\nx &lt;- 1:10\ncumsum(x)\n#&gt;  [1]  1  3  6 10 15 21 28 36 45 55\n\nSe você precisar de agregadores cumulativos ou rolantes mais complexos, experimente o pacote slider.\n\n13.4.8 Exercícios\n\nExplique o que cada linha de código usada para gerar a Figura 13.1 faz.\nQuais funções de trigonometria o R oferece? Adivinhe alguns nomes e veja a documentação. Elas usam graus ou radianos?\n\nAtualmente horario_saida e saida_programada são convenientes para consultá-las, mas difícil de calculá-las pois elas não são realmente números contínuos. Você pode ver o problema básico executando o código abaixo: há um intervalo entre cada hora.\n\nvoos |&gt; \n  filter(mes == 1, dia == 1) |&gt; \n  ggplot(aes(x = saida_programada, y = atraso_saida)) +\n  geom_point()\n\nConverta estas variáveis para uma representação real de tempo (em frações de hora ou minutos a partir da meia-noite).\n\nArredonde horario_saida e horario_chegada para os cinco minutos mais próximos.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#transformações-gerais",
    "href": "numbers.html#transformações-gerais",
    "title": "13  ✅ Números",
    "section": "\n13.5 Transformações gerais",
    "text": "13.5 Transformações gerais\nA seção seguinte descreve algumas transformações gerais que são frequentemente usadas em vetores numéricos, mas podem ser usadas em outros tipos de colunas.\n\n13.5.1 Ranqueamento (rank)\nO dplyr oferece diversas funções de ranqueamento inspiradas no SQL, mas você deve sempre começar com dplyr::min_rank(). Ela usa o método típico para lidar com empates, ex.: 1o, 2o, 2o, 4o.\n\nx &lt;- c(1, 2, 2, 3, 4, NA)\nmin_rank(x)\n#&gt; [1]  1  2  2  4  5 NA\n\nNote que o valor mais baixo tem o menor ranqueamento; use desc(x) para dar aos maiores valores o menor ranqueamento:\n\nmin_rank(desc(x))\n#&gt; [1]  5  3  3  2  1 NA\n\nCaso min_rank() não fizer o que você deseja, então veja as variantes dplyr::row_number(), dplyr::dense_rank(), dplyr::percent_rank() e dplyr::cume_dist(). Veja a documentação para mais detalhes.\n\ndf &lt;- tibble(x = x)\ndf |&gt; \n  mutate(\n    num_linha = row_number(x),\n    ranqueamento_dense = dense_rank(x),\n    ranqueamento_percentual = percent_rank(x),\n    distrib_cumulativa = cume_dist(x)\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;       x num_linha ranqueamento_dense ranqueamento_percentual\n#&gt;   &lt;dbl&gt;     &lt;int&gt;              &lt;int&gt;                   &lt;dbl&gt;\n#&gt; 1     1         1                  1                    0   \n#&gt; 2     2         2                  2                    0.25\n#&gt; 3     2         3                  2                    0.25\n#&gt; 4     3         4                  3                    0.75\n#&gt; 5     4         5                  4                    1   \n#&gt; 6    NA        NA                 NA                   NA   \n#&gt; # ℹ 1 more variable: distrib_cumulativa &lt;dbl&gt;\n\nVocê pode chegar nos mesmos resultados selecionando o argumento ties.method adequado na rank() do R base; você provavelmente desejará definir na.last = \"keep\" para manter NAs como NA.\nrow_number() também pode ser usada sem nenhum argumento dentro de um verbo dplyr. Neste caso, irá te retornar o número da linha “atual”. Quando combinado com %% ou %/%, pode ser uma ferramenta útil para dividir os dados em grupos de tamanhos parecidos:\n\ndf &lt;- tibble(id = 1:10)\n\ndf |&gt; \n  mutate(\n    linha_0 = row_number() - 1,\n    tres_grupos = linha_0 %% 3,\n    tres_em_cada_grupo = linha_0 %/% 3\n  )\n#&gt; # A tibble: 10 × 4\n#&gt;      id linha_0 tres_grupos tres_em_cada_grupo\n#&gt;   &lt;int&gt;   &lt;dbl&gt;       &lt;dbl&gt;              &lt;dbl&gt;\n#&gt; 1     1       0           0                  0\n#&gt; 2     2       1           1                  0\n#&gt; 3     3       2           2                  0\n#&gt; 4     4       3           0                  1\n#&gt; 5     5       4           1                  1\n#&gt; 6     6       5           2                  1\n#&gt; # ℹ 4 more rows\n\n\n13.5.2 Deslocamentos (offsets)\ndplyr::lead() e dplyr::lag() permitem que você consulte os valores imediatamente antes ou logo após o valor “atual”. Elas retornam um vetor do mesmo comprimento da entrada, preenchido com NAs no início ou no final:\n\nx &lt;- c(2, 5, 11, 11, 19, 35)\nlag(x)\n#&gt; [1] NA  2  5 11 11 19\nlead(x)\n#&gt; [1]  5 11 11 19 35 NA\n\n\n\nx - lag(x) fornece a diferença entre o valor atual e o anterior.\n\nx - lag(x)\n#&gt; [1] NA  3  6  0  8 16\n\n\n\nx == lag(x) informa quando o valor atual muda.\n\nx == lag(x)\n#&gt; [1]    NA FALSE FALSE  TRUE FALSE FALSE\n\n\n\nVocê pode determinar o número de posições para frente (lead) ou para trás (lag) usando o segundo argumento n.\n\n13.5.3 Identificadores consecutivos\nÀs vezes você deseja iniciar um novo grupo sempre que algum evento ocorrer. Por exemplo, quando você analisa dados de um site, é comum querer dividir os eventos em sessões, onde você inicia uma nova sessão após um intervalo de mais de x minutos desde a última atividade. Por exemplo, imagine que você tenha os horários em que alguém visitou um site:\n\neventos &lt;- tibble(\n  horario = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)\n)\n\nE você calculou o período entre cada ocorrência de eventos, e descobriu se há um intervalo grande o suficiente para se qualificar:\n\neventos &lt;- eventos |&gt; \n  mutate(\n    diferenca = horario - lag(horario, default = first(horario)),\n    tem_intervalo_grande = diferenca &gt;= 5\n  )\neventos\n#&gt; # A tibble: 14 × 3\n#&gt;   horario diferenca tem_intervalo_grande\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;               \n#&gt; 1       0         0 FALSE               \n#&gt; 2       1         1 FALSE               \n#&gt; 3       2         1 FALSE               \n#&gt; 4       3         1 FALSE               \n#&gt; 5       5         2 FALSE               \n#&gt; 6      10         5 TRUE                \n#&gt; # ℹ 8 more rows\n\nMas como podemos ir deste vetor lógico para algo que podemos agrupar com group_by()? cumsum(), da Seção 13.4.7, vem pra ajudar com intervalos (gaps), ex. tem_intervalo_grande como TRUE, irá incrementar grupo em um (Seção 12.4.2):\n\neventos |&gt; mutate(\n  grupo = cumsum(tem_intervalo_grande)\n)\n#&gt; # A tibble: 14 × 4\n#&gt;   horario diferenca tem_intervalo_grande grupo\n#&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;                &lt;int&gt;\n#&gt; 1       0         0 FALSE                    0\n#&gt; 2       1         1 FALSE                    0\n#&gt; 3       2         1 FALSE                    0\n#&gt; 4       3         1 FALSE                    0\n#&gt; 5       5         2 FALSE                    0\n#&gt; 6      10         5 TRUE                     1\n#&gt; # ℹ 8 more rows\n\nOutra abordagem para criar variáveis de grupo é consecutive_id(), que inicia um novo grupo toda vez que algum de seus argumentos muda. Por exemplo, inspirado nesta pergunta do stackoverflow, imagine que você tenha um data frame com vários valores repetidos:\n\ndf &lt;- tibble(\n  x = c(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"e\", \"a\", \"a\", \"b\", \"b\"),\n  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)\n)\n\nSe você quer manter a primeira linha para cada xrepetido, você pode usar group_by(), consecutive_id() e slice_head():\n\ndf |&gt; \n  group_by(id = consecutive_id(x)) |&gt; \n  slice_head(n = 1)\n#&gt; # A tibble: 7 × 3\n#&gt; # Groups:   id [7]\n#&gt;   x         y    id\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 a         1     1\n#&gt; 2 b         2     2\n#&gt; 3 c         4     3\n#&gt; 4 d         3     4\n#&gt; 5 e         9     5\n#&gt; 6 a         4     6\n#&gt; # ℹ 1 more row\n\n\n13.5.4 Exercícios\n\nEncontre os 10 voos mais atrasados ​​usando uma função de ranqueamento. Como você quer lidar com os empates? Leia atentamente a documentação da min_rank().\nQual avião (codigo_cauda) tem o pior histórico de pontualidade?\nEm qual horário você deve voar se quiser evitar atrasos o máximo possível?\nO que faz voos |&gt; group_by(destino) |&gt; filter(row_number() &lt; 4) ? O que faz voos |&gt; group_by(destino) |&gt; filter(row_number(atraso_saida) &lt; 4) ?\nPara cada destino, calcule o total de minutos de atraso. Para cada voo, calcule a proporção do atraso total para o seu destino.\n\nOs atrasos são normalmente correlacionados temporalmente: mesmo depois de o problema que causou o atraso inicial ter sido resolvido, os voos posteriores são atrasados ​​para permitir a saída dos voos anteriores. Usando lag(), explore como o atraso médio do voo de uma hora está relacionado ao atraso médio da hora anterior..\n\nvoos |&gt; \n  mutate(hora = horario_saida %/% 100) |&gt; \n  group_by(ano, mes, dia, hora) |&gt; \n  summarize(\n    atraso_saida = mean(atraso_saida, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(n &gt; 5)\n\n\nVeja cada destino. Você consegue encontrar voos suspeitosamente rápidos (ou seja, voos que representam um possível erro de entrada de dados)? Calcule o tempo de viagem de um voo em relação ao voo mais curto para esse destino. Quais voos tiveram mais atrasos no ar?\nEncontre todos os destinos operados por pelo menos duas companhias aéreas. Use esses destinos para chegar a um ranqueamento relativo das transportadoras com base no seu desempenho para o mesmo destino.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#sumarização-numérica",
    "href": "numbers.html#sumarização-numérica",
    "title": "13  ✅ Números",
    "section": "\n13.6 Sumarização numérica",
    "text": "13.6 Sumarização numérica\nApenas usar as contagens, médias e somas que já apresentamos pode ajudar você a percorrer um longo caminho, mas o R fornece muitas outras funções de úteis de sumarização. Aqui está uma seleção que você pode achar útil.\n\n13.6.1 Centro\nAté agora, na maioria da vezes, usamos a média com mean() para sumarizar o centro de um vetor de valores. Como vimos na Seção 3.6, uma vez que a média é a soma dividida pela contagem, ela é sensível até mesmo por um pequeno número de valores muito altos ou muito baixos. Uma alternativa é usar a mediana, com median(), que encontra o valor que se encontra no “meio” do vetor, ex. 50% dos valores estão acima e 50% estão abaixo. Dependendo da forma da distribuição da variável de interesse, média ou mediana podem ser uma melhor medida de posição. Por exemplo, para distribuições simétricas, geralmente reportamos a média, enquanto para distribuições assimétricas (skewed), geralmente reportamos a mediana.\nA Figura 13.2 compara a média e a mediana dos valores de atraso na saída (em minutos) para cada destino. A mediana de atraso é sempre menor que a média de atraso, pois em alguns casos, os voos saem com várias horas de atraso, mas nunca saem várias horas antecipadamente.\n\nvoos |&gt;\n  group_by(ano, mes, dia) |&gt;\n  summarize(\n    media = mean(atraso_saida, na.rm = TRUE),\n    mediana = median(atraso_saida, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  ggplot(aes(x = media, y = mediana)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n\n\n\n\n\n\nFigura 13.2: Um gráfico de dispersão mostrando a diferença entre sumarizar atraso das saídas diárias com mediana ao invés da média.\n\n\n\n\nVocê também pode estar se perguntando sobre a moda, ou valor mais comum (ou mais frequente). Esta é uma medida que funciona bem apenas para casos muito simples (que pode ser a razão que você aprendeu sobre ela na escola primária), mas não funciona bem para conjuntos de dados reais. Se o dados forem discretos, podem existir muitos valores comuns, e se os dados forem contínuos, podem não existir valores comuns pois cada valor é ligeiramente diferente um do outro. Por estas razões, a moda tende a não ser usada por estatísticos e não há uma função de moda no R básico2.\n\n13.6.2 Minimos, maximos e quantis\nE se você tiver interesse em saber as posições diferentes do centro? min() e max() te darão os menores e maiores valores. Uma outra poderosa ferramenta é a quantile() que é uma generalização da mediana: quantile(x, 0.25) retorna o valor de x que é maior que 25% dos valores, quantile(x, 0.5) é equivalente à mediana e quantile(x, 0.95) retornará o valor que é maior que 95% dos valores.\nPara os dados de voos, você pode querer olhar no quantil 95% dos voos em atraso ao invés do valor máximo, pois isto ignora os voos com maior atraso, os quais podem ser muito extremos.\n\nvoos |&gt;\n  group_by(ano, mes, dia) |&gt;\n  summarize(\n    max = max(atraso_saida, na.rm = TRUE),\n    q95 = quantile(atraso_saida, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;     ano   mes   dia   max   q95\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2013     1     1   853  70.1\n#&gt; 2  2013     1     2   379  85  \n#&gt; 3  2013     1     3   291  68  \n#&gt; 4  2013     1     4   288  60  \n#&gt; 5  2013     1     5   327  41  \n#&gt; 6  2013     1     6   202  51  \n#&gt; # ℹ 359 more rows\n\n\n13.6.3 Dispersão\nAlgumas vezes você não tem interesse em onde a maior parte dos dados se encontra, mas sim como estão dispersos. Duas medidas de dispersão muito usadas são, o desvio padrão, sd(x), e o intervalo interquartil (inter-quartile range), IQR(). Não iremos explicar o sd() aqui, pois você já deve ser algo familiar a você, mas IQR() pode ser algo novo, — ele é quantile(x, 0.75) - quantile(x, 0.25) e retornar um intervalo que contém a metade (50%) dos dados.\nPodemos usar isso para revelar uma pequena estranheza nos dados dos voos. Você poderia esperar que a dispersão da distância entre a origem e o destino fosse zero, uma vez que os aeroportos estão sempre no mesmo lugar. Mas o código abaixo revela uma estranheza nos dados do aeroporto EGE:\n\nvoos |&gt; \n  group_by(origem, destino) |&gt; \n  summarize(\n    distancia_sd = IQR(distancia), \n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(distancia_sd &gt; 0)\n#&gt; # A tibble: 2 × 4\n#&gt;   origem destino distancia_sd     n\n#&gt;   &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 EWR    EGE                1   110\n#&gt; 2 JFK    EGE                1   103\n\n\n13.6.4 Distribuições\nVale lembrar que todas as estatísticas de sumarização descritas acima são uma forma de reduzir a distribuição a um único número. Isso significa que eles são fundamentalmente redutores e, se você escolher a sumarização errada, poderá facilmente perder diferenças importantes entre os grupos. É por isso que é sempre uma boa ideia visualizar a distribuição antes de se comprometer com suas estatísticas de sumarização.\nA Figura 13.3 mostra a distribuição geral dos atrasos nas saídas. A distribuição é tão distorcida que precisamos ampliar para ver a maior parte dos dados. Isto sugere que é pouco provável que a média seja um bom resumo e que poderíamos preferir a mediana.\n\n\n\n\n\n\n\nFigura 13.3: (Esquerda) O histograma dos dados completos é extremamente distorcido, tornando-o difícil obter detalhes. (Direita) Focar nos atrasos de menos de duas horas torna possível ver o que está acontecendo com a maior parte das observações.\n\n\n\n\nTambém é uma boa ideia verificar se as distribuições dos subgrupos se assemelham ao todo. No gráfico a seguir, 365 polígonos de frequência de atraso_saida, um para cada dia, são sobrepostos. As distribuições parecem seguir um padrão comum, sugerindo que não há problema em usar a mesma sumarização para cada dia.\n\nvoos |&gt;\n  filter(atraso_saida &lt; 120) |&gt; \n  ggplot(aes(x = atraso_saida, group = interaction(dia, mes))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n\n\n\n\n\n\n\nNão tenha medo de explorar suas próprias sumarizações personalizadas especificamente adaptadas aos dados com os quais você está trabalhando. Nesse caso, isso pode significar resumir separadamente os voos que partiram mais cedo versus os voos que partiram tarde, ou dado que os valores estão muito distorcidos, você pode tentar uma transformação logarítmica. Por fim, não esqueça o que você aprendeu na Seção 3.6: sempre que criar sumarizações numéricas, é uma boa ideia incluir o número de observações em cada grupo.\n\n13.6.5 Posições\nHá um último tipo de sumarização útil para vetores numéricos, que também funciona para outros tipos de valores: extrair um valor em uma posição específica: first(x), last(x) e nth(x, n).\nPor exemplo, podemos encontrar a primeira e última saída em cada dia:\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt; \n  summarize(\n    primeira_saida = first(horario_saida, na_rm = TRUE), \n    quinta_saida = nth(horario_saida, 5, na_rm = TRUE),\n    ultima_saida = last(horario_saida, na_rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by 'ano', 'mes'. You can override using the\n#&gt; `.groups` argument.\n#&gt; # A tibble: 365 × 6\n#&gt; # Groups:   ano, mes [12]\n#&gt;     ano   mes   dia primeira_saida quinta_saida ultima_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;        &lt;int&gt;        &lt;int&gt;\n#&gt; 1  2013     1     1            517          554         2356\n#&gt; 2  2013     1     2             42          535         2354\n#&gt; 3  2013     1     3             32          520         2349\n#&gt; 4  2013     1     4             25          531         2358\n#&gt; 5  2013     1     5             14          534         2357\n#&gt; 6  2013     1     6             16          555         2355\n#&gt; # ℹ 359 more rows\n\n(NB: Uma vez que as funções do dplyr usam _ para separar componentes da função e nomes de argumentos, estas funções usam na_rm ao invés de na.rm.)\nSe você está familiarizado com [, o qual retornaremos na Seção 27.2, você pode estar se perguntando se você realmente precisa destas funções. Existem três razões: o argumento default permite que você forneça um padrão se a posição especificada não existir, o argumento order_by permite que você ordene localmente sobrescrevendo a ordenação das linhas, e o argumento na_rm permite você ignorar valores faltantes (missing values).\nExtrair valores em determinada posição é complementar à filtrar em ranqueamentos. Filtrar retorna todas as variáveis, com cada observação em uma linha separada:\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt; \n  mutate(r = min_rank(saida_programada)) |&gt; \n  filter(r %in% c(1, max(r)))\n#&gt; # A tibble: 1,195 × 20\n#&gt; # Groups:   ano, mes, dia [365]\n#&gt;     ano   mes   dia horario_saida saida_programada atraso_saida\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;         &lt;int&gt;            &lt;int&gt;        &lt;dbl&gt;\n#&gt; 1  2013     1     1           517              515            2\n#&gt; 2  2013     1     1          2353             2359           -6\n#&gt; 3  2013     1     1          2353             2359           -6\n#&gt; 4  2013     1     1          2356             2359           -3\n#&gt; 5  2013     1     2            42             2359           43\n#&gt; 6  2013     1     2           458              500           -2\n#&gt; # ℹ 1,189 more rows\n#&gt; # ℹ 14 more variables: horario_chegada &lt;int&gt;, chegada_prevista &lt;int&gt;, …\n\n\n13.6.6 Com mutate()\n\nComo o nome sugere, funções de sumarização são usadas tipicamente com summarize(). Entretando, devido às regras de reciclagem discutidas na Seção 13.4.1, elas podem ser usadas também com mutate(), particularmente quando você deseja fazer algum tipo de padronização. Por exemplo:\n\n\nx / sum(x) calcula a proporção de um total.\n\n(x - mean(x)) / sd(x) calcula o Z-score (padronização com média 0 e desvio padrão 1).\n\n(x - min(x)) / (max(x) - min(x)) padroniza em intervalo [0, 1].\n\nx / first(x) calcula um índice baseado na primeira observação.\n\n13.6.7 Exercícios\n\nPense em pelo menos 5 maneiras diferentes de avaliar as características típicas de atraso de um grupo de voos. Quando a mean() é útil? Quando a median() é útil? Quando você poderia querer usar alguma outra maneira? Você deveria usar atraso_chegada ou atraso_saida? Quando você poderia querer usar dados de dados::avioes?\nQuais destinos apresentam a maior variação na velocidade aérea?\nCrie um gráfico para explorar ainda mais as aventuras do EGE. Você pode encontrar alguma evidência de que o aeroporto mudou de local? Você pode encontrar outra variável que possa explicar a diferença?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#resumo",
    "href": "numbers.html#resumo",
    "title": "13  ✅ Números",
    "section": "\n13.7 Resumo",
    "text": "13.7 Resumo\nVocê já tem familiaridade com muitas ferramentas para trabalhar com números e, depois de ler este capítulo, agora sabe como usá-las no R. Você também aprendeu algumas transformações gerais úteis que são comumente, mas não exclusivamente, aplicadas a vetores numéricos, como ranqueamentos e deslocamentos. Por fim, você trabalhou com várias sumarizações numéricas e discutiu alguns dos desafios estatísticos que deveria considerar.\nNos próximos dois capítulos, nos aprofundaremos em strings com o pacote stringr. Strings são um grande tópico, então elas têm dois capítulos, um sobre os fundamentos de strings e outro sobre expressões regulares (regex).",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#footnotes",
    "href": "numbers.html#footnotes",
    "title": "13  ✅ Números",
    "section": "",
    "text": "ggplot2 oferece funções de ajuda para casos comuns como cut_interval(), cut_number() e cut_width(). ggplot2 é um lugar reconhecidamente estranho para manter essas funções, mas elas são úteis como parte do cálculo do histograma e foram escritas antes de qualquer outra parte do tidyverse existir.↩︎\nA função mode() faz algo um pouco diferente!↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>✅ Números</span>"
    ]
  },
  {
    "objectID": "strings.html",
    "href": "strings.html",
    "title": "14  Strings",
    "section": "",
    "text": "14.1 Introduction\nSo far, you’ve used a bunch of strings without learning much about the details. Now it’s time to dive into them, learn what makes strings tick, and master some of the powerful string manipulation tools you have at your disposal.\nWe’ll begin with the details of creating strings and character vectors. You’ll then dive into creating strings from data, then the opposite: extracting strings from data. We’ll then discuss tools that work with individual letters. The chapter finishes with functions that work with individual letters and a brief discussion of where your expectations from English might steer you wrong when working with other languages.\nWe’ll keep working with strings in the next chapter, where you’ll learn more about the power of regular expressions.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#introduction",
    "href": "strings.html#introduction",
    "title": "14  Strings",
    "section": "",
    "text": "14.1.1 Prerequisites\nIn this chapter, we’ll use functions from the stringr package, which is part of the core tidyverse. We’ll also use the babynames data since it provides some fun strings to manipulate.\n\nlibrary(tidyverse)\nlibrary(babynames)\n\nYou can quickly tell when you’re using a stringr function because all stringr functions start with str_. This is particularly useful if you use RStudio because typing str_ will trigger autocomplete, allowing you to jog your memory of the available functions.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#creating-a-string",
    "href": "strings.html#creating-a-string",
    "title": "14  Strings",
    "section": "\n14.2 Creating a string",
    "text": "14.2 Creating a string\nWe’ve created strings in passing earlier in the book but didn’t discuss the details. Firstly, you can create a string using either single quotes (') or double quotes (\"). There’s no difference in behavior between the two, so in the interests of consistency, the tidyverse style guide recommends using \", unless the string contains multiple \".\n\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\n\nIf you forget to close a quote, you’ll see +, the continuation prompt:\n&gt; \"This is a string without a closing quote\n+ \n+ \n+ HELP I'M STUCK IN A STRING\nIf this happens to you and you can’t figure out which quote to close, press Escape to cancel and try again.\n\n14.2.1 Escapes\nTo include a literal single or double quote in a string, you can use \\ to “escape” it:\n\ndouble_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\"\n\nSo if you want to include a literal backslash in your string, you’ll need to escape it: \"\\\\\":\n\nbackslash &lt;- \"\\\\\"\n\nBeware that the printed representation of a string is not the same as the string itself because the printed representation shows the escapes (in other words, when you print a string, you can copy and paste the output to recreate that string). To see the raw contents of the string, use str_view()1:\n\nx &lt;- c(single_quote, double_quote, backslash)\nx\n#&gt; [1] \"'\"  \"\\\"\" \"\\\\\"\n\nstr_view(x)\n#&gt; [1] │ '\n#&gt; [2] │ \"\n#&gt; [3] │ \\\n\n\n14.2.2 Raw strings\nCreating a string with multiple quotes or backslashes gets confusing quickly. To illustrate the problem, let’s create a string that contains the contents of the code block where we define the double_quote and single_quote variables:\n\ntricky &lt;- \"double_quote &lt;- \\\"\\\\\\\"\\\" # or '\\\"'\nsingle_quote &lt;- '\\\\'' # or \\\"'\\\"\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\nThat’s a lot of backslashes! (This is sometimes called leaning toothpick syndrome.) To eliminate the escaping, you can instead use a raw string2:\n\ntricky &lt;- r\"(double_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\")\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\nA raw string usually starts with r\"( and finishes with )\". But if your string contains )\" you can instead use r\"[]\" or r\"{}\", and if that’s still not enough, you can insert any number of dashes to make the opening and closing pairs unique, e.g., r\"--()--\", r\"---()---\", etc. Raw strings are flexible enough to handle any text.\n\n14.2.3 Other special characters\nAs well as \\\", \\', and \\\\, there are a handful of other special characters that may come in handy. The most common are \\n, a new line, and \\t, tab. You’ll also sometimes see strings containing Unicode escapes that start with \\u or \\U. This is a way of writing non-English characters that work on all systems. You can see the complete list of other special characters in ?Quotes.\n\nx &lt;- c(\"one\\ntwo\", \"one\\ttwo\", \"\\u00b5\", \"\\U0001f604\")\nx\n#&gt; [1] \"one\\ntwo\" \"one\\ttwo\" \"µ\"        \"😄\"\nstr_view(x)\n#&gt; [1] │ one\n#&gt;     │ two\n#&gt; [2] │ one{\\t}two\n#&gt; [3] │ µ\n#&gt; [4] │ 😄\n\nNote that str_view() uses curly braces for tabs to make them easier to spot3. One of the challenges of working with text is that there’s a variety of ways that white space can end up in the text, so this background helps you recognize that something strange is going on.\n\n14.2.4 Exercises\n\n\nCreate strings that contain the following values:\n\nHe said \"That's amazing!\"\n\\a\\b\\c\\d\n\\\\\\\\\\\\\n\n\n\nCreate the string in your R session and print it. What happens to the special “\\u00a0”? How does str_view() display it? Can you do a little googling to figure out what this special character is?\n\nx &lt;- \"This\\u00a0is\\u00a0tricky\"",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#creating-many-strings-from-data",
    "href": "strings.html#creating-many-strings-from-data",
    "title": "14  Strings",
    "section": "\n14.3 Creating many strings from data",
    "text": "14.3 Creating many strings from data\nNow that you’ve learned the basics of creating a string or two by “hand”, we’ll go into the details of creating strings from other strings. This will help you solve the common problem where you have some text you wrote that you want to combine with strings from a data frame. For example, you might combine “Hello” with a name variable to create a greeting. We’ll show you how to do this with str_c() and str_glue() and how you can use them with mutate(). That naturally raises the question of what stringr functions you might use with summarize(), so we’ll finish this section with a discussion of str_flatten(), which is a summary function for strings.\n\n14.3.1 str_c()\n\nstr_c() takes any number of vectors as arguments and returns a character vector:\n\nstr_c(\"x\", \"y\")\n#&gt; [1] \"xy\"\nstr_c(\"x\", \"y\", \"z\")\n#&gt; [1] \"xyz\"\nstr_c(\"Hello \", c(\"John\", \"Susan\"))\n#&gt; [1] \"Hello John\"  \"Hello Susan\"\n\nstr_c() is very similar to the base paste0(), but is designed to be used with mutate() by obeying the usual tidyverse rules for recycling and propagating missing values:\n\ndf &lt;- tibble(name = c(\"Flora\", \"David\", \"Terra\", NA))\ndf |&gt; mutate(greeting = str_c(\"Hi \", name, \"!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  &lt;NA&gt;\n\nIf you want missing values to display in another way, use coalesce() to replace them. Depending on what you want, you might use it either inside or outside of str_c():\n\ndf |&gt; \n  mutate(\n    greeting1 = str_c(\"Hi \", coalesce(name, \"you\"), \"!\"),\n    greeting2 = coalesce(str_c(\"Hi \", name, \"!\"), \"Hi!\")\n  )\n#&gt; # A tibble: 4 × 3\n#&gt;   name  greeting1 greeting2\n#&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora! Hi Flora!\n#&gt; 2 David Hi David! Hi David!\n#&gt; 3 Terra Hi Terra! Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi you!   Hi!\n\n\n14.3.2 str_glue()\n\nIf you are mixing many fixed and variable strings with str_c(), you’ll notice that you type a lot of \"s, making it hard to see the overall goal of the code. An alternative approach is provided by the glue package via str_glue()4. You give it a single string that has a special feature: anything inside {} will be evaluated like it’s outside of the quotes:\n\ndf |&gt; mutate(greeting = str_glue(\"Hi {name}!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;glue&gt;   \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi NA!\n\nAs you can see, str_glue() currently converts missing values to the string \"NA\", unfortunately making it inconsistent with str_c().\nYou also might wonder what happens if you need to include a regular { or } in your string. You’re on the right track if you guess you’ll need to escape it somehow. The trick is that glue uses a slightly different escaping technique: instead of prefixing with special character like \\, you double up the special characters:\n\ndf |&gt; mutate(greeting = str_glue(\"{{Hi {name}!}}\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting   \n#&gt;   &lt;chr&gt; &lt;glue&gt;     \n#&gt; 1 Flora {Hi Flora!}\n#&gt; 2 David {Hi David!}\n#&gt; 3 Terra {Hi Terra!}\n#&gt; 4 &lt;NA&gt;  {Hi NA!}\n\n\n14.3.3 str_flatten()\n\nstr_c() and str_glue() work well with mutate() because their output is the same length as their inputs. What if you want a function that works well with summarize(), i.e. something that always returns a single string? That’s the job of str_flatten()5: it takes a character vector and combines each element of the vector into a single string:\n\nstr_flatten(c(\"x\", \"y\", \"z\"))\n#&gt; [1] \"xyz\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \")\n#&gt; [1] \"x, y, z\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \", last = \", and \")\n#&gt; [1] \"x, y, and z\"\n\nThis makes it work well with summarize():\n\ndf &lt;- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"mandarin\"\n)\ndf |&gt;\n  group_by(name) |&gt; \n  summarize(fruits = str_flatten(fruit, \", \"))\n#&gt; # A tibble: 3 × 2\n#&gt;   name    fruits                      \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                       \n#&gt; 1 Carmen  banana, apple               \n#&gt; 2 Marvin  nectarine                   \n#&gt; 3 Terence cantaloupe, papaya, mandarin\n\n\n14.3.4 Exercises\n\n\nCompare and contrast the results of paste0() with str_c() for the following inputs:\n\nstr_c(\"hi \", NA)\nstr_c(letters[1:2], letters[1:3])\n\n\nWhat’s the difference between paste() and paste0()? How can you recreate the equivalent of paste() with str_c()?\n\nConvert the following expressions from str_c() to str_glue() or vice versa:\n\nstr_c(\"The price of \", food, \" is \", price)\nstr_glue(\"I'm {age} years old and live in {country}\")\nstr_c(\"\\\\section{\", title, \"}\")",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#extracting-data-from-strings",
    "href": "strings.html#extracting-data-from-strings",
    "title": "14  Strings",
    "section": "\n14.4 Extracting data from strings",
    "text": "14.4 Extracting data from strings\nIt’s very common for multiple variables to be crammed together into a single string. In this section, you’ll learn how to use four tidyr functions to extract them:\n\ndf |&gt; separate_longer_delim(col, delim)\ndf |&gt; separate_longer_position(col, width)\ndf |&gt; separate_wider_delim(col, delim, names)\ndf |&gt; separate_wider_position(col, widths)\n\nIf you look closely, you can see there’s a common pattern here: separate_, then longer or wider, then _, then by delim or position. That’s because these four functions are composed of two simpler primitives:\n\nJust like with pivot_longer() and pivot_wider(), _longer functions make the input data frame longer by creating new rows and _wider functions make the input data frame wider by generating new columns.\n\ndelim splits up a string with a delimiter like \", \" or \" \"; position splits at specified widths, like c(3, 5, 2).\n\nWe’ll return to the last member of this family, separate_wider_regex(), in Capítulo 15. It’s the most flexible of the wider functions, but you need to know something about regular expressions before you can use it.\nThe following two sections will give you the basic idea behind these separate functions, first separating into rows (which is a little simpler) and then separating into columns. We’ll finish off by discussing the tools that the wider functions give you to diagnose problems.\n\n14.4.1 Separating into rows\nSeparating a string into rows tends to be most useful when the number of components varies from row to row. The most common case is requiring separate_longer_delim() to split based on a delimiter:\n\ndf1 &lt;- tibble(x = c(\"a,b,c\", \"d,e\", \"f\"))\ndf1 |&gt; \n  separate_longer_delim(x, delim = \",\")\n#&gt; # A tibble: 6 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a    \n#&gt; 2 b    \n#&gt; 3 c    \n#&gt; 4 d    \n#&gt; 5 e    \n#&gt; 6 f\n\nIt’s rarer to see separate_longer_position() in the wild, but some older datasets do use a very compact format where each character is used to record a value:\n\ndf2 &lt;- tibble(x = c(\"1211\", \"131\", \"21\"))\ndf2 |&gt; \n  separate_longer_position(x, width = 1)\n#&gt; # A tibble: 9 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1    \n#&gt; 2 2    \n#&gt; 3 1    \n#&gt; 4 1    \n#&gt; 5 1    \n#&gt; 6 3    \n#&gt; # ℹ 3 more rows\n\n\n14.4.2 Separating into columns\nSeparating a string into columns tends to be most useful when there are a fixed number of components in each string, and you want to spread them into columns. They are slightly more complicated than their longer equivalents because you need to name the columns. For example, in this following dataset, x is made up of a code, an edition number, and a year, separated by \".\". To use separate_wider_delim(), we supply the delimiter and the names in two arguments:\n\ndf3 &lt;- tibble(x = c(\"a10.1.2022\", \"b10.2.2011\", \"e15.1.2015\"))\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", \"edition\", \"year\")\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   code  edition year \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 a10   1       2022 \n#&gt; 2 b10   2       2011 \n#&gt; 3 e15   1       2015\n\nIf a specific piece is not useful you can use an NA name to omit it from the results:\n\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", NA, \"year\")\n  )\n#&gt; # A tibble: 3 × 2\n#&gt;   code  year \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 a10   2022 \n#&gt; 2 b10   2011 \n#&gt; 3 e15   2015\n\nseparate_wider_position() works a little differently because you typically want to specify the width of each column. So you give it a named integer vector, where the name gives the name of the new column, and the value is the number of characters it occupies. You can omit values from the output by not naming them:\n\ndf4 &lt;- tibble(x = c(\"202215TX\", \"202122LA\", \"202325CA\")) \ndf4 |&gt; \n  separate_wider_position(\n    x,\n    widths = c(year = 4, age = 2, state = 2)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   year  age   state\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2022  15    TX   \n#&gt; 2 2021  22    LA   \n#&gt; 3 2023  25    CA\n\n\n14.4.3 Diagnosing widening problems\nseparate_wider_delim()6 requires a fixed and known set of columns. What happens if some of the rows don’t have the expected number of pieces? There are two possible problems, too few or too many pieces, so separate_wider_delim() provides two arguments to help: too_few and too_many. Let’s first look at the too_few case with the following sample dataset:\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3\", \"1-3-2\", \"1\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too short.\n#&gt; ℹ Use `too_few = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_few = \"align_start\"/\"align_end\"` to silence this message.\n\nYou’ll notice that we get an error, but the error gives us some suggestions on how you might proceed. Let’s start by debugging the problem:\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug\n#&gt; # A tibble: 5 × 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-1-1 1     1     TRUE         3 \"\"         \n#&gt; 2 1-1-2 1     2     TRUE         3 \"\"         \n#&gt; 3 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 4 1-3-2 3     2     TRUE         3 \"\"         \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nWhen you use the debug mode, you get three extra columns added to the output: x_ok, x_pieces, and x_remainder (if you separate a variable with a different name, you’ll get a different prefix). Here, x_ok lets you quickly find the inputs that failed:\n\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 × 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 2 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nx_pieces tells us how many pieces were found, compared to the expected 3 (the length of names). x_remainder isn’t useful when there are too few pieces, but we’ll see it again shortly.\nSometimes looking at this debugging information will reveal a problem with your delimiter strategy or suggest that you need to do more preprocessing before separating. In that case, fix the problem upstream and make sure to remove too_few = \"debug\" to ensure that new problems become errors.\nIn other cases, you may want to fill in the missing pieces with NAs and move on. That’s the job of too_few = \"align_start\" and too_few = \"align_end\" which allow you to control where the NAs should go:\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"align_start\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     &lt;NA&gt; \n#&gt; 4 1     3     2    \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;\n\nThe same principles apply if you have too many pieces:\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3-5-6\", \"1-3-2\", \"1-3-5-7-9\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too long.\n#&gt; ℹ Use `too_many = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_many = \"drop\"/\"merge\"` to silence this message.\n\nBut now, when we debug the result, you can see the purpose of x_remainder:\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 × 6\n#&gt;   x         y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3-5-6   3     5     FALSE        4 -6         \n#&gt; 2 1-3-5-7-9 3     5     FALSE        5 -7-9\n\nYou have a slightly different set of options for handling too many pieces: you can either silently “drop” any additional pieces or “merge” them all into the final column:\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"drop\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5    \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5\n\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"merge\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5-6  \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5-7-9",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#letters",
    "href": "strings.html#letters",
    "title": "14  Strings",
    "section": "\n14.5 Letters",
    "text": "14.5 Letters\nIn this section, we’ll introduce you to functions that allow you to work with the individual letters within a string. You’ll learn how to find the length of a string, extract substrings, and handle long strings in plots and tables.\n\n14.5.1 Length\nstr_length() tells you the number of letters in the string:\n\nstr_length(c(\"a\", \"R for data science\", NA))\n#&gt; [1]  1 18 NA\n\nYou could use this with count() to find the distribution of lengths of US babynames and then with filter() to look at the longest names, which happen to have 15 letters7:\n\nbabynames |&gt;\n  count(length = str_length(name), wt = n)\n#&gt; # A tibble: 14 × 2\n#&gt;   length        n\n#&gt;    &lt;int&gt;    &lt;int&gt;\n#&gt; 1      2   338150\n#&gt; 2      3  8589596\n#&gt; 3      4 48506739\n#&gt; 4      5 87011607\n#&gt; 5      6 90749404\n#&gt; 6      7 72120767\n#&gt; # ℹ 8 more rows\n\nbabynames |&gt; \n  filter(str_length(name) == 15) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 34 × 2\n#&gt;   name                n\n#&gt;   &lt;chr&gt;           &lt;int&gt;\n#&gt; 1 Franciscojavier   123\n#&gt; 2 Christopherjohn   118\n#&gt; 3 Johnchristopher   118\n#&gt; 4 Christopherjame   108\n#&gt; 5 Christophermich    52\n#&gt; 6 Ryanchristopher    45\n#&gt; # ℹ 28 more rows\n\n\n14.5.2 Subsetting\nYou can extract parts of a string using str_sub(string, start, end), where start and end are the positions where the substring should start and end. The start and end arguments are inclusive, so the length of the returned string will be end - start + 1:\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n#&gt; [1] \"App\" \"Ban\" \"Pea\"\n\nYou can use negative values to count back from the end of the string: -1 is the last character, -2 is the second to last character, etc.\n\nstr_sub(x, -3, -1)\n#&gt; [1] \"ple\" \"ana\" \"ear\"\n\nNote that str_sub() won’t fail if the string is too short: it will just return as much as possible:\n\nstr_sub(\"a\", 1, 5)\n#&gt; [1] \"a\"\n\nWe could use str_sub() with mutate() to find the first and last letter of each name:\n\nbabynames |&gt; \n  mutate(\n    first = str_sub(name, 1, 1),\n    last = str_sub(name, -1, -1)\n  )\n#&gt; # A tibble: 1,924,665 × 7\n#&gt;    year sex   name          n   prop first last \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1  1880 F     Mary       7065 0.0724 M     y    \n#&gt; 2  1880 F     Anna       2604 0.0267 A     a    \n#&gt; 3  1880 F     Emma       2003 0.0205 E     a    \n#&gt; 4  1880 F     Elizabeth  1939 0.0199 E     h    \n#&gt; 5  1880 F     Minnie     1746 0.0179 M     e    \n#&gt; 6  1880 F     Margaret   1578 0.0162 M     t    \n#&gt; # ℹ 1,924,659 more rows\n\n\n14.5.3 Exercises\n\nWhen computing the distribution of the length of babynames, why did we use wt = n?\nUse str_length() and str_sub() to extract the middle letter from each baby name. What will you do if the string has an even number of characters?\nAre there any major trends in the length of babynames over time? What about the popularity of first and last letters?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#sec-other-languages",
    "href": "strings.html#sec-other-languages",
    "title": "14  Strings",
    "section": "\n14.6 Non-English text",
    "text": "14.6 Non-English text\nSo far, we’ve focused on English language text which is particularly easy to work with for two reasons. Firstly, the English alphabet is relatively simple: there are just 26 letters. Secondly (and maybe more importantly), the computing infrastructure we use today was predominantly designed by English speakers. Unfortunately, we don’t have room for a full treatment of non-English languages. Still, we wanted to draw your attention to some of the biggest challenges you might encounter: encoding, letter variations, and locale-dependent functions.\n\n14.6.1 Encoding\nWhen working with non-English text, the first challenge is often the encoding. To understand what’s going on, we need to dive into how computers represent strings. In R, we can get at the underlying representation of a string using charToRaw():\n\ncharToRaw(\"Hadley\")\n#&gt; [1] 48 61 64 6c 65 79\n\nEach of these six hexadecimal numbers represents one letter: 48 is H, 61 is a, and so on. The mapping from hexadecimal number to character is called the encoding, and in this case, the encoding is called ASCII. ASCII does a great job of representing English characters because it’s the American Standard Code for Information Interchange.\nThings aren’t so easy for languages other than English. In the early days of computing, there were many competing standards for encoding non-English characters. For example, there were two different encodings for Europe: Latin1 (aka ISO-8859-1) was used for Western European languages, and Latin2 (aka ISO-8859-2) was used for Central European languages. In Latin1, the byte b1 is “±”, but in Latin2, it’s “ą”! Fortunately, today there is one standard that is supported almost everywhere: UTF-8. UTF-8 can encode just about every character used by humans today and many extra symbols like emojis.\nreadr uses UTF-8 everywhere. This is a good default but will fail for data produced by older systems that don’t use UTF-8. If this happens, your strings will look weird when you print them. Sometimes just one or two characters might be messed up; other times, you’ll get complete gibberish. For example here are two inline CSVs with unusual encodings8:\n\nx1 &lt;- \"text\\nEl Ni\\xf1o was particularly bad this year\"\nread_csv(x1)$text\n#&gt; [1] \"El Ni\\xf1o was particularly bad this year\"\n\nx2 &lt;- \"text\\n\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\nread_csv(x2)$text\n#&gt; [1] \"\\x82\\xb1\\x82\\xf1\\x82ɂ\\xbf\\x82\\xcd\"\n\nTo read these correctly, you specify the encoding via the locale argument:\n\nread_csv(x1, locale = locale(encoding = \"Latin1\"))$text\n#&gt; [1] \"El Niño was particularly bad this year\"\n\nread_csv(x2, locale = locale(encoding = \"Shift-JIS\"))$text\n#&gt; [1] \"こんにちは\"\n\nHow do you find the correct encoding? If you’re lucky, it’ll be included somewhere in the data documentation. Unfortunately, that’s rarely the case, so readr provides guess_encoding() to help you figure it out. It’s not foolproof and works better when you have lots of text (unlike here), but it’s a reasonable place to start. Expect to try a few different encodings before you find the right one.\nEncodings are a rich and complex topic; we’ve only scratched the surface here. If you’d like to learn more, we recommend reading the detailed explanation at http://kunststube.net/encoding/.\n\n14.6.2 Letter variations\nWorking in languages with accents poses a significant challenge when determining the position of letters (e.g., with str_length() and str_sub()) as accented letters might be encoded as a single individual character (e.g., ü) or as two characters by combining an unaccented letter (e.g., u) with a diacritic mark (e.g., ¨). For example, this code shows two ways of representing ü that look identical:\n\nu &lt;- c(\"\\u00fc\", \"u\\u0308\")\nstr_view(u)\n#&gt; [1] │ ü\n#&gt; [2] │ ü\n\nBut both strings differ in length, and their first characters are different:\n\nstr_length(u)\n#&gt; [1] 1 2\nstr_sub(u, 1, 1)\n#&gt; [1] \"ü\" \"u\"\n\nFinally, note that a comparison of these strings with == interprets these strings as different, while the handy str_equal() function in stringr recognizes that both have the same appearance:\n\nu[[1]] == u[[2]]\n#&gt; [1] FALSE\n\nstr_equal(u[[1]], u[[2]])\n#&gt; [1] TRUE\n\n\n14.6.3 Locale-dependent functions\nFinally, there are a handful of stringr functions whose behavior depends on your locale. A locale is similar to a language but includes an optional region specifier to handle regional variations within a language. A locale is specified by a lower-case language abbreviation, optionally followed by a _ and an upper-case region identifier. For example, “en” is English, “en_GB” is British English, and “en_US” is American English. If you don’t already know the code for your language, Wikipedia has a good list, and you can see which are supported in stringr by looking at stringi::stri_locale_list().\nBase R string functions automatically use the locale set by your operating system. This means that base R string functions do what you expect for your language, but your code might work differently if you share it with someone who lives in a different country. To avoid this problem, stringr defaults to English rules by using the “en” locale and requires you to specify the locale argument to override it. Fortunately, there are two sets of functions where the locale really matters: changing case and sorting.\nThe rules for changing cases differ among languages. For example, Turkish has two i’s: with and without a dot. Since they’re two distinct letters, they’re capitalized differently:\n\nstr_to_upper(c(\"i\", \"ı\"))\n#&gt; [1] \"I\" \"I\"\nstr_to_upper(c(\"i\", \"ı\"), locale = \"tr\")\n#&gt; [1] \"İ\" \"I\"\n\nSorting strings depends on the order of the alphabet, and the order of the alphabet is not the same in every language9! Here’s an example: in Czech, “ch” is a compound letter that appears after h in the alphabet.\n\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"))\n#&gt; [1] \"a\"  \"c\"  \"ch\" \"h\"  \"z\"\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"), locale = \"cs\")\n#&gt; [1] \"a\"  \"c\"  \"h\"  \"ch\" \"z\"\n\nThis also comes up when sorting strings with dplyr::arrange(), which is why it also has a locale argument.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#summary",
    "href": "strings.html#summary",
    "title": "14  Strings",
    "section": "\n14.7 Summary",
    "text": "14.7 Summary\nIn this chapter, you’ve learned about some of the power of the stringr package: how to create, combine, and extract strings, and about some of the challenges you might face with non-English strings. Now it’s time to learn one of the most important and powerful tools for working with strings: regular expressions. Regular expressions are a very concise but very expressive language for describing patterns within strings and are the topic of the next chapter.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "strings.html#footnotes",
    "href": "strings.html#footnotes",
    "title": "14  Strings",
    "section": "",
    "text": "Or use the base R function writeLines().↩︎\nAvailable in R 4.0.0 and above.↩︎\nstr_view() also uses color to bring tabs, spaces, matches, etc. to your attention. The colors don’t currently show up in the book, but you’ll notice them when running code interactively.↩︎\nIf you’re not using stringr, you can also access it directly with glue::glue().↩︎\nThe base R equivalent is paste() used with the collapse argument.↩︎\nThe same principles apply to separate_wider_position() and separate_wider_regex().↩︎\nLooking at these entries, we’d guess that the babynames data drops spaces or hyphens and truncates after 15 letters.↩︎\nHere I’m using the special \\x to encode binary data directly into a string.↩︎\nSorting in languages that don’t have an alphabet, like Chinese, is more complicated still.↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "regexps.html",
    "href": "regexps.html",
    "title": "15  Regular expressions",
    "section": "",
    "text": "15.1 Introduction\nIn Capítulo 14, you learned a whole bunch of useful functions for working with strings. This chapter will focus on functions that use regular expressions, a concise and powerful language for describing patterns within strings. The term “regular expression” is a bit of a mouthful, so most people abbreviate it to “regex”1 or “regexp”.\nThe chapter starts with the basics of regular expressions and the most useful stringr functions for data analysis. We’ll then expand your knowledge of patterns and cover seven important new topics (escaping, anchoring, character classes, shorthand classes, quantifiers, precedence, and grouping). Next, we’ll talk about some of the other types of patterns that stringr functions can work with and the various “flags” that allow you to tweak the operation of regular expressions. We’ll finish with a survey of other places in the tidyverse and base R where you might use regexes.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#introduction",
    "href": "regexps.html#introduction",
    "title": "15  Regular expressions",
    "section": "",
    "text": "15.1.1 Prerequisites\nIn this chapter, we’ll use regular expression functions from stringr and tidyr, both core members of the tidyverse, as well as data from the babynames package.\n\nlibrary(tidyverse)\nlibrary(babynames)\n\nThrough this chapter, we’ll use a mix of very simple inline examples so you can get the basic idea, the baby names data, and three character vectors from stringr:\n\n\nfruit contains the names of 80 fruits.\n\nwords contains 980 common English words.\n\nsentences contains 720 short sentences.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-reg-basics",
    "href": "regexps.html#sec-reg-basics",
    "title": "15  Regular expressions",
    "section": "\n15.2 Pattern basics",
    "text": "15.2 Pattern basics\nWe’ll use str_view() to learn how regex patterns work. We used str_view() in the last chapter to better understand a string vs. its printed representation, and now we’ll use it with its second argument, a regular expression. When this is supplied, str_view() will show only the elements of the string vector that match, surrounding each match with &lt;&gt;, and, where possible, highlighting the match in blue.\nThe simplest patterns consist of letters and numbers which match those characters exactly:\n\nstr_view(fruit, \"berry\")\n#&gt;  [6] │ bil&lt;berry&gt;\n#&gt;  [7] │ black&lt;berry&gt;\n#&gt; [10] │ blue&lt;berry&gt;\n#&gt; [11] │ boysen&lt;berry&gt;\n#&gt; [19] │ cloud&lt;berry&gt;\n#&gt; [21] │ cran&lt;berry&gt;\n#&gt; ... and 8 more\n\nLetters and numbers match exactly and are called literal characters. Most punctuation characters, like ., +, *, [, ], and ?, have special meanings2 and are called metacharacters. For example, . will match any character3, so \"a.\" will match any string that contains an “a” followed by another character :\n\nstr_view(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ae&gt;\n#&gt; [6] │ e&lt;ab&gt;\n\nOr we could find all the fruits that contain an “a”, followed by three letters, followed by an “e”:\n\nstr_view(fruit, \"a...e\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt;  [7] │ bl&lt;ackbe&gt;rry\n#&gt; [48] │ mand&lt;arine&gt;\n#&gt; [51] │ nect&lt;arine&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [64] │ pomegr&lt;anate&gt;\n#&gt; ... and 2 more\n\nQuantifiers control how many times a pattern can match:\n\n\n? makes a pattern optional (i.e. it matches 0 or 1 times)\n\n+ lets a pattern repeat (i.e. it matches at least once)\n\n* lets a pattern be optional or repeat (i.e. it matches any number of times, including 0).\n\n\n# ab? matches an \"a\", optionally followed by a \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ab&gt;b\n\n# ab+ matches an \"a\", followed by at least one \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\n# ab* matches an \"a\", followed by any number of \"b\"s.\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\nCharacter classes are defined by [] and let you match a set of characters, e.g., [abcd] matches “a”, “b”, “c”, or “d”. You can also invert the match by starting with ^: [^abcd] matches anything except “a”, “b”, “c”, or “d”. We can use this idea to find the words containing an “x” surrounded by vowels, or a “y” surrounded by consonants:\n\nstr_view(words, \"[aeiou]x[aeiou]\")\n#&gt; [284] │ &lt;exa&gt;ct\n#&gt; [285] │ &lt;exa&gt;mple\n#&gt; [288] │ &lt;exe&gt;rcise\n#&gt; [289] │ &lt;exi&gt;st\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n#&gt; [836] │ &lt;sys&gt;tem\n#&gt; [901] │ &lt;typ&gt;e\n\nYou can use alternation, |, to pick between one or more alternative patterns. For example, the following patterns look for fruits containing “apple”, “melon”, or “nut”, or a repeated vowel.\n\nstr_view(fruit, \"apple|melon|nut\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [13] │ canary &lt;melon&gt;\n#&gt; [20] │ coco&lt;nut&gt;\n#&gt; [52] │ &lt;nut&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [72] │ rock &lt;melon&gt;\n#&gt; ... and 1 more\nstr_view(fruit, \"aa|ee|ii|oo|uu\")\n#&gt;  [9] │ bl&lt;oo&gt;d orange\n#&gt; [33] │ g&lt;oo&gt;seberry\n#&gt; [47] │ lych&lt;ee&gt;\n#&gt; [66] │ purple mangost&lt;ee&gt;n\n\nRegular expressions are very compact and use a lot of punctuation characters, so they can seem overwhelming and hard to read at first. Don’t worry; you’ll get better with practice, and simple patterns will soon become second nature. Let’s kick off that process by practicing with some useful stringr functions.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-stringr-regex-funs",
    "href": "regexps.html#sec-stringr-regex-funs",
    "title": "15  Regular expressions",
    "section": "\n15.3 Key functions",
    "text": "15.3 Key functions\nNow that you’ve got the basics of regular expressions under your belt, let’s use them with some stringr and tidyr functions. In the following section, you’ll learn how to detect the presence or absence of a match, how to count the number of matches, how to replace a match with fixed text, and how to extract text using a pattern.\n\n15.3.1 Detect matches\nstr_detect() returns a logical vector that is TRUE if the pattern matches an element of the character vector and FALSE otherwise:\n\nstr_detect(c(\"a\", \"b\", \"c\"), \"[aeiou]\")\n#&gt; [1]  TRUE FALSE FALSE\n\nSince str_detect() returns a logical vector of the same length as the initial vector, it pairs well with filter(). For example, this code finds all the most popular names containing a lower-case “x”:\n\nbabynames |&gt; \n  filter(str_detect(name, \"x\")) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 974 × 2\n#&gt;   name           n\n#&gt;   &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 Alexander 665492\n#&gt; 2 Alexis    399551\n#&gt; 3 Alex      278705\n#&gt; 4 Alexandra 232223\n#&gt; 5 Max       148787\n#&gt; 6 Alexa     123032\n#&gt; # ℹ 968 more rows\n\nWe can also use str_detect() with summarize() by pairing it with sum() or mean(): sum(str_detect(x, pattern)) tells you the number of observations that match and mean(str_detect(x, pattern)) tells you the proportion that match. For example, the following snippet computes and visualizes the proportion of baby names4 that contain “x”, broken down by year. It looks like they’ve radically increased in popularity lately!\n\nbabynames |&gt; \n  group_by(year) |&gt; \n  summarize(prop_x = mean(str_detect(name, \"x\"))) |&gt; \n  ggplot(aes(x = year, y = prop_x)) + \n  geom_line()\n\n\n\n\n\n\n\nThere are two functions that are closely related to str_detect(): str_subset() and str_which(). str_subset() returns a character vector containing only the strings that match. str_which() returns an integer vector giving the positions of the strings that match.\n\n15.3.2 Count matches\nThe next step up in complexity from str_detect() is str_count(): rather than a true or false, it tells you how many matches there are in each string.\n\nx &lt;- c(\"apple\", \"banana\", \"pear\")\nstr_count(x, \"p\")\n#&gt; [1] 2 0 1\n\nNote that each match starts at the end of the previous match, i.e. regex matches never overlap. For example, in \"abababa\", how many times will the pattern \"aba\" match? Regular expressions say two, not three:\n\nstr_count(\"abababa\", \"aba\")\n#&gt; [1] 2\nstr_view(\"abababa\", \"aba\")\n#&gt; [1] │ &lt;aba&gt;b&lt;aba&gt;\n\nIt’s natural to use str_count() with mutate(). The following example uses str_count() with character classes to count the number of vowels and consonants in each name.\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 Aaban        10      2          3\n#&gt; 2 Aabha         5      2          3\n#&gt; 3 Aabid         2      2          3\n#&gt; 4 Aabir         1      2          3\n#&gt; 5 Aabriella     5      4          5\n#&gt; 6 Aada          1      2          2\n#&gt; # ℹ 97,304 more rows\n\nIf you look closely, you’ll notice that there’s something off with our calculations: “Aaban” contains three “a”s, but our summary reports only two vowels. That’s because regular expressions are case sensitive. There are three ways we could fix this:\n\nAdd the upper case vowels to the character class: str_count(name, \"[aeiouAEIOU]\").\nTell the regular expression to ignore case: str_count(name, regex(\"[aeiou]\", ignore_case = TRUE)). We’ll talk about more in Seção 15.5.1.\nUse str_to_lower() to convert the names to lower case: str_count(str_to_lower(name), \"[aeiou]\").\n\nThis variety of approaches is pretty typical when working with strings — there are often multiple ways to reach your goal, either by making your pattern more complicated or by doing some preprocessing on your string. If you get stuck trying one approach, it can often be useful to switch gears and tackle the problem from a different perspective.\nIn this case, since we’re applying two functions to the name, I think it’s easier to transform it first:\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    name = str_to_lower(name),\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 aaban        10      3          2\n#&gt; 2 aabha         5      3          2\n#&gt; 3 aabid         2      3          2\n#&gt; 4 aabir         1      3          2\n#&gt; 5 aabriella     5      5          4\n#&gt; 6 aada          1      3          1\n#&gt; # ℹ 97,304 more rows\n\n\n15.3.3 Replace values\nAs well as detecting and counting matches, we can also modify them with str_replace() and str_replace_all(). str_replace() replaces the first match, and as the name suggests, str_replace_all() replaces all matches.\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_replace_all(x, \"[aeiou]\", \"-\")\n#&gt; [1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\n\nstr_remove() and str_remove_all() are handy shortcuts for str_replace(x, pattern, \"\"):\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_remove_all(x, \"[aeiou]\")\n#&gt; [1] \"ppl\" \"pr\"  \"bnn\"\n\nThese functions are naturally paired with mutate() when doing data cleaning, and you’ll often apply them repeatedly to peel off layers of inconsistent formatting.\n\n15.3.4 Extract variables\nThe last function we’ll discuss uses regular expressions to extract data out of one column into one or more new columns: separate_wider_regex(). It’s a peer of the separate_wider_position() and separate_wider_delim() functions that you learned about in Seção 14.4.2. These functions live in tidyr because they operate on (columns of) data frames, rather than individual vectors.\nLet’s create a simple dataset to show how it works. Here we have some data derived from babynames where we have the name, gender, and age of a bunch of people in a rather weird format5:\n\ndf &lt;- tribble(\n  ~str,\n  \"&lt;Sheryl&gt;-F_34\",\n  \"&lt;Kisha&gt;-F_45\", \n  \"&lt;Brandon&gt;-N_33\",\n  \"&lt;Sharon&gt;-F_38\", \n  \"&lt;Penny&gt;-F_58\",\n  \"&lt;Justin&gt;-M_41\", \n  \"&lt;Patricia&gt;-F_84\", \n)\n\nTo extract this data using separate_wider_regex() we just need to construct a sequence of regular expressions that match each piece. If we want the contents of that piece to appear in the output, we give it a name:\n\ndf |&gt; \n  separate_wider_regex(\n    str,\n    patterns = c(\n      \"&lt;\", \n      name = \"[A-Za-z]+\", \n      \"&gt;-\", \n      gender = \".\",\n      \"_\",\n      age = \"[0-9]+\"\n    )\n  )\n#&gt; # A tibble: 7 × 3\n#&gt;   name    gender age  \n#&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 Sheryl  F      34   \n#&gt; 2 Kisha   F      45   \n#&gt; 3 Brandon N      33   \n#&gt; 4 Sharon  F      38   \n#&gt; 5 Penny   F      58   \n#&gt; 6 Justin  M      41   \n#&gt; # ℹ 1 more row\n\nIf the match fails, you can use too_short = \"debug\" to figure out what went wrong, just like separate_wider_delim() and separate_wider_position().\n\n15.3.5 Exercises\n\nWhat baby name has the most vowels? What name has the highest proportion of vowels? (Hint: what is the denominator?)\nReplace all forward slashes in \"a/b/c/d/e\" with backslashes. What happens if you attempt to undo the transformation by replacing all backslashes with forward slashes? (We’ll discuss the problem very soon.)\nImplement a simple version of str_to_lower() using str_replace_all().\nCreate a regular expression that will match telephone numbers as commonly written in your country.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#pattern-details",
    "href": "regexps.html#pattern-details",
    "title": "15  Regular expressions",
    "section": "\n15.4 Pattern details",
    "text": "15.4 Pattern details\nNow that you understand the basics of the pattern language and how to use it with some stringr and tidyr functions, it’s time to dig into more of the details. First, we’ll start with escaping, which allows you to match metacharacters that would otherwise be treated specially. Next, you’ll learn about anchors which allow you to match the start or end of the string. Then, you’ll learn more about character classes and their shortcuts which allow you to match any character from a set. Next, you’ll learn the final details of quantifiers which control how many times a pattern can match. Then, we have to cover the important (but complex) topic of operator precedence and parentheses. And we’ll finish off with some details of grouping components of the pattern.\nThe terms we use here are the technical names for each component. They’re not always the most evocative of their purpose, but it’s very helpful to know the correct terms if you later want to Google for more details.\n\n15.4.1 Escaping\nIn order to match a literal ., you need an escape which tells the regular expression to match metacharacters6 literally. Like strings, regexps use the backslash for escaping. So, to match a ., you need the regexp \\.. Unfortunately this creates a problem. We use strings to represent regular expressions, and \\ is also used as an escape symbol in strings. So to create the regular expression \\. we need the string \"\\\\.\", as the following example shows.\n\n# To create the regular expression \\., we need to use \\\\.\ndot &lt;- \"\\\\.\"\n\n# But the expression itself only contains one \\\nstr_view(dot)\n#&gt; [1] │ \\.\n\n# And this tells R to look for an explicit .\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n#&gt; [2] │ &lt;a.c&gt;\n\nIn this book, we’ll usually write regular expression without quotes, like \\.. If we need to emphasize what you’ll actually type, we’ll surround it with quotes and add extra escapes, like \"\\\\.\".\nIf \\ is used as an escape character in regular expressions, how do you match a literal \\? Well, you need to escape it, creating the regular expression \\\\. To create that regular expression, you need to use a string, which also needs to escape \\. That means to match a literal \\ you need to write \"\\\\\\\\\" — you need four backslashes to match one!\n\nx &lt;- \"a\\\\b\"\nstr_view(x)\n#&gt; [1] │ a\\b\nstr_view(x, \"\\\\\\\\\")\n#&gt; [1] │ a&lt;\\&gt;b\n\nAlternatively, you might find it easier to use the raw strings you learned about in Seção 14.2.2). That lets you avoid one layer of escaping:\n\nstr_view(x, r\"{\\\\}\")\n#&gt; [1] │ a&lt;\\&gt;b\n\nIf you’re trying to match a literal ., $, |, *, +, ?, {, }, (, ), there’s an alternative to using a backslash escape: you can use a character class: [.], [$], [|], ... all match the literal values.\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n#&gt; [2] │ &lt;a.c&gt;\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n#&gt; [3] │ &lt;a*c&gt;\n\n\n15.4.2 Anchors\nBy default, regular expressions will match any part of a string. If you want to match at the start or end you need to anchor the regular expression using ^ to match the start or $ to match the end:\n\nstr_view(fruit, \"^a\")\n#&gt; [1] │ &lt;a&gt;pple\n#&gt; [2] │ &lt;a&gt;pricot\n#&gt; [3] │ &lt;a&gt;vocado\nstr_view(fruit, \"a$\")\n#&gt;  [4] │ banan&lt;a&gt;\n#&gt; [15] │ cherimoy&lt;a&gt;\n#&gt; [30] │ feijo&lt;a&gt;\n#&gt; [36] │ guav&lt;a&gt;\n#&gt; [56] │ papay&lt;a&gt;\n#&gt; [74] │ satsum&lt;a&gt;\n\nIt’s tempting to think that $ should match the start of a string, because that’s how we write dollar amounts, but that’s not what regular expressions want.\nTo force a regular expression to match only the full string, anchor it with both ^ and $:\n\nstr_view(fruit, \"apple\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [62] │ pine&lt;apple&gt;\nstr_view(fruit, \"^apple$\")\n#&gt; [1] │ &lt;apple&gt;\n\nYou can also match the boundary between words (i.e. the start or end of a word) with \\b. This can be particularly useful when using RStudio’s find and replace tool. For example, if to find all uses of sum(), you can search for \\bsum\\b to avoid matching summarize, summary, rowsum and so on:\n\nx &lt;- c(\"summary(x)\", \"summarize(df)\", \"rowsum(x)\", \"sum(x)\")\nstr_view(x, \"sum\")\n#&gt; [1] │ &lt;sum&gt;mary(x)\n#&gt; [2] │ &lt;sum&gt;marize(df)\n#&gt; [3] │ row&lt;sum&gt;(x)\n#&gt; [4] │ &lt;sum&gt;(x)\nstr_view(x, \"\\\\bsum\\\\b\")\n#&gt; [4] │ &lt;sum&gt;(x)\n\nWhen used alone, anchors will produce a zero-width match:\n\nstr_view(\"abc\", c(\"$\", \"^\", \"\\\\b\"))\n#&gt; [1] │ abc&lt;&gt;\n#&gt; [2] │ &lt;&gt;abc\n#&gt; [3] │ &lt;&gt;abc&lt;&gt;\n\nThis helps you understand what happens when you replace a standalone anchor:\n\nstr_replace_all(\"abc\", c(\"$\", \"^\", \"\\\\b\"), \"--\")\n#&gt; [1] \"abc--\"   \"--abc\"   \"--abc--\"\n\n\n15.4.3 Character classes\nA character class, or character set, allows you to match any character in a set. As we discussed above, you can construct your own sets with [], where [abc] matches “a”, “b”, or “c” and [^abc] matches any character except “a”, “b”, or “c”. Apart from ^ there are two other characters that have special meaning inside of []:\n\n\n- defines a range, e.g., [a-z] matches any lower case letter and [0-9] matches any number.\n\n\\ escapes special characters, so [\\^\\-\\]] matches ^, -, or ].\n\nHere are few examples:\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"[abc]+\")\n#&gt; [1] │ &lt;abc&gt;d ABCD 12345 -!@#%.\nstr_view(x, \"[a-z]+\")\n#&gt; [1] │ &lt;abcd&gt; ABCD 12345 -!@#%.\nstr_view(x, \"[^a-z0-9]+\")\n#&gt; [1] │ abcd&lt; ABCD &gt;12345&lt; -!@#%.&gt;\n\n# You need an escape to match characters that are otherwise\n# special inside of []\nstr_view(\"a-b-c\", \"[a-c]\")\n#&gt; [1] │ &lt;a&gt;-&lt;b&gt;-&lt;c&gt;\nstr_view(\"a-b-c\", \"[a\\\\-c]\")\n#&gt; [1] │ &lt;a&gt;&lt;-&gt;b&lt;-&gt;&lt;c&gt;\n\nSome character classes are used so commonly that they get their own shortcut. You’ve already seen ., which matches any character apart from a newline. There are three other particularly useful pairs7:\n\n\n\\d matches any digit;\\D matches anything that isn’t a digit.\n\n\\s matches any whitespace (e.g., space, tab, newline);\\S matches anything that isn’t whitespace.\n\n\\w matches any “word” character, i.e. letters and numbers;\\W matches any “non-word” character.\n\nThe following code demonstrates the six shortcuts with a selection of letters, numbers, and punctuation characters.\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"\\\\d+\")\n#&gt; [1] │ abcd ABCD &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\D+\")\n#&gt; [1] │ &lt;abcd ABCD &gt;12345&lt; -!@#%.&gt;\nstr_view(x, \"\\\\s+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; &gt;-!@#%.\nstr_view(x, \"\\\\S+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; &lt;-!@#%.&gt;\nstr_view(x, \"\\\\w+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\W+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; -!@#%.&gt;\n\n\n15.4.4 Quantifiers\nQuantifiers control how many times a pattern matches. In Seção 15.2 you learned about ? (0 or 1 matches), + (1 or more matches), and * (0 or more matches). For example, colou?r will match American or British spelling, \\d+ will match one or more digits, and \\s? will optionally match a single item of whitespace. You can also specify the number of matches precisely with {}:\n\n\n{n} matches exactly n times.\n\n{n,} matches at least n times.\n\n{n,m} matches between n and m times.\n\n15.4.5 Operator precedence and parentheses\nWhat does ab+ match? Does it match “a” followed by one or more “b”s, or does it match “ab” repeated any number of times? What does ^a|b$ match? Does it match the complete string a or the complete string b, or does it match a string starting with a or a string ending with b?\nThe answer to these questions is determined by operator precedence, similar to the PEMDAS or BEDMAS rules you might have learned in school. You know that a + b * c is equivalent to a + (b * c) not (a + b) * c because * has higher precedence and + has lower precedence: you compute * before +.\nSimilarly, regular expressions have their own precedence rules: quantifiers have high precedence and alternation has low precedence which means that ab+ is equivalent to a(b+), and ^a|b$ is equivalent to (^a)|(b$). Just like with algebra, you can use parentheses to override the usual order. But unlike algebra you’re unlikely to remember the precedence rules for regexes, so feel free to use parentheses liberally.\n\n15.4.6 Grouping and capturing\nAs well as overriding operator precedence, parentheses have another important effect: they create capturing groups that allow you to use sub-components of the match.\nThe first way to use a capturing group is to refer back to it within a match with back reference: \\1 refers to the match contained in the first parenthesis, \\2 in the second parenthesis, and so on. For example, the following pattern finds all fruits that have a repeated pair of letters:\n\nstr_view(fruit, \"(..)\\\\1\")\n#&gt;  [4] │ b&lt;anan&gt;a\n#&gt; [20] │ &lt;coco&gt;nut\n#&gt; [22] │ &lt;cucu&gt;mber\n#&gt; [41] │ &lt;juju&gt;be\n#&gt; [56] │ &lt;papa&gt;ya\n#&gt; [73] │ s&lt;alal&gt; berry\n\nAnd this one finds all words that start and end with the same pair of letters:\n\nstr_view(words, \"^(..).*\\\\1$\")\n#&gt; [152] │ &lt;church&gt;\n#&gt; [217] │ &lt;decide&gt;\n#&gt; [617] │ &lt;photograph&gt;\n#&gt; [699] │ &lt;require&gt;\n#&gt; [739] │ &lt;sense&gt;\n\nYou can also use back references in str_replace(). For example, this code switches the order of the second and third words in sentences:\n\nsentences |&gt; \n  str_replace(\"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\1 \\\\3 \\\\2\") |&gt; \n  str_view()\n#&gt; [1] │ The canoe birch slid on the smooth planks.\n#&gt; [2] │ Glue sheet the to the dark blue background.\n#&gt; [3] │ It's to easy tell the depth of a well.\n#&gt; [4] │ These a days chicken leg is a rare dish.\n#&gt; [5] │ Rice often is served in round bowls.\n#&gt; [6] │ The of juice lemons makes fine punch.\n#&gt; ... and 714 more\n\nIf you want to extract the matches for each group you can use str_match(). But str_match() returns a matrix, so it’s not particularly easy to work with8:\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  head()\n#&gt;      [,1]                [,2]     [,3]    \n#&gt; [1,] \"the smooth planks\" \"smooth\" \"planks\"\n#&gt; [2,] \"the sheet to\"      \"sheet\"  \"to\"    \n#&gt; [3,] \"the depth of\"      \"depth\"  \"of\"    \n#&gt; [4,] NA                  NA       NA      \n#&gt; [5,] NA                  NA       NA      \n#&gt; [6,] NA                  NA       NA\n\nYou could convert to a tibble and name the columns:\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  as_tibble(.name_repair = \"minimal\") |&gt; \n  set_names(\"match\", \"word1\", \"word2\")\n#&gt; # A tibble: 720 × 3\n#&gt;   match             word1  word2 \n#&gt;   &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 the smooth planks smooth planks\n#&gt; 2 the sheet to      sheet  to    \n#&gt; 3 the depth of      depth  of    \n#&gt; 4 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 5 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 6 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; # ℹ 714 more rows\n\nBut then you’ve basically recreated your own version of separate_wider_regex(). Indeed, behind the scenes, separate_wider_regex() converts your vector of patterns to a single regex that uses grouping to capture the named components.\nOccasionally, you’ll want to use parentheses without creating matching groups. You can create a non-capturing group with (?:).\n\nx &lt;- c(\"a gray cat\", \"a grey dog\")\nstr_match(x, \"gr(e|a)y\")\n#&gt;      [,1]   [,2]\n#&gt; [1,] \"gray\" \"a\" \n#&gt; [2,] \"grey\" \"e\"\nstr_match(x, \"gr(?:e|a)y\")\n#&gt;      [,1]  \n#&gt; [1,] \"gray\"\n#&gt; [2,] \"grey\"\n\n\n15.4.7 Exercises\n\nHow would you match the literal string \"'\\? How about \"$^$\"?\nExplain why each of these patterns don’t match a \\: \"\\\", \"\\\\\", \"\\\\\\\".\n\nGiven the corpus of common words in stringr::words, create regular expressions that find all words that:\n\nStart with “y”.\nDon’t start with “y”.\nEnd with “x”.\nAre exactly three letters long. (Don’t cheat by using str_length()!)\nHave seven letters or more.\nContain a vowel-consonant pair.\nContain at least two vowel-consonant pairs in a row.\nOnly consist of repeated vowel-consonant pairs.\n\n\nCreate 11 regular expressions that match the British or American spellings for each of the following words: airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise. Try and make the shortest possible regex!\nSwitch the first and last letters in words. Which of those strings are still words?\n\nDescribe in words what these regular expressions match: (read carefully to see if each entry is a regular expression or a string that defines a regular expression.)\n\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\n\\..\\..\\..\n(.)\\1\\1\n\"(..)\\\\1\"\n\n\nSolve the beginner regexp crosswords at https://regexcrossword.com/challenges/beginner.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#pattern-control",
    "href": "regexps.html#pattern-control",
    "title": "15  Regular expressions",
    "section": "\n15.5 Pattern control",
    "text": "15.5 Pattern control\nIt’s possible to exercise extra control over the details of the match by using a pattern object instead of just a string. This allows you to control the so called regex flags and match various types of fixed strings, as described below.\n\n15.5.1 Regex flags\nThere are a number of settings that can be used to control the details of the regexp. These settings are often called flags in other programming languages. In stringr, you can use these by wrapping the pattern in a call to regex(). The most useful flag is probably ignore_case = TRUE because it allows characters to match either their uppercase or lowercase forms:\n\nbananas &lt;- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#&gt; [1] │ &lt;banana&gt;\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#&gt; [1] │ &lt;banana&gt;\n#&gt; [2] │ &lt;Banana&gt;\n#&gt; [3] │ &lt;BANANA&gt;\n\nIf you’re doing a lot of work with multiline strings (i.e. strings that contain \\n), dotalland multiline may also be useful:\n\n\ndotall = TRUE lets . match everything, including \\n:\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \".Line\")\nstr_view(x, regex(\".Line\", dotall = TRUE))\n#&gt; [1] │ Line 1&lt;\n#&gt;     │ Line&gt; 2&lt;\n#&gt;     │ Line&gt; 3\n\n\n\nmultiline = TRUE makes ^ and $ match the start and end of each line rather than the start and end of the complete string:\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \"^Line\")\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ Line 2\n#&gt;     │ Line 3\nstr_view(x, regex(\"^Line\", multiline = TRUE))\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ &lt;Line&gt; 2\n#&gt;     │ &lt;Line&gt; 3\n\n\n\nFinally, if you’re writing a complicated regular expression and you’re worried you might not understand it in the future, you might try comments = TRUE. It tweaks the pattern language to ignore spaces and new lines, as well as everything after #. This allows you to use comments and whitespace to make complex regular expressions more understandable9, as in the following example:\n\nphone &lt;- regex(\n  r\"(\n    \\(?     # optional opening parens\n    (\\d{3}) # area code\n    [)\\-]?  # optional closing parens or dash\n    \\ ?     # optional space\n    (\\d{3}) # another three numbers\n    [\\ -]?  # optional space or dash\n    (\\d{4}) # four more numbers\n  )\", \n  comments = TRUE\n)\n\nstr_extract(c(\"514-791-8141\", \"(123) 456 7890\", \"123456\"), phone)\n#&gt; [1] \"514-791-8141\"   \"(123) 456 7890\" NA\n\nIf you’re using comments and want to match a space, newline, or #, you’ll need to escape it with \\.\n\n15.5.2 Fixed matches\nYou can opt-out of the regular expression rules by using fixed():\n\nstr_view(c(\"\", \"a\", \".\"), fixed(\".\"))\n#&gt; [3] │ &lt;.&gt;\n\nfixed() also gives you the ability to ignore case:\n\nstr_view(\"x X\", \"X\")\n#&gt; [1] │ x &lt;X&gt;\nstr_view(\"x X\", fixed(\"X\", ignore_case = TRUE))\n#&gt; [1] │ &lt;x&gt; &lt;X&gt;\n\nIf you’re working with non-English text, you will probably want coll() instead of fixed(), as it implements the full rules for capitalization as used by the locale you specify. See Seção 14.6 for more details on locales.\n\nstr_view(\"i İ ı I\", fixed(\"İ\", ignore_case = TRUE))\n#&gt; [1] │ i &lt;İ&gt; ı I\nstr_view(\"i İ ı I\", coll(\"İ\", ignore_case = TRUE, locale = \"tr\"))\n#&gt; [1] │ &lt;i&gt; &lt;İ&gt; ı I",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#practice",
    "href": "regexps.html#practice",
    "title": "15  Regular expressions",
    "section": "\n15.6 Practice",
    "text": "15.6 Practice\nTo put these ideas into practice we’ll solve a few semi-authentic problems next. We’ll discuss three general techniques:\n\nchecking your work by creating simple positive and negative controls\ncombining regular expressions with Boolean algebra\ncreating complex patterns using string manipulation\n\n\n15.6.1 Check your work\nFirst, let’s find all sentences that start with “The”. Using the ^ anchor alone is not enough:\n\nstr_view(sentences, \"^The\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [4] │ &lt;The&gt;se days a chicken leg is a rare dish.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; ... and 271 more\n\nBecause that pattern also matches sentences starting with words like They or These. We need to make sure that the “e” is the last letter in the word, which we can do by adding a word boundary:\n\nstr_view(sentences, \"^The\\\\b\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; [13] │ &lt;The&gt; source of the huge river is the clear spring.\n#&gt; ... and 250 more\n\nWhat about finding all sentences that begin with a pronoun?\n\nstr_view(sentences, \"^She|He|It|They\\\\b\")\n#&gt;  [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt; [15] │ &lt;He&gt;lp the woman get back to her feet.\n#&gt; [27] │ &lt;He&gt;r purse was full of useless trash.\n#&gt; [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt; [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt; [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; ... and 57 more\n\nA quick inspection of the results shows that we’re getting some spurious matches. That’s because we’ve forgotten to use parentheses:\n\nstr_view(sentences, \"^(She|He|It|They)\\\\b\")\n#&gt;   [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt;  [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt;  [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt;  [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; [116] │ &lt;He&gt; ordered peach pie with ice cream.\n#&gt; [127] │ &lt;It&gt; caught its hind paw in a rusty trap.\n#&gt; ... and 51 more\n\nYou might wonder how you might spot such a mistake if it didn’t occur in the first few matches. A good technique is to create a few positive and negative matches and use them to test that your pattern works as expected:\n\npos &lt;- c(\"He is a boy\", \"She had a good time\")\nneg &lt;- c(\"Shells come from the sea\", \"Hadley said 'It's a great day'\")\n\npattern &lt;- \"^(She|He|It|They)\\\\b\"\nstr_detect(pos, pattern)\n#&gt; [1] TRUE TRUE\nstr_detect(neg, pattern)\n#&gt; [1] FALSE FALSE\n\nIt’s typically much easier to come up with good positive examples than negative examples, because it takes a while before you’re good enough with regular expressions to predict where your weaknesses are. Nevertheless, they’re still useful: as you work on the problem you can slowly accumulate a collection of your mistakes, ensuring that you never make the same mistake twice.\n\n15.6.2 Boolean operations\nImagine we want to find words that only contain consonants. One technique is to create a character class that contains all letters except for the vowels ([^aeiou]), then allow that to match any number of letters ([^aeiou]+), then force it to match the whole string by anchoring to the beginning and the end (^[^aeiou]+$):\n\nstr_view(words, \"^[^aeiou]+$\")\n#&gt; [123] │ &lt;by&gt;\n#&gt; [249] │ &lt;dry&gt;\n#&gt; [328] │ &lt;fly&gt;\n#&gt; [538] │ &lt;mrs&gt;\n#&gt; [895] │ &lt;try&gt;\n#&gt; [952] │ &lt;why&gt;\n\nBut you can make this problem a bit easier by flipping the problem around. Instead of looking for words that contain only consonants, we could look for words that don’t contain any vowels:\n\nstr_view(words[!str_detect(words, \"[aeiou]\")])\n#&gt; [1] │ by\n#&gt; [2] │ dry\n#&gt; [3] │ fly\n#&gt; [4] │ mrs\n#&gt; [5] │ try\n#&gt; [6] │ why\n\nThis is a useful technique whenever you’re dealing with logical combinations, particularly those involving “and” or “not”. For example, imagine if you want to find all words that contain “a” and “b”. There’s no “and” operator built in to regular expressions so we have to tackle it by looking for all words that contain an “a” followed by a “b”, or a “b” followed by an “a”:\n\nstr_view(words, \"a.*b|b.*a\")\n#&gt;  [2] │ &lt;ab&gt;le\n#&gt;  [3] │ &lt;ab&gt;out\n#&gt;  [4] │ &lt;ab&gt;solute\n#&gt; [62] │ &lt;availab&gt;le\n#&gt; [66] │ &lt;ba&gt;by\n#&gt; [67] │ &lt;ba&gt;ck\n#&gt; ... and 24 more\n\nIt’s simpler to combine the results of two calls to str_detect():\n\nwords[str_detect(words, \"a\") & str_detect(words, \"b\")]\n#&gt;  [1] \"able\"      \"about\"     \"absolute\"  \"available\" \"baby\"      \"back\"     \n#&gt;  [7] \"bad\"       \"bag\"       \"balance\"   \"ball\"      \"bank\"      \"bar\"      \n#&gt; [13] \"base\"      \"basis\"     \"bear\"      \"beat\"      \"beauty\"    \"because\"  \n#&gt; [19] \"black\"     \"board\"     \"boat\"      \"break\"     \"brilliant\" \"britain\"  \n#&gt; [25] \"debate\"    \"husband\"   \"labour\"    \"maybe\"     \"probable\"  \"table\"\n\nWhat if we wanted to see if there was a word that contains all vowels? If we did it with patterns we’d need to generate 5! (120) different patterns:\n\nwords[str_detect(words, \"a.*e.*i.*o.*u\")]\n# ...\nwords[str_detect(words, \"u.*o.*i.*e.*a\")]\n\nIt’s much simpler to combine five calls to str_detect():\n\nwords[\n  str_detect(words, \"a\") &\n  str_detect(words, \"e\") &\n  str_detect(words, \"i\") &\n  str_detect(words, \"o\") &\n  str_detect(words, \"u\")\n]\n#&gt; character(0)\n\nIn general, if you get stuck trying to create a single regexp that solves your problem, take a step back and think if you could break the problem down into smaller pieces, solving each challenge before moving onto the next one.\n\n15.6.3 Creating a pattern with code\nWhat if we wanted to find all sentences that mention a color? The basic idea is simple: we just combine alternation with word boundaries.\n\nstr_view(sentences, \"\\\\b(red|green|blue)\\\\b\")\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [148] │ The spot on the blotter was made by &lt;green&gt; ink.\n#&gt; [160] │ The sofa cushion is &lt;red&gt; and of light weight.\n#&gt; [174] │ The sky that morning was clear and bright &lt;blue&gt;.\n#&gt; ... and 20 more\n\nBut as the number of colors grows, it would quickly get tedious to construct this pattern by hand. Wouldn’t it be nice if we could store the colors in a vector?\n\nrgb &lt;- c(\"red\", \"green\", \"blue\")\n\nWell, we can! We’d just need to create the pattern from the vector using str_c() and str_flatten():\n\nstr_c(\"\\\\b(\", str_flatten(rgb, \"|\"), \")\\\\b\")\n#&gt; [1] \"\\\\b(red|green|blue)\\\\b\"\n\nWe could make this pattern more comprehensive if we had a good list of colors. One place we could start from is the list of built-in colors that R can use for plots:\n\nstr_view(colors())\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ antiquewhite1\n#&gt; [5] │ antiquewhite2\n#&gt; [6] │ antiquewhite3\n#&gt; ... and 651 more\n\nBut lets first eliminate the numbered variants:\n\ncols &lt;- colors()\ncols &lt;- cols[!str_detect(cols, \"\\\\d\")]\nstr_view(cols)\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ aquamarine\n#&gt; [5] │ azure\n#&gt; [6] │ beige\n#&gt; ... and 137 more\n\nThen we can turn this into one giant pattern. We won’t show the pattern here because it’s huge, but you can see it working:\n\npattern &lt;- str_c(\"\\\\b(\", str_flatten(cols, \"|\"), \")\\\\b\")\nstr_view(sentences, pattern)\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [12] │ A rod is used to catch &lt;pink&gt; &lt;salmon&gt;.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [66] │ Cars and busses stalled in &lt;snow&gt; drifts.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [112] │ Leaves turn &lt;brown&gt; and &lt;yellow&gt; in the fall.\n#&gt; ... and 57 more\n\nIn this example, cols only contains numbers and letters so you don’t need to worry about metacharacters. But in general, whenever you create patterns from existing strings it’s wise to run them through str_escape() to ensure they match literally.\n\n15.6.4 Exercises\n\n\nFor each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple str_detect() calls.\n\nFind all words that start or end with x.\nFind all words that start with a vowel and end with a consonant.\nAre there any words that contain at least one of each different vowel?\n\n\nConstruct patterns to find evidence for and against the rule “i before e except after c”?\ncolors() contains a number of modifiers like “lightgray” and “darkblue”. How could you automatically identify these modifiers? (Think about how you might detect and then remove the colors that are modified).\nCreate a regular expression that finds any base R dataset. You can get a list of these datasets via a special use of the data() function: data(package = \"datasets\")$results[, \"Item\"]. Note that a number of old datasets are individual vectors; these contain the name of the grouping “data frame” in parentheses, so you’ll need to strip those off.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#regular-expressions-in-other-places",
    "href": "regexps.html#regular-expressions-in-other-places",
    "title": "15  Regular expressions",
    "section": "\n15.7 Regular expressions in other places",
    "text": "15.7 Regular expressions in other places\nJust like in the stringr and tidyr functions, there are many other places in R where you can use regular expressions. The following sections describe some other useful functions in the wider tidyverse and base R.\n\n15.7.1 tidyverse\nThere are three other particularly useful places where you might want to use a regular expressions\n\nmatches(pattern) will select all variables whose name matches the supplied pattern. It’s a “tidyselect” function that you can use anywhere in any tidyverse function that selects variables (e.g., select(), rename_with() and across()).\npivot_longer()'s names_pattern argument takes a vector of regular expressions, just like separate_wider_regex(). It’s useful when extracting data out of variable names with a complex structure\nThe delim argument in separate_longer_delim() and separate_wider_delim() usually matches a fixed string, but you can use regex() to make it match a pattern. This is useful, for example, if you want to match a comma that is optionally followed by a space, i.e. regex(\", ?\").\n\n15.7.2 Base R\napropos(pattern) searches all objects available from the global environment that match the given pattern. This is useful if you can’t quite remember the name of a function:\n\napropos(\"replace\")\n#&gt; [1] \"%+replace%\"       \"replace\"          \"replace_na\"      \n#&gt; [4] \"setReplaceMethod\" \"str_replace\"      \"str_replace_all\" \n#&gt; [7] \"str_replace_na\"   \"theme_replace\"\n\nlist.files(path, pattern) lists all files in path that match a regular expression pattern. For example, you can find all the R Markdown files in the current directory with:\n\nhead(list.files(pattern = \"\\\\.Rmd$\"))\n#&gt; character(0)\n\nIt’s worth noting that the pattern language used by base R is very slightly different to that used by stringr. That’s because stringr is built on top of the stringi package, which is in turn built on top of the ICU engine, whereas base R functions use either the TRE engine or the PCRE engine, depending on whether or not you’ve set perl = TRUE. Fortunately, the basics of regular expressions are so well established that you’ll encounter few variations when working with the patterns you’ll learn in this book. You only need to be aware of the difference when you start to rely on advanced features like complex Unicode character ranges or special features that use the (?…) syntax.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#summary",
    "href": "regexps.html#summary",
    "title": "15  Regular expressions",
    "section": "\n15.8 Summary",
    "text": "15.8 Summary\nWith every punctuation character potentially overloaded with meaning, regular expressions are one of the most compact languages out there. They’re definitely confusing at first but as you train your eyes to read them and your brain to understand them, you unlock a powerful skill that you can use in R and in many other places.\nIn this chapter, you’ve started your journey to become a regular expression master by learning the most useful stringr functions and the most important components of the regular expression language. And there are plenty of resources to learn more.\nA good place to start is vignette(\"regular-expressions\", package = \"stringr\"): it documents the full set of syntax supported by stringr. Another useful reference is https://www.regular-expressions.info/. It’s not R specific, but you can use it to learn about the most advanced features of regexes and how they work under the hood.\nIt’s also good to know that stringr is implemented on top of the stringi package by Marek Gagolewski. If you’re struggling to find a function that does what you need in stringr, don’t be afraid to look in stringi. You’ll find stringi very easy to pick up because it follows many of the the same conventions as stringr.\nIn the next chapter, we’ll talk about a data structure closely related to strings: factors. Factors are used to represent categorical data in R, i.e. data with a fixed and known set of possible values identified by a vector of strings.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "regexps.html#footnotes",
    "href": "regexps.html#footnotes",
    "title": "15  Regular expressions",
    "section": "",
    "text": "You can pronounce it with either a hard-g (reg-x) or a soft-g (rej-x).↩︎\nYou’ll learn how to escape these special meanings in Seção 15.4.1.↩︎\nWell, any character apart from \\n.↩︎\nThis gives us the proportion of names that contain an “x”; if you wanted the proportion of babies with a name containing an x, you’d need to perform a weighted mean.↩︎\nWe wish we could reassure you that you’d never see something this weird in real life, but unfortunately over the course of your career you’re likely to see much weirder!↩︎\nThe complete set of metacharacters is .^$\\|*+?{}[]()↩︎\nRemember, to create a regular expression containing \\d or \\s, you’ll need to escape the \\ for the string, so you’ll type \"\\\\d\" or \"\\\\s\".↩︎\nMostly because we never discuss matrices in this book!↩︎\ncomments = TRUE is particularly effective in combination with a raw string, as we use here.↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "factors.html",
    "href": "factors.html",
    "title": "16  ✅ Fatores",
    "section": "",
    "text": "16.1 Introdução\nFatores (factors) são usados ​​para variáveis ​​categóricas, variáveis ​​que possuem um conjunto fixo e conhecido de valores possíveis. Eles também são úteis quando você deseja exibir vetores de caracteres em ordem não alfabética.\nComeçaremos motivando a necessidade de fatores para a análise de dados1 e como você pode criá-los com a função factor(). Em seguida, apresentaremos o conjunto de dados questionario do pacote dados, que contém um monte de variáveis ​​​​categóricas para experimentarmos. Em seguida, você usará esse conjunto de dados para praticar a modificação da ordem e dos valores dos fatores, antes de terminarmos com uma discussão sobre fatores ordenados.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#introdução",
    "href": "factors.html#introdução",
    "title": "16  ✅ Fatores",
    "section": "",
    "text": "16.1.1 Pré-requisitos\nO R base fornece algumas ferramentas básicas para criar e manipular fatores. Iremos complementá-las com o pacote forcats, que é um integrante do tidyverse. Ele fornece ferramentas para lidar com variáveis ​​categóricas (e é um anagrama de fatores!) usando uma ampla gama de funções auxiliares para trabalhar com fatores.\n\nlibrary(tidyverse)\nlibrary(dados)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#o-básico-sobre-fatores",
    "href": "factors.html#o-básico-sobre-fatores",
    "title": "16  ✅ Fatores",
    "section": "\n16.2 O básico sobre fatores",
    "text": "16.2 O básico sobre fatores\nImagine que você tem uma variável que registra o mês:\n\nx1 &lt;- c(\"Dez\", \"Abr\", \"Jan\", \"Mar\")\n\nUsar uma string para registrar esta variável tem dois problemas:\n\n\nExistem apenas doze meses possíveis e não há nada que proteja você contra erros de digitação:\n\nx2 &lt;- c(\"Dez\", \"Abr\", \"Jam\", \"Mar\")\n\n\n\nNão ordena de maneira útil:\n\nsort(x1)\n#&gt; [1] \"Abr\" \"Dez\" \"Jan\" \"Mar\"\n\n\n\nVocê pode corrigir esses dois problemas com um fator. Para criar um fator você deve começar criando uma lista com níveis (levels) válidos:\n\nniveis_meses &lt;- c(\n  \"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\", \n  \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\"\n)\n\nAgora você pode criar o fator:\n\ny1 &lt;- factor(x1, levels = niveis_meses)\ny1\n#&gt; [1] Dez Abr Jan Mar\n#&gt; Levels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez\n\nsort(y1)\n#&gt; [1] Jan Mar Abr Dez\n#&gt; Levels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez\n\nE quaisquer valores que não estejam nos níveis serão convertidos silenciosamente para NA:\n\ny2 &lt;- factor(x2, levels = niveis_meses)\ny2\n#&gt; [1] Dez  Abr  &lt;NA&gt; Mar \n#&gt; Levels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez\n\nIsso parece arriscado, então você pode querer usar forcats::fct() em vez disso:\n\ny2 &lt;- fct(x2, levels = niveis_meses)\n#&gt; Error in `fct()`:\n#&gt; ! All values of `x` must appear in `levels` or `na`\n#&gt; ℹ Missing level: \"Jam\"\n\nSe você omitir os níveis, eles serão retirados dos dados em ordem alfabética:\n\nfactor(x1)\n#&gt; [1] Dez Abr Jan Mar\n#&gt; Levels: Abr Dez Jan Mar\n\nClassificar em ordem alfabética é um pouco arriscado porque nem todo computador classificará as strings da mesma maneira. Então forcats::fct() ordena pela primeira aparição:\n\nfct(x1)\n#&gt; [1] Dez Abr Jan Mar\n#&gt; Levels: Dez Abr Jan Mar\n\nSe você precisar acessar diretamente o conjunto de níveis válidos, poderá fazê-lo com levels():\n\nlevels(y2)\n#&gt;  [1] \"Jan\" \"Fev\" \"Mar\" \"Abr\" \"Mai\" \"Jun\" \"Jul\" \"Ago\" \"Set\" \"Out\" \"Nov\" \"Dez\"\n\nVocê também pode criar um fator ao ler seus dados com readr usando a col_factor():\n\ncsv &lt;- \"\nmes,valor\nJan,12\nFev,56\nMar,12\"\n\ndf &lt;- read_csv(csv, col_types = cols(mes = col_factor(niveis_meses)))\ndf$mes\n#&gt; [1] Jan Fev Mar\n#&gt; Levels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#questionário",
    "href": "factors.html#questionário",
    "title": "16  ✅ Fatores",
    "section": "\n16.3 Questionário",
    "text": "16.3 Questionário\nNo restante deste capítulo, usaremos dados::questionario. É uma amostra de dados da Pesquisa Social Geral, uma pesquisa de longa data nos EUA conduzida pela organização de pesquisa independente NORC da Universidade de Chicago. A pesquisa tem milhares de perguntas, então em questionario, Hadley selecionou algumas que ilustrarão alguns desafios comuns que você encontrará ao trabalhar com fatores.\n\nquestionario\n#&gt; # A tibble: 21,483 × 9\n#&gt;     ano estado_civil  idade raca   renda             partido                 \n#&gt;   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;             &lt;fct&gt;                   \n#&gt; 1  2000 Nunca casou      26 Branca US$ 8000 - 9999   Independente, inclinaçã…\n#&gt; 2  2000 Divorciado(a)    48 Branca US$ 8000 - 9999   Não fortemente repubica…\n#&gt; 3  2000 Viúvo(a)         67 Branca Não se aplica     Independente            \n#&gt; 4  2000 Nunca casou      39 Branca Não se aplica     Independente, inclinaçã…\n#&gt; 5  2000 Divorciado(a)    25 Branca Não se aplica     Não fortemente democrata\n#&gt; 6  2000 Casado(a)        25 Branca US$ 20000 - 24999 Fortemente democrata    \n#&gt; # ℹ 21,477 more rows\n#&gt; # ℹ 3 more variables: religiao &lt;fct&gt;, denominacao &lt;fct&gt;, horas_tv &lt;int&gt;\n\n(Lembre-se, como este conjunto de dados é fornecido por um pacote, você pode obter mais informações sobre as variáveis ​​com ?questionario.)\nQuando os fatores são armazenados em um tibble, você não consegue ver seus níveis tão facilmente. Uma maneira de visualizá-los é com count():\n\nquestionario |&gt;\n  count(raca)\n#&gt; # A tibble: 3 × 2\n#&gt;   raca       n\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 Outra   1959\n#&gt; 2 Negra   3129\n#&gt; 3 Branca 16395\n\nAo trabalhar com fatores, as duas operações mais comuns são alterar a ordem dos níveis e alterar os valores dos níveis. Essas operações são descritas nas seções abaixo.\n\n16.3.1 Exercícios\n\nExplore a distribuição de renda (renda informada). O que torna o gráfico de barras padrão difícil de ser entendido? Como você pode melhorar o gráfico?\nQual a religiao mais comum neste questionário? Qual o partido mais comum?\nQual denominacao se aplica a qual religiao? Como você pode descobrir isso com uma tabela? Como você pode descobrir isso com uma visualização?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-modifying-factor-order",
    "href": "factors.html#sec-modifying-factor-order",
    "title": "16  ✅ Fatores",
    "section": "\n16.4 Modificando a ordem de um fator",
    "text": "16.4 Modificando a ordem de um fator\nMuitas vezes é útil alterar a ordem dos níveis dos fatores em uma visualização. Por exemplo, imagine que você deseja explorar o número médio de horas gastas assistindo TV por dia em todas as religiões:\n\nresumo_religiao &lt;- questionario |&gt;\n  group_by(religiao) |&gt;\n  summarize(\n    horas_tv = mean(horas_tv, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(resumo_religiao, aes(x = horas_tv, y = religiao)) + \n  geom_point()\n\n\n\n\n\n\n\nÉ difícil ler esse gráfico porque não existe um padrão geral. Podemos melhorá-lo reordenando os níveis de religiao usando fct_reorder(). fct_reorder() possui três argumentos:\n\n\nf, o fator cujos níveis você deseja modificar.\n\nx, um vetor numérico que você deseja usar para reordenar os níveis.\nOpcionalmente, fun, uma função que é usada se houver vários valores de x para cada valor de f. A função padrão é median.\n\n\nggplot(resumo_religiao, aes(x = horas_tv, y = fct_reorder(religiao, horas_tv))) +\n  geom_point()\n\n\n\n\n\n\n\nReordenar a religião torna muito mais fácil ver que as pessoas na categoria “Não sabe” assistem muito mais TV, e o Hinduísmo e outras religiões orientais assistem muito menos.\nÀ medida que você começa a fazer transformações mais complicadas, recomendamos movê-las de aes() para uma etapa separada, usando mutate(). Por exemplo, você poderia reescrever o gráfico acima como:\n\nresumo_religiao |&gt;\n  mutate(\n    religiao = fct_reorder(religiao, horas_tv)\n  ) |&gt;\n  ggplot(aes(x = horas_tv, y = religiao)) +\n  geom_point()\n\nE se criarmos um gráfico semelhante observando como a idade média varia de acordo com o nível de renda informada?\n\nresumo_renda &lt;- questionario |&gt;\n  group_by(renda) |&gt;\n  summarize(\n    idade = mean(idade, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(resumo_renda, aes(x = idade, y = fct_reorder(renda, idade))) + \n  geom_point()\n\n\n\n\n\n\n\nAqui, reordenar arbitrariamente os níveis não é uma boa ideia! Isso porque renda já tem uma ordem fundamentada com a qual não devemos mexer. Reserve fct_reorder() para fatores cujos níveis são ordenados arbitrariamente.\nNo entanto, faz sentido colocar “Não se aplica” na frente com os outros níveis especiais. Você pode usar fct_relevel(). É necessário um fator, f, e então qualquer número de níveis que você deseja mover para o início da linha.\n\nggplot(resumo_renda, aes(x = idade, y = fct_relevel(renda, \"Não se aplica\"))) +\n  geom_point()\n\n\n\n\n\n\n\nPor que você acha que a idade média para “Não se aplica” é tão alta?\nOutro tipo de reordenação é útil quando você está colorindo as linhas em um gráfico. fct_reorder2(f, x, y) reordena o fator f pelos valores y associados aos maiores valores x. Isso torna o gráfico mais fácil de ler porque as cores da linha na extremidade direita do gráfico se alinharão com a legenda.\npor_idade &lt;- questionario |&gt;\n  filter(!is.na(idade)) |&gt; \n  count(idade, estado_civil) |&gt;\n  group_by(idade) |&gt;\n  mutate(\n    prop = n / sum(n)\n  )\n\nggplot(por_idade, aes(x = idade, y = prop, color = estado_civil)) +\n  geom_line(linewidth = 1) + \n  scale_color_brewer(palette = \"Set1\")\n\nggplot(por_idade, aes(x = idade, y = prop, color = fct_reorder2(estado_civil, idade, prop))) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\") + \n  labs(color = \"estado civil\") \n\n\n\n\n\n\n\n\n\n\nFinalmente, para gráficos de barras, você pode usar fct_infreq() para ordenar os níveis em frequência decrescente: este é o tipo mais simples de reordenação porque não precisa de nenhuma variável extra.. Combine-a com a fct_rev() se desejar que eles aumentem a frequência, de modo que no gráfico de barras os maiores valores fiquem à direita, não à esquerda.\n\nquestionario |&gt;\n  mutate(estado_civil = estado_civil |&gt; fct_infreq() |&gt; fct_rev()) |&gt;\n  ggplot(aes(x = estado_civil)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n16.4.1 Exercícios\n\nExistem alguns números suspeitosamente altos em horas_tv. A média é um bom resumo?\nPara cada fator em questionario, identifique se a ordem dos níveis é arbitrária ou fundamentada.\nPor que mover “Não se aplica” para a frente dos níveis o moveu para a parte inferior do gráfico?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#modificando-os-níveis-do-fator",
    "href": "factors.html#modificando-os-níveis-do-fator",
    "title": "16  ✅ Fatores",
    "section": "\n16.5 Modificando os níveis do fator",
    "text": "16.5 Modificando os níveis do fator\nMais poderoso do que alterar as ordens dos níveis é alterar os seus valores. Isso permite esclarecer rótulos para publicação e recolher níveis para exibições de alto nível. A ferramenta mais geral e poderosa é fct_recode(). Ela permite recodificar, ou alterar, o valor de cada nível. Por exemplo, pegue a variável partido do data frame questionario:\n\nquestionario |&gt; count(partido)\n#&gt; # A tibble: 10 × 2\n#&gt;   partido                                  n\n#&gt;   &lt;fct&gt;                                &lt;int&gt;\n#&gt; 1 Sem resposta                           154\n#&gt; 2 Não sabe                                 1\n#&gt; 3 Outro partido                          393\n#&gt; 4 Fortemente republicano                2314\n#&gt; 5 Não fortemente repubicano             3032\n#&gt; 6 Independente, inclinação republicana  1791\n#&gt; # ℹ 4 more rows\n\nOs níveis são concisos e inconsistentes. Vamos ajustá-los para serem mais longos e usar uma construção paralela. Como a maioria das funções de renomeação e recodificação no tidyverse, os novos valores ficam à esquerda e os valores antigos à direita:\n\nquestionario |&gt;\n  mutate(\n    partido = fct_recode(partido,\n      \"Indivíduo fortemente republicano\"    = \"Fortemente republicano\",\n      \"Indivíduo não fortemente republicano\"      = \"Não fortemente republicano\",\n      \"Indivíduo independente com inclinação republicana\" = \"Independente, inclinação republicana\",\n      \"Indivíduo independente com inclinação democrata\" = \"Independente, inclinação democrata\",\n      \"Indivíduo não fortemente democrata\"        = \"Não fortemente democrata\",\n      \"Indivíduo fortemente democrata\"      = \"Fortemente democrata\"\n    )\n  ) |&gt;\n  count(partido)\n#&gt; Warning: There was 1 warning in `mutate()`.\n#&gt; ℹ In argument: `partido = fct_recode(...)`.\n#&gt; Caused by warning:\n#&gt; ! Unknown levels in `f`: Não fortemente republicano\n#&gt; # A tibble: 10 × 2\n#&gt;   partido                                               n\n#&gt;   &lt;fct&gt;                                             &lt;int&gt;\n#&gt; 1 Sem resposta                                        154\n#&gt; 2 Não sabe                                              1\n#&gt; 3 Outro partido                                       393\n#&gt; 4 Indivíduo fortemente republicano                   2314\n#&gt; 5 Não fortemente repubicano                          3032\n#&gt; 6 Indivíduo independente com inclinação republicana  1791\n#&gt; # ℹ 4 more rows\n\nfct_recode() deixará os níveis que não são explicitamente mencionados como estão e irá avisá-lo se você acidentalmente se referir a um nível que não existe.\nPara combinar grupos, você pode atribuir vários níveis antigos a um mesmo nível novo:\n\nquestionario |&gt;\n  mutate(\n    partido = fct_recode(partido,\n      \"Indivíduo fortemente republicano\"    = \"Fortemente republicano\",\n      \"Indivíduo não fortemente republicano\"      = \"Não fortemente republicano\",\n      \"Indivíduo independente com inclinação republicana\" = \"Independente, inclinação republicana\",\n      \"Indivíduo independente com inclinação democrata\" = \"Independente, inclinação democrata\",\n      \"Indivíduo não fortemente democrata\"        = \"Não fortemente democrata\",\n      \"Indivíduo fortemente democrata\"      = \"Fortemente democrata\",\n      \"Outro\"                 = \"Sem resposta\",\n      \"Outro\"                 = \"Não sabe\",\n      \"Outro\"                 = \"Outro partido\"\n    )\n  )\n#&gt; Warning: There was 1 warning in `mutate()`.\n#&gt; ℹ In argument: `partido = fct_recode(...)`.\n#&gt; Caused by warning:\n#&gt; ! Unknown levels in `f`: Não fortemente republicano\n\nUse esta técnica com cuidado: se você agrupar categorias que são realmente diferentes, você acabará com resultados enganosos.\nSe você deseja recolher vários níveis, fct_collapse() é uma variante útil de fct_recode(). Para cada nova variável, você pode fornecer um vetor de níveis antigos:\n\nquestionario |&gt;\n  mutate(\n    partido = fct_collapse(partido,\n      \"other\" = c(\"Sem resposta\", \"Não sabe\", \"Outro partido\"),\n      \"rep\" = c(\"Fortemente republicano\", \"Não fortemente republicano\"),\n      \"ind\" = c(\"Independente, inclinação republicana\", \"Independente\", \"Independente, inclinação democrata\"),\n      \"dem\" = c(\"Não fortemente democrata\", \"Fortemente democrata\")\n    )\n  ) |&gt;\n  count(partido)\n#&gt; Warning: There was 1 warning in `mutate()`.\n#&gt; ℹ In argument: `partido = fct_collapse(...)`.\n#&gt; Caused by warning:\n#&gt; ! Unknown levels in `f`: Não fortemente republicano\n#&gt; # A tibble: 5 × 2\n#&gt;   partido                       n\n#&gt;   &lt;fct&gt;                     &lt;int&gt;\n#&gt; 1 other                       548\n#&gt; 2 rep                        2314\n#&gt; 3 Não fortemente repubicano  3032\n#&gt; 4 ind                        8409\n#&gt; 5 dem                        7180\n\nÀs vezes, você só quer juntar em pequenos grupos para simplificar um gráfico ou uma tabela. Esse é o trabalho da família de funções fct_lump_*(). fct_lump_lowfreq() é um ponto de partida simples que agrupa progressivamente as categorias dos menores grupos em “Outros”, sempre mantendo “Outros” como a menor categoria.\n\nquestionario |&gt;\n  mutate(religiao = fct_lump_lowfreq(religiao)) |&gt;\n  count(religiao)\n#&gt; # A tibble: 2 × 2\n#&gt;   religiao        n\n#&gt;   &lt;fct&gt;       &lt;int&gt;\n#&gt; 1 Protestante 10846\n#&gt; 2 Other       10637\n\nNeste caso, não ajuda muito: é verdade que a maioria dos americanos nesta pesquisa são protestantes, mas provavelmente gostaríamos de ver mais alguns detalhes! Em vez disso, podemos usar fct_lump_n() para especificar que queremos exatamente 10 grupos:\n\nquestionario |&gt;\n  mutate(religiao = fct_lump_n(religiao, n = 10)) |&gt;\n  count(religiao, sort = TRUE)\n#&gt; # A tibble: 11 × 2\n#&gt;   religiao        n\n#&gt;   &lt;fct&gt;       &lt;int&gt;\n#&gt; 1 Protestante 10846\n#&gt; 2 Católica     5124\n#&gt; 3 Nenhuma      3523\n#&gt; 4 Cristã        689\n#&gt; 5 Judaísmo      388\n#&gt; 6 Other         234\n#&gt; # ℹ 5 more rows\n\nLeia a documentação para aprender sobre fct_lump_min() e fct_lump_prop() que são úteis em outros casos.\n\n16.5.1 Exercícios\n\nComo mudaram ao longo do tempo as proporções de pessoas que se identificam como Democratas, Republicanas e Independentes?\nComo você poderia agrupar a “renda” em um pequeno conjunto de categorias?\nObserve que existem 9 grupos (excluindo outros) no exemplo fct_lump acima. Por que não 10? (Dica: digite ?fct_lump e note que o padrão para o argumento other_level é “Other”.)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-ordered-factors",
    "href": "factors.html#sec-ordered-factors",
    "title": "16  ✅ Fatores",
    "section": "\n16.6 Fatores ordenados",
    "text": "16.6 Fatores ordenados\nAntes de prosseguirmos, há um tipo especial de fator que precisa ser mencionado brevemente: fatores ordenados. Fatores ordenados, criados com ordered(), implicam uma ordenação estrita e distância igual entre os níveis: o primeiro nível é “menor que” o segundo nível na mesma quantidade que o segundo nível é “menor que” o terceiro nível e assim por diante. Você pode reconhecê-los ao imprimir porque eles usam &lt; entre os níveis dos fatores:\n\nordered(c(\"a\", \"b\", \"c\"))\n#&gt; [1] a b c\n#&gt; Levels: a &lt; b &lt; c\n\nNa prática, os fatores ordenados (ordered()) se comportam de forma muito semelhante aos fatores regulares. Existem apenas dois lugares onde você pode notar um comportamento diferente:\n\nSe você mapear um fator ordenado para colorir ou preencher no ggplot2, o padrão será scale_color_viridis()/scale_fill_viridis(), uma escala de cores que implica um ranqueamento.\nSe você usar uma função ordenada em um modelo linear, ela usará “contrastes poligonais”. Eles são moderadamente úteis, mas é improvável que você já tenha ouvido falar deles, a menos que tenha um PhD em Estatística e, mesmo assim, provavelmente não os interpreta rotineiramente. Se você quiser saber mais, recomendamos a vignette(\"contrasts\", package = \"faux\") de Lisa DeBruine.\n\nDada a utilidade discutível dessas diferenças, geralmente não recomendamos o uso de fatores ordenados.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#resumo",
    "href": "factors.html#resumo",
    "title": "16  ✅ Fatores",
    "section": "\n16.7 Resumo",
    "text": "16.7 Resumo\nEste capítulo apresentou o prático pacote forcats para trabalhar com fatores, apresentando as funções mais comumente usadas. O pacote forcats contém uma ampla gama de outras funções auxiliares que não tivemos espaço para discutir aqui, portanto, sempre que você estiver enfrentando um desafio de análise com fatores que não encontrou antes, recomendo fortemente dar uma olhada no índice remissivo para ver se existe uma função pronta que pode ajudar a resolver seu problema.\nSe você quiser aprender mais sobre fatores depois de ler este capítulo, recomendamos a leitura do artigo de Amelia McNamara e Nicholas Horton, Wrangling categorical data in R. Este artigo apresenta um pouco da história discutida em stringsAsFactors: Uma biografia não autorizada e stringsAsFactors = &lt;sigh&gt; e compara as abordagens organizadas (tidy approach) para dados categóricos descritos neste livro com métodos do R base. Uma versão inicial do documento ajudou a motivar e definir o escopo do pacote forcats; obrigado Amélia e Nick!\nNo próximo capítulo, mudaremos de assunto para começar a aprender sobre datas e horários no R. Datas e horários parecem enganosamente simples, mas como você verá em breve, quanto mais você aprende sobre eles, mais complexos eles parecem se tornar!",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "factors.html#footnotes",
    "href": "factors.html#footnotes",
    "title": "16  ✅ Fatores",
    "section": "",
    "text": "Eles também são muito importantes para modelagem.↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>✅ Fatores</span>"
    ]
  },
  {
    "objectID": "datetimes.html",
    "href": "datetimes.html",
    "title": "17  Dates and times",
    "section": "",
    "text": "17.1 Introduction\nThis chapter will show you how to work with dates and times in R. At first glance, dates and times seem simple. You use them all the time in your regular life, and they don’t seem to cause much confusion. However, the more you learn about dates and times, the more complicated they seem to get!\nTo warm up think about how many days there are in a year, and how many hours there are in a day. You probably remembered that most years have 365 days, but leap years have 366. Do you know the full rule for determining if a year is a leap year1? The number of hours in a day is a little less obvious: most days have 24 hours, but in places that use daylight saving time (DST), one day each year has 23 hours and another has 25.\nDates and times are hard because they have to reconcile two physical phenomena (the rotation of the Earth and its orbit around the sun) with a whole raft of geopolitical phenomena including months, time zones, and DST. This chapter won’t teach you every last detail about dates and times, but it will give you a solid grounding of practical skills that will help you with common data analysis challenges.\nWe’ll begin by showing you how to create date-times from various inputs, and then once you’ve got a date-time, how you can extract components like year, month, and day. We’ll then dive into the tricky topic of working with time spans, which come in a variety of flavors depending on what you’re trying to do. We’ll conclude with a brief discussion of the additional challenges posed by time zones.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#introduction",
    "href": "datetimes.html#introduction",
    "title": "17  Dates and times",
    "section": "",
    "text": "17.1.1 Prerequisites\nThis chapter will focus on the lubridate package, which makes it easier to work with dates and times in R. As of the latest tidyverse release, lubridate is part of core tidyverse. We will also need nycflights13 for practice data.\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#sec-creating-datetimes",
    "href": "datetimes.html#sec-creating-datetimes",
    "title": "17  Dates and times",
    "section": "\n17.2 Creating date/times",
    "text": "17.2 Creating date/times\nThere are three types of date/time data that refer to an instant in time:\n\nA date. Tibbles print this as &lt;date&gt;.\nA time within a day. Tibbles print this as &lt;time&gt;.\nA date-time is a date plus a time: it uniquely identifies an instant in time (typically to the nearest second). Tibbles print this as &lt;dttm&gt;. Base R calls these POSIXct, but doesn’t exactly trip off the tongue.\n\nIn this chapter we are going to focus on dates and date-times as R doesn’t have a native class for storing times. If you need one, you can use the hms package.\nYou should always use the simplest possible data type that works for your needs. That means if you can use a date instead of a date-time, you should. Date-times are substantially more complicated because of the need to handle time zones, which we’ll come back to at the end of the chapter.\nTo get the current date or date-time you can use today() or now():\n\ntoday()\n#&gt; [1] \"2024-05-12\"\nnow()\n#&gt; [1] \"2024-05-12 18:52:13 AEST\"\n\nOtherwise, the following sections describe the four ways you’re likely to create a date/time:\n\nWhile reading a file with readr.\nFrom a string.\nFrom individual date-time components.\nFrom an existing date/time object.\n\n\n17.2.1 During import\nIf your CSV contains an ISO8601 date or date-time, you don’t need to do anything; readr will automatically recognize it:\n\ncsv &lt;- \"\n  date,datetime\n  2022-01-02,2022-01-02 05:12\n\"\nread_csv(csv)\n#&gt; # A tibble: 1 × 2\n#&gt;   date       datetime           \n#&gt;   &lt;date&gt;     &lt;dttm&gt;             \n#&gt; 1 2022-01-02 2022-01-02 05:12:00\n\nIf you haven’t heard of ISO8601 before, it’s an international standard2 for writing dates where the components of a date are organized from biggest to smallest separated by -. For example, in ISO8601 May 3 2022 is 2022-05-03. ISO8601 dates can also include times, where hour, minute, and second are separated by :, and the date and time components are separated by either a T or a space. For example, you could write 4:26pm on May 3 2022 as either 2022-05-03 16:26 or 2022-05-03T16:26.\nFor other date-time formats, you’ll need to use col_types plus col_date() or col_datetime() along with a date-time format. The date-time format used by readr is a standard used across many programming languages, describing a date component with a % followed by a single character. For example, %Y-%m-%d specifies a date that’s a year, -, month (as number) -, day. Table Tabela 17.1 lists all the options.\n\n\nTabela 17.1: All date formats understood by readr\n\n\n\nType\nCode\nMeaning\nExample\n\n\n\nYear\n%Y\n4 digit year\n2021\n\n\n\n%y\n2 digit year\n21\n\n\nMonth\n%m\nNumber\n2\n\n\n\n%b\nAbbreviated name\nFeb\n\n\n\n%B\nFull name\nFebruary\n\n\nDay\n%d\nOne or two digits\n2\n\n\n\n%e\nTwo digits\n02\n\n\nTime\n%H\n24-hour hour\n13\n\n\n\n%I\n12-hour hour\n1\n\n\n\n%p\nAM/PM\npm\n\n\n\n%M\nMinutes\n35\n\n\n\n%S\nSeconds\n45\n\n\n\n%OS\nSeconds with decimal component\n45.35\n\n\n\n%Z\nTime zone name\nAmerica/Chicago\n\n\n\n%z\nOffset from UTC\n+0800\n\n\nOther\n%.\nSkip one non-digit\n:\n\n\n\n%*\nSkip any number of non-digits\n\n\n\n\n\n\n\nAnd this code shows a few options applied to a very ambiguous date:\n\ncsv &lt;- \"\n  date\n  01/02/15\n\"\n\nread_csv(csv, col_types = cols(date = col_date(\"%m/%d/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-01-02\n\nread_csv(csv, col_types = cols(date = col_date(\"%d/%m/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-02-01\n\nread_csv(csv, col_types = cols(date = col_date(\"%y/%m/%d\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2001-02-15\n\nNote that no matter how you specify the date format, it’s always displayed the same way once you get it into R.\nIf you’re using %b or %B and working with non-English dates, you’ll also need to provide a locale(). See the list of built-in languages in date_names_langs(), or create your own with date_names(),\n\n17.2.2 From strings\nThe date-time specification language is powerful, but requires careful analysis of the date format. An alternative approach is to use lubridate’s helpers which attempt to automatically determine the format once you specify the order of the component. To use them, identify the order in which year, month, and day appear in your dates, then arrange “y”, “m”, and “d” in the same order. That gives you the name of the lubridate function that will parse your date. For example:\n\nymd(\"2017-01-31\")\n#&gt; [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")\n#&gt; [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")\n#&gt; [1] \"2017-01-31\"\n\nymd() and friends create dates. To create a date-time, add an underscore and one or more of “h”, “m”, and “s” to the name of the parsing function:\n\nymd_hms(\"2017-01-31 20:11:59\")\n#&gt; [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")\n#&gt; [1] \"2017-01-31 08:01:00 UTC\"\n\nYou can also force the creation of a date-time from a date by supplying a timezone:\n\nymd(\"2017-01-31\", tz = \"UTC\")\n#&gt; [1] \"2017-01-31 UTC\"\n\nHere I use the UTC3 timezone which you might also know as GMT, or Greenwich Mean Time, the time at 0° longitude4 . It doesn’t use daylight saving time, making it a bit easier to compute with .\n\n17.2.3 From individual components\nInstead of a single string, sometimes you’ll have the individual components of the date-time spread across multiple columns. This is what we have in the flights data:\n\nflights |&gt; \n  select(year, month, day, hour, minute)\n#&gt; # A tibble: 336,776 × 5\n#&gt;    year month   day  hour minute\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  2013     1     1     5     15\n#&gt; 2  2013     1     1     5     29\n#&gt; 3  2013     1     1     5     40\n#&gt; 4  2013     1     1     5     45\n#&gt; 5  2013     1     1     6      0\n#&gt; 6  2013     1     1     5     58\n#&gt; # ℹ 336,770 more rows\n\nTo create a date/time from this sort of input, use make_date() for dates, or make_datetime() for date-times:\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year month   day  hour minute departure          \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n#&gt; 1  2013     1     1     5     15 2013-01-01 05:15:00\n#&gt; 2  2013     1     1     5     29 2013-01-01 05:29:00\n#&gt; 3  2013     1     1     5     40 2013-01-01 05:40:00\n#&gt; 4  2013     1     1     5     45 2013-01-01 05:45:00\n#&gt; 5  2013     1     1     6      0 2013-01-01 06:00:00\n#&gt; 6  2013     1     1     5     58 2013-01-01 05:58:00\n#&gt; # ℹ 336,770 more rows\n\nLet’s do the same thing for each of the four time columns in flights. The times are represented in a slightly odd format, so we use modulus arithmetic to pull out the hour and minute components. Once we’ve created the date-time variables, we focus in on the variables we’ll explore in the rest of the chapter.\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\nflights_dt &lt;- flights |&gt; \n  filter(!is.na(dep_time), !is.na(arr_time)) |&gt; \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) |&gt; \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\nflights_dt\n#&gt; # A tibble: 328,063 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n#&gt; 2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n#&gt; 3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n#&gt; 4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n#&gt; 5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n#&gt; 6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n#&gt; # ℹ 328,057 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\nWith this data, we can visualize the distribution of departure times across the year:\n\nflights_dt |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day\n\n\n\n\n\n\n\nOr within a single day:\n\nflights_dt |&gt; \n  filter(dep_time &lt; ymd(20130102)) |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes\n\n\n\n\n\n\n\nNote that when you use date-times in a numeric context (like in a histogram), 1 means 1 second, so a binwidth of 86400 means one day. For dates, 1 means 1 day.\n\n17.2.4 From other types\nYou may want to switch between a date-time and a date. That’s the job of as_datetime() and as_date():\n\nas_datetime(today())\n#&gt; [1] \"2024-05-12 UTC\"\nas_date(now())\n#&gt; [1] \"2024-05-12\"\n\nSometimes you’ll get date/times as numeric offsets from the “Unix Epoch”, 1970-01-01. If the offset is in seconds, use as_datetime(); if it’s in days, use as_date().\n\nas_datetime(60 * 60 * 10)\n#&gt; [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)\n#&gt; [1] \"1980-01-01\"\n\n\n17.2.5 Exercises\n\n\nWhat happens if you parse a string that contains invalid dates?\n\nymd(c(\"2010-10-10\", \"bananas\"))\n\n\nWhat does the tzone argument to today() do? Why is it important?\n\nFor each of the following date-times, show how you’d parse it using a readr column specification and a lubridate function.\n\nd1 &lt;- \"January 1, 2010\"\nd2 &lt;- \"2015-Mar-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 &lt;- \"12/30/14\" # Dec 30, 2014\nt1 &lt;- \"1705\"\nt2 &lt;- \"11:15:10.12 PM\"",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#date-time-components",
    "href": "datetimes.html#date-time-components",
    "title": "17  Dates and times",
    "section": "\n17.3 Date-time components",
    "text": "17.3 Date-time components\nNow that you know how to get date-time data into R’s date-time data structures, let’s explore what you can do with them. This section will focus on the accessor functions that let you get and set individual components. The next section will look at how arithmetic works with date-times.\n\n17.3.1 Getting components\nYou can pull out individual parts of the date with the accessor functions year(), month(), mday() (day of the month), yday() (day of the year), wday() (day of the week), hour(), minute(), and second(). These are effectively the opposites of make_datetime().\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n#&gt; [1] 2026\nmonth(datetime)\n#&gt; [1] 7\nmday(datetime)\n#&gt; [1] 8\n\nyday(datetime)\n#&gt; [1] 189\nwday(datetime)\n#&gt; [1] 4\n\nFor month() and wday() you can set label = TRUE to return the abbreviated name of the month or day of the week. Set abbr = FALSE to return the full name.\n\nmonth(datetime, label = TRUE)\n#&gt; [1] Jul\n#&gt; 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\nwday(datetime, label = TRUE, abbr = FALSE)\n#&gt; [1] Wednesday\n#&gt; 7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday\n\nWe can use wday() to see that more flights depart during the week than on the weekend:\n\nflights_dt |&gt; \n  mutate(wday = wday(dep_time, label = TRUE)) |&gt; \n  ggplot(aes(x = wday)) +\n  geom_bar()\n\n\n\n\n\n\n\nWe can also look at the average departure delay by minute within the hour. There’s an interesting pattern: flights leaving in minutes 20-30 and 50-60 have much lower delays than the rest of the hour!\n\nflights_dt |&gt; \n  mutate(minute = minute(dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()\n  ) |&gt; \n  ggplot(aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\nInterestingly, if we look at the scheduled departure time we don’t see such a strong pattern:\n\nsched_dep &lt;- flights_dt |&gt; \n  mutate(minute = minute(sched_dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(sched_dep, aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\n\n\n\nSo why do we see that pattern with the actual departure times? Well, like much data collected by humans, there’s a strong bias towards flights leaving at “nice” departure times, as Figura 17.1 shows. Always be alert for this sort of pattern whenever you work with data that involves human judgement!\n\n\n\n\n\n\n\nFigura 17.1: A frequency polygon showing the number of flights scheduled to depart each hour. You can see a strong preference for round numbers like 0 and 30 and generally for numbers that are a multiple of five.\n\n\n\n\n\n17.3.2 Rounding\nAn alternative approach to plotting individual components is to round the date to a nearby unit of time, with floor_date(), round_date(), and ceiling_date(). Each function takes a vector of dates to adjust and then the name of the unit to round down (floor), round up (ceiling), or round to. This, for example, allows us to plot the number of flights per week:\n\nflights_dt |&gt; \n  count(week = floor_date(dep_time, \"week\")) |&gt; \n  ggplot(aes(x = week, y = n)) +\n  geom_line() + \n  geom_point()\n\n\n\n\n\n\n\nYou can use rounding to show the distribution of flights across the course of a day by computing the difference between dep_time and the earliest instant of that day:\n\nflights_dt |&gt; \n  mutate(dep_hour = dep_time - floor_date(dep_time, \"day\")) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n#&gt; Don't know how to automatically pick scale for object of type &lt;difftime&gt;.\n#&gt; Defaulting to continuous.\n\n\n\n\n\n\n\nComputing the difference between a pair of date-times yields a difftime (more on that in Seção 17.4.3). We can convert that to an hms object to get a more useful x-axis:\n\nflights_dt |&gt; \n  mutate(dep_hour = hms::as_hms(dep_time - floor_date(dep_time, \"day\"))) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n\n\n\n\n\n\n\n\n17.3.3 Modifying components\nYou can also use each accessor function to modify the components of a date/time. This doesn’t come up much in data analysis, but can be useful when cleaning data that has clearly incorrect dates.\n\n(datetime &lt;- ymd_hms(\"2026-07-08 12:34:56\"))\n#&gt; [1] \"2026-07-08 12:34:56 UTC\"\n\nyear(datetime) &lt;- 2030\ndatetime\n#&gt; [1] \"2030-07-08 12:34:56 UTC\"\nmonth(datetime) &lt;- 01\ndatetime\n#&gt; [1] \"2030-01-08 12:34:56 UTC\"\nhour(datetime) &lt;- hour(datetime) + 1\ndatetime\n#&gt; [1] \"2030-01-08 13:34:56 UTC\"\n\nAlternatively, rather than modifying an existing variable, you can create a new date-time with update(). This also allows you to set multiple values in one step:\n\nupdate(datetime, year = 2030, month = 2, mday = 2, hour = 2)\n#&gt; [1] \"2030-02-02 02:34:56 UTC\"\n\nIf values are too big, they will roll-over:\n\nupdate(ymd(\"2023-02-01\"), mday = 30)\n#&gt; [1] \"2023-03-02\"\nupdate(ymd(\"2023-02-01\"), hour = 400)\n#&gt; [1] \"2023-02-17 16:00:00 UTC\"\n\n\n17.3.4 Exercises\n\nHow does the distribution of flight times within a day change over the course of the year?\nCompare dep_time, sched_dep_time and dep_delay. Are they consistent? Explain your findings.\nCompare air_time with the duration between the departure and arrival. Explain your findings. (Hint: consider the location of the airport.)\nHow does the average delay time change over the course of a day? Should you use dep_time or sched_dep_time? Why?\nOn what day of the week should you leave if you want to minimise the chance of a delay?\nWhat makes the distribution of diamonds$carat and flights$sched_dep_time similar?\nConfirm our hypothesis that the early departures of flights in minutes 20-30 and 50-60 are caused by scheduled flights that leave early. Hint: create a binary variable that tells you whether or not a flight was delayed.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#time-spans",
    "href": "datetimes.html#time-spans",
    "title": "17  Dates and times",
    "section": "\n17.4 Time spans",
    "text": "17.4 Time spans\nNext you’ll learn about how arithmetic with dates works, including subtraction, addition, and division. Along the way, you’ll learn about three important classes that represent time spans:\n\n\nDurations, which represent an exact number of seconds.\n\nPeriods, which represent human units like weeks and months.\n\nIntervals, which represent a starting and ending point.\n\nHow do you pick between duration, periods, and intervals? As always, pick the simplest data structure that solves your problem. If you only care about physical time, use a duration; if you need to add human times, use a period; if you need to figure out how long a span is in human units, use an interval.\n\n17.4.1 Durations\nIn R, when you subtract two dates, you get a difftime object:\n\n# How old is Hadley?\nh_age &lt;- today() - ymd(\"1979-10-14\")\nh_age\n#&gt; Time difference of 16282 days\n\nA difftime class object records a time span of seconds, minutes, hours, days, or weeks. This ambiguity can make difftimes a little painful to work with, so lubridate provides an alternative which always uses seconds: the duration.\n\nas.duration(h_age)\n#&gt; [1] \"1406764800s (~44.58 years)\"\n\nDurations come with a bunch of convenient constructors:\n\ndseconds(15)\n#&gt; [1] \"15s\"\ndminutes(10)\n#&gt; [1] \"600s (~10 minutes)\"\ndhours(c(12, 24))\n#&gt; [1] \"43200s (~12 hours)\" \"86400s (~1 days)\"\nddays(0:5)\n#&gt; [1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n#&gt; [4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\ndweeks(3)\n#&gt; [1] \"1814400s (~3 weeks)\"\ndyears(1)\n#&gt; [1] \"31557600s (~1 years)\"\n\nDurations always record the time span in seconds. Larger units are created by converting minutes, hours, days, weeks, and years to seconds: 60 seconds in a minute, 60 minutes in an hour, 24 hours in a day, and 7 days in a week. Larger time units are more problematic. A year uses the “average” number of days in a year, i.e. 365.25. There’s no way to convert a month to a duration, because there’s just too much variation.\nYou can add and multiply durations:\n\n2 * dyears(1)\n#&gt; [1] \"63115200s (~2 years)\"\ndyears(1) + dweeks(12) + dhours(15)\n#&gt; [1] \"38869200s (~1.23 years)\"\n\nYou can add and subtract durations to and from days:\n\ntomorrow &lt;- today() + ddays(1)\nlast_year &lt;- today() - dyears(1)\n\nHowever, because durations represent an exact number of seconds, sometimes you might get an unexpected result:\n\none_am &lt;- ymd_hms(\"2026-03-08 01:00:00\", tz = \"America/New_York\")\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\n\nWhy is one day after 1am March 8, 2am March 9? If you look carefully at the date you might also notice that the time zones have changed. March 8 only has 23 hours because it’s when DST starts, so if we add a full days worth of seconds we end up with a different time.\n\n17.4.2 Periods\nTo solve this problem, lubridate provides periods. Periods are time spans but don’t have a fixed length in seconds, instead they work with “human” times, like days and months. That allows them to work in a more intuitive way:\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\nLike durations, periods can be created with a number of friendly constructor functions.\n\nhours(c(12, 24))\n#&gt; [1] \"12H 0M 0S\" \"24H 0M 0S\"\ndays(7)\n#&gt; [1] \"7d 0H 0M 0S\"\nmonths(1:6)\n#&gt; [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n#&gt; [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\nYou can add and multiply periods:\n\n10 * (months(6) + days(1))\n#&gt; [1] \"60m 10d 0H 0M 0S\"\ndays(50) + hours(25) + minutes(2)\n#&gt; [1] \"50d 25H 2M 0S\"\n\nAnd of course, add them to dates. Compared to durations, periods are more likely to do what you expect:\n\n# A leap year\nymd(\"2024-01-01\") + dyears(1)\n#&gt; [1] \"2024-12-31 06:00:00 UTC\"\nymd(\"2024-01-01\") + years(1)\n#&gt; [1] \"2025-01-01\"\n\n# Daylight saving time\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\nLet’s use periods to fix an oddity related to our flight dates. Some planes appear to have arrived at their destination before they departed from New York City.\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 10,633 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    BQN           9        -4 2013-01-01 19:29:00 2013-01-01 19:20:00\n#&gt; 2 JFK    DFW          59        NA 2013-01-01 19:39:00 2013-01-01 18:40:00\n#&gt; 3 EWR    TPA          -2         9 2013-01-01 20:58:00 2013-01-01 21:00:00\n#&gt; 4 EWR    SJU          -6       -12 2013-01-01 21:02:00 2013-01-01 21:08:00\n#&gt; 5 EWR    SFO          11       -14 2013-01-01 21:08:00 2013-01-01 20:57:00\n#&gt; 6 LGA    FLL         -10        -2 2013-01-01 21:20:00 2013-01-01 21:30:00\n#&gt; # ℹ 10,627 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\nThese are overnight flights. We used the same date information for both the departure and the arrival times, but these flights arrived on the following day. We can fix this by adding days(1) to the arrival time of each overnight flight.\n\nflights_dt &lt;- flights_dt |&gt; \n  mutate(\n    overnight = arr_time &lt; dep_time,\n    arr_time = arr_time + days(overnight),\n    sched_arr_time = sched_arr_time + days(overnight)\n  )\n\nNow all of our flights obey the laws of physics.\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 0 × 10\n#&gt; # ℹ 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;,\n#&gt; #   arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, …\n\n\n17.4.3 Intervals\nWhat does dyears(1) / ddays(365) return? It’s not quite one, because dyears() is defined as the number of seconds per average year, which is 365.25 days.\nWhat does years(1) / days(1) return? Well, if the year was 2015 it should return 365, but if it was 2016, it should return 366! There’s not quite enough information for lubridate to give a single clear answer. What it does instead is give an estimate:\n\nyears(1) / days(1)\n#&gt; [1] 365.25\n\nIf you want a more accurate measurement, you’ll have to use an interval. An interval is a pair of starting and ending date times, or you can think of it as a duration with a starting point.\nYou can create an interval by writing start %--% end:\n\ny2023 &lt;- ymd(\"2023-01-01\") %--% ymd(\"2024-01-01\")\ny2024 &lt;- ymd(\"2024-01-01\") %--% ymd(\"2025-01-01\")\n\ny2023\n#&gt; [1] 2023-01-01 UTC--2024-01-01 UTC\ny2024\n#&gt; [1] 2024-01-01 UTC--2025-01-01 UTC\n\nYou could then divide it by days() to find out how many days fit in the year:\n\ny2023 / days(1)\n#&gt; [1] 365\ny2024 / days(1)\n#&gt; [1] 366\n\n\n17.4.4 Exercises\n\nExplain days(!overnight) and days(overnight) to someone who has just started learning R. What is the key fact you need to know?\nCreate a vector of dates giving the first day of every month in 2015. Create a vector of dates giving the first day of every month in the current year.\nWrite a function that given your birthday (as a date), returns how old you are in years.\nWhy can’t (today() %--% (today() + years(1))) / months(1) work?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#time-zones",
    "href": "datetimes.html#time-zones",
    "title": "17  Dates and times",
    "section": "\n17.5 Time zones",
    "text": "17.5 Time zones\nTime zones are an enormously complicated topic because of their interaction with geopolitical entities. Fortunately we don’t need to dig into all the details as they’re not all important for data analysis, but there are a few challenges we’ll need to tackle head on.\n\nThe first challenge is that everyday names of time zones tend to be ambiguous. For example, if you’re American you’re probably familiar with EST, or Eastern Standard Time. However, both Australia and Canada also have EST! To avoid confusion, R uses the international standard IANA time zones. These use a consistent naming scheme {area}/{location}, typically in the form {continent}/{city} or {ocean}/{city}. Examples include “America/New_York”, “Europe/Paris”, and “Pacific/Auckland”.\nYou might wonder why the time zone uses a city, when typically you think of time zones as associated with a country or region within a country. This is because the IANA database has to record decades worth of time zone rules. Over the course of decades, countries change names (or break apart) fairly frequently, but city names tend to stay the same. Another problem is that the name needs to reflect not only the current behavior, but also the complete history. For example, there are time zones for both “America/New_York” and “America/Detroit”. These cities both currently use Eastern Standard Time but in 1969-1972 Michigan (the state in which Detroit is located), did not follow DST, so it needs a different name. It’s worth reading the raw time zone database (available at https://www.iana.org/time-zones) just to read some of these stories!\nYou can find out what R thinks your current time zone is with Sys.timezone():\n\nSys.timezone()\n#&gt; [1] \"Australia/Sydney\"\n\n(If R doesn’t know, you’ll get an NA.)\nAnd see the complete list of all time zone names with OlsonNames():\n\nlength(OlsonNames())\n#&gt; [1] 597\nhead(OlsonNames())\n#&gt; [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n#&gt; [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"\n\nIn R, the time zone is an attribute of the date-time that only controls printing. For example, these three objects represent the same instant in time:\n\nx1 &lt;- ymd_hms(\"2024-06-01 12:00:00\", tz = \"America/New_York\")\nx1\n#&gt; [1] \"2024-06-01 12:00:00 EDT\"\n\nx2 &lt;- ymd_hms(\"2024-06-01 18:00:00\", tz = \"Europe/Copenhagen\")\nx2\n#&gt; [1] \"2024-06-01 18:00:00 CEST\"\n\nx3 &lt;- ymd_hms(\"2024-06-02 04:00:00\", tz = \"Pacific/Auckland\")\nx3\n#&gt; [1] \"2024-06-02 04:00:00 NZST\"\n\nYou can verify that they’re the same time using subtraction:\n\nx1 - x2\n#&gt; Time difference of 0 secs\nx1 - x3\n#&gt; Time difference of 0 secs\n\nUnless otherwise specified, lubridate always uses UTC. UTC (Coordinated Universal Time) is the standard time zone used by the scientific community and is roughly equivalent to GMT (Greenwich Mean Time). It does not have DST, which makes a convenient representation for computation. Operations that combine date-times, like c(), will often drop the time zone. In that case, the date-times will display in the time zone of the first element:\n\nx4 &lt;- c(x1, x2, x3)\nx4\n#&gt; [1] \"2024-06-01 12:00:00 EDT\" \"2024-06-01 12:00:00 EDT\"\n#&gt; [3] \"2024-06-01 12:00:00 EDT\"\n\nYou can change the time zone in two ways:\n\n\nKeep the instant in time the same, and change how it’s displayed. Use this when the instant is correct, but you want a more natural display.\n\nx4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#&gt; [1] \"2024-06-02 02:30:00 +1030\" \"2024-06-02 02:30:00 +1030\"\n#&gt; [3] \"2024-06-02 02:30:00 +1030\"\nx4a - x4\n#&gt; Time differences in secs\n#&gt; [1] 0 0 0\n\n(This also illustrates another challenge of times zones: they’re not all integer hour offsets!)\n\n\nChange the underlying instant in time. Use this when you have an instant that has been labelled with the incorrect time zone, and you need to fix it.\n\nx4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#&gt; [1] \"2024-06-01 12:00:00 +1030\" \"2024-06-01 12:00:00 +1030\"\n#&gt; [3] \"2024-06-01 12:00:00 +1030\"\nx4b - x4\n#&gt; Time differences in hours\n#&gt; [1] -14.5 -14.5 -14.5",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#summary",
    "href": "datetimes.html#summary",
    "title": "17  Dates and times",
    "section": "\n17.6 Summary",
    "text": "17.6 Summary\nThis chapter has introduced you to the tools that lubridate provides to help you work with date-time data. Working with dates and times can seem harder than necessary, but hopefully this chapter has helped you see why — date-times are more complex than they seem at first glance, and handling every possible situation adds complexity. Even if your data never crosses a day light savings boundary or involves a leap year, the functions need to be able to handle it.\nThe next chapter gives a round up of missing values. You’ve seen them in a few places and have no doubt encounter in your own analysis, and it’s now time to provide a grab bag of useful techniques for dealing with them.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "datetimes.html#footnotes",
    "href": "datetimes.html#footnotes",
    "title": "17  Dates and times",
    "section": "",
    "text": "A year is a leap year if it’s divisible by 4, unless it’s also divisible by 100, except if it’s also divisible by 400. In other words, in every set of 400 years, there’s 97 leap years.↩︎\nhttps://xkcd.com/1179/↩︎\nYou might wonder what UTC stands for. It’s a compromise between the English “Coordinated Universal Time” and French “Temps Universel Coordonné”.↩︎\nNo prizes for guessing which country came up with the longitude system.↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dates and times</span>"
    ]
  },
  {
    "objectID": "missing-values.html",
    "href": "missing-values.html",
    "title": "18  ✅ Valores faltantes",
    "section": "",
    "text": "18.1 Introdução\nVocê já aprendeu o básico sobre valores faltantes (missing values) no início deste livro. Você os viu pela primeira vez no Capítulo 1, onde resultaram em um aviso ao criar um gráfico, bem como na Seção 3.5.2, onde interferiram no cálculo de estatísticas sumarizadas, e aprendeu sobre sua natureza de propagação e como verificar sua presença na Seção 12.2.2. Agora voltaremos a eles com mais profundidade, para que você possa aprender mais detalhes.\nComeçaremos discutindo algumas ferramentas gerais para trabalhar com valores faltantes registrados como NA (do inglês Not Available - “não disponível”). Em seguida, exploraremos a ideia de valores faltantes implícitos, ou seja, valores que estão simplesmente ausentes em seus dados, e mostraremos algumas ferramentas que você pode usar para torná-los explícitos. Terminaremos com uma discussão relacionada sobre grupos vazios, causados ​​por níveis de fatores que não aparecem nos dados.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "missing-values.html#introdução",
    "href": "missing-values.html#introdução",
    "title": "18  ✅ Valores faltantes",
    "section": "",
    "text": "18.1.1 Pré-requisitos\nAs funções para trabalhar com dados ausentes vêm principalmente dos pacotes dplyr e tidyr, que são membros principais do tidyverse.\n\nlibrary(tidyverse)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "missing-values.html#valores-faltantes-explícitos",
    "href": "missing-values.html#valores-faltantes-explícitos",
    "title": "18  ✅ Valores faltantes",
    "section": "\n18.2 Valores faltantes explícitos",
    "text": "18.2 Valores faltantes explícitos\nPara começar, vamos explorar algumas ferramentas úteis para criar ou eliminar valores explícitos ausentes, ou seja, células onde você vê um NA.\n\n18.2.1 Última observação levada adiante\nUm uso comum de valores faltantes (missing values) é como conveniência na entrada de dados. Quando os dados são inseridos manualmente, os valores ausentes às vezes indicam que o valor da linha anterior foi repetido (levado adiante):\n\ntratamento &lt;- tribble(\n  ~pessoa,           ~tratamento, ~resposta,\n  \"Derrick Whitmore\", 1,         7,\n  NA,                 2,         10,\n  NA,                 3,         NA,\n  \"Katherine Burke\",  1,         4\n)\n\nVocê pode preencher esses valores ausentes com a função tidyr::fill(). Funciona como a função select(), pegando um conjunto de colunas como argumento:\n\ntratamento |&gt;\n  fill(everything())\n#&gt; # A tibble: 4 × 3\n#&gt;   pessoa           tratamento resposta\n#&gt;   &lt;chr&gt;                 &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 Derrick Whitmore          1        7\n#&gt; 2 Derrick Whitmore          2       10\n#&gt; 3 Derrick Whitmore          3       10\n#&gt; 4 Katherine Burke           1        4\n\nEste tratamento às vezes é chamado de “última observação realizada” (last observation carried forward) ou locf, abreviadamente. Você pode usar o argumento .direction para preencher valores ausentes que foram gerados de maneiras mais exóticas.\n\n18.2.2 Valores fixos\nAlgumas vezes, os valores ausentes representam algum valor fixo e conhecido, mais comumente 0. Você pode usar a dplyr::coalesce() para substituí-los:\n\nx &lt;- c(1, 4, 5, 7, NA)\ncoalesce(x, 0)\n#&gt; [1] 1 4 5 7 0\n\nÀs vezes você encontrará o problema oposto, onde algum valor concreto na verdade representa um valor ausente. Isso normalmente surge em dados gerados por softwares mais antigos que não possuem uma maneira adequada de representar valores ausentes; portanto, deve-se usar algum valor especial como 99 ou -999.\nSe possível, lide com isso ao ler os dados, por exemplo, usando o argumento na para readr::read_csv(), por exemplo, read_csv(caminho, na = \"99\"). Se você descobrir o problema mais tarde, ou se sua fonte de dados não fornecer uma maneira de lidar com isso na leitura, você pode usar dplyr::na_if():\n\nx &lt;- c(1, 4, 5, 7, -99)\nna_if(x, -99)\n#&gt; [1]  1  4  5  7 NA\n\n\n18.2.3 NaN\nAntes de continuarmos, há um tipo especial de valor ausente que você encontrará de tempos em tempos: um NaN (pronuncia-se “nan”) ou em inglês, not a number (em português, seria como “não é um número”). Não é tão importante saber sobre ele, já que geralmente se comporta como `NA:\n\nx &lt;- c(NA, NaN)\nx * 10\n#&gt; [1]  NA NaN\nx == 1\n#&gt; [1] NA NA\nis.na(x)\n#&gt; [1] TRUE TRUE\n\nSe você tiver um caso raro e precisar distinguir um NA de um NaN, você pode usar is.nan(x).\nVocê geralmente encontrará um NaN ao realizar uma operação matemática que tem um resultado indeterminado:\n\n0 / 0 \n#&gt; [1] NaN\n0 * Inf\n#&gt; [1] NaN\nInf - Inf\n#&gt; [1] NaN\nsqrt(-1)\n#&gt; Warning in sqrt(-1): NaNs produced\n#&gt; [1] NaN",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "missing-values.html#sec-missing-implicit",
    "href": "missing-values.html#sec-missing-implicit",
    "title": "18  ✅ Valores faltantes",
    "section": "\n18.3 Valores faltantes implícitos",
    "text": "18.3 Valores faltantes implícitos\nAté agora falamos sobre valores que estão explicitamente ausentes, ou seja, você pode ver um NA em seus dados. Mas os valores também podem estar implicitamente ausentes, se uma linha inteira de dados estiver simplesmente ausente dos dados. Vamos ilustrar a diferença com um conjunto de dados simples que registra o preço de algumas ações a cada trimestre:\n\nacoes &lt;- tibble(\n  ano  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),\n  trimestre   = c(   1,    2,    3,    4,    2,    3,    4),\n  preco = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\n\nEste conjunto de dados tem duas observações faltantes:\n\nO preco no quarto trimestre de 2020 está explicitamente ausente, porque o seu valor é NA.\nO preço para o primeiro trimestre de 2021 está implicitamente ausente, porque simplesmente não aparece no conjunto de dados.\n\nUma maneira de pensar sobre a diferença é como este diálogo meio filosófico:\n\nUm valor ausente explícito é a presença de uma ausência.\nUm valor ausente implícito é a ausência de presença.\n\nÀs vezes, você deseja tornar explícitos os valores ausentes implícitos para ter algo físico com o qual trabalhar. Em outros casos, valores faltantes explícitos são impostos pela estrutura dos dados e você deseja se livrar deles. As seções a seguir discutem algumas ferramentas para alternar entre ausências implícitas e explícitas.\n\n18.3.1 Pivotagem\nVocê já viu uma ferramenta que pode tornar explícitas as ausências implícitas e vice-versa: pivotagem. Deixar os dados mais largos (com mais colunas) pode tornar explícitos os valores ausentes implícitos porque cada combinação de linhas e novas colunas deve ter algum valor. Por exemplo, se pivotarmos acoes para colocar o trimestre nas colunas, ambos os valores faltantes se tornarão explícitos:\n\nacoes |&gt;\n  pivot_wider(\n    names_from = trimestre, \n    values_from = preco\n  )\n#&gt; # A tibble: 2 × 5\n#&gt;     ano   `1`   `2`   `3`   `4`\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020  1.88  0.59  0.35 NA   \n#&gt; 2  2021 NA     0.92  0.17  2.66\n\nPor padrão, tornar os dados mais longos preserva os valores ausentes explícitos, mas se eles forem valores estruturalmente ausentes que só existem porque os dados não estão organizados, você pode eliminá-los (torná-los implícitos) definindo values_drop_na = TRUE. Veja os exemplos na Seção 5.2 para mais detalhes.\n\n18.3.2 Completar\nA função tidyr::complete() permite gerar valores faltantes explícitos, fornecendo um conjunto de variáveis ​​que definem a combinação de linhas que devem existir. Por exemplo, sabemos que todas as combinações de ano e trimestre devem existir nos dados de acoes:\n\nacoes |&gt;\n  complete(ano, trimestre)\n#&gt; # A tibble: 8 × 3\n#&gt;     ano trimestre preco\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2020         1  1.88\n#&gt; 2  2020         2  0.59\n#&gt; 3  2020         3  0.35\n#&gt; 4  2020         4 NA   \n#&gt; 5  2021         1 NA   \n#&gt; 6  2021         2  0.92\n#&gt; # ℹ 2 more rows\n\nNormalmente, você chamará complete() com nomes de variáveis ​​existentes, preenchendo as combinações que faltam. No entanto, às vezes as variáveis ​​individuais estão incompletas, então você pode fornecer seus próprios dados. Por exemplo, você pode saber que o conjunto de dados acoes deve ser executado de 2019 a 2021, então você pode fornecer explicitamente esses valores para ano:\n\nacoes |&gt;\n  complete(ano = 2019:2021, trimestre)\n#&gt; # A tibble: 12 × 3\n#&gt;     ano trimestre preco\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2019         1 NA   \n#&gt; 2  2019         2 NA   \n#&gt; 3  2019         3 NA   \n#&gt; 4  2019         4 NA   \n#&gt; 5  2020         1  1.88\n#&gt; 6  2020         2  0.59\n#&gt; # ℹ 6 more rows\n\nSe o intervalo de uma variável estiver correto, mas nem todos os valores estiverem presentes, você pode usar a full_seq(x, 1) para gerar todos os valores de min(x) a max(x) espaçados por 1.\nEm alguns casos, o conjunto completo de observações não pode ser gerado por uma simples combinação de variáveis. Nesse caso, você pode fazer manualmente o que complete() faz por você: criar um dataframe que contenha todas as linhas que deveriam existir (usando qualquer combinação de técnicas necessárias) e, em seguida, combiná-lo com seu conjunto de dados original com dplyr::full_join().\n\n18.3.3 Uniões (joins)\nIsso nos leva a outra forma importante de revelar observações implicitamente ausentes: uniões (joins). Você aprenderá mais sobre uniões na Capítulo 19, mas gostaríamos de mencioná-las rapidamente aqui, já que muitas vezes você só pode saber que valores estão faltando em um conjunto de dados quando você o compara com outro.\ndplyr::anti_join(x, y) é uma função particularmente útil aqui porque seleciona apenas as linhas em x que não têm correspondência em y. Por exemplo, podemos usar dois anti_join() para revelar que faltam informações de quatro aeroportos e 722 aviões mencionados em voos:\n\nlibrary(dados)\n\nvoos |&gt; \n  distinct(codigo_aeroporto = destino) |&gt; \n  anti_join(aeroportos)\n#&gt; Joining with `by = join_by(codigo_aeroporto)`\n#&gt; # A tibble: 4 × 1\n#&gt;   codigo_aeroporto\n#&gt;   &lt;chr&gt;           \n#&gt; 1 BQN             \n#&gt; 2 SJU             \n#&gt; 3 STT             \n#&gt; 4 PSE\n\nvoos |&gt; \n  distinct(codigo_cauda) |&gt; \n  anti_join(avioes)\n#&gt; Joining with `by = join_by(codigo_cauda)`\n#&gt; # A tibble: 722 × 1\n#&gt;   codigo_cauda\n#&gt;   &lt;chr&gt;       \n#&gt; 1 N3ALAA      \n#&gt; 2 N3DUAA      \n#&gt; 3 N542MQ      \n#&gt; 4 N730MQ      \n#&gt; 5 N9EAMQ      \n#&gt; 6 N532UA      \n#&gt; # ℹ 716 more rows\n\n\n18.3.4 Exercícios\n\nVocê consegue encontrar alguma relação entre a companhia_aerea e as linhas que parecem estar faltando em avioes?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "missing-values.html#fatores-e-grupos-vazios",
    "href": "missing-values.html#fatores-e-grupos-vazios",
    "title": "18  ✅ Valores faltantes",
    "section": "\n18.4 Fatores e grupos vazios",
    "text": "18.4 Fatores e grupos vazios\nUm último tipo de ausência é a de grupo vazio, um grupo que não contém nenhuma observação, que pode surgir ao trabalhar com fatores (factors). Por exemplo, imagine que temos um conjunto de dados que contém algumas informações de saúde sobre pessoas:\n\nsaude &lt;- tibble(\n  nome   = c(\"Ikaia\", \"Oletta\", \"Leriah\", \"Dashay\", \"Tresaun\"),\n  fumante = factor(c(\"nao\", \"nao\", \"nao\", \"nao\", \"nao\"), levels = c(\"sim\", \"nao\")),\n  idade    = c(34, 88, 75, 47, 56),\n)\n\nE queremos contar o número de fumantes com a função dplyr::count():\n\nsaude |&gt; count(fumante)\n#&gt; # A tibble: 1 × 2\n#&gt;   fumante     n\n#&gt;   &lt;fct&gt;   &lt;int&gt;\n#&gt; 1 nao         5\n\nEste conjunto de dados contém apenas não fumantes, mas sabemos que existem fumantes; o grupo de não fumantes está vazio. Podemos solicitar count() para manter todos os grupos, mesmo aqueles não vistos nos dados usando .drop = FALSE:\n\nsaude |&gt; count(fumante, .drop = FALSE)\n#&gt; # A tibble: 2 × 2\n#&gt;   fumante     n\n#&gt;   &lt;fct&gt;   &lt;int&gt;\n#&gt; 1 sim         0\n#&gt; 2 nao         5\n\nO mesmo princípio se aplica aos eixos discretos (discrete axis) do ggplot2, que também eliminarão níveis que não possuem nenhum valor. Você pode forçá-los a serem exibidos fornecendo drop = FALSE ao eixo discreto apropriado:\nggplot(saude, aes(x = fumante)) +\n  geom_bar() +\n  scale_x_discrete()\n\nggplot(saude, aes(x = fumante)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\n\n\n\n\n\n\n\n\n\n\nO mesmo problema surge de forma mais geral com dplyr::group_by(). E novamente você pode usar .drop = FALSE para preservar todos os níveis dos fatores:\n\nsaude |&gt; \n  group_by(fumante, .drop = FALSE) |&gt; \n  summarize(\n    n = n(),\n    idade_media = mean(idade),\n    idade_min = min(idade),\n    idade_max = max(idade),\n    idade_desvpad = sd(idade)\n  )\n#&gt; # A tibble: 2 × 6\n#&gt;   fumante     n idade_media idade_min idade_max idade_desvpad\n#&gt;   &lt;fct&gt;   &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1 sim         0         NaN       Inf      -Inf          NA  \n#&gt; 2 nao         5          60        34        88          21.6\n\nObtemos alguns resultados interessantes aqui porque ao sumarizar um grupo vazio, as funções de sumarização são aplicadas a vetores de comprimento zero. Há uma distinção importante entre vetores vazios, que têm comprimento 0, e valores ausentes, cada um dos quais tem comprimento 1.\n\n# Um vetor com dois valores ausentes\nx1 &lt;- c(NA, NA)\nlength(x1)\n#&gt; [1] 2\n\n# Um vetor contendo nada\nx2 &lt;- numeric()\nlength(x2)\n#&gt; [1] 0\n\nTodas as funções de sumarização funcionam com vetores de comprimento zero, mas podem retornar resultados surpreendentes à primeira vista. Aqui vemos mean(idade) retornando NaN porque mean(idade) = sum(age)/length(idade) que aqui é 0/0. max() e min() retornam -Inf e Inf para vetores vazios, então se você combinar os resultados com um vetor não vazio de novos dados e recalcular, você obterá o mínimo ou máximo dos novos dados1.\nÀs vezes, uma abordagem mais simples é realizar a sumarização e então tornar explícitas as faltas implícitas com complete().\n\nsaude |&gt; \n  group_by(fumante) |&gt; \n  summarize(\n    n = n(),\n    idade_media = mean(idade),\n    idade_min = min(idade),\n    idade_max = max(idade),\n    idade_desvpad = sd(idade)\n  ) |&gt; \n  complete(fumante)\n#&gt; # A tibble: 2 × 6\n#&gt;   fumante     n idade_media idade_min idade_max idade_desvpad\n#&gt;   &lt;fct&gt;   &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1 sim        NA          NA        NA        NA          NA  \n#&gt; 2 nao         5          60        34        88          21.6\n\nA principal desvantagem desta abordagem é que você obtém um NA para a contagem, mesmo sabendo que deveria ser zero.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "missing-values.html#resumo",
    "href": "missing-values.html#resumo",
    "title": "18  ✅ Valores faltantes",
    "section": "\n18.5 Resumo",
    "text": "18.5 Resumo\nValores faltantes são estranhos! Às vezes eles são registrados como um NA explícito, mas outras vezes você só os percebe pela sua ausência. Este capítulo forneceu algumas ferramentas para trabalhar com valores faltantes explícitos, ferramentas para descobrir valores faltantes implícitos e discutiu algumas das maneiras pelas quais os implícitos podem se tornar explícitos e vice-versa.\nNo próximo capítulo, abordamos o capítulo final desta parte do livro: uniões. Isso é uma pequena mudança em relação aos capítulos até agora porque discutiremos ferramentas que funcionam com data frames como um todo, não algo que você coloca dentro de um data frame.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "missing-values.html#footnotes",
    "href": "missing-values.html#footnotes",
    "title": "18  ✅ Valores faltantes",
    "section": "",
    "text": "Em outras palavras, min(c(x, y)) é sempre igual a min(min(x), min(y)).↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>✅ Valores faltantes</span>"
    ]
  },
  {
    "objectID": "joins.html",
    "href": "joins.html",
    "title": "19  Joins",
    "section": "",
    "text": "19.1 Introduction\nIt’s rare that a data analysis involves only a single data frame. Typically you have many data frames, and you must join them together to answer the questions that you’re interested in. This chapter will introduce you to two important types of joins:\nWe’ll begin by discussing keys, the variables used to connect a pair of data frames in a join. We cement the theory with an examination of the keys in the datasets from the nycflights13 package, then use that knowledge to start joining data frames together. Next we’ll discuss how joins work, focusing on their action on the rows. We’ll finish up with a discussion of non-equi joins, a family of joins that provide a more flexible way of matching keys than the default equality relationship.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#introduction",
    "href": "joins.html#introduction",
    "title": "19  Joins",
    "section": "",
    "text": "Mutating joins, which add new variables to one data frame from matching observations in another.\nFiltering joins, which filter observations from one data frame based on whether or not they match an observation in another.\n\n\n\n19.1.1 Prerequisites\nIn this chapter, we’ll explore the five related datasets from nycflights13 using the join functions from dplyr.\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#keys",
    "href": "joins.html#keys",
    "title": "19  Joins",
    "section": "\n19.2 Keys",
    "text": "19.2 Keys\nTo understand joins, you need to first understand how two tables can be connected through a pair of keys, within each table. In this section, you’ll learn about the two types of key and see examples of both in the datasets of the nycflights13 package. You’ll also learn how to check that your keys are valid, and what to do if your table lacks a key.\n\n19.2.1 Primary and foreign keys\nEvery join involves a pair of keys: a primary key and a foreign key. A primary key is a variable or set of variables that uniquely identifies each observation. When more than one variable is needed, the key is called a compound key. For example, in nycflights13:\n\n\nairlines records two pieces of data about each airline: its carrier code and its full name. You can identify an airline with its two letter carrier code, making carrier the primary key.\n\nairlines\n#&gt; # A tibble: 16 × 2\n#&gt;   carrier name                    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                   \n#&gt; 1 9E      Endeavor Air Inc.       \n#&gt; 2 AA      American Airlines Inc.  \n#&gt; 3 AS      Alaska Airlines Inc.    \n#&gt; 4 B6      JetBlue Airways         \n#&gt; 5 DL      Delta Air Lines Inc.    \n#&gt; 6 EV      ExpressJet Airlines Inc.\n#&gt; # ℹ 10 more rows\n\n\n\nairports records data about each airport. You can identify each airport by its three letter airport code, making faa the primary key.\n\nairports\n#&gt; # A tibble: 1,458 × 8\n#&gt;   faa   name                            lat   lon   alt    tz dst  \n#&gt;   &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A    \n#&gt; 2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A    \n#&gt; 3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A    \n#&gt; 4 06N   Randall Airport                41.4 -74.4   523    -5 A    \n#&gt; 5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A    \n#&gt; 6 0A9   Elizabethton Municipal Airpo…  36.4 -82.2  1593    -5 A    \n#&gt; # ℹ 1,452 more rows\n#&gt; # ℹ 1 more variable: tzone &lt;chr&gt;\n\n\n\nplanes records data about each plane. You can identify a plane by its tail number, making tailnum the primary key.\n\nplanes\n#&gt; # A tibble: 3,322 × 9\n#&gt;   tailnum  year type              manufacturer    model     engines\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 N10156   2004 Fixed wing multi… EMBRAER         EMB-145XR       2\n#&gt; 2 N102UW   1998 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 3 N103US   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 4 N104UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 5 N10575   2002 Fixed wing multi… EMBRAER         EMB-145LR       2\n#&gt; 6 N105UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; # ℹ 3,316 more rows\n#&gt; # ℹ 3 more variables: seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\n\n\nweather records data about the weather at the origin airports. You can identify each observation by the combination of location and time, making origin and time_hour the compound primary key.\n\nweather\n#&gt; # A tibble: 26,115 × 15\n#&gt;   origin  year month   day  hour  temp  dewp humid wind_dir\n#&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 EWR     2013     1     1     1  39.0  26.1  59.4      270\n#&gt; 2 EWR     2013     1     1     2  39.0  27.0  61.6      250\n#&gt; 3 EWR     2013     1     1     3  39.0  28.0  64.4      240\n#&gt; 4 EWR     2013     1     1     4  39.9  28.0  62.2      250\n#&gt; 5 EWR     2013     1     1     5  39.0  28.0  64.4      260\n#&gt; 6 EWR     2013     1     1     6  37.9  28.0  67.2      240\n#&gt; # ℹ 26,109 more rows\n#&gt; # ℹ 6 more variables: wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, …\n\n\n\nA foreign key is a variable (or set of variables) that corresponds to a primary key in another table. For example:\n\n\nflights$tailnum is a foreign key that corresponds to the primary key planes$tailnum.\n\nflights$carrier is a foreign key that corresponds to the primary key airlines$carrier.\n\nflights$origin is a foreign key that corresponds to the primary key airports$faa.\n\nflights$dest is a foreign key that corresponds to the primary key airports$faa.\n\nflights$origin-flights$time_hour is a compound foreign key that corresponds to the compound primary key weather$origin-weather$time_hour.\n\nThese relationships are summarized visually in Figura 19.1.\n\n\n\n\n\n\n\nFigura 19.1: Connections between all five data frames in the nycflights13 package. Variables making up a primary key are colored grey, and are connected to their corresponding foreign keys with arrows.\n\n\n\n\nYou’ll notice a nice feature in the design of these keys: the primary and foreign keys almost always have the same names, which, as you’ll see shortly, will make your joining life much easier. It’s also worth noting the opposite relationship: almost every variable name used in multiple tables has the same meaning in each place. There’s only one exception: year means year of departure in flights and year of manufacturer in planes. This will become important when we start actually joining tables together.\n\n19.2.2 Checking primary keys\nNow that that we’ve identified the primary keys in each table, it’s good practice to verify that they do indeed uniquely identify each observation. One way to do that is to count() the primary keys and look for entries where n is greater than one. This reveals that planes and weather both look good:\n\nplanes |&gt; \n  count(tailnum) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 2\n#&gt; # ℹ 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt;\n\nweather |&gt; \n  count(time_hour, origin) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 3\n#&gt; # ℹ 3 variables: time_hour &lt;dttm&gt;, origin &lt;chr&gt;, n &lt;int&gt;\n\nYou should also check for missing values in your primary keys — if a value is missing then it can’t identify an observation!\n\nplanes |&gt; \n  filter(is.na(tailnum))\n#&gt; # A tibble: 0 × 9\n#&gt; # ℹ 9 variables: tailnum &lt;chr&gt;, year &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;,\n#&gt; #   model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\nweather |&gt; \n  filter(is.na(time_hour) | is.na(origin))\n#&gt; # A tibble: 0 × 15\n#&gt; # ℹ 15 variables: origin &lt;chr&gt;, year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;,\n#&gt; #   hour &lt;int&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, …\n\n\n19.2.3 Surrogate keys\nSo far we haven’t talked about the primary key for flights. It’s not super important here, because there are no data frames that use it as a foreign key, but it’s still useful to consider because it’s easier to work with observations if we have some way to describe them to others.\nAfter a little thinking and experimentation, we determined that there are three variables that together uniquely identify each flight:\n\nflights |&gt; \n  count(time_hour, carrier, flight) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: time_hour &lt;dttm&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, n &lt;int&gt;\n\nDoes the absence of duplicates automatically make time_hour-carrier-flight a primary key? It’s certainly a good start, but it doesn’t guarantee it. For example, are altitude and latitude a good primary key for airports?\n\nairports |&gt;\n  count(alt, lat) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 × 3\n#&gt;     alt   lat     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    13  40.6     2\n\nIdentifying an airport by its altitude and latitude is clearly a bad idea, and in general it’s not possible to know from the data alone whether or not a combination of variables makes a good a primary key. But for flights, the combination of time_hour, carrier, and flight seems reasonable because it would be really confusing for an airline and its customers if there were multiple flights with the same flight number in the air at the same time.\nThat said, we might be better off introducing a simple numeric surrogate key using the row number:\n\nflights2 &lt;- flights |&gt; \n  mutate(id = row_number(), .before = 1)\nflights2\n#&gt; # A tibble: 336,776 × 20\n#&gt;      id  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1     1  2013     1     1      517            515         2      830\n#&gt; 2     2  2013     1     1      533            529         4      850\n#&gt; 3     3  2013     1     1      542            540         2      923\n#&gt; 4     4  2013     1     1      544            545        -1     1004\n#&gt; 5     5  2013     1     1      554            600        -6      812\n#&gt; 6     6  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\nSurrogate keys can be particularly useful when communicating to other humans: it’s much easier to tell someone to take a look at flight 2001 than to say look at UA430 which departed 9am 2013-01-03.\n\n19.2.4 Exercises\n\nWe forgot to draw the relationship between weather and airports in Figura 19.1. What is the relationship and how should it appear in the diagram?\nweather only contains information for the three origin airports in NYC. If it contained weather records for all airports in the USA, what additional connection would it make to flights?\nThe year, month, day, hour, and origin variables almost form a compound key for weather, but there’s one hour that has duplicate observations. Can you figure out what’s special about that hour?\nWe know that some days of the year are special and fewer people than usual fly on them (e.g., Christmas eve and Christmas day). How might you represent that data as a data frame? What would be the primary key? How would it connect to the existing data frames?\nDraw a diagram illustrating the connections between the Batting, People, and Salaries data frames in the Lahman package. Draw another diagram that shows the relationship between People, Managers, AwardsManagers. How would you characterize the relationship between the Batting, Pitching, and Fielding data frames?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-mutating-joins",
    "href": "joins.html#sec-mutating-joins",
    "title": "19  Joins",
    "section": "\n19.3 Basic joins",
    "text": "19.3 Basic joins\nNow that you understand how data frames are connected via keys, we can start using joins to better understand the flights dataset. dplyr provides six join functions: left_join(), inner_join(), right_join(), full_join(), semi_join(), and anti_join(). They all have the same interface: they take a pair of data frames (x and y) and return a data frame. The order of the rows and columns in the output is primarily determined by x.\nIn this section, you’ll learn how to use one mutating join, left_join(), and two filtering joins, semi_join() and anti_join(). In the next section, you’ll learn exactly how these functions work, and about the remaining inner_join(), right_join() and full_join().\n\n19.3.1 Mutating joins\nA mutating join allows you to combine variables from two data frames: it first matches observations by their keys, then copies across variables from one data frame to the other. Like mutate(), the join functions add variables to the right, so if your dataset has many variables, you won’t see the new ones. For these examples, we’ll make it easier to see what’s going on by creating a narrower dataset with just six variables1:\n\nflights2 &lt;- flights |&gt; \n  select(year, time_hour, origin, dest, tailnum, carrier)\nflights2\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year time_hour           origin dest  tailnum carrier\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     \n#&gt; # ℹ 336,770 more rows\n\nThere are four types of mutating join, but there’s one that you’ll use almost all of the time: left_join(). It’s special because the output will always have the same rows as x, the data frame you’re joining to2. The primary use of left_join() is to add in additional metadata. For example, we can use left_join() to add the full airline name to the flights2 data:\n\nflights2 |&gt;\n  left_join(airlines)\n#&gt; Joining with `by = join_by(carrier)`\n#&gt; # A tibble: 336,776 × 7\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines In…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines In…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines I…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines In…\n#&gt; # ℹ 336,770 more rows\n\nOr we could find out the temperature and wind speed when each plane departed:\n\nflights2 |&gt; \n  left_join(weather |&gt; select(origin, time_hour, temp, wind_speed))\n#&gt; Joining with `by = join_by(time_hour, origin)`\n#&gt; # A tibble: 336,776 × 8\n#&gt;    year time_hour           origin dest  tailnum carrier  temp wind_speed\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7\n#&gt; # ℹ 336,770 more rows\n\nOr what size of plane was flying:\n\nflights2 |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 336,776 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Fixed wing multi en…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      Fixed wing multi en…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Fixed wing multi en…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      Fixed wing multi en…\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Fixed wing multi en…\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Fixed wing multi en…\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 2 more variables: engines &lt;int&gt;, seats &lt;int&gt;\n\nWhen left_join() fails to find a match for a row in x, it fills in the new variables with missing values. For example, there’s no information about the plane with tail number N3ALAA so the type, engines, and seats will be missing:\n\nflights2 |&gt; \n  filter(tailnum == \"N3ALAA\") |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 63 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type  engines seats\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 2  2013 2013-01-02 18:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 3  2013 2013-01-03 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 4  2013 2013-01-07 19:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 5  2013 2013-01-08 17:00:00 JFK    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 6  2013 2013-01-16 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; # ℹ 57 more rows\n\nWe’ll come back to this problem a few times in the rest of the chapter.\n\n19.3.2 Specifying join keys\nBy default, left_join() will use all variables that appear in both data frames as the join key, the so called natural join. This is a useful heuristic, but it doesn’t always work. For example, what happens if we try to join flights2 with the complete planes dataset?\n\nflights2 |&gt; \n  left_join(planes)\n#&gt; Joining with `by = join_by(year, tailnum)`\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier type  manufacturer\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 5 more variables: model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, …\n\nWe get a lot of missing matches because our join is trying to use tailnum and year as a compound key. Both flights and planes have a year column but they mean different things: flights$year is the year the flight occurred and planes$year is the year the plane was built. We only want to join on tailnum so we need to provide an explicit specification with join_by():\n\nflights2 |&gt; \n  left_join(planes, join_by(tailnum))\n#&gt; # A tibble: 336,776 × 14\n#&gt;   year.x time_hour           origin dest  tailnum carrier year.y\n#&gt;    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999\n#&gt; 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998\n#&gt; 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990\n#&gt; 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012\n#&gt; 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991\n#&gt; 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 7 more variables: type &lt;chr&gt;, manufacturer &lt;chr&gt;, model &lt;chr&gt;, …\n\nNote that the year variables are disambiguated in the output with a suffix (year.x and year.y), which tells you whether the variable came from the x or y argument. You can override the default suffixes with the suffix argument.\njoin_by(tailnum) is short for join_by(tailnum == tailnum). It’s important to know about this fuller form for two reasons. Firstly, it describes the relationship between the two tables: the keys must be equal. That’s why this type of join is often called an equi join. You’ll learn about non-equi joins in Seção 19.5.\nSecondly, it’s how you specify different join keys in each table. For example, there are two ways to join the flight2 and airports table: either by dest or origin:\n\nflights2 |&gt; \n  left_join(airports, join_by(dest == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bush Interco…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bush Interco…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl          \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;                \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfield Jackson …\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago Ohare Intl  \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\nflights2 |&gt; \n  left_join(airports, join_by(origin == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name               \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;              \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Newark Liberty Intl\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia         \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia         \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Newark Liberty Intl\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\nIn older code you might see a different way of specifying the join keys, using a character vector:\n\n\nby = \"x\" corresponds to join_by(x).\n\nby = c(\"a\" = \"x\") corresponds to join_by(a == x).\n\nNow that it exists, we prefer join_by() since it provides a clearer and more flexible specification.\ninner_join(), right_join(), full_join() have the same interface as left_join(). The difference is which rows they keep: left join keeps all the rows in x, the right join keeps all rows in y, the full join keeps all rows in either x or y, and the inner join only keeps rows that occur in both x and y. We’ll come back to these in more detail later.\n\n19.3.3 Filtering joins\nAs you might guess the primary action of a filtering join is to filter the rows. There are two types: semi-joins and anti-joins. Semi-joins keep all rows in x that have a match in y. For example, we could use a semi-join to filter the airports dataset to show just the origin airports:\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == origin))\n#&gt; # A tibble: 3 × 8\n#&gt;   faa   name                  lat   lon   alt    tz dst   tzone           \n#&gt;   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n#&gt; 1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n#&gt; 2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n#&gt; 3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York\n\nOr just the destinations:\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == dest))\n#&gt; # A tibble: 101 × 8\n#&gt;   faa   name                     lat    lon   alt    tz dst   tzone          \n#&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          \n#&gt; 1 ABQ   Albuquerque Internati…  35.0 -107.   5355    -7 A     America/Denver \n#&gt; 2 ACK   Nantucket Mem           41.3  -70.1    48    -5 A     America/New_Yo…\n#&gt; 3 ALB   Albany Intl             42.7  -73.8   285    -5 A     America/New_Yo…\n#&gt; 4 ANC   Ted Stevens Anchorage…  61.2 -150.    152    -9 A     America/Anchor…\n#&gt; 5 ATL   Hartsfield Jackson At…  33.6  -84.4  1026    -5 A     America/New_Yo…\n#&gt; 6 AUS   Austin Bergstrom Intl   30.2  -97.7   542    -6 A     America/Chicago\n#&gt; # ℹ 95 more rows\n\nAnti-joins are the opposite: they return all rows in x that don’t have a match in y. They’re useful for finding missing values that are implicit in the data, the topic of Seção 18.3. Implicitly missing values don’t show up as NAs but instead only exist as an absence. For example, we can find rows that are missing from airports by looking for flights that don’t have a matching destination airport:\n\nflights2 |&gt; \n  anti_join(airports, join_by(dest == faa)) |&gt; \n  distinct(dest)\n#&gt; # A tibble: 4 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\nOr we can find which tailnums are missing from planes:\n\nflights2 |&gt;\n  anti_join(planes, join_by(tailnum)) |&gt; \n  distinct(tailnum)\n#&gt; # A tibble: 722 × 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # ℹ 716 more rows\n\n\n19.3.4 Exercises\n\nFind the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns?\n\nImagine you’ve found the top 10 most popular destinations using this code:\n\ntop_dest &lt;- flights2 |&gt;\n  count(dest, sort = TRUE) |&gt;\n  head(10)\n\nHow can you find all flights to those destinations?\n\nDoes every departing flight have corresponding weather data for that hour?\nWhat do the tail numbers that don’t have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.)\nAdd a column to planes that lists every carrier that has flown that plane. You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned in previous chapters.\nAdd the latitude and the longitude of the origin and destination airport to flights. Is it easier to rename the columns before or after the join?\n\nCompute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States:\n\nairports |&gt;\n  semi_join(flights, join_by(faa == dest)) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()\n\nYou might want to use the size or color of the points to display the average delay for each airport.\n\nWhat happened on June 13 2013? Draw a map of the delays, and then use Google to cross-reference with the weather.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#how-do-joins-work",
    "href": "joins.html#how-do-joins-work",
    "title": "19  Joins",
    "section": "\n19.4 How do joins work?",
    "text": "19.4 How do joins work?\nNow that you’ve used joins a few times it’s time to learn more about how they work, focusing on how each row in x matches rows in y. We’ll begin by introducing a visual representation of joins, using the simple tibbles defined below and shown in Figura 19.2. In these examples we’ll use a single key called key and a single value column (val_x and val_y), but the ideas all generalize to multiple keys and multiple values.\n\nx &lt;- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     3, \"x3\"\n)\ny &lt;- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     4, \"y3\"\n)\n\n\n\n\n\n\n\n\nFigura 19.2: Graphical representation of two simple tables. The colored key columns map background color to key value. The grey columns represent the “value” columns that are carried along for the ride.\n\n\n\n\nFigura 19.3 introduces the foundation for our visual representation. It shows all potential matches between x and y as the intersection between lines drawn from each row of x and each row of y. The rows and columns in the output are primarily determined by x, so the x table is horizontal and lines up with the output.\n\n\n\n\n\n\n\nFigura 19.3: To understand how joins work, it’s useful to think of every possible match. Here we show that with a grid of connecting lines.\n\n\n\n\nTo describe a specific type of join, we indicate matches with dots. The matches determine the rows in the output, a new data frame that contains the key, the x values, and the y values. For example, Figura 19.4 shows an inner join, where rows are retained if and only if the keys are equal.\n\n\n\n\n\n\n\nFigura 19.4: An inner join matches each row in x to the row in y that has the same value of key. Each match becomes a row in the output.\n\n\n\n\nWe can apply the same principles to explain the outer joins, which keep observations that appear in at least one of the data frames. These joins work by adding an additional “virtual” observation to each data frame. This observation has a key that matches if no other key matches, and values filled with NA. There are three types of outer joins:\n\n\nA left join keeps all observations in x, Figura 19.5. Every row of x is preserved in the output because it can fall back to matching a row of NAs in y.\n\n\n\n\n\n\n\nFigura 19.5: A visual representation of the left join where every row in x appears in the output.\n\n\n\n\n\n\nA right join keeps all observations in y, Figura 19.6. Every row of y is preserved in the output because it can fall back to matching a row of NAs in x. The output still matches x as much as possible; any extra rows from y are added to the end.\n\n\n\n\n\n\n\nFigura 19.6: A visual representation of the right join where every row of y appears in the output.\n\n\n\n\n\n\nA full join keeps all observations that appear in x or y, Figura 19.7. Every row of x and y is included in the output because both x and y have a fall back row of NAs. Again, the output starts with all rows from x, followed by the remaining unmatched y rows.\n\n\n\n\n\n\n\nFigura 19.7: A visual representation of the full join where every row in x and y appears in the output.\n\n\n\n\n\n\nAnother way to show how the types of outer join differ is with a Venn diagram, as in Figura 19.8. However, this is not a great representation because while it might jog your memory about which rows are preserved, it fails to illustrate what’s happening with the columns.\n\n\n\n\n\n\n\nFigura 19.8: Venn diagrams showing the difference between inner, left, right, and full joins.\n\n\n\n\nThe joins shown here are the so-called equi joins, where rows match if the keys are equal. Equi joins are the most common type of join, so we’ll typically omit the equi prefix, and just say “inner join” rather than “equi inner join”. We’ll come back to non-equi joins in Seção 19.5.\n\n19.4.1 Row matching\nSo far we’ve explored what happens if a row in x matches zero or one row in y. What happens if it matches more than one row? To understand what’s going let’s first narrow our focus to the inner_join() and then draw a picture, Figura 19.9.\n\n\n\n\n\n\n\nFigura 19.9: The three ways a row in x can match. x1 matches one row in y, x2 matches two rows in y, x3 matches zero rows in y. Note that while there are three rows in x and three rows in the output, there isn’t a direct correspondence between the rows.\n\n\n\n\nThere are three possible outcomes for a row in x:\n\nIf it doesn’t match anything, it’s dropped.\nIf it matches 1 row in y, it’s preserved.\nIf it matches more than 1 row in y, it’s duplicated once for each match.\n\nIn principle, this means that there’s no guaranteed correspondence between the rows in the output and the rows in x, but in practice, this rarely causes problems. There is, however, one particularly dangerous case which can cause a combinatorial explosion of rows. Imagine joining the following two tables:\n\ndf1 &lt;- tibble(key = c(1, 2, 2), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(key = c(1, 2, 2), val_y = c(\"y1\", \"y2\", \"y3\"))\n\nWhile the first row in df1 only matches one row in df2, the second and third rows both match two rows. This is sometimes called a many-to-many join, and will cause dplyr to emit a warning:\n\ndf1 |&gt; \n  inner_join(df2, join_by(key))\n#&gt; Warning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.\n#&gt; ℹ Row 2 of `x` matches multiple rows in `y`.\n#&gt; ℹ Row 2 of `y` matches multiple rows in `x`.\n#&gt; ℹ If a many-to-many relationship is expected, set `relationship =\n#&gt;   \"many-to-many\"` to silence this warning.\n#&gt; # A tibble: 5 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y3   \n#&gt; 4     2 x3    y2   \n#&gt; 5     2 x3    y3\n\nIf you are doing this deliberately, you can set relationship = \"many-to-many\", as the warning suggests.\n\n19.4.2 Filtering joins\nThe number of matches also determines the behavior of the filtering joins. The semi-join keeps rows in x that have one or more matches in y, as in Figura 19.10. The anti-join keeps rows in x that match zero rows in y, as in Figura 19.11. In both cases, only the existence of a match is important; it doesn’t matter how many times it matches. This means that filtering joins never duplicate rows like mutating joins do.\n\n\n\n\n\n\n\nFigura 19.10: In a semi-join it only matters that there is a match; otherwise values in y don’t affect the output.\n\n\n\n\n\n\n\n\n\n\n\nFigura 19.11: An anti-join is the inverse of a semi-join, dropping rows from x that have a match in y.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#sec-non-equi-joins",
    "href": "joins.html#sec-non-equi-joins",
    "title": "19  Joins",
    "section": "\n19.5 Non-equi joins",
    "text": "19.5 Non-equi joins\nSo far you’ve only seen equi joins, joins where the rows match if the x key equals the y key. Now we’re going to relax that restriction and discuss other ways of determining if a pair of rows match.\nBut before we can do that, we need to revisit a simplification we made above. In equi joins the x keys and y are always equal, so we only need to show one in the output. We can request that dplyr keep both keys with keep = TRUE, leading to the code below and the re-drawn inner_join() in Figura 19.12.\n\nx |&gt; inner_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 2 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2\n\n\n\n\n\n\n\n\nFigura 19.12: An inner join showing both x and y keys in the output.\n\n\n\n\nWhen we move away from equi joins we’ll always show the keys, because the key values will often be different. For example, instead of matching only when the x$key and y$key are equal, we could match whenever the x$key is greater than or equal to the y$key, leading to Figura 19.13. dplyr’s join functions understand this distinction equi and non-equi joins so will always show both keys when you perform a non-equi join.\n\n\n\n\n\n\n\nFigura 19.13: A non-equi join where the x key must be greater than or equal to the y key. Many rows generate multiple matches.\n\n\n\n\nNon-equi join isn’t a particularly useful term because it only tells you what the join is not, not what it is. dplyr helps by identifying four particularly useful types of non-equi join:\n\n\nCross joins match every pair of rows.\n\nInequality joins use &lt;, &lt;=, &gt;, and &gt;= instead of ==.\n\nRolling joins are similar to inequality joins but only find the closest match.\n\nOverlap joins are a special type of inequality join designed to work with ranges.\n\nEach of these is described in more detail in the following sections.\n\n19.5.1 Cross joins\nA cross join matches everything, as in Figura 19.14, generating the Cartesian product of rows. This means the output will have nrow(x) * nrow(y) rows.\n\n\n\n\n\n\n\nFigura 19.14: A cross join matches each row in x with every row in y.\n\n\n\n\nCross joins are useful when generating permutations. For example, the code below generates every possible pair of names. Since we’re joining df to itself, this is sometimes called a self-join. Cross joins use a different join function because there’s no distinction between inner/left/right/full when you’re matching every row.\n\ndf &lt;- tibble(name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\ndf |&gt; cross_join(df)\n#&gt; # A tibble: 16 × 2\n#&gt;   name.x name.y\n#&gt;   &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 John   John  \n#&gt; 2 John   Simon \n#&gt; 3 John   Tracy \n#&gt; 4 John   Max   \n#&gt; 5 Simon  John  \n#&gt; 6 Simon  Simon \n#&gt; # ℹ 10 more rows\n\n\n19.5.2 Inequality joins\nInequality joins use &lt;, &lt;=, &gt;=, or &gt; to restrict the set of possible matches, as in Figura 19.13 and Figura 19.15.\n\n\n\n\n\n\n\nFigura 19.15: An inequality join where x is joined to y on rows where the key of x is less than the key of y. This makes a triangular shape in the top-left corner.\n\n\n\n\nInequality joins are extremely general, so general that it’s hard to come up with meaningful specific use cases. One small useful technique is to use them to restrict the cross join so that instead of generating all permutations, we generate all combinations:\n\ndf &lt;- tibble(id = 1:4, name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\n\ndf |&gt; inner_join(df, join_by(id &lt; id))\n#&gt; # A tibble: 6 × 4\n#&gt;    id.x name.x  id.y name.y\n#&gt;   &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; \n#&gt; 1     1 John       2 Simon \n#&gt; 2     1 John       3 Tracy \n#&gt; 3     1 John       4 Max   \n#&gt; 4     2 Simon      3 Tracy \n#&gt; 5     2 Simon      4 Max   \n#&gt; 6     3 Tracy      4 Max\n\n\n19.5.3 Rolling joins\nRolling joins are a special type of inequality join where instead of getting every row that satisfies the inequality, you get just the closest row, as in Figura 19.16. You can turn any inequality join into a rolling join by adding closest(). For example join_by(closest(x &lt;= y)) matches the smallest y that’s greater than or equal to x, and join_by(closest(x &gt; y)) matches the biggest y that’s less than x.\n\n\n\n\n\n\n\nFigura 19.16: A rolling join is similar to a greater-than-or-equal inequality join but only matches the first value.\n\n\n\n\nRolling joins are particularly useful when you have two tables of dates that don’t perfectly line up and you want to find (e.g.) the closest date in table 1 that comes before (or after) some date in table 2.\nFor example, imagine that you’re in charge of the party planning commission for your office. Your company is rather cheap so instead of having individual parties, you only have a party once each quarter. The rules for determining when a party will be held are a little complex: parties are always on a Monday, you skip the first week of January since a lot of people are on holiday, and the first Monday of Q3 2022 is July 4, so that has to be pushed back a week. That leads to the following party days:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\"))\n)\n\nNow imagine that you have a table of employee birthdays:\n\nset.seed(123)\nemployees &lt;- tibble(\n  name = sample(babynames::babynames$name, 100),\n  birthday = ymd(\"2022-01-01\") + (sample(365, 100, replace = TRUE) - 1)\n)\nemployees\n#&gt; # A tibble: 100 × 2\n#&gt;   name     birthday  \n#&gt;   &lt;chr&gt;    &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22\n#&gt; 2 Orean    2022-06-26\n#&gt; 3 Kirstyn  2022-02-11\n#&gt; 4 Amparo   2022-11-11\n#&gt; 5 Belen    2022-03-25\n#&gt; 6 Rayshaun 2022-01-11\n#&gt; # ℹ 94 more rows\n\nAnd for each employee we want to find the first party date that comes after (or on) their birthday. We can express that with a rolling join:\n\nemployees |&gt; \n  left_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 100 × 4\n#&gt;   name     birthday       q party     \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10\n#&gt; 2 Orean    2022-06-26     2 2022-04-04\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03\n#&gt; 5 Belen    2022-03-25     1 2022-01-10\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10\n#&gt; # ℹ 94 more rows\n\nThere is, however, one problem with this approach: the folks with birthdays before January 10 don’t get a party:\n\nemployees |&gt; \n  anti_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 2 × 2\n#&gt;   name   birthday  \n#&gt;   &lt;chr&gt;  &lt;date&gt;    \n#&gt; 1 Maks   2022-01-07\n#&gt; 2 Nalani 2022-01-04\n\nTo resolve that issue we’ll need to tackle the problem a different way, with overlap joins.\n\n19.5.4 Overlap joins\nOverlap joins provide three helpers that use inequality joins to make it easier to work with intervals:\n\n\nbetween(x, y_lower, y_upper) is short for x &gt;= y_lower, x &lt;= y_upper.\n\nwithin(x_lower, x_upper, y_lower, y_upper) is short for x_lower &gt;= y_lower, x_upper &lt;= y_upper.\n\noverlaps(x_lower, x_upper, y_lower, y_upper) is short for x_lower &lt;= y_upper, x_upper &gt;= y_lower.\n\nLet’s continue the birthday example to see how you might use them. There’s one problem with the strategy we used above: there’s no party preceding the birthdays Jan 1-9. So it might be better to be explicit about the date ranges that each party spans, and make a special case for those early birthdays:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-11\", \"2022-10-02\", \"2022-12-31\"))\n)\nparties\n#&gt; # A tibble: 4 × 4\n#&gt;       q party      start      end       \n#&gt;   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2     2 2022-04-04 2022-04-04 2022-07-11\n#&gt; 3     3 2022-07-11 2022-07-11 2022-10-02\n#&gt; 4     4 2022-10-03 2022-10-03 2022-12-31\n\nHadley is hopelessly bad at data entry so he also wanted to check that the party periods don’t overlap. One way to do this is by using a self-join to check if any start-end interval overlap with another:\n\nparties |&gt; \n  inner_join(parties, join_by(overlaps(start, end, start, end), q &lt; q)) |&gt; \n  select(start.x, end.x, start.y, end.y)\n#&gt; # A tibble: 1 × 4\n#&gt;   start.x    end.x      start.y    end.y     \n#&gt;   &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02\n\nOoops, there is an overlap, so let’s fix that problem and continue:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-10\", \"2022-10-02\", \"2022-12-31\"))\n)\n\nNow we can match each employee to their party. This is a good place to use unmatched = \"error\" because we want to quickly find out if any employees didn’t get assigned a party.\n\nemployees |&gt; \n  inner_join(parties, join_by(between(birthday, start, end)), unmatched = \"error\")\n#&gt; # A tibble: 100 × 6\n#&gt;   name     birthday       q party      start      end       \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2 Orean    2022-06-26     2 2022-04-04 2022-04-04 2022-07-10\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03 2022-10-03 2022-12-31\n#&gt; 5 Belen    2022-03-25     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; # ℹ 94 more rows\n\n\n19.5.5 Exercises\n\n\nCan you explain what’s happening with the keys in this equi join? Why are they different?\n\nx |&gt; full_join(y, join_by(key == key))\n#&gt; # A tibble: 4 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y3\n\nx |&gt; full_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 4 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2   \n#&gt; 3     3 x3       NA &lt;NA&gt; \n#&gt; 4    NA &lt;NA&gt;      4 y3\n\n\nWhen finding if any party period overlapped with another party period we used q &lt; q in the join_by()? Why? What happens if you remove this inequality?",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#summary",
    "href": "joins.html#summary",
    "title": "19  Joins",
    "section": "\n19.6 Summary",
    "text": "19.6 Summary\nIn this chapter, you’ve learned how to use mutating and filtering joins to combine data from a pair of data frames. Along the way you learned how to identify keys, and the difference between primary and foreign keys. You also understand how joins work and how to figure out how many rows the output will have. Finally, you’ve gained a glimpse into the power of non-equi joins and seen a few interesting use cases.\nThis chapter concludes the “Transform” part of the book where the focus was on the tools you could use with individual columns and tibbles. You learned about dplyr and base functions for working with logical vectors, numbers, and complete tables, stringr functions for working with strings, lubridate functions for working with date-times, and forcats functions for working with factors.\nIn the next part of the book, you’ll learn more about getting various types of data into R in a tidy form.",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "joins.html#footnotes",
    "href": "joins.html#footnotes",
    "title": "19  Joins",
    "section": "",
    "text": "Remember that in RStudio you can also use View() to avoid this problem.↩︎\nThat’s not 100% true, but you’ll get a warning whenever it isn’t.↩︎",
    "crumbs": [
      "✅ Transformar",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "✅ Importar",
    "section": "",
    "text": "Nesta parte do livro, você aprenderá como importar uma vasta variedade de dados para o R, assim como deixá-los em uma forma útil para suas análises. Algumas vezes, isto é apenas uma questão de chamar uma função de um pacote de importação de dados apropriado. Mas em casos mais complexos, será necessário tanto a organização e transformação dos dados para se obter o formato retangular (tidy) que você gostaria de trabalhar.\n\n\n\n\n\n\n\nFigura 1: Importação dos dados é o início do processo da ciência de dados; sem dados você não pode praticar ciência de dados!\n\n\n\n\nNesta parte do livro você aprenderá como acessar dados armazenados das seguintes maneiras:\n\nNo 20  Spreadsheets, você aprenderá como importar dados de planilhas do Excel e do Planilhas Google (Google Sheets).\nNo 21  ✅ Bancos de dados, você aprenderá sobre obter dados de um banco de dados (databases) e importar para o R (e você também aprenderá um pouco sobre como exportar dados do R para um banco de dados).\nNo 22  Arrow, você aprenderá sobre o Arrow, uma poderosa ferramenta para trabalhar com volume de dados que não cabem na memória do seu computador, particularmente quando são armazenados em formato parquet.\nNo 23  Hierarchical data, você aprenderá como trabalhar com dados hierárquicos, incluindo as listas profundamente aninhadas produzidas por dados em formato JSON.\nNo 24  ✅ Raspagem de dados (Web scraping), você aprenderá sobre raspagem de dados (web scraping), a arte e a ciência de extrair dados de páginas web.\n\nExistem dois pacotes tidyverse importantes que não são apresentados aqui: haven e xml2. Se você está trabalhando com dados de arquivos do SPSS, Stata ou SAS, veja o pacote haven , https://haven.tidyverse.org. Se você está trabalhando com dados XML, veja o pacote xml2 , https://xml2.r-lib.org. Caso contrário, você precisará pesquisar qual pacote você deverá utilizar; o Google será seu amigo neste caso 😃.",
    "crumbs": [
      "✅ Importar"
    ]
  },
  {
    "objectID": "spreadsheets.html",
    "href": "spreadsheets.html",
    "title": "20  Spreadsheets",
    "section": "",
    "text": "20.1 Introduction\nIn Capítulo 7 you learned about importing data from plain text files like .csv and .tsv. Now it’s time to learn how to get data out of a spreadsheet, either an Excel spreadsheet or a Google Sheet. This will build on much of what you’ve learned in Capítulo 7, but we will also discuss additional considerations and complexities when working with data from spreadsheets.\nIf you or your collaborators are using spreadsheets for organizing data, we strongly recommend reading the paper “Data Organization in Spreadsheets” by Karl Broman and Kara Woo: https://doi.org/10.1080/00031305.2017.1375989. The best practices presented in this paper will save you much headache when you import data from a spreadsheet into R to analyze and visualize.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#excel",
    "href": "spreadsheets.html#excel",
    "title": "20  Spreadsheets",
    "section": "\n20.2 Excel",
    "text": "20.2 Excel\nMicrosoft Excel is a widely used spreadsheet software program where data are organized in worksheets inside of spreadsheet files.\n\n20.2.1 Prerequisites\nIn this section, you’ll learn how to load data from Excel spreadsheets in R with the readxl package. This package is non-core tidyverse, so you need to load it explicitly, but it is installed automatically when you install the tidyverse package. Later, we’ll also use the writexl package, which allows us to create Excel spreadsheets.\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(writexl)\n\n\n20.2.2 Getting started\nMost of readxl’s functions allow you to load Excel spreadsheets into R:\n\n\nread_xls() reads Excel files with xls format.\n\nread_xlsx() read Excel files with xlsx format.\n\nread_excel() can read files with both xls and xlsx format. It guesses the file type based on the input.\n\nThese functions all have similar syntax just like other functions we have previously introduced for reading other types of files, e.g., read_csv(), read_table(), etc. For the rest of the chapter we will focus on using read_excel().\n\n20.2.3 Reading Excel spreadsheets\nFigura 20.1 shows what the spreadsheet we’re going to read into R looks like in Excel. This spreadsheet can be downloaded an Excel file from https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w/.\n\n\n\n\n\n\n\nFigura 20.1: Spreadsheet called students.xlsx in Excel.\n\n\n\n\nThe first argument to read_excel() is the path to the file to read.\n\nstudents &lt;- read_excel(\"data/students.xlsx\")\n\nread_excel() will read the file in as a tibble.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\nWe have six students in the data and five variables on each student. However there are a few things we might want to address in this dataset:\n\n\nThe column names are all over the place. You can provide column names that follow a consistent format; we recommend snake_case using the col_names argument.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\")\n)\n#&gt; # A tibble: 7 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1 Student ID Full Name        favourite.food     mealPlan            AGE  \n#&gt; 2 1          Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 3 2          Barclay Lynn     French fries       Lunch only          5    \n#&gt; 4 3          Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 5 4          Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 6 5          Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 7 6          Güvenç Attila    Ice cream          Lunch only          6\n\nUnfortunately, this didn’t quite do the trick. We now have the variable names we want, but what was previously the header row now shows up as the first observation in the data. You can explicitly skip that row using the skip argument.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\nIn the favourite_food column, one of the observations is N/A, which stands for “not available” but it’s currently not recognized as an NA (note the contrast between this N/A and the age of the fourth student in the list). You can specify which character strings should be recognized as NAs with the na argument. By default, only \"\" (empty string, or, in the case of reading from a spreadsheet, an empty cell or a cell with the formula =NA()) is recognized as an NA.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\")\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\nOne other remaining issue is that age is read in as a character variable, but it really should be numeric. Just like with read_csv() and friends for reading data from flat files, you can supply a col_types argument to read_excel() and specify the column types for the variables you read in. The syntax is a bit different, though. Your options are \"skip\", \"guess\", \"logical\", \"numeric\", \"date\", \"text\" or \"list\".\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"numeric\")\n)\n#&gt; Warning: Expecting numeric in E6 / R6C5: got 'five'\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch    NA\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\nHowever, this didn’t quite produce the desired result either. By specifying that age should be numeric, we have turned the one cell with the non-numeric entry (which had the value five) into an NA. In this case, we should read age in as \"text\" and then make the change once the data is loaded in R.\n\nstudents &lt;- read_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"text\")\n)\n\nstudents &lt;- students |&gt;\n  mutate(\n    age = if_else(age == \"five\", \"5\", age),\n    age = parse_number(age)\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\nIt took us multiple steps and trial-and-error to load the data in exactly the format we want, and this is not unexpected. Data science is an iterative process, and the process of iteration can be even more tedious when reading data in from spreadsheets compared to other plain text, rectangular data files because humans tend to input data into spreadsheets and use them not just for data storage but also for sharing and communication.\nThere is no way to know exactly what the data will look like until you load it and take a look at it. Well, there is one way, actually. You can open the file in Excel and take a peek. If you’re going to do so, we recommend making a copy of the Excel file to open and browse interactively while leaving the original data file untouched and reading into R from the untouched file. This will ensure you don’t accidentally overwrite anything in the spreadsheet while inspecting it. You should also not be afraid of doing what we did here: load the data, take a peek, make adjustments to your code, load it again, and repeat until you’re happy with the result.\n\n20.2.4 Reading worksheets\nAn important feature that distinguishes spreadsheets from flat files is the notion of multiple sheets, called worksheets. Figura 20.2 shows an Excel spreadsheet with multiple worksheets. The data come from the palmerpenguins package, and you can download this spreadsheet as an Excel file from https://docs.google.com/spreadsheets/d/1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY/. Each worksheet contains information on penguins from a different island where data were collected.\n\n\n\n\n\n\n\nFigura 20.2: Spreadsheet called penguins.xlsx in Excel containing three worksheets.\n\n\n\n\nYou can read a single worksheet from a spreadsheet with the sheet argument in read_excel(). The default, which we’ve been relying on up until now, is the first sheet.\n\nread_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\")\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm     bill_depth_mm      flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;            \n#&gt; 1 Adelie  Torgersen 39.1               18.7               181              \n#&gt; 2 Adelie  Torgersen 39.5               17.399999999999999 186              \n#&gt; 3 Adelie  Torgersen 40.299999999999997 18                 195              \n#&gt; 4 Adelie  Torgersen NA                 NA                 NA               \n#&gt; 5 Adelie  Torgersen 36.700000000000003 19.3               193              \n#&gt; 6 Adelie  Torgersen 39.299999999999997 20.6               190              \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;chr&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nSome variables that appear to contain numerical data are read in as characters due to the character string \"NA\" not being recognized as a true NA.\n\npenguins_torgersen &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\", na = \"NA\")\n\npenguins_torgersen\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nAlternatively, you can use excel_sheets() to get information on all worksheets in an Excel spreadsheet, and then read the one(s) you’re interested in.\n\nexcel_sheets(\"data/penguins.xlsx\")\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\nOnce you know the names of the worksheets, you can read them in individually with read_excel().\n\npenguins_biscoe &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Biscoe Island\", na = \"NA\")\npenguins_dream  &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Dream Island\", na = \"NA\")\n\nIn this case the full penguins dataset is spread across three worksheets in the spreadsheet. Each worksheet has the same number of columns but different numbers of rows.\n\ndim(penguins_torgersen)\n#&gt; [1] 52  8\ndim(penguins_biscoe)\n#&gt; [1] 168   8\ndim(penguins_dream)\n#&gt; [1] 124   8\n\nWe can put them together with bind_rows().\n\npenguins &lt;- bind_rows(penguins_torgersen, penguins_biscoe, penguins_dream)\npenguins\n#&gt; # A tibble: 344 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nIn Capítulo 26 we’ll talk about ways of doing this sort of task without repetitive code.\n\n20.2.5 Reading part of a sheet\nSince many use Excel spreadsheets for presentation as well as for data storage, it’s quite common to find cell entries in a spreadsheet that are not part of the data you want to read into R. Figura 20.3 shows such a spreadsheet: in the middle of the sheet is what looks like a data frame but there is extraneous text in cells above and below the data.\n\n\n\n\n\n\n\nFigura 20.3: Spreadsheet called deaths.xlsx in Excel.\n\n\n\n\nThis spreadsheet is one of the example spreadsheets provided in the readxl package. You can use the readxl_example() function to locate the spreadsheet on your system in the directory where the package is installed. This function returns the path to the spreadsheet, which you can use in read_excel() as usual.\n\ndeaths_path &lt;- readxl_example(\"deaths.xlsx\")\ndeaths &lt;- read_excel(deaths_path)\n#&gt; New names:\n#&gt; • `` -&gt; `...2`\n#&gt; • `` -&gt; `...3`\n#&gt; • `` -&gt; `...4`\n#&gt; • `` -&gt; `...5`\n#&gt; • `` -&gt; `...6`\ndeaths\n#&gt; # A tibble: 18 × 6\n#&gt;   `Lots of people`    ...2       ...3  ...4     ...5          ...6           \n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;          \n#&gt; 1 simply cannot resi… &lt;NA&gt;       &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          some notes     \n#&gt; 2 at                  the        top   &lt;NA&gt;     of            their spreadsh…\n#&gt; 3 or                  merging    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          cells          \n#&gt; 4 Name                Profession Age   Has kids Date of birth Date of death  \n#&gt; 5 David Bowie         musician   69    TRUE     17175         42379          \n#&gt; 6 Carrie Fisher       actor      60    TRUE     20749         42731          \n#&gt; # ℹ 12 more rows\n\nThe top three rows and the bottom four rows are not part of the data frame. It’s possible to eliminate these extraneous rows using the skip and n_max arguments, but we recommend using cell ranges. In Excel, the top left cell is A1. As you move across columns to the right, the cell label moves down the alphabet, i.e. B1, C1, etc. And as you move down a column, the number in the cell label increases, i.e. A2, A3, etc.\nHere the data we want to read in starts in cell A5 and ends in cell F15. In spreadsheet notation, this is A5:F15, which we supply to the range argument:\n\nread_excel(deaths_path, range = \"A5:F15\")\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.2.6 Data types\nIn CSV files, all values are strings. This is not particularly true to the data, but it is simple: everything is a string.\nThe underlying data in Excel spreadsheets is more complex. A cell can be one of four things:\n\nA boolean, like TRUE, FALSE, or NA.\nA number, like “10” or “10.5”.\nA datetime, which can also include time like “11/1/21” or “11/1/21 3:00 PM”.\nA text string, like “ten”.\n\nWhen working with spreadsheet data, it’s important to keep in mind that the underlying data can be very different than what you see in the cell. For example, Excel has no notion of an integer. All numbers are stored as floating points, but you can choose to display the data with a customizable number of decimal points. Similarly, dates are actually stored as numbers, specifically the number of seconds since January 1, 1970. You can customize how you display the date by applying formatting in Excel. Confusingly, it’s also possible to have something that looks like a number but is actually a string (e.g., type '10 into a cell in Excel).\nThese differences between how the underlying data are stored vs. how they’re displayed can cause surprises when the data are loaded into R. By default readxl will guess the data type in a given column. A recommended workflow is to let readxl guess the column types, confirm that you’re happy with the guessed column types, and if not, go back and re-import specifying col_types as shown in Seção 20.2.3.\nAnother challenge is when you have a column in your Excel spreadsheet that has a mix of these types, e.g., some cells are numeric, others text, others dates. When importing the data into R readxl has to make some decisions. In these cases you can set the type for this column to \"list\", which will load the column as a list of length 1 vectors, where the type of each element of the vector is guessed.\n\n\n\n\n\n\nSometimes data is stored in more exotic ways, like the color of the cell background, or whether or not the text is bold. In such cases, you might find the tidyxl package useful. See https://nacnudus.github.io/spreadsheet-munging-strategies/ for more on strategies for working with non-tabular data from Excel.\n\n\n\n\n20.2.7 Writing to Excel\nLet’s create a small data frame that we can then write out. Note that item is a factor and quantity is an integer.\n\nbake_sale &lt;- tibble(\n  item     = factor(c(\"brownie\", \"cupcake\", \"cookie\")),\n  quantity = c(10, 5, 8)\n)\n\nbake_sale\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;fct&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\nYou can write data back to disk as an Excel file using the write_xlsx() from the writexl package:\n\nwrite_xlsx(bake_sale, path = \"data/bake-sale.xlsx\")\n\nFigura 20.4 shows what the data looks like in Excel. Note that column names are included and bolded. These can be turned off by setting col_names and format_headers arguments to FALSE.\n\n\n\n\n\n\n\nFigura 20.4: Spreadsheet called bake_sale.xlsx in Excel.\n\n\n\n\nJust like reading from a CSV, information on data type is lost when we read the data back in. This makes Excel files unreliable for caching interim results as well. For alternatives, see Seção 7.5.\n\nread_excel(\"data/bake-sale.xlsx\")\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\n\n20.2.8 Formatted output\nThe writexl package is a light-weight solution for writing a simple Excel spreadsheet, but if you’re interested in additional features like writing to sheets within a spreadsheet and styling, you will want to use the openxlsx package. We won’t go into the details of using this package here, but we recommend reading https://ycphs.github.io/openxlsx/articles/Formatting.html for an extensive discussion on further formatting functionality for data written from R to Excel with openxlsx.\nNote that this package is not part of the tidyverse so the functions and workflows may feel unfamiliar. For example, function names are camelCase, multiple functions can’t be composed in pipelines, and arguments are in a different order than they tend to be in the tidyverse. However, this is ok. As your R learning and usage expands outside of this book you will encounter lots of different styles used in various R packages that you might use to accomplish specific goals in R. A good way of familiarizing yourself with the coding style used in a new package is to run the examples provided in function documentation to get a feel for the syntax and the output formats as well as reading any vignettes that might come with the package.\n\n20.2.9 Exercises\n\n\nIn an Excel file, create the following dataset and save it as survey.xlsx. Alternatively, you can download it as an Excel file from here.\n\n\n\n\n\n\n\n\nThen, read it into R, with survey_id as a character variable and n_pets as a numerical variable.\n\n#&gt; # A tibble: 6 × 2\n#&gt;   survey_id n_pets\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 1              0\n#&gt; 2 2              1\n#&gt; 3 3             NA\n#&gt; 4 4              2\n#&gt; 5 5              2\n#&gt; 6 6             NA\n\n\n\nIn another Excel file, create the following dataset and save it as roster.xlsx. Alternatively, you can download it as an Excel file from here.\n\n\n\n\n\n\n\n\nThen, read it into R. The resulting data frame should be called roster and should look like the following.\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12\n\n\n\nIn a new Excel file, create the following dataset and save it as sales.xlsx. Alternatively, you can download it as an Excel file from here.\n\n\n\n\n\n\n\n\na. Read sales.xlsx in and save as sales. The data frame should look like the following, with id and n as column names and with 9 rows.\n\n#&gt; # A tibble: 9 × 2\n#&gt;   id      n    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 Brand 1 n    \n#&gt; 2 1234    8    \n#&gt; 3 8721    2    \n#&gt; 4 1822    3    \n#&gt; 5 Brand 2 n    \n#&gt; 6 3333    1    \n#&gt; 7 2156    3    \n#&gt; 8 3987    6    \n#&gt; 9 3216    5\n\nb. Modify sales further to get it into the following tidy format with three columns (brand, id, and n) and 7 rows of data. Note that id and n are numeric, brand is a character variable.\n\n#&gt; # A tibble: 7 × 3\n#&gt;   brand      id     n\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Brand 1  1234     8\n#&gt; 2 Brand 1  8721     2\n#&gt; 3 Brand 1  1822     3\n#&gt; 4 Brand 2  3333     1\n#&gt; 5 Brand 2  2156     3\n#&gt; 6 Brand 2  3987     6\n#&gt; 7 Brand 2  3216     5\n\n\nRecreate the bake_sale data frame, write it out to an Excel file using the write.xlsx() function from the openxlsx package.\nIn Capítulo 7 you learned about the janitor::clean_names() function to turn column names into snake case. Read the students.xlsx file that we introduced earlier in this section and use this function to “clean” the column names.\nWhat happens if you try to read in a file with .xlsx extension with read_xls()?",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#google-sheets",
    "href": "spreadsheets.html#google-sheets",
    "title": "20  Spreadsheets",
    "section": "\n20.3 Google Sheets",
    "text": "20.3 Google Sheets\nGoogle Sheets is another widely used spreadsheet program. It’s free and web-based. Just like with Excel, in Google Sheets data are organized in worksheets (also called sheets) inside of spreadsheet files.\n\n20.3.1 Prerequisites\nThis section will also focus on spreadsheets, but this time you’ll be loading data from a Google Sheet with the googlesheets4 package. This package is non-core tidyverse as well, you need to load it explicitly.\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\n\nA quick note about the name of the package: googlesheets4 uses v4 of the Sheets API v4 to provide an R interface to Google Sheets, hence the name.\n\n20.3.2 Getting started\nThe main function of the googlesheets4 package is read_sheet(), which reads a Google Sheet from a URL or a file id. This function also goes by the name range_read().\nYou can also create a brand new sheet with gs4_create() or write to an existing sheet with sheet_write() and friends.\nIn this section we’ll work with the same datasets as the ones in the Excel section to highlight similarities and differences between workflows for reading data from Excel and Google Sheets. readxl and googlesheets4 packages are both designed to mimic the functionality of the readr package, which provides the read_csv() function you’ve seen in Capítulo 7. Therefore, many of the tasks can be accomplished with simply swapping out read_excel() for read_sheet(). However you’ll also see that Excel and Google Sheets don’t behave in exactly the same way, therefore other tasks may require further updates to the function calls.\n\n20.3.3 Reading Google Sheets\nFigura 20.5 shows what the spreadsheet we’re going to read into R looks like in Google Sheets. This is the same dataset as in Figura 20.1, except it’s stored in a Google Sheet instead of Excel.\n\n\n\n\n\n\n\nFigura 20.5: Google Sheet called students in a browser window.\n\n\n\n\nThe first argument to read_sheet() is the URL of the file to read, and it returns a tibble:https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w. These URLs are not pleasant to work with, so you’ll often want to identify a sheet by its ID.\n\ngs4_deauth()\n\n\nstudents_sheet_id &lt;- \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\nstudents &lt;- read_sheet(students_sheet_id)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range Sheet1.\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE   \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;list&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          &lt;dbl&gt; \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          &lt;dbl&gt; \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch &lt;dbl&gt; \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NULL&gt;\n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch &lt;chr&gt; \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          &lt;dbl&gt;\n\nJust like we did with read_excel(), we can supply column names, NA strings, and column types to read_sheet().\n\nstudents &lt;- read_sheet(\n  students_sheet_id,\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = \"dcccc\"\n)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range 2:10000000.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\nNote that we defined column types a bit differently here, using short codes. For example, “dcccc” stands for “double, character, character, character, character”.\nIt’s also possible to read individual sheets from Google Sheets as well. Let’s read the “Torgersen Island” sheet from the penguins Google Sheet:\n\npenguins_sheet_id &lt;- \"1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY\"\nread_sheet(penguins_sheet_id, sheet = \"Torgersen Island\")\n#&gt; ✔ Reading from penguins.\n#&gt; ✔ Range ''Torgersen Island''.\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;list&gt;         &lt;list&gt;        &lt;list&gt;           \n#&gt; 1 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 2 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 3 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 4 Adelie  Torgersen &lt;chr [1]&gt;      &lt;chr [1]&gt;     &lt;chr [1]&gt;        \n#&gt; 5 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 6 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;list&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nYou can obtain a list of all sheets within a Google Sheet with sheet_names():\n\nsheet_names(penguins_sheet_id)\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\nFinally, just like with read_excel(), we can read in a portion of a Google Sheet by defining a range in read_sheet(). Note that we’re also using the gs4_example() function below to locate an example Google Sheet that comes with the googlesheets4 package.\n\ndeaths_url &lt;- gs4_example(\"deaths\")\ndeaths &lt;- read_sheet(deaths_url, range = \"A5:F15\")\n#&gt; ✔ Reading from deaths.\n#&gt; ✔ Range A5:F15.\ndeaths\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n20.3.4 Writing to Google Sheets\nYou can write from R to Google Sheets with write_sheet(). The first argument is the data frame to write, and the second argument is the name (or other identifier) of the Google Sheet to write to:\n\nwrite_sheet(bake_sale, ss = \"bake-sale\")\n\nIf you’d like to write your data to a specific (work)sheet inside a Google Sheet, you can specify that with the sheet argument as well.\n\nwrite_sheet(bake_sale, ss = \"bake-sale\", sheet = \"Sales\")\n\n\n20.3.5 Authentication\nWhile you can read from a public Google Sheet without authenticating with your Google account and with gs4_deauth(), reading a private sheet or writing to a sheet requires authentication so that googlesheets4 can view and manage your Google Sheets.\nWhen you attempt to read in a sheet that requires authentication, googlesheets4 will direct you to a web browser with a prompt to sign in to your Google account and grant permission to operate on your behalf with Google Sheets. However, if you want to specify a specific Google account, authentication scope, etc. you can do so with gs4_auth(), e.g., gs4_auth(email = \"mine@example.com\"), which will force the use of a token associated with a specific email. For further authentication details, we recommend reading the documentation googlesheets4 auth vignette: https://googlesheets4.tidyverse.org/articles/auth.html.\n\n20.3.6 Exercises\n\nRead the students dataset from earlier in the chapter from Excel and also from Google Sheets, with no additional arguments supplied to the read_excel() and read_sheet() functions. Are the resulting data frames in R exactly the same? If not, how are they different?\nRead the Google Sheet titled survey from https://pos.it/r4ds-survey, with survey_id as a character variable and n_pets as a numerical variable.\n\nRead the Google Sheet titled roster from https://pos.it/r4ds-roster. The resulting data frame should be called roster and should look like the following.\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "spreadsheets.html#summary",
    "href": "spreadsheets.html#summary",
    "title": "20  Spreadsheets",
    "section": "\n20.4 Summary",
    "text": "20.4 Summary\nMicrosoft Excel and Google Sheets are two of the most popular spreadsheet systems. Being able to interact with data stored in Excel and Google Sheets files directly from R is a superpower! In this chapter you learned how to read data into R from spreadsheets from Excel with read_excel() from the readxl package and from Google Sheets with read_sheet() from the googlesheets4 package. These functions work very similarly to each other and have similar arguments for specifying column names, NA strings, rows to skip on top of the file you’re reading in, etc. Additionally, both functions make it possible to read a single sheet from a spreadsheet as well.\nOn the other hand, writing to an Excel file requires a different package and function (writexl::write_xlsx()) while you can write to a Google Sheet with the googlesheets4 package, with write_sheet().\nIn the next chapter, you’ll learn about a different data source and how to read data from that source into R: databases.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Spreadsheets</span>"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "21  ✅ Bancos de dados",
    "section": "",
    "text": "21.1 Introdução\nUm grande volume de dados são armazenados em bancos de dados (databases), portanto, é essencial que você saiba como acessá-los. Em alguns casos você pode pedir para alguém fazer uma cópia para um .csv para você, mas isto se torna problemático rapidamente: toda vez que você precisar fazer uma mudança, você precisará se comunicar com outra pessoa. Você deve ser capaz de acessar diretamente o banco de dados para obter os dados necessários quando quiser.\nNeste capítulo, você aprenderá primeiro o básico do pacote DBI: como utilizá-lo para se conectar a um banco de dados e então obter dados através de uma consulta SQL1. SQL é uma abreviação de structured query language, e é a lingua franca dos bancos de dados, portanto uma linguagem muito importante que todas pessoas que praticam ciência de dados devem aprender. Dito isto, não iremos começar com SQL, mas sim, iremos ensinar você sobre o dbplyr, um pacote capaz de traduzir código dplyr para código SQL. Faremos isto de maneira a ensinar algumas das características mais importantes do SQL. Você não se tornará um especialista em SQL ao final deste capítulo, mas será capaz de identificar a maioria de seus componentes principais e entender o que fazem.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#introdução",
    "href": "databases.html#introdução",
    "title": "21  ✅ Bancos de dados",
    "section": "",
    "text": "21.1.1 Pré-requisitos\nNeste capítulo, faremos uma introdução aos pacotes DBI e dbplyr. DBI é uma interface de baixo nível que se conecta aos bancos de dados e executa SQL; dbplyr é uma interface de alto nível que traduz seu código dplyr para um código de consultas SQL e então as executa através do DBI.\n\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)\nlibrary(dados)",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#o-básico-sobre-bancos-de-dados",
    "href": "databases.html#o-básico-sobre-bancos-de-dados",
    "title": "21  ✅ Bancos de dados",
    "section": "\n21.2 O básico sobre bancos de dados",
    "text": "21.2 O básico sobre bancos de dados\nEm um nível mais simples, você pode imaginar um banco de dados como uma coleção de data frames, que são chamados de tabelas na terminologia dos bancos de dados. Assim como um data frame, uma tabela de um banco de dados é uma coleção de colunas com nomes, onde cada valor na coluna tem o mesmo tipo. Existem três diferenças de alto nível entre data frames e as tabelas de um banco de dados:\n\nTabelas são armazenadas em disco e podem ser arbitrariamente grandes. Data frames são armazenados na memória do computador, e são fundamentalmente limitados (apesar deste limite ser suficientemente grande para muitos problemas).\nTabelas quase sempre possuem um índice. Assim como um índice de um livro, um índice no banco de dados torna possível encontrar rapidamente as linhas de interesse, sem a necessidade de examinar uma a uma todas as linhas. Data frames e tibbles não possuem índices, porém data.tables possuem, e esta é umas das razões para serem tão rápidos.\nMuitos bancos de dados clássicos são otimizados para coletar dados rapidamente, mas não para analizar dados existentes. Estes bancos de dados são chamados orientados à linhas (row-oriented), pois os dados são armazenados linha-a-linha ao invés de coluna-por-coluna como no R. Mais recentemente, tem-se visto o desenvolvimento de bancos de dados orientados à colunas (column-oriented), o que torna a análise de dados existentes mais rápida.\n\nBancos de dados são executados por sistemas de gerenciamento de banco de dados (SGBD), os quais podem ser de três categorias:\n\nSGBDs Cliente-servidor rodam em um servidor central poderoso, ao qual você se conecta do seu computador (o cliente). Eles são muito bons para compartilhar dados com várias pessoas em uma organização. SGBDs cliente-servidor populares incluem o PostgreSQL, MariaDB, SQL Server e Oracle.\nSGBDs na Nuvem (Cloud), como o Snowflake, RedShift da Amazon e o BigQuery do Google, são similares aos SGBDs cliente-servidor, mas eles rodam na nuvem. Isto significa que eles podem facilmente lidar com bancos de dados extremamente grandes e podem automaticamente obter mais recursos computacionais quando necessário.\nSGBDs No-processo (In-process), como o SQLite ou duckdb, rodam inteiramente em seu computador. Eles são ótimos para trabalhar com conjunto de dados grandes nos quais você é o principal usuário.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#conectando-a-um-banco-de-dados",
    "href": "databases.html#conectando-a-um-banco-de-dados",
    "title": "21  ✅ Bancos de dados",
    "section": "\n21.3 Conectando a um banco de dados",
    "text": "21.3 Conectando a um banco de dados\nPara se conectar a um banco de dados pelo R, você usa um par de pacotes:\n\nVocê sempre usuará o DBI (database interface), pois este fornece um conjunto de funções genéricas que se conectam com os bancos de dados, enviam dados, executam consultas SQL, etc.\nVocê também usará um pacote feito especificamente para o SGBD ao qual você está se conectando. Este pacote traduz os comandos genéricos do DBI para as necessidades específicas de um determinado SGBD. Existe geralmente um pacote para cada SGBD, ex: RPostgres para PostgreSQL e RMariaDB para MySQL.\n\nSe você não puder encontrar um pacote específico para seu SGBD, você pode utilizar o pacote odbc. Este usa o protocolo ODBC suportado por muitos SGBDs. odbc exige uma configuração um pouco mais elaborada, pois você deve instalar o driver ODBC e informar o pacote odbc onde encontrá-lo.\nEfetivamente, você cria uma conexão com o banco de dados usando DBI::dbConnect(). O primeiro argumento seleciona o SGBD2, e os argumentos seguintes descrevem como se conectar a ele (ou seja, onde está localizado e as credenciais necessárias para acessá-lo). O código a seguir demonstra alguns exemplos típicos:\n\ncon &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(), \n  username = \"foo\"\n)\ncon &lt;- DBI::dbConnect(\n  RPostgres::Postgres(), \n  hostname = \"bancodados.minhaempresa.com\", \n  port = 1234\n)\n\nOs detalhes precisos de conexão variam muito de SGBD para SGBD, portanto infelizmente não poderemos cobrir todos aqui. Isto significa que você deverá fazer um pouco de pesquisa por conta própria. Geralmente, você pode perguntar a outras pessoas cientistas de dados do time ou falar com a pessoa que administra o banco de dados (DBA) (database administrator). A configuração inicial geralmente exige um pouco de ajuste (e talvez um pouco de pesquisa no Google) para ser feita corretamente, mas em geral você precisará fazer uma única vez.\n\n21.3.1 Neste livro\nConfigurar um SGBD cliente-servidor ou SGBD da nuvem neste livro seria bastante chato, portanto usaremos um SGBD “no-processo” que vem inteiramente em um pacote do R: duckdb. Graças à magia do DBI, a única diferença entre usar o duckdb e outro SGBD é como você se conectará ao banco de dados. Isto se torna muito bom para ensinar, pois você pode executar facilmente este código e, da mesma forma, aplicar o que aprendeu em outros lugares com facilidade.\nConectar ao duckdb é particularmente simples, pois por padrão, um banco de dados temporário é criado e depois removido ao sair do R. Isto é muito bom para o aprendizado, pois garante que você iniciará de um estado limpo toda vez que reiniciar o R:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\n\nduckdb é um banco de dados de alto desempenho desenhado muito para as necessidades da pessoa cientista de dados. O usaremos aqui pois é muito fácil de se iniciar, mas também porque é capaz de lidar com gigabytes de dados com grande velocidade. Se você quiser usar o duckdb em um projeto de análise de dados real, será necessário incluir o argumento dbdir para um banco de dados persistente e dizer ao duckdb onde salvar. Assumindo que você está usando um projeto (Capítulo 6), é razoável armazená-lo no diretório duckdb do projeto atual:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), dbdir = \"duckdb\")\n\n\n21.3.2 Carregando alguns dados\nJá que este é um banco de dados novo, precisaremos começar adicionando alguns dados. Aqui adicionaremos os conjuntos de dados milhas e diamante do pacote dados usando DBI::dbWriteTable(). O exemplo de uso mais simples de dbWriteTable() precisa de três argumentos: uma conexão ao banco de dados, o nome da tabela a ser criada no banco de dados e um data frame com os dados.\n\ndbWriteTable(con, \"milhas\", dados::milhas)\ndbWriteTable(con, \"diamante\", dados::diamante)\n\nSe você está usando o duckdb em um projeto real, recomendamos fortemente ler sobre duckdb_read_csv() e duckdb_register_arrow(). Estas funções te dão formas poderosas e de alto desempenho para carregar dados diretamente ao duckdb sem ter que os carregar primeiro no R. Nós também demonstraremos uma técnica útil para carregar vários arquivos em um banco de dados na Seção 26.4.1.\n\n21.3.3 O básico do DBI\nVocê pode confirmar se os dados foram carregados corretamente usando um par de funções do DBI: dbListTables() lista todas as tabelas da banco de dados3 e dbReadTable() retorna o conteúdo de uma tabela.\n\ndbListTables(con)\n#&gt; [1] \"diamante\" \"milhas\"\n\ncon |&gt; \n  dbReadTable(\"diamante\") |&gt; \n  as_tibble()\n#&gt; # A tibble: 53,940 × 10\n#&gt;   preco quilate corte     cor   transparencia profundidade tabela     x     y\n#&gt;   &lt;int&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   326    0.23 Ideal     E     SI2                   61.5     55  3.95  3.98\n#&gt; 2   326    0.21 Premium   E     SI1                   59.8     61  3.89  3.84\n#&gt; 3   327    0.23 Bom       E     VS1                   56.9     65  4.05  4.07\n#&gt; 4   334    0.29 Premium   I     VS2                   62.4     58  4.2   4.23\n#&gt; 5   335    0.31 Bom       J     SI2                   63.3     58  4.34  4.35\n#&gt; 6   336    0.24 Muito Bom J     VVS2                  62.8     57  3.94  3.96\n#&gt; # ℹ 53,934 more rows\n#&gt; # ℹ 1 more variable: z &lt;dbl&gt;\n\ndbReadTable() retorna um data.frame, portanto usamos as_tibble() para converter em um tibble para que imprima de forma mais bonita na tela.\nSe você já sabe SQL, você pode usar dbGetQuery() pata obter os resultados de uma consulta executada no banco de dados:\n\nsql &lt;- \"\n  SELECT quilate, corte, transparencia, cor, preco \n  FROM diamante \n  WHERE preco &gt; 15000\n\"\nas_tibble(dbGetQuery(con, sql))\n#&gt; # A tibble: 1,655 × 5\n#&gt;   quilate corte     transparencia cor   preco\n#&gt;     &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;         &lt;fct&gt; &lt;int&gt;\n#&gt; 1    1.54 Premium   VS2           E     15002\n#&gt; 2    1.19 Ideal     VVS1          F     15005\n#&gt; 3    2.1  Premium   SI1           I     15007\n#&gt; 4    1.69 Ideal     SI1           D     15011\n#&gt; 5    1.5  Muito Bom VVS2          G     15013\n#&gt; 6    1.73 Muito Bom VS1           G     15014\n#&gt; # ℹ 1,649 more rows\n\nSe você nunca viu SQL antes, não se preocupe! Em breve você aprenderá mais sobre isto. Mas se você ler atentamente, você pode adivinhar que estamos selecionando cinco colunas do conjunto de dados diamante e todas as linhas onde o preco é maior que 15.000.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#o-básico-do-dbplyr",
    "href": "databases.html#o-básico-do-dbplyr",
    "title": "21  ✅ Bancos de dados",
    "section": "\n21.4 O básico do dbplyr",
    "text": "21.4 O básico do dbplyr\nAgora que você se conectou ao banco de dados e carregou alguns dados, você pode começar a aprender sobre dbplyr. dbplyr roda por tráz do dplyr, isso significa que você continua a escrever códigos dplyr, mas o backend o executa de maneira diferente. Neste caso, o dbplyr traduz para SQL; existem outros backends incluindo dtplyr que traduz o código para data.table e multidplyr que executa o código em vários núcleos (cores).\nPara usar dbplyr, primeiro você usa tbl() para criar um objeto que representa a tabela do banco de dados:\n\ndiamantes_bd &lt;- tbl(con, \"diamante\")\ndiamantes_bd\n#&gt; # Source:   table&lt;diamante&gt; [?? x 10]\n#&gt; # Database: DuckDB v0.10.0 [root@Darwin 21.6.0:R 4.3.3/:memory:]\n#&gt;   preco quilate corte     cor   transparencia profundidade tabela     x     y\n#&gt;   &lt;int&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   326    0.23 Ideal     E     SI2                   61.5     55  3.95  3.98\n#&gt; 2   326    0.21 Premium   E     SI1                   59.8     61  3.89  3.84\n#&gt; 3   327    0.23 Bom       E     VS1                   56.9     65  4.05  4.07\n#&gt; 4   334    0.29 Premium   I     VS2                   62.4     58  4.2   4.23\n#&gt; 5   335    0.31 Bom       J     SI2                   63.3     58  4.34  4.35\n#&gt; 6   336    0.24 Muito Bom J     VVS2                  62.8     57  3.94  3.96\n#&gt; # ℹ more rows\n#&gt; # ℹ 1 more variable: z &lt;dbl&gt;\n\n\n\n\n\n\n\nExistem duas outras formas comuns de interagir com banco de dados. Primeiro, muitas organizações possuem banco de dados muito grandes, então você precisa de alguma hierarquia para manter todas as tabelas organizadas. Neste caso, você deve precisar fornecer um esquema (schema) ou um catálogo (catalog) e um esquema, de maneira a obter a tabela que você tem interesse:\n\ndiamantes_bd &lt;- tbl(con, in_schema(\"vendas\", \"diamante\"))\ndiamantes_bd &lt;- tbl(con, in_catalog(\"america_norte\", \"vendas\", \"diamante\"))\n\nOutras vezes você pode querer usar seu próprio SQL como ponto de partida:\n\ndiamantes_bd &lt;- tbl(con, sql(\"SELECT * FROM diamante\"))\n\n\n\n\nEste é um objeto lazy; quando você usa verbos do dpluyr nele, dplyr não faz nada, ele apenas registra a sequência de operações que você deseja executar e as executa apenas quando necessário. Por exemplo, veja o seguinte pipeline:\n\ngrandes_diamantes_bd &lt;- diamantes_bd |&gt; \n  filter(preco &gt; 15000) |&gt; \n  select(quilate:transparencia, preco)\n\ngrandes_diamantes_bd\n#&gt; # Source:   SQL [?? x 5]\n#&gt; # Database: DuckDB v0.10.0 [root@Darwin 21.6.0:R 4.3.3/:memory:]\n#&gt;   quilate corte     cor   transparencia preco\n#&gt;     &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;         &lt;int&gt;\n#&gt; 1    1.54 Premium   E     VS2           15002\n#&gt; 2    1.19 Ideal     F     VVS1          15005\n#&gt; 3    2.1  Premium   I     SI1           15007\n#&gt; 4    1.69 Ideal     D     SI1           15011\n#&gt; 5    1.5  Muito Bom G     VVS2          15013\n#&gt; 6    1.73 Muito Bom G     VS1           15014\n#&gt; # ℹ more rows\n\nVocê pode dizer que este objeto representa uma consulta ao banco de dados pois imprime o nome do SGBD no topo e apesar de também dizer o número de colunas, geralmente não sabe o número de linhas. Isso ocorre porque encontrar o número total de linhas geralmente requer a execução da consulta completa, algo que estamos tentando evitar.\nVocê também pode ver o código SQL gerado através da função show_query() do dplyr. Se você conhece dplyr, esta é uma boa maneira de aprender SQL! Escreva algum código dplyr, deixe o dbplyr traduzir para o SQL, e então tente entender como as duas linguagens se relacionam.\n\ngrandes_diamantes_bd |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT quilate, corte, cor, transparencia, preco\n#&gt; FROM diamante\n#&gt; WHERE (preco &gt; 15000.0)\n\nPara puxar os dados de volta para o R, você chama a função collect(). Por trás dos panos, isto gera o SQL, chama dbGetQuery() para obter os dados, e então transforma o resultado em um tibble:\n\ngrandes_diamantes &lt;- grandes_diamantes_bd |&gt; \n  collect()\ngrandes_diamantes\n#&gt; # A tibble: 1,655 × 5\n#&gt;   quilate corte     cor   transparencia preco\n#&gt;     &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;         &lt;int&gt;\n#&gt; 1    1.54 Premium   E     VS2           15002\n#&gt; 2    1.19 Ideal     F     VVS1          15005\n#&gt; 3    2.1  Premium   I     SI1           15007\n#&gt; 4    1.69 Ideal     D     SI1           15011\n#&gt; 5    1.5  Muito Bom G     VVS2          15013\n#&gt; 6    1.73 Muito Bom G     VS1           15014\n#&gt; # ℹ 1,649 more rows\n\nGeralmente, você usará dbplyr para selecionar os dados que você deseja do conjunto de dados, efetuar alguns filtros básicos e agregações usando as traduções descritas abaixo. Então, assim que estiver pronto para analisar os dados com as funções que são únicas do R, você chamará collect() para obter os dados em um tibble na memória do seu computador, e continuará o trabalho com código R puro.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#sql",
    "href": "databases.html#sql",
    "title": "21  ✅ Bancos de dados",
    "section": "\n21.5 SQL",
    "text": "21.5 SQL\nO resto do capítulo irá te ensinar um pouco de SQL pelas lentes do dbplyr. É uma introdução não tradicional ao SQL, mas esperamos que te leve rapidamente a um conhecimento básico. Felizmente, se você conhece dplyr você está em um bom lugar para rapidamente aprender SQL, pois muitos conceitos são iguais.\nNós iremos explorar o relacionamento entre dplyr e SQL usando alguns velhos amigos do pacote dados: voos e avioes. Estes conjuntos de dados são fáceis para usar no aprendizado sobre bancos de dados, e podemos copiá-las 4:\n\n# Copiando as tabelas para o banco de dados\ndbWriteTable(con, name = \"voos\", value = voos)\ndbWriteTable(con, name = \"avioes\", value = avioes)\n\n# Lendo as tabelas do banco de dados\nvoos &lt;- tbl(con, \"voos\")\navioes &lt;- tbl(con, \"avioes\")\n\n\n21.5.1 O básico do SQL\nOs componentes de nível mais alto do SQL são chamados declarações (statements). Declarações comuns incluem CREATE para definir novas tableas, INSERT para adicionar dados e SELECT para retornar dados. Iremos focar em declarações SELECT, também chamadas de consultas (queries), pois são quase que exclusivamente o que você precisa para atuar em ciência de dados.\nUm consulta é formada por cláusulas (clauses). Existem cinco cláusulas importantes: SELECT, FROM, WHERE, ORDER BY e GROUP BY. Toda consulta precisa ter cláusulas SELECT5 e FROM6 e a consulta mais simples é SELECT * FROM tabela, que seleciona todas colunas de determinada tabela . Isto é o que dbplyr gera de uma tabela sem mudanças :\n\nvoos |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM voos\navioes |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM avioes\n\nWHERE e ORDER BY controlam quais linhas serão incluídas e como estarão ordenadas:\n\nvoos |&gt; \n  filter(destino == \"IAH\") |&gt; \n  arrange(atraso_saida) |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*\n#&gt; FROM voos\n#&gt; WHERE (destino = 'IAH')\n#&gt; ORDER BY atraso_saida\n\nGROUP BY converte a consulta em uma sumarização, fazendo com que aconteça uma agregação:\n\nvoos |&gt; \n  group_by(destino) |&gt; \n  summarize(atraso_saida = mean(atraso_saida, na.rm = TRUE)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT destino, AVG(atraso_saida) AS atraso_saida\n#&gt; FROM voos\n#&gt; GROUP BY destino\n\nExistem duas principais diferenças entre verbos dplyr e cláusulas SELECT:\n\nNo SQL, a maiúscula e minúscula não fazem diferença: você pode escrever select, SELECT ou até SeLeCt. Neste livro ficaremos com a convenção comum de escrever as palavras-chaves SQL usando letras maiúsculas para distinguir de nomes de tabelas ou variáveis.\nNo SQL, a ordem importa: você sempre deve escrever as declarações em ordem SELECT, FROM, WHERE, GROUP BY, ORDER BY. É um pouco confuso, pois esta ordem não é a mesma de como as declarações são realmente avaliadas com FROM em primeiro, depois WHERE, GROUP BY, SELECT e ORDER BY.\n\nAs seções seguintes exploram com mais detalhes cada cláusula.\n\n\n\n\n\n\nObserve que apesar do SQL ser um padrão, ele é extramamente complexo e nenhum banco de dados o segue exatamente. Enquanto os componentes principais que iremos focar neste livro são muito similares entre os SGBDs, há muitas pequenas variações. Felizmente, dbplyr é desenhado para gerenciar este problema e gerar diferentes traduções para diferentes bancos de dados. Não é perfeito, mas está melhorando continuamente e se você encontrar um problema, pode abrir um caso (issue) no GitHub para nos ajudar a melhorar.\n\n\n\n\n21.5.2 SELECT\nA cláusula SELECT é o motor das consultas e faz o mesmo trabalho que select(), mutate(), rename(), relocate() e, como você aprenderá na próxima seção, summarize().\nselect(), rename() e relocate() tem uma tradução muito direta para o SELECT já que apenas afetam onde uma coluna aparece (e se aparece) assim como seu nome:\n\navioes |&gt; \n  select(codigo_cauda, tipo, fabricante, modelo, ano) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT codigo_cauda, tipo, fabricante, modelo, ano\n#&gt; FROM avioes\n\navioes |&gt; \n  select(codigo_cauda, tipo, fabricante, modelo, ano) |&gt; \n  rename(ano_construcao = ano) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT codigo_cauda, tipo, fabricante, modelo, ano AS ano_construcao\n#&gt; FROM avioes\n\navioes |&gt; \n  select(codigo_cauda, tipo, fabricante, modelo, ano) |&gt; \n  relocate(fabricante, modelo, .before = tipo) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT codigo_cauda, fabricante, modelo, tipo, ano\n#&gt; FROM avioes\n\nEste exemplo também mostra como SQL renomeia. Na terminologia SQL, renomear é chamado de aliasing e é feito com AS. Note que diferente de mutate(), o nome antigo vai ao lado esquerdo e o novo nome ao lado direito.\n\n\n\n\n\n\nNos exemplos acima, se tivéssemos os nomes de \"ano\" e \"tipo\", elas apareceriam entre aspas duplas. Isto é devido a year e type serem palavras reservadas (reserved words) no duckdb, então dbplyr coloca aspas para evitar potencial confusão entre nome de colunas/tabelas e os operadores SQL.\nQuando estiver trabalhando com outros bancos de dados é provavel que você veja todas as variáveis com aspas, pois apenas alguns poucos pacotes clientes, como o duckdb, sabem quais são todas as palavras reservadas, então eles colocam aspas em todas para evitar problemas.\nSELECT \"codigo_cauda\", \"tipo\", \"fabricante\", \"modelo\", \"ano\"\nFROM \"avioes\"\nAlguns outros bancos de dados usam a crase ao invés de aspas duplas:\nSELECT `codigo_cauda`, `tipo`, `fabricante`, `modelo`, `ano`\nFROM `avioes`\n\n\n\nA tradução para mutate() é da mesma forma bastante direta: cada variável se torna uma nova expressão no SELECT:\n\nvoos |&gt; \n  mutate(\n    velocidade = distancia / (tempo_voo / 60)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*, distancia / (tempo_voo / 60.0) AS velocidade\n#&gt; FROM voos\n\nRetornaremos para a tradução de componentes individuais (como /) na Seção 21.6.\n\n21.5.3 FROM\nA cláusula FROM define a fonte de dados. Será um pouco desinteressante por um período, pois estamos usando apenas uma única tabela. Você verá exemplos mais complexos quando chegarmos nas funções de união (join).\n\n21.5.4 GROUP BY\ngroup_by() é traduzido como a clásula GROUP BY7 e summarize() é traduzido como a cláusula SELECT:\n\ndiamantes_bd |&gt; \n  group_by(corte) |&gt; \n  summarize(\n    n = n(),\n    avg_price = mean(preco, na.rm = TRUE)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT corte, COUNT(*) AS n, AVG(preco) AS avg_price\n#&gt; FROM diamante\n#&gt; GROUP BY corte\n\nRetornaremos em o que acontece com a tradução de n() e mean() na Seção 21.6.\n\n21.5.5 WHERE\nfilter() é traduzido como a cláusula WHERE:\n\nvoos |&gt; \n  filter(destino == \"IAH\" | destino == \"HOU\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*\n#&gt; FROM voos\n#&gt; WHERE (destino = 'IAH' OR destino = 'HOU')\n\nvoos |&gt; \n  filter(atraso_chegada &gt; 0 & atraso_chegada &lt; 20) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*\n#&gt; FROM voos\n#&gt; WHERE (atraso_chegada &gt; 0.0 AND atraso_chegada &lt; 20.0)\n\nExistem alguns detalhes importantes a serem observados aqui:\n\n\n| se torna OR e & se torna AND.\nSQL usa = para comparação, e não ==. SQL não possui atribuição (assignment), portanto não há potencial para confusão aqui.\nSQL usa somente '' para strings, não usa \"\". No SQL, \"\" é usado para identificar variáveis, como a `` do R.\n\nOutro operator SQL útil é o IN, o qual se parece muito com o %in%do R:\n\nvoos |&gt; \n  filter(destino %in% c(\"IAH\", \"HOU\")) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*\n#&gt; FROM voos\n#&gt; WHERE (destino IN ('IAH', 'HOU'))\n\nSQL usa NULL ao invés de NA. NULL se comporta de forma similar ao NA. A principal diferença é que enquanto são considerados nas comparações e aritmética, eles são silenciosamente ignorados quando sumarizados. dbplyr irá te lembrar disto a primeira vez que você encontrar:\n\nvoos |&gt; \n  group_by(destino) |&gt; \n  summarize(atraso = mean(atraso_chegada))\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v0.10.0 [root@Darwin 21.6.0:R 4.3.3/:memory:]\n#&gt;   destino atraso\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 CLT      7.36 \n#&gt; 2 MDW     12.4  \n#&gt; 3 HOU      7.18 \n#&gt; 4 SDF     12.7  \n#&gt; 5 LAS      0.258\n#&gt; 6 PHX      2.10 \n#&gt; # ℹ more rows\n\nSe você quiser saber mais em como o NULL funciona, você irá gostar do artigo “Three valued logic” de Markus Winand.\nEm geral, você pode trabalhar com NULL usando as funções que você usaria para NA no R:\n\nvoos |&gt; \n  filter(!is.na(atraso_saida)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*\n#&gt; FROM voos\n#&gt; WHERE (NOT((atraso_saida IS NULL)))\n\nEsta consulta SQL ilustra uma das desvatagens do dbplyr: apesar do SQL estar correto, ela não é tão simples quanto se estivesse sido escrita à mão. Neste caso, você poderia eliminar os parênteses e usar um operador especial que é mais simples de se ler:\nWHERE \"atraso_saida\" IS NOT NULL\nNote que se você usar filter() em uma variável que você criou usando um summarize, dbplyr irá gerar uma cláusula HAVING, ao invés de uma cláusula WHERE. Esta é uma das indiosincrasias do SQL: WHERE é avaliado antes do SELECT e GROUP BY, então o SQL precisa de uma outra cláusula que seja avaliada depois.\n\ndiamantes_bd |&gt; \n  group_by(corte) |&gt; \n  summarize(n = n()) |&gt; \n  filter(n &gt; 100) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT corte, COUNT(*) AS n\n#&gt; FROM diamante\n#&gt; GROUP BY corte\n#&gt; HAVING (COUNT(*) &gt; 100.0)\n\n\n21.5.6 ORDER BY\nOrdenar linhas involve uma tradução direta de arrange() para a cláusula ORDER BY:\n\nvoos |&gt; \n  arrange(ano, mes, dia, desc(atraso_saida)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT voos.*\n#&gt; FROM voos\n#&gt; ORDER BY ano, mes, dia, atraso_saida DESC\n\nNote como desc() é traduzido para DESC: esta é uma das muitas funções dplyr cujo o nome foi diretamente inspirado pelo SQL.\n\n21.5.7 Subconsultas\nAlgumas vezes não é possível traduzir um pipeline dplyr em uma única declaração SELECT e você precisa usar uma subconsulta. Uma subconsulta é apenas uma consulta usada como uma fonte de dados na cláusula FROM ao invés de uma tabela normal.\nO dbplyr tipicamente usa subconsultas para solucionar paleativamente limitações do SQL. Por exemplo, expressões na cláusula SELECT não podem referenciar colunas que acabaram de ser criadas. Isto significa que o seguinte pipeline (muito simples) precisa acontecer em duas etapas: a primeira consulta (interna) computa ano1 e então a segunda consulta (externa) pode computar ano2.\n\nvoos |&gt; \n  mutate(\n    ano1 = ano + 1,\n    ano2 = ano1 + 1\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*, ano1 + 1.0 AS ano2\n#&gt; FROM (\n#&gt;   SELECT voos.*, ano + 1.0 AS ano1\n#&gt;   FROM voos\n#&gt; ) q01\n\nVocê também verá isso se tentar filtrar com filter() a variável que você criou recentemente. Lembre-se que, apesar de WHERE ser escrita depois de SELECT, ela é avaliada antes, por isso você precisa de uma subconsulta neste simples exemplo:\n\nvoos |&gt; \n  mutate(ano1 = ano + 1) |&gt; \n  filter(ano1 == 2014) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*\n#&gt; FROM (\n#&gt;   SELECT voos.*, ano + 1.0 AS ano1\n#&gt;   FROM voos\n#&gt; ) q01\n#&gt; WHERE (ano1 = 2014.0)\n\nAlgumas vezes, dbplyr irá criar uma subconsulta mesmo onde não é necessário, pois não sabe ainda como otimizar tal tradução. Conforme dbplyr melhora, estes casos vão ficando mais raros, mas provavelmente nunca desaparecerão por completo.\n\n21.5.8 Uniões (Joins)\nSe você está familiarizado com uniões (joins) com dplyr, as uniões do SQL são bem parecidas. Aqui está um exemplo simples:\n\nvoos |&gt; \n  left_join(avioes |&gt; rename(ano_construcao = ano), by = \"codigo_cauda\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   voos.*,\n#&gt;   avioes.ano AS ano_construcao,\n#&gt;   tipo,\n#&gt;   fabricante,\n#&gt;   modelo,\n#&gt;   motores,\n#&gt;   assentos,\n#&gt;   velocidade,\n#&gt;   tipo_motor\n#&gt; FROM voos\n#&gt; LEFT JOIN avioes\n#&gt;   ON (voos.codigo_cauda = avioes.codigo_cauda)\n\nA principal coisa a se notar aqui é a sintaxe: as uniões SQL usam sub-cláusulas da cláusula FROM para associar tabelas adicionais, usando ON para definir como as tabelas estão relacionadas.\nOs nomes das funções dplyr são tão parecidas com as do SQL que você pode facilmente adivinhar o SQL equivalente para inner_join(), right_join() e full_join():\nSELECT voos.*, \"tipo\", fabricante, modelo, motores, assentos, velocidade\nFROM voos\nINNER JOIN avioes ON (voos.codigo_cauda = avioes.codigo_cauda)\n\nSELECT voos.*, \"tipo\", fabricante, modelo, motores, assentos, velocidade\nFROM voos\nRIGHT JOIN avioes ON (voos.codigo_cauda = avioes.codigo_cauda)\n\nSELECT voos.*, \"tipo\", fabricante, modelo, motores, assentos, velocidade\nFROM voos\nFULL JOIN avioes ON (voos.codigo_cauda = avioes.codigo_cauda)\nÉ muito provavel que você precise de muitas uniões (joins) quando trabalhar com dados de um banco de dados. Isto porque tabelas são frequentemente armazenadas de uma forma altamente normalizada, onde cada “fato” é armazenado em um único local e para manter um conjunto de dados completo para análise, você precisa navegar por uma rede complexa de tabelas conectadas por chaves primárias (primary key) e chaves estrangeiras (foreign key). Se você encontrar este cenário, o pacote dm, de Tobias Schieferdecker, Kirill Müller e Darko Bergant é um salva-vidas. Ele pode automaticamente determinar as conexões entre as tabelas usando restrições (constraints) que as pessoas que adminstram bancos de dados (DBAs) geralmente fornecem, gera visualizações para que você entenda o que está acontecendo e gera as uniões (joins) que você precisa para conectar uma tabela à outra.\n\n21.5.9 Outros verbos\nO dbplyr também traduz outros verbos como distinct(), slice_*(), intersect(), e uma seleção crescente de funções do tidyr como pivot_longer() e pivot_wider(). O jeito mais fácil de ver a lista completa do que está disponível no momento é visitando o website dbplyr: https://dbplyr.tidyverse.org/reference/.\n\n21.5.10 Exercícios\n\nEm que se traduz a distinct()? E a head()?\n\nExplique o que cada um desses comandos SQL fazem e tente recriá-los usando dbplyr.\nSELECT * \nFROM voos\nWHERE atraso_saida &lt; atraso_chegada\n\nSELECT *, distancia / (tempo_voo / 60) AS velocidade\nFROM voos",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-sql-expressions",
    "href": "databases.html#sec-sql-expressions",
    "title": "21  ✅ Bancos de dados",
    "section": "\n21.6 Tradução de funções",
    "text": "21.6 Tradução de funções\nAté agora focamos na visão geral de como os verbos dplyr são traduzidos para cláusulas em uma consulta. Agora iremos focar um pouco mais e falar sobre a tradução de funções do R que trabalham com colunas, por exemplo, o que acontece quando você usa mean(x) em um summarize()?\nPara ajudar a entender o que acontece, usaremos algumas funções de ajuda que chamam um summarize() ou mutate() and mostram o SQL produzido. Isto tornará um pouco mais fácil explorar algumas variações e ver como sumarizações e transformações podem ser diferentes.\n\nconsulta_summarize &lt;- function(df, ...) {\n  df |&gt; \n    summarize(...) |&gt; \n    show_query()\n}\nconsulta_mutate &lt;- function(df, ...) {\n  df |&gt; \n    mutate(..., .keep = \"none\") |&gt; \n    show_query()\n}\n\nVamos mergulhar em algumas sumarizações! Olhando o código abaixo, você perceberá que algumas funções de sumarização como mean(), tem uma tradução relativamente simples, enquanto outras, como median() são muito mais complexas. Esta complexidade é geralmente maior para operações que são comuns na estatística mas menos comuns em bancos de dados.\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt;  \n  consulta_summarize(\n    media = mean(atraso_chegada, na.rm = TRUE),\n    mediana = median(atraso_chegada, na.rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by \"ano\" and \"mes\". You can override using\n#&gt; the `.groups` argument.\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   ano,\n#&gt;   mes,\n#&gt;   dia,\n#&gt;   AVG(atraso_chegada) AS media,\n#&gt;   PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY atraso_chegada) AS mediana\n#&gt; FROM voos\n#&gt; GROUP BY ano, mes, dia\n\nA tradução de funções de sumarização se tornam mais complicadas quando você as usa dentro de um mutate() pois elas se transformam naquilo que conhecemos como funções de janela (window functions). No SQL, você transforma uma funções normal em uma função de janela adicionando OVER depois dela:\n\nvoos |&gt; \n  group_by(ano, mes, dia) |&gt;  \n  consulta_mutate(\n    media = mean(atraso_chegada, na.rm = TRUE),\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   ano,\n#&gt;   mes,\n#&gt;   dia,\n#&gt;   AVG(atraso_chegada) OVER (PARTITION BY ano, mes, dia) AS media\n#&gt; FROM voos\n\nNo SQL, a clásula GROUP BY é usada exclusivamente para sumarizações, portanto aqui você pode ver que o agrupamento foi movido do argumento PARTITION BY para o OVER.\nFunções de janela incluem todas as funções que olham para trás ou para frente como lead() e lag() que olham para os valores “anteriores” ou “posteriores” respectivamente:\n\nvoos |&gt; \n  group_by(destino) |&gt;  \n  arrange(data_hora) |&gt; \n  consulta_mutate(\n    lead = lead(atraso_chegada),\n    lag = lag(atraso_chegada)\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   destino,\n#&gt;   LEAD(atraso_chegada, 1, NULL) OVER (PARTITION BY destino ORDER BY data_hora) AS lead,\n#&gt;   LAG(atraso_chegada, 1, NULL) OVER (PARTITION BY destino ORDER BY data_hora) AS lag\n#&gt; FROM voos\n#&gt; ORDER BY data_hora\n\nAqui é importante ordenar com arrange() os dados, pois tabelas SQL não possuem um ordem intrínseca. Na verdade, se você não usar arrange() você pode obter resultados em ordens diferentes toda vez! Note que nas funções de janela, a ordenação da informação se repete: a cláusula ORDER BY da consulta principal não se aplica automaticamente às funções de janela.\nOutra função SQL importante é a CASE WHEN. É usada para traduzir as funções if_else() e case_when() que dplyr se inspirou diretamente. Aqui estão alguns exemplos simples:\n\nvoos |&gt; \n  consulta_mutate(\n    descricao = if_else(atraso_chegada &gt; 0, \"atrasado\", \"no horario\")\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE WHEN (atraso_chegada &gt; 0.0) THEN 'atrasado' WHEN NOT (atraso_chegada &gt; 0.0) THEN 'no horario' END AS descricao\n#&gt; FROM voos\n\nvoos |&gt; \n  consulta_mutate(\n    descricao = \n      case_when(\n        atraso_chegada &lt; -5 ~ \"adiantado\", \n        atraso_chegada &lt; 5 ~ \"no horario\",\n        atraso_chegada &gt;= 5 ~ \"atrasado\"\n      )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (atraso_chegada &lt; -5.0) THEN 'adiantado'\n#&gt; WHEN (atraso_chegada &lt; 5.0) THEN 'no horario'\n#&gt; WHEN (atraso_chegada &gt;= 5.0) THEN 'atrasado'\n#&gt; END AS descricao\n#&gt; FROM voos\n\nCASE WHEN também é usado para algumas funções que não tem tradução direta do R para o SQL. Um bom exemplo disso é cut():\n\nvoos |&gt; \n  consulta_mutate(\n    descricao =  cut(\n      atraso_chegada, \n      breaks = c(-Inf, -5, 5, Inf), \n      labels = c(\"adiantado\", \"no horario\", \"atrasado\")\n    )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (atraso_chegada &lt;= -5.0) THEN 'adiantado'\n#&gt; WHEN (atraso_chegada &lt;= 5.0) THEN 'no horario'\n#&gt; WHEN (atraso_chegada &gt; 5.0) THEN 'atrasado'\n#&gt; END AS descricao\n#&gt; FROM voos\n\nO dbplyr também traduz funções comuns de manipulação de string e data/hora (datetime), as quais você pode aprender sobre na vignette(\"translation-function\", package = \"dbplyr\"). As traduções do dbplyr certamente não são perfeitas, e ainda existem muitas funções do R que ainda não são traduzidas, mas o dbplyr faz um surpreendente bom trabalho em traduzir as funções que você usará na maior parte do tempo.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#resumo",
    "href": "databases.html#resumo",
    "title": "21  ✅ Bancos de dados",
    "section": "\n21.7 Resumo",
    "text": "21.7 Resumo\nNeste capítulo você aprendeu como acessar dados de um banco de dados. Nós focamos no dbplyr, um “backend” do dplyr que permite que você escreva o código dplyr que está familiarizado e o tenha automaticamente traduzido em SQL. Nós utilizamos esta tradução para te ensinar um pouco de SQL; é importante aprender SQL pois é a linguagem mais comumente utilizada para se trabalhar com dados e conhecê-la um pouco facilitrá sua comunicação com outras pessoas de dados que não usam o R. Se você terminou este capítulo e gostaria de aprender mais sobre SQL. Nós temos duas recomendações:\n\n\nSQL for Data Scientists de Renée M. P. Teate é uma introdução ao SQL desenhada especificamente para as necessidades de cientistas de dados e inclui exemplos com dados altamente interconectados que você geralmente encontra em organizações reais.\n\nPractical SQL de Anthony DeBarros é escrito sob a perspectiva de uma pessoa jornalista de dados (cientista de dados especialista em contar histórias atraentes) e entra em mais detalhes sobre ter seus dados em um banco de dados e rodar seu próprio SGBD.\n\nNo próximo capítulo, você aprenderá sobre outro backend dplyr para trabalhar com grandes volumes de dados: arrow. Arrow é desenhado para trabalhar com grandes arquivos em disco e é um complemento natural aos bancos de dados.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "databases.html#footnotes",
    "href": "databases.html#footnotes",
    "title": "21  ✅ Bancos de dados",
    "section": "",
    "text": "SQL é pronunciado “s”-“q”-“l”.↩︎\nNormalmente, esta é a única função que você usará do pacote cliente, por isso recomendamos usar o :: para referenciar esta função específica, ao invés de carregar todo o pacote usando library().↩︎\nAo menos, todas as tabelas que você tem permissão para ver.↩︎\nNota de tradução: O pacote dbplyr vem com a função dbplyr::copy_nycflights13() que copia as tabelas originais, em inglês, para o banco de dados. Como estamos utilizando os dados traduzidos, disponíveis no pacote dados, vamos copiar as tabelas traduzidas para o banco de dados utilizando a função dbWriteTable() do pacote DBI.↩︎\nÉ estranho, mas dependendo do contexto, SELECT pode ser tanto uma declaração quanto uma cláusula. Para evitar esta confusão, iremos usar uma consulta SELECT ao invés de um declaração SELECT.↩︎\nOk, tecnicamente, somente o SELECT é necessário, já que você pode escrever consultas como SELECT 1+1 para executar cálculos básicos. Mas se você quer trabalhar com dados (como você faz sempre!) você precisará da cláusula FROM.↩︎\nIsto não é uma coincidência: A função dplyr foi inspirada na cláusula SQL.↩︎",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>✅ Bancos de dados</span>"
    ]
  },
  {
    "objectID": "arrow.html",
    "href": "arrow.html",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1 Introdução\nArquivos CSV são feitos para serem lidos facilmente por seres humanos. Eles são um bom formato de intercâmbio porque são muito simples e podem ser lidos por qualquer ferramenta existente. Porém, arquivos CSV não são muito eficientes: você tem muito trabalho para importar os dados para o R. Neste capítulo, você aprenderá uma alternativa poderosa: o formato parquet, um formato baseado em um padrão aberto amplamente utilizado em sistemas de grande volume de dados (big data).\nNós iremos juntar arquivos parquet com o Apache Arrow, um conjunto de ferramentas multi-linguagens projetado para análise eficiente e transporte de grandes conjunto de dados. Usaremos Apache Arrow via o pacote arrow, o qual fornece um backend dplyr, permitindo que você analise conjuntos de dados maiores que a quantidade de memória de seu computador, usando a familiar sintaxe dplyr. Como benefício adicional, o arrow é extremamente rápido: você verá alguns exemplos a seguir neste capítulo.\nTanto o pacote arrow quanto o pacote dbplyr rodam por trás do dplyr (dplyr backends), assim, você deve estar se perguntando quando usar um ou outro. Em muitos casos, a escolha já foi feita para você, pois os dados já estão em bancos de dados ou em arquivos parquet e você trabalhará com eles da forma como já estão. Mas se você está começando com seus próprios dados (talvez arquivos CSV), você pode carregá-los em um banco de dados ou convertê-los para parquet. Geralmente, é dificil saber qual funcionará melhor, então para fases iniciais da tua análise, vamos te encorajar a tentar usar ambos e escolher aquele que funcione melhor para você.\n(Um grande obrigado à Danielle Navarro que contribuiu com a versão inicial deste capítulo.)",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#introdução",
    "href": "arrow.html#introdução",
    "title": "22  Arrow",
    "section": "",
    "text": "22.1.1 Pré-requisitos\nNeste capítulo, continuaremos a usar o tidyverse, particularmente o dplyr, mas iremos combiná-lo com o pacote arrow, que foi projetado especificamente para trabalhar com grandes conjuntos de dados.\n\nlibrary(tidyverse)\nlibrary(arrow)\n\nPosteriormente neste capítulo, veremos também algumas conexões entre o arrow e o duckdb, portanto também precisaremos do dbplyr e duckdb.\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n#&gt; Loading required package: DBI",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#obtendo-os-dados",
    "href": "arrow.html#obtendo-os-dados",
    "title": "22  Arrow",
    "section": "\n22.2 Obtendo os dados",
    "text": "22.2 Obtendo os dados\nComeçamos obtendo um conjunto de dados que precise destas ferramentas: um conjunto de dados de items retirados das bibliotecas públicas de Seattle, disponível online em data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6. Este conjunto de dados possui 41.389.465 linhas que informam quantas vezes cada livro foi retirado em cada mês, desde Abril de 2005 até Outubro de 2022.\nO código abaixo faz download de uma cópia em cache desses dados. O dado é um arquivo CSV de 9 GB, portanto leva um certo tempo para baixar. Eu recomendo fortemente usar curl::multi_download() para baixar grandes arquivos já que foi projetado exatamente para este propósito: fornece uma barra de progresso e pode retomar o download se for interrompido.\n\ndir.create(\"data\", showWarnings = FALSE)\n\ncurl::multi_download(\n  \"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\",\n  \"data/seattle-library-checkouts.csv\",\n  resume = TRUE\n)\n#&gt; # A tibble: 1 × 10\n#&gt;   success status_code resumefrom url                    destfile        error\n#&gt;   &lt;lgl&gt;         &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;           &lt;chr&gt;\n#&gt; 1 TRUE            200          0 https://r4ds.s3.us-we… data/seattle-l… &lt;NA&gt; \n#&gt; # ℹ 4 more variables: type &lt;chr&gt;, modified &lt;dttm&gt;, time &lt;dbl&gt;,\n#&gt; #   headers &lt;list&gt;",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#abrindo-o-conjunto-de-dados",
    "href": "arrow.html#abrindo-o-conjunto-de-dados",
    "title": "22  Arrow",
    "section": "\n22.3 Abrindo o conjunto de dados",
    "text": "22.3 Abrindo o conjunto de dados\nVamos começar dando uma olhada nos dados. Com 9 GB, este arquivo é tão grande que provavelmente não queremos carregá-lo por inteiro na memória do computador. Como regra geral, dizemos que você vai querer ter no mínimo duas vezes mais memória que o tamanho dos dados e muitos notebooks chegam até 16 GB. Isto significa que queremos evitar read_csv() e, ao invés disso, usar arrow::open_dataset():\n\nseattle_csv &lt;- open_dataset(\n  sources = \"data/seattle-library-checkouts.csv\", \n  col_types = schema(ISBN = string()),\n  format = \"csv\"\n)\n\nO que acontece quando este código é executado? open_dataset() irá inspecionar (scan) alguns milhares de linhas para entender a estrutura do conjunto de dados. A coluna ISBN contém valores em branco nas primeiras 80.000 linhas, portanto devemos especificar o tipo da coluna para ajudar o arrow a trabalhar com a estrutura de dados. Uma vez que os dados foram varridos pela open_dataset(), ele registra o que encontrou e para; ele lerá mais linhas apenas quando você explicitamente solicitar. Este metadado é o que vemos quando imprimimos seattle_csv:\n\nseattle_csv\n#&gt; FileSystemDataset with 1 csv file\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutYear: int64\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n\nA primeira linha na saída te diz que seattle_csv está armazenado localmente em disco como um único arquivo CSV; ele será carregado em memória apenas quando necessário. O restante da saída informa o tipo atribuído pelo arrow para cada coluna.\nPodemos ver o que realmente temos no conjunto de dados com glimpse(). Isto revela que há ~41 milhões de linhas e 12 colunas, e nos mostra alguns valores.\n\nseattle_csv |&gt; glimpse()\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 41,389,465 rows x 12 columns\n#&gt; $ UsageClass      &lt;string&gt; \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Ph…\n#&gt; $ CheckoutType    &lt;string&gt; \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Hor…\n#&gt; $ MaterialType    &lt;string&gt; \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOO…\n#&gt; $ CheckoutYear     &lt;int64&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20…\n#&gt; $ CheckoutMonth    &lt;int64&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n#&gt; $ Checkouts        &lt;int64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,…\n#&gt; $ Title           &lt;string&gt; \"Super rich : a guide to having it all / Russell S…\n#&gt; $ ISBN            &lt;string&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#&gt; $ Creator         &lt;string&gt; \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim …\n#&gt; $ Subjects        &lt;string&gt; \"Self realization, Conduct of life, Attitude Psych…\n#&gt; $ Publisher       &lt;string&gt; \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Di…\n#&gt; $ PublicationYear &lt;string&gt; \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20…\n\nPodemos começar a usar este conjunto de dados com verbos dplyr usando collect() para forçar o arrow a executar a computação e retornar algum dado. Por exemplo, este código nos mostra o número total de retiradas (checkouts) por ano (year):\n\nseattle_csv |&gt; \n  group_by(CheckoutYear) |&gt; \n  summarise(Checkouts = sum(Checkouts)) |&gt; \n  arrange(CheckoutYear) |&gt; \n  collect()\n#&gt; # A tibble: 18 × 2\n#&gt;   CheckoutYear Checkouts\n#&gt;          &lt;int&gt;     &lt;int&gt;\n#&gt; 1         2005   3798685\n#&gt; 2         2006   6599318\n#&gt; 3         2007   7126627\n#&gt; 4         2008   8438486\n#&gt; 5         2009   9135167\n#&gt; 6         2010   8608966\n#&gt; # ℹ 12 more rows\n\nGraças ao arrow, este código funcionará independente do tamanho do conjunto de dados que tivermos. Porém, ainda é um pouco lento: no computador do Hadley demorou ~10 segundos para concluir. Não é tão terrível considerando a quantidade de dados que temos, mas podemos deixá-lo mais rápido mudando para um formato melhor.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#sec-parquet",
    "href": "arrow.html#sec-parquet",
    "title": "22  Arrow",
    "section": "\n22.4 O formato parquet\n",
    "text": "22.4 O formato parquet\n\nPara tornar este conjunto de dados mais fácil de trabalhar, vamos trocá-lo para o formato de arquivo parquet e dividí-lo em múltiplos arquivos. As seções seguintes irão primeiramente introduzir você ao parquet e particionamento (partitioning) e então aplicar o que aprendemos nos dados das bibliotecas de Seattle.\n\n22.4.1 Vantagens do parquet\n\nAssim como CSV, parquet é usado para dados retangulares, mas ao invés de ser um formato texto que você pode ler com qualquer editor de arquivo, é um formato binário personalizado projetado especificamente para as necessidades de grandes volumes de dados (big data). Isto significa que:\n\nArquivos parquet são normalmente menores que seus arquivos equivalentes CSV. Parquet é baseado em codificação eficiente para manter o tamanho do arquivo menor, e permite a compressão do arquivo. Isto ajuda a tornar os arquivos parquet rápidos, pois há menos dados para serem movidos do disco para a memória.\nArquivos parquet possuem um rico sistema de tipagem. Como falamos na Seção 7.3, um arquivo CSV não fornece nenhuma informação sobre os tipos das colunas. Por exemplo, um leitor de CSV precisa adivinhar se \"08-10-2022\" deve ser lido como texto ou data. Diferentemente, arquivos parquet armazenam dados de maneira a registrar o tipo juntamente com os dados.\nArquivos parquet são “orientados-a-colunas” (column-oriented). Isto significa que eles são organizados coluna por coluna, muito parecido com os data frames do R. Isto geramente leva a um melhor desempenho para tarefas de análise de dados quando comparado aos arquivos CSV, que são organizados linha a linha.\nArquivos parquet são “fragmentados” (chunked), o que torna possível trabalhar em diferentes partes do mesmo arquivo ao mesmo tempo e, se você tiver sorte, pular alguns fragmentos completamente.\n\nHá uma desvantagem primária nos arquivos parquet: eles não podem mais ser “lidos por humanos”, ou seja, se você olhar para um arquivo parquet usando readr::read_file(), você verá apenas um monte de caracteres sem sentido.\n\n22.4.2 Particionamento\nConforme os conjuntos de dados vão ficando cada vez maiores, armazenar todos os dados em um único arquivo fica cada vez mais problemático, e geralmente é mais útil dividi-los em vários arquivos. Quando esta estrutura é feita de forma inteligente, esta estratégia pode levar a melhoras significativas de desempenho, pois muitas análises precisam apenas de um subconjunto dos arquivos.\nNão existem regras absolutas sobre como particionar seu conjunto de dados: os resultados dependerão de seus dados, padrões de acesso e os sistemas que lêem os dados. Você provavelmente precisará fazer alguns experimentos antes de encontrar o particionamento ideal para sua situação. Como uma recomendação aproximada, arrow sugere que você evite arquivos menores que 20MB e maiores que 2GB e evite particionamentos que produzam mais que 10.000 arquivos. Você deve também tentar particionar por variáveis usadas em filtros; como você verá em breve, isto permite que o arrow evite trabalho desnecessário e leia apenas os arquivos relevantes.\n\n22.4.3 Reescrevendo os dados das bibliotecas de Seattle\n\nVamos aplicar estas ideias nos dados das bibliotecas de Seattle e ver como se saem na prática. Vamos particionar os dados por CheckoutYear (ano da retirada), já que é provável que algumas análises queiram apenas olhar para dados recentes e particionar por ano gera 18 fragmentos de tamanho razoável.\nPara reescrever os dados, definimos o particionamento usando dplyr::group_by() e então salvamos as partições em um diretório com arrow::write_dataset(). write_dataset() tem dois argumentos importantes: um diretório onde criaremos os arquivos e o formato que usaremos.\n\npq_path &lt;- \"data/seattle-library-checkouts\"\n\n\nseattle_csv |&gt;\n  group_by(CheckoutYear) |&gt;\n  write_dataset(path = pq_path, format = \"parquet\")\n\nIsto leva aproximadamente um minuto para executar; como veremos em breve, este investimento de tempo inicial será compensado, pois tornará as operações futuras muito mais rápidas.\nVamos ver o que acabamos de produzir:\n\ntibble(\n  arquivos = list.files(pq_path, recursive = TRUE),\n  tamanho_MB = file.size(file.path(pq_path, arquivos)) / 1024^2\n)\n#&gt; # A tibble: 18 × 2\n#&gt;   arquivos                         tamanho_MB\n#&gt;   &lt;chr&gt;                                 &lt;dbl&gt;\n#&gt; 1 CheckoutYear=2005/part-0.parquet       109.\n#&gt; 2 CheckoutYear=2006/part-0.parquet       164.\n#&gt; 3 CheckoutYear=2007/part-0.parquet       178.\n#&gt; 4 CheckoutYear=2008/part-0.parquet       195.\n#&gt; 5 CheckoutYear=2009/part-0.parquet       214.\n#&gt; 6 CheckoutYear=2010/part-0.parquet       222.\n#&gt; # ℹ 12 more rows\n\nO arquivo CSV único de 9GB foi reescrito como 18 arquivos parquet. Os nomes dos arquivos usam uma convenção de “auto-descrição” usada pelo projeto Apache Hive. Partições no estilo Hive nomeiam as pastas com uma convenção “chave=valor” e como você pode imaginar, o diretório CheckoutYear=2005 contém todos os dados onde o ano da retirada (CheckoutYear) é 2005. Cada arquivo tem entre 100 e 300 MB e o tamanho total agora é aproximandamente 4 GB, um pouco mais que a metade do arquivo CSV original. Isto é o que esperamos, já que parquet é um formato muito mais eficiente.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#usando-dplyr-com-arrow",
    "href": "arrow.html#usando-dplyr-com-arrow",
    "title": "22  Arrow",
    "section": "\n22.5 Usando dplyr com arrow\n",
    "text": "22.5 Usando dplyr com arrow\n\nAgora que criamos estes arquivos parquet, precisamos lê-los novamente. Nós usamos open_dataset() novamente, mas dessa vez informando um diretório:\n\nseattle_pq &lt;- open_dataset(pq_path)\n\nAgora podemos escrever nosso pipeline dplyr. Por exemplo, poderíamos contar o número total de livros retirados em cada mês dos últimos cinco anos:\n\nquery &lt;- seattle_pq |&gt; \n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear, CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(CheckoutYear, CheckoutMonth)\n\nEscrever código dplyr para arrow é conceitualmente similar ao dbplyr, Capítulo 21: você escreve o código dplyr, que é automaticamente transformado em uma consulta compreensível para a biblioteca C++ do Apache Arrow e que será executada quando você chamar collect(). Se imprimirmos o objeto query podemos ver algumas informações sobre o que esperamos que o Arrow nos retorne quando a execução ocorrer:\n\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\nE podemos obter os resultados chamando collect():\n\nquery |&gt; collect()\n#&gt; # A tibble: 58 × 3\n#&gt; # Groups:   CheckoutYear [5]\n#&gt;   CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;          &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt; 1         2018             1         355101\n#&gt; 2         2018             2         309813\n#&gt; 3         2018             3         344487\n#&gt; 4         2018             4         330988\n#&gt; 5         2018             5         318049\n#&gt; 6         2018             6         341825\n#&gt; # ℹ 52 more rows\n\nAssim como dbplyr, arrow entende apenas algumas expressões do R, portanto você pode não conseguir escrever exatamente o mesmo código que escreveria normalmente. Entretanto, a lista de operações e funções suportadas é bastante extensa e continua aumentando; veja a lista completa de funções atualmente suportadas digitando ?acero.\n\n22.5.1 Desempenho\nVamos dar uma olhada rápida em como a mudança de CSV para parquet impactou o desempenho. Primeiro, vamos medir quanto tempo demora para calcular o número de livros retirados em cada mês de 2021 quando os dados estão armazenados em um único grande arquivo csv:\n\nseattle_csv |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;  15.691   1.408  14.932\n\nAgora, vamos usar nossa nova versão do conjunto de dados na qual os dados de retiradas das bibliotecas de Seattle foram particionadas em 18 arquivos parquet menores:\n\nseattle_pq |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;   0.339   0.054   0.081\n\nA melhora de desempenho de ~100x é atribuída a dois fatores: O particionamento de vários arquivos e o formato de cada arquivo:\n\nO particionamento melhora o desempenho pois esta consulta usa CheckoutYear == 2021 para filtrar os dados, e arrow é inteligente o suficiente para reconhecer que precisa ler apenas 1 dos 18 arquivos parquet.\nO formato parquet melhora o desempenho por armazenar dados em formato binário que pode ser carregado mais diretamente para a memória. O formato colunar (column-wise) e os metadados ricos fazem com que o arrow precise ler apenas as quatro colunas usadas na consulta (CheckoutYear, MaterialType, CheckoutMonth e Checkouts).\n\nEsta diferença de desempenho massiva é o motivo pelo qual vale a pena converter grandes arquivos CSV para parquet!\n\n22.5.2 Usando duckdb com arrow\n\nTem uma última vantagem de usar parquet e arrow — é muito fácil transformar um conjunto de dados arrow em um banco de dados DuckDB (Capítulo 21) chamando arrow::to_duckdb():\n\nseattle_pq |&gt; \n  to_duckdb() |&gt;\n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutYear)) |&gt;\n  collect()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # A tibble: 5 × 2\n#&gt;   CheckoutYear TotalCheckouts\n#&gt;          &lt;int&gt;          &lt;dbl&gt;\n#&gt; 1         2022        2431502\n#&gt; 2         2021        2266438\n#&gt; 3         2020        1241999\n#&gt; 4         2019        3931688\n#&gt; 5         2018        3987569\n\nO legal da função to_duckdb() é que a transferência não envolve nenhuma cópia de memória e atende aos objetivos do ecossistema arrow: permitir transições transparentes de um ambiente computacional para outro.\n\n22.5.3 Exercícios\n\nEncontre os livros mais populares para cada ano.\nQual autor tem mais livros no sistema de bibliotecas de Seattle?\nComo as retiradas de livros vs livros eletrônicos (ebooks) mudaram ao longo dos últimos 10 anos?",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "arrow.html#resumo",
    "href": "arrow.html#resumo",
    "title": "22  Arrow",
    "section": "\n22.6 Resumo",
    "text": "22.6 Resumo\nNeste capítulo, você experimentou o pacote arrow, que fornece um backend dplyr para trabalhar com grandes conjuntos de dados em disco. Ele pode funcionar com arquivos CSV e é muito mais rápido se você converter seus dados para parquet. Parquet é um formato de dados binários projetado especificamente para análise de dados em computadores modernos. Um número muito menor de ferramentas podem funcionar com arquivos parquet em comparação com CSV, mas sua estrutura particionada, compactada e colunar torna sua análise muito mais eficiente.\nA seguir, você aprenderá sobre sua primeira fonte de dados não retangular, que você manipulará usando ferramentas fornecidas pelo pacote tidyr. Vamos nos concentrar nos dados provenientes de arquivos JSON, mas os princípios gerais se aplicam a dados com estrutura baseada em árvore (tree-like), independentemente de sua origem.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>✅ Arrow</span>"
    ]
  },
  {
    "objectID": "rectangling.html",
    "href": "rectangling.html",
    "title": "23  Hierarchical data",
    "section": "",
    "text": "23.1 Introduction\nIn this chapter, you’ll learn the art of data rectangling: taking data that is fundamentally hierarchical, or tree-like, and converting it into a rectangular data frame made up of rows and columns. This is important because hierarchical data is surprisingly common, especially when working with data that comes from the web.\nTo learn about rectangling, you’ll need to first learn about lists, the data structure that makes hierarchical data possible. Then you’ll learn about two crucial tidyr functions: tidyr::unnest_longer() and tidyr::unnest_wider(). We’ll then show you a few case studies, applying these simple functions again and again to solve real problems. We’ll finish off by talking about JSON, the most frequent source of hierarchical datasets and a common format for data exchange on the web.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#introduction",
    "href": "rectangling.html#introduction",
    "title": "23  Hierarchical data",
    "section": "",
    "text": "23.1.1 Prerequisites\nIn this chapter, we’ll use many functions from tidyr, a core member of the tidyverse. We’ll also use repurrrsive to provide some interesting datasets for rectangling practice, and we’ll finish by using jsonlite to read JSON files into R lists.\n\nlibrary(tidyverse)\nlibrary(repurrrsive)\nlibrary(jsonlite)",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#lists",
    "href": "rectangling.html#lists",
    "title": "23  Hierarchical data",
    "section": "\n23.2 Lists",
    "text": "23.2 Lists\nSo far you’ve worked with data frames that contain simple vectors like integers, numbers, characters, date-times, and factors. These vectors are simple because they’re homogeneous: every element is of the same data type. If you want to store elements of different types in the same vector, you’ll need a list, which you create with list():\n\nx1 &lt;- list(1:4, \"a\", TRUE)\nx1\n#&gt; [[1]]\n#&gt; [1] 1 2 3 4\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"a\"\n#&gt; \n#&gt; [[3]]\n#&gt; [1] TRUE\n\nIt’s often convenient to name the components, or children, of a list, which you can do in the same way as naming the columns of a tibble:\n\nx2 &lt;- list(a = 1:2, b = 1:3, c = 1:4)\nx2\n#&gt; $a\n#&gt; [1] 1 2\n#&gt; \n#&gt; $b\n#&gt; [1] 1 2 3\n#&gt; \n#&gt; $c\n#&gt; [1] 1 2 3 4\n\nEven for these very simple lists, printing takes up quite a lot of space. A useful alternative is str(), which generates a compact display of the structure, de-emphasizing the contents:\n\nstr(x1)\n#&gt; List of 3\n#&gt;  $ : int [1:4] 1 2 3 4\n#&gt;  $ : chr \"a\"\n#&gt;  $ : logi TRUE\nstr(x2)\n#&gt; List of 3\n#&gt;  $ a: int [1:2] 1 2\n#&gt;  $ b: int [1:3] 1 2 3\n#&gt;  $ c: int [1:4] 1 2 3 4\n\nAs you can see, str() displays each child of the list on its own line. It displays the name, if present, then an abbreviation of the type, then the first few values.\n\n23.2.1 Hierarchy\nLists can contain any type of object, including other lists. This makes them suitable for representing hierarchical (tree-like) structures:\n\nx3 &lt;- list(list(1, 2), list(3, 4))\nstr(x3)\n#&gt; List of 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 1\n#&gt;   ..$ : num 2\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 3\n#&gt;   ..$ : num 4\n\nThis is notably different to c(), which generates a flat vector:\n\nc(c(1, 2), c(3, 4))\n#&gt; [1] 1 2 3 4\n\nx4 &lt;- c(list(1, 2), list(3, 4))\nstr(x4)\n#&gt; List of 4\n#&gt;  $ : num 1\n#&gt;  $ : num 2\n#&gt;  $ : num 3\n#&gt;  $ : num 4\n\nAs lists get more complex, str() gets more useful, as it lets you see the hierarchy at a glance:\n\nx5 &lt;- list(1, list(2, list(3, list(4, list(5)))))\nstr(x5)\n#&gt; List of 2\n#&gt;  $ : num 1\n#&gt;  $ :List of 2\n#&gt;   ..$ : num 2\n#&gt;   ..$ :List of 2\n#&gt;   .. ..$ : num 3\n#&gt;   .. ..$ :List of 2\n#&gt;   .. .. ..$ : num 4\n#&gt;   .. .. ..$ :List of 1\n#&gt;   .. .. .. ..$ : num 5\n\nAs lists get even larger and more complex, str() eventually starts to fail, and you’ll need to switch to View()1. Figura 23.1 shows the result of calling View(x5). The viewer starts by showing just the top level of the list, but you can interactively expand any of the components to see more, as in Figura 23.2. RStudio will also show you the code you need to access that element, as in Figura 23.3. We’ll come back to how this code works in Seção 27.3.\n\n\n\n\n\n\n\nFigura 23.1: The RStudio view lets you interactively explore a complex list. The viewer opens showing only the top level of the list.\n\n\n\n\n\n\n\n\n\n\n\nFigura 23.2: Clicking on the rightward facing triangle expands that component of the list so that you can also see its children.\n\n\n\n\n\n\n\n\n\n\n\nFigura 23.3: You can repeat this operation as many times as needed to get to the data you’re interested in. Note the bottom-left corner: if you click an element of the list, RStudio will give you the subsetting code needed to access it, in this case x5[[2]][[2]][[2]].\n\n\n\n\n\n23.2.2 List-columns\nLists can also live inside a tibble, where we call them list-columns. List-columns are useful because they allow you to place objects in a tibble that wouldn’t usually belong in there. In particular, list-columns are used a lot in the tidymodels ecosystem, because they allow you to store things like model outputs or resamples in a data frame.\nHere’s a simple example of a list-column:\n\ndf &lt;- tibble(\n  x = 1:2, \n  y = c(\"a\", \"b\"),\n  z = list(list(1, 2), list(3, 4, 5))\n)\ndf\n#&gt; # A tibble: 2 × 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n#&gt; 2     2 b     &lt;list [3]&gt;\n\nThere’s nothing special about lists in a tibble; they behave like any other column:\n\ndf |&gt; \n  filter(x == 1)\n#&gt; # A tibble: 1 × 3\n#&gt;       x y     z         \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;list&gt;    \n#&gt; 1     1 a     &lt;list [2]&gt;\n\nComputing with list-columns is harder, but that’s because computing with lists is harder in general; we’ll come back to that in Capítulo 26. In this chapter, we’ll focus on unnesting list-columns out into regular variables so you can use your existing tools on them.\nThe default print method just displays a rough summary of the contents. The list column could be arbitrarily complex, so there’s no good way to print it. If you want to see it, you’ll need to pull out just the one list-column and apply one of the techniques that you’ve learned above, like df |&gt; pull(z) |&gt; str() or df |&gt; pull(z) |&gt; View().\n\n\n\n\n\n\nBase R\n\n\n\nIt’s possible to put a list in a column of a data.frame, but it’s a lot fiddlier because data.frame() treats a list as a list of columns:\n\ndata.frame(x = list(1:3, 3:5))\n#&gt;   x.1.3 x.3.5\n#&gt; 1     1     3\n#&gt; 2     2     4\n#&gt; 3     3     5\n\nYou can force data.frame() to treat a list as a list of rows by wrapping it in list I(), but the result doesn’t print particularly well:\n\ndata.frame(\n  x = I(list(1:2, 3:5)), \n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n#&gt;         x       y\n#&gt; 1    1, 2    1, 2\n#&gt; 2 3, 4, 5 3, 4, 5\n\nIt’s easier to use list-columns with tibbles because tibble() treats lists like vectors and the print method has been designed with lists in mind.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#unnesting",
    "href": "rectangling.html#unnesting",
    "title": "23  Hierarchical data",
    "section": "\n23.3 Unnesting",
    "text": "23.3 Unnesting\nNow that you’ve learned the basics of lists and list-columns, let’s explore how you can turn them back into regular rows and columns. Here we’ll use very simple sample data so you can get the basic idea; in the next section we’ll switch to real data.\nList-columns tend to come in two basic forms: named and unnamed. When the children are named, they tend to have the same names in every row. For example, in df1, every element of list-column y has two elements named a and b. Named list-columns naturally unnest into columns: each named element becomes a new named column.\n\ndf1 &lt;- tribble(\n  ~x, ~y,\n  1, list(a = 11, b = 12),\n  2, list(a = 21, b = 22),\n  3, list(a = 31, b = 32),\n)\n\nWhen the children are unnamed, the number of elements tends to vary from row-to-row. For example, in df2, the elements of list-column y are unnamed and vary in length from one to three. Unnamed list-columns naturally unnest into rows: you’ll get one row for each child.\n\n\ndf2 &lt;- tribble(\n  ~x, ~y,\n  1, list(11, 12, 13),\n  2, list(21),\n  3, list(31, 32),\n)\n\ntidyr provides two functions for these two cases: unnest_wider() and unnest_longer(). The following sections explain how they work.\n\n23.3.1 unnest_wider()\n\nWhen each row has the same number of elements with the same names, like df1, it’s natural to put each component into its own column with unnest_wider():\n\ndf1 |&gt; \n  unnest_wider(y)\n#&gt; # A tibble: 3 × 3\n#&gt;       x     a     b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\nBy default, the names of the new columns come exclusively from the names of the list elements, but you can use the names_sep argument to request that they combine the column name and the element name. This is useful for disambiguating repeated names.\n\ndf1 |&gt; \n  unnest_wider(y, names_sep = \"_\")\n#&gt; # A tibble: 3 × 3\n#&gt;       x   y_a   y_b\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11    12\n#&gt; 2     2    21    22\n#&gt; 3     3    31    32\n\n\n23.3.2 unnest_longer()\n\nWhen each row contains an unnamed list, it’s most natural to put each element into its own row with unnest_longer():\n\ndf2 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 6 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    11\n#&gt; 2     1    12\n#&gt; 3     1    13\n#&gt; 4     2    21\n#&gt; 5     3    31\n#&gt; 6     3    32\n\nNote how x is duplicated for each element inside of y: we get one row of output for each element inside the list-column. But what happens if one of the elements is empty, as in the following example?\n\ndf6 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1, 2),\n  \"b\", list(3),\n  \"c\", list()\n)\ndf6 |&gt; unnest_longer(y)\n#&gt; # A tibble: 3 × 2\n#&gt;   x         y\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 a         1\n#&gt; 2 a         2\n#&gt; 3 b         3\n\nWe get zero rows in the output, so the row effectively disappears. If you want to preserve that row, adding NA in y, set keep_empty = TRUE.\n\n23.3.3 Inconsistent types\nWhat happens if you unnest a list-column that contains different types of vector? For example, take the following dataset where the list-column y contains two numbers, a character, and a logical, which can’t normally be mixed in a single column.\n\ndf4 &lt;- tribble(\n  ~x, ~y,\n  \"a\", list(1),\n  \"b\", list(\"a\", TRUE, 5)\n)\n\nunnest_longer() always keeps the set of columns unchanged, while changing the number of rows. So what happens? How does unnest_longer() produce five rows while keeping everything in y?\n\ndf4 |&gt; \n  unnest_longer(y)\n#&gt; # A tibble: 4 × 2\n#&gt;   x     y        \n#&gt;   &lt;chr&gt; &lt;list&gt;   \n#&gt; 1 a     &lt;dbl [1]&gt;\n#&gt; 2 b     &lt;chr [1]&gt;\n#&gt; 3 b     &lt;lgl [1]&gt;\n#&gt; 4 b     &lt;dbl [1]&gt;\n\nAs you can see, the output contains a list-column, but every element of the list-column contains a single element. Because unnest_longer() can’t find a common type of vector, it keeps the original types in a list-column. You might wonder if this breaks the commandment that every element of a column must be the same type. It doesn’t: every element is a list, even though the contents are of different types.\nDealing with inconsistent types is challenging and the details depend on the precise nature of the problem and your goals, but you’ll most likely need tools from Capítulo 26.\n\n23.3.4 Other functions\ntidyr has a few other useful rectangling functions that we’re not going to cover in this book:\n\n\nunnest_auto() automatically picks between unnest_longer() and unnest_wider() based on the structure of the list-column. It’s great for rapid exploration, but ultimately it’s a bad idea because it doesn’t force you to understand how your data is structured, and makes your code harder to understand.\n\nunnest() expands both rows and columns. It’s useful when you have a list-column that contains a 2d structure like a data frame, which you don’t see in this book, but you might encounter if you use the tidymodels ecosystem.\n\nThese functions are good to know about as you might encounter them when reading other people’s code or tackling rarer rectangling challenges yourself.\n\n23.3.5 Exercises\n\nWhat happens when you use unnest_wider() with unnamed list-columns like df2? What argument is now necessary? What happens to missing values?\nWhat happens when you use unnest_longer() with named list-columns like df1? What additional information do you get in the output? How can you suppress that extra detail?\n\nFrom time-to-time you encounter data frames with multiple list-columns with aligned values. For example, in the following data frame, the values of y and z are aligned (i.e. y and z will always have the same length within a row, and the first value of y corresponds to the first value of z). What happens if you apply two unnest_longer() calls to this data frame? How can you preserve the relationship between x and y? (Hint: carefully read the docs).\n\ndf4 &lt;- tribble(\n  ~x, ~y, ~z,\n  \"a\", list(\"y-a-1\", \"y-a-2\"), list(\"z-a-1\", \"z-a-2\"),\n  \"b\", list(\"y-b-1\", \"y-b-2\", \"y-b-3\"), list(\"z-b-1\", \"z-b-2\", \"z-b-3\")\n)",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#case-studies",
    "href": "rectangling.html#case-studies",
    "title": "23  Hierarchical data",
    "section": "\n23.4 Case studies",
    "text": "23.4 Case studies\nThe main difference between the simple examples we used above and real data is that real data typically contains multiple levels of nesting that require multiple calls to unnest_longer() and/or unnest_wider(). To show that in action, this section works through three real rectangling challenges using datasets from the repurrrsive package.\n\n23.4.1 Very wide data\nWe’ll start with gh_repos. This is a list that contains data about a collection of GitHub repositories retrieved using the GitHub API. It’s a very deeply nested list so it’s difficult to show the structure in this book; we recommend exploring a little on your own with View(gh_repos) before we continue.\ngh_repos is a list, but our tools work with list-columns, so we’ll begin by putting it into a tibble. We call this column json for reasons we’ll get to later.\n\nrepos &lt;- tibble(json = gh_repos)\nrepos\n#&gt; # A tibble: 6 × 1\n#&gt;   json       \n#&gt;   &lt;list&gt;     \n#&gt; 1 &lt;list [30]&gt;\n#&gt; 2 &lt;list [30]&gt;\n#&gt; 3 &lt;list [30]&gt;\n#&gt; 4 &lt;list [26]&gt;\n#&gt; 5 &lt;list [30]&gt;\n#&gt; 6 &lt;list [30]&gt;\n\nThis tibble contains 6 rows, one row for each child of gh_repos. Each row contains a unnamed list with either 26 or 30 rows. Since these are unnamed, we’ll start with unnest_longer() to put each child in its own row:\n\nrepos |&gt; \n  unnest_longer(json)\n#&gt; # A tibble: 176 × 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [68]&gt;\n#&gt; 2 &lt;named list [68]&gt;\n#&gt; 3 &lt;named list [68]&gt;\n#&gt; 4 &lt;named list [68]&gt;\n#&gt; 5 &lt;named list [68]&gt;\n#&gt; 6 &lt;named list [68]&gt;\n#&gt; # ℹ 170 more rows\n\nAt first glance, it might seem like we haven’t improved the situation: while we have more rows (176 instead of 6) each element of json is still a list. However, there’s an important difference: now each element is a named list so we can use unnest_wider() to put each element into its own column:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) \n#&gt; # A tibble: 176 × 68\n#&gt;         id name        full_name         owner        private html_url       \n#&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;list&gt;       &lt;lgl&gt;   &lt;chr&gt;          \n#&gt; 1 61160198 after       gaborcsardi/after &lt;named list&gt; FALSE   https://github…\n#&gt; 2 40500181 argufy      gaborcsardi/argu… &lt;named list&gt; FALSE   https://github…\n#&gt; 3 36442442 ask         gaborcsardi/ask   &lt;named list&gt; FALSE   https://github…\n#&gt; 4 34924886 baseimports gaborcsardi/base… &lt;named list&gt; FALSE   https://github…\n#&gt; 5 61620661 citest      gaborcsardi/cite… &lt;named list&gt; FALSE   https://github…\n#&gt; 6 33907457 clisymbols  gaborcsardi/clis… &lt;named list&gt; FALSE   https://github…\n#&gt; # ℹ 170 more rows\n#&gt; # ℹ 62 more variables: description &lt;chr&gt;, fork &lt;lgl&gt;, url &lt;chr&gt;, …\n\nThis has worked but the result is a little overwhelming: there are so many columns that tibble doesn’t even print all of them! We can see them all with names(); and here we look at the first 10:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  names() |&gt; \n  head(10)\n#&gt;  [1] \"id\"          \"name\"        \"full_name\"   \"owner\"       \"private\"    \n#&gt;  [6] \"html_url\"    \"description\" \"fork\"        \"url\"         \"forks_url\"\n\nLet’s pull out a few that look interesting:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description)\n#&gt; # A tibble: 176 × 4\n#&gt;         id full_name               owner             description             \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;list&gt;            &lt;chr&gt;                   \n#&gt; 1 61160198 gaborcsardi/after       &lt;named list [17]&gt; Run Code in the Backgro…\n#&gt; 2 40500181 gaborcsardi/argufy      &lt;named list [17]&gt; Declarative function ar…\n#&gt; 3 36442442 gaborcsardi/ask         &lt;named list [17]&gt; Friendly CLI interactio…\n#&gt; 4 34924886 gaborcsardi/baseimports &lt;named list [17]&gt; Do we get warnings for …\n#&gt; 5 61620661 gaborcsardi/citest      &lt;named list [17]&gt; Test R package and repo…\n#&gt; 6 33907457 gaborcsardi/clisymbols  &lt;named list [17]&gt; Unicode symbols for CLI…\n#&gt; # ℹ 170 more rows\n\nYou can use this to work back to understand how gh_repos was structured: each child was a GitHub user containing a list of up to 30 GitHub repositories that they created.\nowner is another list-column, and since it contains a named list, we can use unnest_wider() to get at the values:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner)\n#&gt; Error in `unnest_wider()`:\n#&gt; ! Can't duplicate names between the affected columns and the original\n#&gt;   data.\n#&gt; ✖ These names are duplicated:\n#&gt;   ℹ `id`, from `owner`.\n#&gt; ℹ Use `names_sep` to disambiguate using the column name.\n#&gt; ℹ Or use `names_repair` to specify a repair strategy.\n\nUh oh, this list column also contains an id column and we can’t have two id columns in the same data frame. As suggested, lets use names_sep to resolve the problem:\n\nrepos |&gt; \n  unnest_longer(json) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, full_name, owner, description) |&gt; \n  unnest_wider(owner, names_sep = \"_\")\n#&gt; # A tibble: 176 × 20\n#&gt;         id full_name               owner_login owner_id owner_avatar_url     \n#&gt;      &lt;int&gt; &lt;chr&gt;                   &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;                \n#&gt; 1 61160198 gaborcsardi/after       gaborcsardi   660288 https://avatars.gith…\n#&gt; 2 40500181 gaborcsardi/argufy      gaborcsardi   660288 https://avatars.gith…\n#&gt; 3 36442442 gaborcsardi/ask         gaborcsardi   660288 https://avatars.gith…\n#&gt; 4 34924886 gaborcsardi/baseimports gaborcsardi   660288 https://avatars.gith…\n#&gt; 5 61620661 gaborcsardi/citest      gaborcsardi   660288 https://avatars.gith…\n#&gt; 6 33907457 gaborcsardi/clisymbols  gaborcsardi   660288 https://avatars.gith…\n#&gt; # ℹ 170 more rows\n#&gt; # ℹ 15 more variables: owner_gravatar_id &lt;chr&gt;, owner_url &lt;chr&gt;, …\n\nThis gives another wide dataset, but you can get the sense that owner appears to contain a lot of additional data about the person who “owns” the repository.\n\n23.4.2 Relational data\nNested data is sometimes used to represent data that we’d usually spread across multiple data frames. For example, take got_chars which contains data about characters that appear in the Game of Thrones books and TV series. Like gh_repos it’s a list, so we start by turning it into a list-column of a tibble:\n\nchars &lt;- tibble(json = got_chars)\nchars\n#&gt; # A tibble: 30 × 1\n#&gt;   json             \n#&gt;   &lt;list&gt;           \n#&gt; 1 &lt;named list [18]&gt;\n#&gt; 2 &lt;named list [18]&gt;\n#&gt; 3 &lt;named list [18]&gt;\n#&gt; 4 &lt;named list [18]&gt;\n#&gt; 5 &lt;named list [18]&gt;\n#&gt; 6 &lt;named list [18]&gt;\n#&gt; # ℹ 24 more rows\n\nThe json column contains named elements, so we’ll start by widening it:\n\nchars |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 30 × 18\n#&gt;   url                    id name            gender culture    born           \n#&gt;   &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;          \n#&gt; 1 https://www.anapio…  1022 Theon Greyjoy   Male   \"Ironborn\" \"In 278 AC or …\n#&gt; 2 https://www.anapio…  1052 Tyrion Lannist… Male   \"\"         \"In 273 AC, at…\n#&gt; 3 https://www.anapio…  1074 Victarion Grey… Male   \"Ironborn\" \"In 268 AC or …\n#&gt; 4 https://www.anapio…  1109 Will            Male   \"\"         \"\"             \n#&gt; 5 https://www.anapio…  1166 Areo Hotah      Male   \"Norvoshi\" \"In 257 AC or …\n#&gt; 6 https://www.anapio…  1267 Chett           Male   \"\"         \"At Hag's Mire\"\n#&gt; # ℹ 24 more rows\n#&gt; # ℹ 12 more variables: died &lt;chr&gt;, alive &lt;lgl&gt;, titles &lt;list&gt;, …\n\nAnd selecting a few columns to make it easier to read:\n\ncharacters &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, name, gender, culture, born, died, alive)\ncharacters\n#&gt; # A tibble: 30 × 7\n#&gt;      id name              gender culture    born              died           \n#&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;          \n#&gt; 1  1022 Theon Greyjoy     Male   \"Ironborn\" \"In 278 AC or 27… \"\"             \n#&gt; 2  1052 Tyrion Lannister  Male   \"\"         \"In 273 AC, at C… \"\"             \n#&gt; 3  1074 Victarion Greyjoy Male   \"Ironborn\" \"In 268 AC or be… \"\"             \n#&gt; 4  1109 Will              Male   \"\"         \"\"                \"In 297 AC, at…\n#&gt; 5  1166 Areo Hotah        Male   \"Norvoshi\" \"In 257 AC or be… \"\"             \n#&gt; 6  1267 Chett             Male   \"\"         \"At Hag's Mire\"   \"In 299 AC, at…\n#&gt; # ℹ 24 more rows\n#&gt; # ℹ 1 more variable: alive &lt;lgl&gt;\n\nThis dataset contains also many list-columns:\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list))\n#&gt; # A tibble: 30 × 8\n#&gt;      id titles    aliases    allegiances books     povBooks tvSeries playedBy\n#&gt;   &lt;int&gt; &lt;list&gt;    &lt;list&gt;     &lt;list&gt;      &lt;list&gt;    &lt;list&gt;   &lt;list&gt;   &lt;list&gt;  \n#&gt; 1  1022 &lt;chr [2]&gt; &lt;chr [4]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 2  1052 &lt;chr [2]&gt; &lt;chr [11]&gt; &lt;chr [1]&gt;   &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 3  1074 &lt;chr [2]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 4  1109 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [1]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 5  1166 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;chr [1]&gt;   &lt;chr [3]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; 6  1267 &lt;chr [1]&gt; &lt;chr [1]&gt;  &lt;NULL&gt;      &lt;chr [2]&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n#&gt; # ℹ 24 more rows\n\nLet’s explore the titles column. It’s an unnamed list-column, so we’ll unnest it into rows:\n\nchars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles)\n#&gt; # A tibble: 59 × 2\n#&gt;      id titles                                              \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # ℹ 53 more rows\n\nYou might expect to see this data in its own table because it would be easy to join to the characters data as needed. Let’s do that, which requires little cleaning: removing the rows containing empty strings and renaming titles to title since each row now only contains a single title.\n\ntitles &lt;- chars |&gt; \n  unnest_wider(json) |&gt; \n  select(id, titles) |&gt; \n  unnest_longer(titles) |&gt; \n  filter(titles != \"\") |&gt; \n  rename(title = titles)\ntitles\n#&gt; # A tibble: 52 × 2\n#&gt;      id title                                               \n#&gt;   &lt;int&gt; &lt;chr&gt;                                               \n#&gt; 1  1022 Prince of Winterfell                                \n#&gt; 2  1022 Lord of the Iron Islands (by law of the green lands)\n#&gt; 3  1052 Acting Hand of the King (former)                    \n#&gt; 4  1052 Master of Coin (former)                             \n#&gt; 5  1074 Lord Captain of the Iron Fleet                      \n#&gt; 6  1074 Master of the Iron Victory                          \n#&gt; # ℹ 46 more rows\n\nYou could imagine creating a table like this for each of the list-columns, then using joins to combine them with the character data as you need it.\n\n23.4.3 Deeply nested\nWe’ll finish off these case studies with a list-column that’s very deeply nested and requires repeated rounds of unnest_wider() and unnest_longer() to unravel: gmaps_cities. This is a two column tibble containing five city names and the results of using Google’s geocoding API to determine their location:\n\ngmaps_cities\n#&gt; # A tibble: 5 × 2\n#&gt;   city       json            \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [2]&gt;\n#&gt; 2 Washington &lt;named list [2]&gt;\n#&gt; 3 New York   &lt;named list [2]&gt;\n#&gt; 4 Chicago    &lt;named list [2]&gt;\n#&gt; 5 Arlington  &lt;named list [2]&gt;\n\njson is a list-column with internal names, so we start with an unnest_wider():\n\ngmaps_cities |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 5 × 3\n#&gt;   city       results    status\n#&gt;   &lt;chr&gt;      &lt;list&gt;     &lt;chr&gt; \n#&gt; 1 Houston    &lt;list [1]&gt; OK    \n#&gt; 2 Washington &lt;list [2]&gt; OK    \n#&gt; 3 New York   &lt;list [1]&gt; OK    \n#&gt; 4 Chicago    &lt;list [1]&gt; OK    \n#&gt; 5 Arlington  &lt;list [2]&gt; OK\n\nThis gives us the status and the results. We’ll drop the status column since they’re all OK; in a real analysis, you’d also want to capture all the rows where status != \"OK\" and figure out what went wrong. results is an unnamed list, with either one or two elements (we’ll see why shortly) so we’ll unnest it into rows:\n\ngmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results)\n#&gt; # A tibble: 7 × 2\n#&gt;   city       results         \n#&gt;   &lt;chr&gt;      &lt;list&gt;          \n#&gt; 1 Houston    &lt;named list [5]&gt;\n#&gt; 2 Washington &lt;named list [5]&gt;\n#&gt; 3 Washington &lt;named list [5]&gt;\n#&gt; 4 New York   &lt;named list [5]&gt;\n#&gt; 5 Chicago    &lt;named list [5]&gt;\n#&gt; 6 Arlington  &lt;named list [5]&gt;\n#&gt; # ℹ 1 more row\n\nNow results is a named list, so we’ll use unnest_wider():\n\nlocations &lt;- gmaps_cities |&gt; \n  unnest_wider(json) |&gt; \n  select(-status) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\nlocations\n#&gt; # A tibble: 7 × 6\n#&gt;   city       address_components formatted_address   geometry        \n#&gt;   &lt;chr&gt;      &lt;list&gt;             &lt;chr&gt;               &lt;list&gt;          \n#&gt; 1 Houston    &lt;list [4]&gt;         Houston, TX, USA    &lt;named list [4]&gt;\n#&gt; 2 Washington &lt;list [2]&gt;         Washington, USA     &lt;named list [4]&gt;\n#&gt; 3 Washington &lt;list [4]&gt;         Washington, DC, USA &lt;named list [4]&gt;\n#&gt; 4 New York   &lt;list [3]&gt;         New York, NY, USA   &lt;named list [4]&gt;\n#&gt; 5 Chicago    &lt;list [4]&gt;         Chicago, IL, USA    &lt;named list [4]&gt;\n#&gt; 6 Arlington  &lt;list [4]&gt;         Arlington, TX, USA  &lt;named list [4]&gt;\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 2 more variables: place_id &lt;chr&gt;, types &lt;list&gt;\n\nNow we can see why two cities got two results: Washington matched both Washington state and Washington, DC, and Arlington matched Arlington, Virginia and Arlington, Texas.\nThere are a few different places we could go from here. We might want to determine the exact location of the match, which is stored in the geometry list-column:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry)\n#&gt; # A tibble: 7 × 6\n#&gt;   city       formatted_address   bounds           location     location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;       &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list&gt; APPROXIMATE  \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: viewport &lt;list&gt;\n\nThat gives us new bounds (a rectangular region) and location (a point). We can unnest location to see the latitude (lat) and longitude (lng):\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  unnest_wider(location)\n#&gt; # A tibble: 7 × 7\n#&gt;   city       formatted_address   bounds             lat    lng location_type\n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;        \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt;  29.8  -95.4 APPROXIMATE  \n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt;  47.8 -121.  APPROXIMATE  \n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt;  38.9  -77.0 APPROXIMATE  \n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt;  40.7  -74.0 APPROXIMATE  \n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt;  41.9  -87.6 APPROXIMATE  \n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt;  32.7  -97.1 APPROXIMATE  \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: viewport &lt;list&gt;\n\nExtracting the bounds requires a few more steps:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  # focus on the variables of interest\n  select(!location:viewport) |&gt;\n  unnest_wider(bounds)\n#&gt; # A tibble: 7 × 4\n#&gt;   city       formatted_address   northeast        southwest       \n#&gt;   &lt;chr&gt;      &lt;chr&gt;               &lt;list&gt;           &lt;list&gt;          \n#&gt; 1 Houston    Houston, TX, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 2 Washington Washington, USA     &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 3 Washington Washington, DC, USA &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 4 New York   New York, NY, USA   &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 5 Chicago    Chicago, IL, USA    &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; 6 Arlington  Arlington, TX, USA  &lt;named list [2]&gt; &lt;named list [2]&gt;\n#&gt; # ℹ 1 more row\n\nWe then rename southwest and northeast (the corners of the rectangle) so we can use names_sep to create short but evocative names:\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  unnest_wider(geometry) |&gt; \n  select(!location:viewport) |&gt;\n  unnest_wider(bounds) |&gt; \n  rename(ne = northeast, sw = southwest) |&gt; \n  unnest_wider(c(ne, sw), names_sep = \"_\") \n#&gt; # A tibble: 7 × 6\n#&gt;   city       formatted_address   ne_lat ne_lng sw_lat sw_lng\n#&gt;   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Houston    Houston, TX, USA      30.1  -95.0   29.5  -95.8\n#&gt; 2 Washington Washington, USA       49.0 -117.    45.5 -125. \n#&gt; 3 Washington Washington, DC, USA   39.0  -76.9   38.8  -77.1\n#&gt; 4 New York   New York, NY, USA     40.9  -73.7   40.5  -74.3\n#&gt; 5 Chicago    Chicago, IL, USA      42.0  -87.5   41.6  -87.9\n#&gt; 6 Arlington  Arlington, TX, USA    32.8  -97.0   32.6  -97.2\n#&gt; # ℹ 1 more row\n\nNote how we unnest two columns simultaneously by supplying a vector of variable names to unnest_wider().\nOnce you’ve discovered the path to get to the components you’re interested in, you can extract them directly using another tidyr function, hoist():\n\nlocations |&gt; \n  select(city, formatted_address, geometry) |&gt; \n  hoist(\n    geometry,\n    ne_lat = c(\"bounds\", \"northeast\", \"lat\"),\n    sw_lat = c(\"bounds\", \"southwest\", \"lat\"),\n    ne_lng = c(\"bounds\", \"northeast\", \"lng\"),\n    sw_lng = c(\"bounds\", \"southwest\", \"lng\"),\n  )\n\nIf these case studies have whetted your appetite for more real-life rectangling, you can see a few more examples in vignette(\"rectangling\", package = \"tidyr\").\n\n23.4.4 Exercises\n\nRoughly estimate when gh_repos was created. Why can you only roughly estimate the date?\nThe owner column of gh_repo contains a lot of duplicated information because each owner can have many repos. Can you construct an owners data frame that contains one row for each owner? (Hint: does distinct() work with list-cols?)\nFollow the steps used for titles to create similar tables for the aliases, allegiances, books, and TV series for the Game of Thrones characters.\n\nExplain the following code line-by-line. Why is it interesting? Why does it work for got_chars but might not work in general?\n\ntibble(json = got_chars) |&gt; \n  unnest_wider(json) |&gt; \n  select(id, where(is.list)) |&gt; \n  pivot_longer(\n    where(is.list), \n    names_to = \"name\", \n    values_to = \"value\"\n  ) |&gt;  \n  unnest_longer(value)\n\n\nIn gmaps_cities, what does address_components contain? Why does the length vary between rows? Unnest it appropriately to figure it out. (Hint: types always appears to contain two elements. Does unnest_wider() make it easier to work with than unnest_longer()?) .",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#json",
    "href": "rectangling.html#json",
    "title": "23  Hierarchical data",
    "section": "\n23.5 JSON",
    "text": "23.5 JSON\nAll of the case studies in the previous section were sourced from wild-caught JSON. JSON is short for javascript object notation and is the way that most web APIs return data. It’s important to understand it because while JSON and R’s data types are pretty similar, there isn’t a perfect 1-to-1 mapping, so it’s good to understand a bit about JSON if things go wrong.\n\n23.5.1 Data types\nJSON is a simple format designed to be easily read and written by machines, not humans. It has six key data types. Four of them are scalars:\n\nThe simplest type is a null (null) which plays the same role as NA in R. It represents the absence of data.\nA string is much like a string in R, but must always use double quotes.\nA number is similar to R’s numbers: they can use integer (e.g., 123), decimal (e.g., 123.45), or scientific (e.g., 1.23e3) notation. JSON doesn’t support Inf, -Inf, or NaN.\nA boolean is similar to R’s TRUE and FALSE, but uses lowercase true and false.\n\nJSON’s strings, numbers, and booleans are pretty similar to R’s character, numeric, and logical vectors. The main difference is that JSON’s scalars can only represent a single value. To represent multiple values you need to use one of the two remaining types: arrays and objects.\nBoth arrays and objects are similar to lists in R; the difference is whether or not they’re named. An array is like an unnamed list, and is written with []. For example [1, 2, 3] is an array containing 3 numbers, and [null, 1, \"string\", false] is an array that contains a null, a number, a string, and a boolean. An object is like a named list, and is written with {}. The names (keys in JSON terminology) are strings, so must be surrounded by quotes. For example, {\"x\": 1, \"y\": 2} is an object that maps x to 1 and y to 2.\nNote that JSON doesn’t have any native way to represent dates or date-times, so they’re often stored as strings, and you’ll need to use readr::parse_date() or readr::parse_datetime() to turn them into the correct data structure. Similarly, JSON’s rules for representing floating point numbers in JSON are a little imprecise, so you’ll also sometimes find numbers stored in strings. Apply readr::parse_double() as needed to get the correct variable type.\n\n23.5.2 jsonlite\nTo convert JSON into R data structures, we recommend the jsonlite package, by Jeroen Ooms. We’ll use only two jsonlite functions: read_json() and parse_json(). In real life, you’ll use read_json() to read a JSON file from disk. For example, the repurrsive package also provides the source for gh_user as a JSON file and you can read it with read_json():\n\n# A path to a json file inside the package:\ngh_users_json()\n#&gt; [1] \"/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/repurrrsive/extdata/gh_users.json\"\n\n# Read it with read_json()\ngh_users2 &lt;- read_json(gh_users_json())\n\n# Check it's the same as the data we were using previously\nidentical(gh_users, gh_users2)\n#&gt; [1] TRUE\n\nIn this book, we’ll also use parse_json(), since it takes a string containing JSON, which makes it good for generating simple examples. To get started, here are three simple JSON datasets, starting with a number, then putting a few numbers in an array, then putting that array in an object:\n\nstr(parse_json('1'))\n#&gt;  int 1\nstr(parse_json('[1, 2, 3]'))\n#&gt; List of 3\n#&gt;  $ : int 1\n#&gt;  $ : int 2\n#&gt;  $ : int 3\nstr(parse_json('{\"x\": [1, 2, 3]}'))\n#&gt; List of 1\n#&gt;  $ x:List of 3\n#&gt;   ..$ : int 1\n#&gt;   ..$ : int 2\n#&gt;   ..$ : int 3\n\njsonlite has another important function called fromJSON(). We don’t use it here because it performs automatic simplification (simplifyVector = TRUE). This often works well, particularly in simple cases, but we think you’re better off doing the rectangling yourself so you know exactly what’s happening and can more easily handle the most complicated nested structures.\n\n23.5.3 Starting the rectangling process\nIn most cases, JSON files contain a single top-level array, because they’re designed to provide data about multiple “things”, e.g., multiple pages, or multiple records, or multiple results. In this case, you’ll start your rectangling with tibble(json) so that each element becomes a row:\n\njson &lt;- '[\n  {\"name\": \"John\", \"age\": 34},\n  {\"name\": \"Susan\", \"age\": 27}\n]'\ndf &lt;- tibble(json = parse_json(json))\ndf\n#&gt; # A tibble: 2 × 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n#&gt; 2 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json)\n#&gt; # A tibble: 2 × 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\nIn rarer cases, the JSON file consists of a single top-level JSON object, representing one “thing”. In this case, you’ll need to kick off the rectangling process by wrapping it in a list, before you put it in a tibble.\n\njson &lt;- '{\n  \"status\": \"OK\", \n  \"results\": [\n    {\"name\": \"John\", \"age\": 34},\n    {\"name\": \"Susan\", \"age\": 27}\n ]\n}\n'\ndf &lt;- tibble(json = list(parse_json(json)))\ndf\n#&gt; # A tibble: 1 × 1\n#&gt;   json            \n#&gt;   &lt;list&gt;          \n#&gt; 1 &lt;named list [2]&gt;\n\ndf |&gt; \n  unnest_wider(json) |&gt; \n  unnest_longer(results) |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 × 3\n#&gt;   status name    age\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 OK     John     34\n#&gt; 2 OK     Susan    27\n\nAlternatively, you can reach inside the parsed JSON and start with the bit that you actually care about:\n\ndf &lt;- tibble(results = parse_json(json)$results)\ndf |&gt; \n  unnest_wider(results)\n#&gt; # A tibble: 2 × 2\n#&gt;   name    age\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 John     34\n#&gt; 2 Susan    27\n\n\n23.5.4 Exercises\n\n\nRectangle the df_col and df_row below. They represent the two ways of encoding a data frame in JSON.\n\njson_col &lt;- parse_json('\n  {\n    \"x\": [\"a\", \"x\", \"z\"],\n    \"y\": [10, null, 3]\n  }\n')\njson_row &lt;- parse_json('\n  [\n    {\"x\": \"a\", \"y\": 10},\n    {\"x\": \"x\", \"y\": null},\n    {\"x\": \"z\", \"y\": 3}\n  ]\n')\n\ndf_col &lt;- tibble(json = list(json_col)) \ndf_row &lt;- tibble(json = json_row)",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#summary",
    "href": "rectangling.html#summary",
    "title": "23  Hierarchical data",
    "section": "\n23.6 Summary",
    "text": "23.6 Summary\nIn this chapter, you learned what lists are, how you can generate them from JSON files, and how to turn them into rectangular data frames. Surprisingly we only need two new functions: unnest_longer() to put list elements into rows and unnest_wider() to put list elements into columns. It doesn’t matter how deeply nested the list-column is; all you need to do is repeatedly call these two functions.\nJSON is the most common data format returned by web APIs. What happens if the website doesn’t have an API, but you can see data you want on the website? That’s the topic of the next chapter: web scraping, extracting data from HTML webpages.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "rectangling.html#footnotes",
    "href": "rectangling.html#footnotes",
    "title": "23  Hierarchical data",
    "section": "",
    "text": "This is an RStudio feature.↩︎",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hierarchical data</span>"
    ]
  },
  {
    "objectID": "webscraping.html",
    "href": "webscraping.html",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "",
    "text": "24.1 Introdução\nEste capítulo faz a introdução do básico sobre raspagem de dados (web scraping) com o pacote rvest. Raspagem de dados é uma ferramenta muito útil para extração de dados de páginas web. Alguns websites oferecem uma API, um conjunto de requisições HTTP estruturadas que retornam dados no formato JSON, com o qual você pode lidar usando as técnicas do Capítulo 23. Sempre que possível, você deve usar uma API1, pois geralmente te retornará dados mais confiáveis. Entretanto, infelizmente, programar com APIs web está fora do escopo deste livro. Ao invés disso, ensinaremos sobre raspagem de dados, uma técnica que funciona independentemente de o site fornecer uma API ou não.\nNeste capítulo, discutiremos primeiro sobre ética e legalidade da raspagem de dados antes de falar sobre o básico de HTML. Você aprenderá o básico sobre seletores CSS para localizar elementos específicos em uma página, e como usar funções do rvest para obter dados de textos e atributos de um HTML para o R. Depois, discutiremos algumas técnicas para descobrir qual seletor CSS você precisa para a página que está fazendo a raspagem de dados e terminaremos falando sobre alguns estudos de caso e uma breve discussão sobre websites dinâmicos.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#introdução",
    "href": "webscraping.html#introdução",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "",
    "text": "24.1.1 Pré-requisitos\nNeste capítulo, iremos focar nas ferramentas fornecidas pelo pacote rvest. O pacote rvest é um membro do tidyverse, mas não faz parte de seus componentes principais, portanto devemos carregá-lo explicitamente. Iremos também carregar o tidyverse completo, já que é geralmente muito útil para trabalhar com os dados obtidos da raspagem.\n\nlibrary(tidyverse)\nlibrary(rvest)",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#ética-e-legalidade-da-raspagem-de-dados",
    "href": "webscraping.html#ética-e-legalidade-da-raspagem-de-dados",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.2 Ética e legalidade da raspagem de dados",
    "text": "24.2 Ética e legalidade da raspagem de dados\nAntes de começarmos a discutir o código que você precisará para efetuar a raspagem de dados, precisamos discutir se é ético e lícito realizá-la. No geral, a situação é complicada em relação a ambos.\nA legislação depende muito de onde você vive. Entretanto, como princípio geral, se um dado é público, impessoal e factual, você provavelmente não terá problemas2. Esses três fatores são importantes porque estão ligados aos termos e condições do site, às informações de identificação pessoal e aos direitos autorais, como discutiremos a seguir.\nSe os dados não forem públicos, impessoais ou factuais, ou se você estiver coletando os dados especificamente para ganhar dinheiro com eles, será necessário falar com um advogado. Em qualquer caso, você deve respeitar os recursos do servidor que hospeda as páginas em que você está efetuando a raspagem de dados. Mais importante ainda, isso significa que se você estiver fazendo raspagem de muitas páginas, certifique-se de esperar um pouco entre cada requisição. Um jeito fácil é utilizar o pacote polite de Dmytro Perepolkin. Ele fará uma pausa automatica entre as requisições e armazenará os resultados (cache) para que você não precise solicitar a mesma página duas vezes.\n\n24.2.1 Termos de serviço\nSe você olhar atentamente, descobrirá que muitos websites incluem em algum lugar da página um link para “termos e condições” ou “termos de serviço”, e se você ler a página atentamente, você geralmente descobrirá que o site especificamente proíbe sua raspagem de dados. Essas páginas tendem a ser uma terra sem lei, onde as empresas fazem reivindicações muito amplas. É educado respeitar estes termos de serviço sempre que possível, mas considere as reivindicações com cautela.\nOs tribunais dos Estados Unidos concluíram que simplesmente colocar os termos de serviço no rodapé do website não é suficiente para que você fique vinculado a eles, e.x., HiQ Labs v. LinkedIn. Em geral, para que você seja submetido aos termos de serviços, você deve ter tido uma ação explícita, como criar uma conta ou marcar uma opção. Isto torna importante saber se um dado é público ou não; se você não precisa ter uma conta para acessá-lo, é improvável que você tenha qualquer vínculo com os termos de serviço. Note que a situação é diferente na Europa, onde os tribunais concluíram que os termos de serviços são aplicáveis mesmo que você não concorde explicitamente com eles.\n\n24.2.2 Informações de identificação pessoal\nMesmo que o dado seja público, você deve ter extremo cuidado em fazer raspagem de informações pessoais como nomes, endereços de email, números telefônicos, datas de nascimento, etc. A Europa, em particular, tem leis bem restritas sobre coleta e armazenamento destes tipos de dados (GDPR), e independente de onde você viva, é provável que passe por complicações éticas. Por exemplo, em 2016, um grupo de pesquisadores rasparam dados públicos contendo informações pessoais (e.x., nomes de usuário, idade, genero, localização, etc.) sobre 70.000 pessoas do site de relacionamento OkCupid e eles liberaram publicamente estes dados sem qualquer tentativa de torná-los anônimos (anonymization). Enquanto os pesquisadores acharam que não havia nada de errado com isso, uma vez que os dados já eram públicos, este trabalho foi largamente condenado devido a preocupações éticas sobre a identificação dos usuários cuja informação foi liberada no conjunto de dados. Se seu trabalho envolve raspagem de dados de informações com identificação pessoal, nós recomendamos fortemente que você leia sobre o estudo do caso OkCupid3 bem como casos similares de estudos com éticas de pesquisa questionáveis envolvendo a aquisição e liberação de informações com idenficação pessoal.\n\n24.2.3 Direitos autorais (copyright)\nFinalmente, você também deve se preocupar com as leis de direitos autorais. As leis de direitos autorais são complicadas, mas vale a pena dar uma olhada na lei estadunidense que descreve exatamente o que é protegido: “[…] obras originais de autoria fixadas em qualquer meio de expressão tangível, […]”. Em seguida, descreve categorias específicas em que as leis se aplicam, como obras literárias, obras musicais, filmes e muito mais. Os dados estão notavelmente ausentes da proteção de direitos autorais. Isso significa que, desde que você limite sua raspagem de dados a fatos, a proteção de direitos autorais não se aplica. (Porém, observe que a Europa possui um direito separado “sui generis” que protege bases de dados (databases).)\nComo um breve exemplo, nos Estados Unidos, listas de ingredientes e de instruções não estão sujeitas às leis de direitos autorais, portanto estas leis não podem ser usadas para proteger uma receita. Mas se esta lista de receitas estiver acompanhada de um conteúdo literário substancial, então ela poderá ser protegida. É por isso que quando você procura por uma receita na internet, ela é acompanhada de tanto conteúdo.\nSe você realmente precisa fazer raspagem de dados de conteúdo original, (como texto ou imagem), você ainda pode estar protegido pela doutrina de uso justo (doctrine of fair use). O uso justo (fair use) não é uma regra rígida e rápida, mas pesa uma série de fatores. É mais provável que se aplique caso você esteja coletando dados para pesquisa ou para fins não comerciais e se limite a coletar apenas o que precisa.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#o-básico-de-html",
    "href": "webscraping.html#o-básico-de-html",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.3 O básico de HTML",
    "text": "24.3 O básico de HTML\nPara fazer raspagem de dados em páginas web, você precisa primeiro entender um pouco sobre HTML, a linguagem usada para criar páginas web. HTML é abreviação HyperText Markup Language e se parece com algo deste tipo:\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Título da Página&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='primeiro'&gt;Um cabeçalho&lt;/h1&gt;\n  &lt;p&gt;Algum texto &amp; &lt;b&gt;algum texto em negrito.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML tem uma estrutura hierárquica formada por elementos que consiste em uma marcação (tag) de início (e.x., &lt;tag&gt;), opcionalmente um atributo (attributes) (id='primeiro'), e uma marcação de fim4 (como &lt;/tag&gt;), e conteúdo (contents) (tudo entre a marcação de início e de fim).\nComo &lt; e &gt; são usados para início e fim das marcações, você não pode escrevê-los diretamente. Ao invés disso, você deve usar os caracteres de fuga (escapes) &gt; (maior que ou greater than) e &lt; (menor que ou less than) do HTML. E como estas fugas usam &, se você quiser escrever o “&” (E comercial ou ampersand) deve usar a fuga &amp;. Há uma grande variedade de caracteres de fuga no HTML, mas você não precisa se preocupar muito com isto, pois o rvest lida automaticamente com elas para você.\nA raspagem de dados é possível porque a maioria das páginas que contém o dado que você quer extrair geralmente possuem uma estrutura consistente.\n\n24.3.1 Elementos\nExistem mais de 100 elementos HTML. Alguns dos mais importantes são:\n\nToda página HTML deve estar entre um elemento &lt;html&gt;, que deve ter dois elementos descendentes (children): &lt;head&gt;, que contém metadados como título da página, e &lt;body&gt;, que tem o conteúdo que você vê através do navegador (browser).\nMarcações de bloco (block) como &lt;h1&gt; (cabeçalho 1 ou heading 1), &lt;section&gt; (seção ou section), &lt;p&gt; (parágrafo ou paragraph), e &lt;ol&gt; (lista ordenada ou ordered list) formam a estrutura geral da página.\nMarcações em linha (inline) como &lt;b&gt; (negrito ou bold), &lt;i&gt; (itálico ou italics), e &lt;a&gt; (link) formatam o texto dentro das marcações de bloco.\n\nSe você encontrar uma marcação que nunca viu antes, você pode pesquisar o que ela faz usando a pesquisa do Google. Um outro ótimo lugar para começar é o MDN Web Docs que descreve todos os aspectos da programação web.\nA maioria dos elementos podem ter conteúdo entre suas marcações de início e fim. Este conteúdo pode ser um texto ou outros elementos. Por exemplo, o HTML a seguir contém um parágrafo de texto com uma palavra em negrito.\n&lt;p&gt;\n  Olá! Meu &lt;b&gt;nome&lt;/b&gt; é Hadley.\n&lt;/p&gt;\nOs descendentes (children) são os elementos contidos em outro, portanto, o elemento &lt;p&gt; acima possui um descendente, o elemento &lt;b&gt;. O elemento &lt;b&gt; não possui descendentes, porém ele tem conteúdo (o texto “nome”).\n\n24.3.2 Atributos\nMarcações podem ter atributos (attributes) com nomes que se parecem com nome1='valor1' nome2='valor2'. Dois dos mais importantes atributos são id e class, que são usados juntamente com as folhas de estilo CSS (Cascading Style Sheets) para controlar a aparência visual da página. Eles são muito úteis quando raspamos dados de uma página. Atributos também são usados para gravar os destinos dos links (o atributo href do elemento &lt;a&gt;) e a origem de imagens (o atributo src do elemento &lt;img&gt;).",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#extraindo-dados",
    "href": "webscraping.html#extraindo-dados",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.4 Extraindo dados",
    "text": "24.4 Extraindo dados\nPara começar com a raspagem de dados, você precisará do endereço (URL) da página que deseja fazer a raspagem, a qual normalmente pode ser copiada do seu navegador. Você precisará então importar o HTML daquela página para o R com read_html(). Esta função retorna um objeto xml_document5 que você então irá manipular usando as funções do rvest:\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html lang=\"en\"&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n    &lt;a href=\"#container\" class=\"visually-hidden-focusable\"&gt;Ski ...\n\nrvest também possui uma função que te permite criar um HTML (inline). Usaremos muito isso neste capítulo conforme ensinamos várias funções do rvest com exemplos simples.\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;Este é um parágrafo&lt;/p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;Esta é uma lista com marcadores&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nhtml\n#&gt; {html_document}\n#&gt; &lt;html&gt;\n#&gt; [1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#&gt; [2] &lt;body&gt;\\n&lt;p&gt;Este é um parágrafo&lt;/p&gt;\\n  &lt;ul&gt;\\n&lt;li&gt;Esta é uma lista com m ...\n\nAgora que você tem o HTML no R, é hora de extrair os dados de interesse. Você aprenderá primeiro sobre seletores CSS, os quais permitem que você identifique elementos de interesse e sobre as funções do rvest que permitem que você extraia dados desses elementos. Depois, falaremos brevemente sobre tabelas HTML, que possuem algumas ferramentas especiais.\n\n24.4.1 Encontrando elementos\nCSS é a abreviação para “folha de estilo em cascata” (cascading style sheets), que é uma ferramenta para definir os estilos visuais dos documentos HTML. CSS inclui uma pequena linguagem chamada seletores CSS (CSS Selectors) para seleção de elementos em uma página. Seletores CSS definem padrões para localizar elementos HTML e são úteis para raspagem de dados, pois definem uma forma concisa de descrever o elemento do qual você quer extrair os dados.\nRetornaremos aos seletores CSS em mais detalhes na Seção 24.5, mas felizmente você já pode percorrer um bom caminho com apenas três seletores:\n\np seleciona todos elementos &lt;p&gt;.\n.titulo seleciona todos elementos com class “titulo”.\n#titulo seleciona os elemento com o atributo id igual a “titulo”. Atributos Id devem ser únicos dentro de um documento HTML, portanto isto sempre retornará apenas um elemento.\n\nVamos testar estes seletores com um exemplo simples:\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;Isto é um cabeçalho&lt;/h1&gt;\n  &lt;p id='primeiro'&gt;Isto é um parágrafo&lt;/p&gt;\n  &lt;p class='importante'&gt;Isto é um parágrafo importante&lt;/p&gt;\n\")\n\nUse html_elements() para encontrar todos os elementos que correspondem ao seletor:\n\nhtml |&gt; html_elements(\"p\")\n#&gt; {xml_nodeset (2)}\n#&gt; [1] &lt;p id=\"primeiro\"&gt;Isto é um parágrafo&lt;/p&gt;\n#&gt; [2] &lt;p class=\"importante\"&gt;Isto é um parágrafo importante&lt;/p&gt;\nhtml |&gt; html_elements(\".importante\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p class=\"importante\"&gt;Isto é um parágrafo importante&lt;/p&gt;\nhtml |&gt; html_elements(\"#primeiro\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;p id=\"primeiro\"&gt;Isto é um parágrafo&lt;/p&gt;\n\nOutra função importante é a html_element() que sempre retorna o mesmo número de saídas que entradas. Se você a usar no documento inteiro, ela retornará a primeira correspondência:\n\nhtml |&gt; html_element(\"p\")\n#&gt; {html_node}\n#&gt; &lt;p id=\"primeiro\"&gt;\n\nHá uma diferença importante entre html_element() e html_elements() quando você usa um seletor que não corresponde a nenhum elemento. html_elements() retorna um vetor de tamanho 0, enquanto html_element() retorna um valor faltante (missing value). Esta diferença será muito importante em breve.\n\nhtml |&gt; html_elements(\"b\")\n#&gt; {xml_nodeset (0)}\nhtml |&gt; html_element(\"b\")\n#&gt; {xml_missing}\n#&gt; &lt;NA&gt;\n\n\n24.4.2 Seleções aninhadas (nesting)\nNa maioria das vezes, você usará html_elements() e html_element() juntas, geralmente usando html_elements() para identificar elementos que virão com várias observações e então usar html_element() para identificar elementos que se tornarão variáveis. Vamos ver isso em ação com um exemplo simples. Aqui temos uma lista não ordenada (&lt;ul&gt;) onde cada item da lista (&lt;li&gt;) contém alguma informação sobre quatro personagens de Guerra nas Estrelas (StarWars):\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt; é um &lt;i&gt;robô&lt;/i&gt; que pesa &lt;span class='weight'&gt;167 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt; é um &lt;i&gt;robô&lt;/i&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt; é um &lt;i&gt;robô&lt;/i&gt; que pesa &lt;span class='weight'&gt;96 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt; pesa &lt;span class='peso'&gt;66 kg&lt;/span&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  \")\n\nPodemos usar html_elements() para criar um vetor onde cada elemento corresponde a um personagem diferente:\n\npersonagens &lt;- html |&gt; html_elements(\"li\")\npersonagens\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;li&gt;\\n&lt;b&gt;C-3PO&lt;/b&gt; é um &lt;i&gt;robô&lt;/i&gt; que pesa &lt;span class=\"weight\"&gt;167  ...\n#&gt; [2] &lt;li&gt;\\n&lt;b&gt;R4-P17&lt;/b&gt; é um &lt;i&gt;robô&lt;/i&gt;\\n&lt;/li&gt;\n#&gt; [3] &lt;li&gt;\\n&lt;b&gt;R2-D2&lt;/b&gt; é um &lt;i&gt;robô&lt;/i&gt; que pesa &lt;span class=\"weight\"&gt;96 k ...\n#&gt; [4] &lt;li&gt;\\n&lt;b&gt;Yoda&lt;/b&gt; pesa &lt;span class=\"peso\"&gt;66 kg&lt;/span&gt;\\n&lt;/li&gt;\n\nPara extrair o nome de cada personagem, usamos html_element(), pois quando aplicada à saída da html_elements() é garantido retornar uma resposta por elemento:\n\npersonagens |&gt; html_element(\"b\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] &lt;b&gt;C-3PO&lt;/b&gt;\n#&gt; [2] &lt;b&gt;R4-P17&lt;/b&gt;\n#&gt; [3] &lt;b&gt;R2-D2&lt;/b&gt;\n#&gt; [4] &lt;b&gt;Yoda&lt;/b&gt;\n\nA diferença entre html_element() e html_elements() não é importante para o nome, mas é importante para o peso. Queremos ter um peso para cada personagem, até mesmo quando não há &lt;span&gt; peso. Isto é o que html_element() faz:\n\npersonagens |&gt; html_element(\".peso\")\n#&gt; {xml_nodeset (4)}\n#&gt; [1] NA\n#&gt; [2] NA\n#&gt; [3] NA\n#&gt; [4] &lt;span class=\"peso\"&gt;66 kg&lt;/span&gt;\n\nhtml_elements() encontra todos os &lt;span&gt;s peso que são descendentes de personagens. Existem apenas três deles, então perdemos a conexão entre os nomes e os pesos:\n\npersonagens |&gt; html_elements(\".peso\")\n#&gt; {xml_nodeset (1)}\n#&gt; [1] &lt;span class=\"peso\"&gt;66 kg&lt;/span&gt;\n\nAgora que você selecionou os elementos de interesse, você precisa extrair os dados, sejam do conteúdo texto quanto de alguns atributos.\n\n24.4.3 Textos e atributos\nhtml_text2()6 extrai o texto puro de um elemento HTML:\n\npersonagens |&gt; \n  html_element(\"b\") |&gt; \n  html_text2()\n#&gt; [1] \"C-3PO\"  \"R4-P17\" \"R2-D2\"  \"Yoda\"\n\npersonagens |&gt; \n  html_element(\".peso\") |&gt; \n  html_text2()\n#&gt; [1] NA      NA      NA      \"66 kg\"\n\nObserve que qualquer caractere de fuga é automaticamente endereçado; você apenas verá estes caracteres no código fonte HTML, mas não nos dados retornados pelo rvest.\nhtml_attr() extrai dados dos atributos:\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;gatos&lt;/a&gt;&lt;/p&gt;\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Dog'&gt;cães&lt;/a&gt;&lt;/p&gt;\n\")\n\nhtml |&gt; \n  html_elements(\"p\") |&gt; \n  html_element(\"a\") |&gt; \n  html_attr(\"href\")\n#&gt; [1] \"https://en.wikipedia.org/wiki/Cat\" \"https://en.wikipedia.org/wiki/Dog\"\n\nhtml_attr() sempre retorna uma string, portanto, se você está extraindo números ou datas, você precisará fazer algum processamento posterior.\n\n24.4.4 Tabelas\nSe você estiver com sorte, seus dados já estarão armazenados em uma tabela HTML, portanto, é apenas uma questão de lê-los diretamenta desta tabela. Geralmente é muito fácil reconhecer uma tabela em seu navegador: ela terá uma estrutura retangular de linhas e colunas e você pode copiar e colar em uma ferramenta como o Excel.\nTabelas HTML são constituídas por quatro elementos principais: &lt;table&gt;, &lt;tr&gt; (linha da tabela), &lt;th&gt; (cabeçalho da tabela), e &lt;td&gt; (dado da tabela). Aqui está uma tabela HTML simples com duas colunas e três linhas:\n\nhtml &lt;- minimal_html(\"\n  &lt;table class='minha_tabela'&gt;\n    &lt;tr&gt;&lt;th&gt;x&lt;/th&gt;   &lt;th&gt;y&lt;/th&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;1.5&lt;/td&gt; &lt;td&gt;2.7&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;4.9&lt;/td&gt; &lt;td&gt;1.3&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;7.2&lt;/td&gt; &lt;td&gt;8.1&lt;/td&gt;&lt;/tr&gt;\n  &lt;/table&gt;\n  \")\n\nrvest fornece uma função que sabe como ler este tipo de dado: html_table(). Ela retorna uma lista contendo um tibble para cada tabela encontrada na página. Use html_element() para identificar a tabela que deseja extrair:\n\nhtml |&gt; \n  html_element(\".minha_tabela\") |&gt; \n  html_table()\n#&gt; # A tibble: 3 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1.5   2.7\n#&gt; 2   4.9   1.3\n#&gt; 3   7.2   8.1\n\nNote que x e y foram automaticamente convertidos para números. Esta conversão automática nem sempre funciona bem, portanto, em cenários mais complexos você deve querer desligá-la com convert = FALSE e então fazer sua própria conversão.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#sec-css-selectors",
    "href": "webscraping.html#sec-css-selectors",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.5 Encontrando os seletores adequados",
    "text": "24.5 Encontrando os seletores adequados\nDescobrir o seletor que você precisa para seus dados é geralmente a parte mais difícil do problema. Você geralmente deverá fazer alguns experimentos para encontrar um seletor que seja ao mesmo tempo específico (e.x. ele não seleciona algo que não interessa) e sensível (e.x. ele seleciona tudo que interessa). Tentativa e erro é parte normal do processo! Existem duas principais ferramentas disponíveis para te ajudar com este processo: SelectorGadget e as Ferramentas do Desenvolvedor de seu navegador.\nSelectorGadget é um aplicativo (bookmarklet) javascript que gera seletores automaticamente baseado em exemplos negativos e positivos fornecidos por você. Ele nem sempre funciona, mas quando o faz, é uma mágica! Você pode aprender a instalar e usar o SelectorGadget lendo https://rvest.tidyverse.org/articles/selectorgadget.html ou assistindo o video de Mine em https://www.youtube.com/watch?v=PetWV5g1Xsc.\nTodo navegador moderno vem com um kit de ferramentas para desenvolvedores, mas recomendamos o Chrome, mesmo que não seja seu navegador padrão: suas ferramentas para desenvolvedores web são algumas das melhores e estão imediatamente disponíveis. Clique com o botão direito em um elemento da página e clique Inspecionar. Isto abrirá uma visão expandida da página HTML completa, centralizando o elemento que você acabou de clicar. Você pode usar isto para explorar a página e ter uma ideia de quais seletores podem funcionar. Preste atenção aos atributos class e id, uma vez que geralmente são usados para formar a estrutura visual da página, e portanto, são boas ferramentas para extrair os dados que você está procurando.\nDentro do menu Elementos, você também pode clicar com o botão direito em um elemento e selecionar Copiar como Seletor para gerar um seletor que identificará de forma única o elemento de interesse.\nCaso o SelectorGadget ou as Ferramentas do Desenvolvedor (DevTools) do Chrome* gerarem um seletor CSS que você não entende, tente Seletores Explicados (Selectors Explained) que traduz seletores CSS para inglês básico. Caso você se encontre fazendo isso muitas vezes, você pode querer aprender mais sobre seletores CSS em geral. Recomendamos começar com o engraçado tutorial jantar CSS e então conferir o MDN web docs.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#juntando-tudo",
    "href": "webscraping.html#juntando-tudo",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.6 Juntando tudo",
    "text": "24.6 Juntando tudo\nVamos juntar tudo isso e fazer a raspagem de dados de alguns websites. Há algum risco destes exemplos não funcionarem mais quando você executá-los — este é o desafio fundamental da raspagem de dados; se a estrutura do site muda, então você terá que mudar seu código de raspagem.\n\n24.6.1 Guerra nas Estrelas (StarWars)\nrvest inclui um simples exemplo na vignette(\"starwars\"). Esta é uma página simples com o mínimo de HTML, portanto, é um bom lugar para se começar. Eu encorajo você a navegar até essa página agora e usar “Inspecionar Elemento” para inspecionar um dos cabeçalhos que tem o título de um filme de Guerra nas Estrelas. Use o teclado ou o mouse para explorar a hierarquia do HTML e veja se consegue ter uma noção da estrutura compartilhada de cada filme.\nVocê deve conseguir ver que cada filme possui uma estrutura compartilhada que se parece com isto:\n&lt;section&gt;\n  &lt;h2 data-id=\"1\"&gt;The Phantom Menace&lt;/h2&gt;\n  &lt;p&gt;Released: 1999-05-19&lt;/p&gt;\n  &lt;p&gt;Director: &lt;span class=\"director\"&gt;George Lucas&lt;/span&gt;&lt;/p&gt;\n  \n  &lt;div class=\"crawl\"&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/section&gt;\nNossa meta é transformar isto em um data frame com 7 linhas e as variáveis titulo, data_lancamento, diretor, e introducao. Começaremos lendo o HTML e extraindo todos os elementos &lt;section&gt;:\n\nurl &lt;- \"https://rvest.tidyverse.org/articles/starwars.html\"\nhtml &lt;- read_html(url)\n\nsecao &lt;- html |&gt; html_elements(\"section\")\nsecao\n#&gt; {xml_nodeset (7)}\n#&gt; [1] &lt;section&gt;&lt;h2 data-id=\"1\"&gt;\\nThe Phantom Menace\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [2] &lt;section&gt;&lt;h2 data-id=\"2\"&gt;\\nAttack of the Clones\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: ...\n#&gt; [3] &lt;section&gt;&lt;h2 data-id=\"3\"&gt;\\nRevenge of the Sith\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased:  ...\n#&gt; [4] &lt;section&gt;&lt;h2 data-id=\"4\"&gt;\\nA New Hope\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1977-05-2 ...\n#&gt; [5] &lt;section&gt;&lt;h2 data-id=\"5\"&gt;\\nThe Empire Strikes Back\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleas ...\n#&gt; [6] &lt;section&gt;&lt;h2 data-id=\"6\"&gt;\\nReturn of the Jedi\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 1 ...\n#&gt; [7] &lt;section&gt;&lt;h2 data-id=\"7\"&gt;\\nThe Force Awakens\\n&lt;/h2&gt;\\n&lt;p&gt;\\nReleased: 20 ...\n\nIsto retorna sete elementos que correspondem aos sete filmes encontrados na página, sugerindo que usar section como seletor é bom. Extrair cada elemento é direto, já que o dado está sempre presente no texto. É simplesmente uma questão de encontrar o seletor correto:\n\nsecao |&gt; html_element(\"h2\") |&gt; html_text2()\n#&gt; [1] \"The Phantom Menace\"      \"Attack of the Clones\"   \n#&gt; [3] \"Revenge of the Sith\"     \"A New Hope\"             \n#&gt; [5] \"The Empire Strikes Back\" \"Return of the Jedi\"     \n#&gt; [7] \"The Force Awakens\"\n\nsecao |&gt; html_element(\".director\") |&gt; html_text2()\n#&gt; [1] \"George Lucas\"     \"George Lucas\"     \"George Lucas\"    \n#&gt; [4] \"George Lucas\"     \"Irvin Kershner\"   \"Richard Marquand\"\n#&gt; [7] \"J. J. Abrams\"\n\nUma vez feito isso para cada componente, podemos encapsular todo o resultado em um tibble:\n\ntibble(\n  titulo = secao |&gt; \n    html_element(\"h2\") |&gt; \n    html_text2(),\n  data_lancamento = secao |&gt; \n    html_element(\"p\") |&gt; \n    html_text2() |&gt; \n    str_remove(\"Released: \") |&gt; \n    parse_date(),\n  diretor = secao |&gt; \n    html_element(\".director\") |&gt; \n    html_text2(),\n  introducao = secao |&gt; \n    html_element(\".crawl\") |&gt; \n    html_text2()\n)\n#&gt; # A tibble: 7 × 4\n#&gt;   titulo                  data_lancamento diretor          introducao        \n#&gt;   &lt;chr&gt;                   &lt;date&gt;          &lt;chr&gt;            &lt;chr&gt;             \n#&gt; 1 The Phantom Menace      1999-05-19      George Lucas     \"Turmoil has engu…\n#&gt; 2 Attack of the Clones    2002-05-16      George Lucas     \"There is unrest …\n#&gt; 3 Revenge of the Sith     2005-05-19      George Lucas     \"War! The Republi…\n#&gt; 4 A New Hope              1977-05-25      George Lucas     \"It is a period o…\n#&gt; 5 The Empire Strikes Back 1980-05-17      Irvin Kershner   \"It is a dark tim…\n#&gt; 6 Return of the Jedi      1983-05-25      Richard Marquand \"Luke Skywalker h…\n#&gt; # ℹ 1 more row\n\nNós processamos um pouco mais a data_lancamento para obter uma variável que será mais fácil de usar depois em nossas análises.\n\n24.6.2 Melhores filmes IMDB\nPara nossa próxima tarefa, abordaremos algo um pouco mais complicado, extraindo os 250 melhores filmes da base de dados da Internet (IMDb). Quando este capítulo foi escrito, a página se parecia com a Figura 24.1.\n\n\n\n\n\n\n\nFigura 24.1: Captura de tela dos melhores filmes da página IMDb feita em 05-12-2022.\n\n\n\n\nEste dados têm uma clara estrutura tabular, então vale a pena começar com html_table():\n\nurl &lt;- \"https://web.archive.org/web/20220201012049/https://www.imdb.com/chart/top/\"\nhtml &lt;- read_html(url)\n\ntabela &lt;- html |&gt; \n  html_element(\"table\") |&gt; \n  html_table()\ntabela\n#&gt; # A tibble: 250 × 5\n#&gt;   ``    `Rank & Title`                    `IMDb Rating` `Your Rating`   ``   \n#&gt;   &lt;lgl&gt; &lt;chr&gt;                                     &lt;dbl&gt; &lt;chr&gt;           &lt;lgl&gt;\n#&gt; 1 NA    \"1.\\n      The Shawshank Redempt…           9.2 \"12345678910\\n… NA   \n#&gt; 2 NA    \"2.\\n      The Godfather\\n      …           9.1 \"12345678910\\n… NA   \n#&gt; 3 NA    \"3.\\n      The Godfather: Part I…           9   \"12345678910\\n… NA   \n#&gt; 4 NA    \"4.\\n      The Dark Knight\\n    …           9   \"12345678910\\n… NA   \n#&gt; 5 NA    \"5.\\n      12 Angry Men\\n       …           8.9 \"12345678910\\n… NA   \n#&gt; 6 NA    \"6.\\n      Schindler's List\\n   …           8.9 \"12345678910\\n… NA   \n#&gt; # ℹ 244 more rows\n\nIsto inclui algumas colunas vazias, mas no geral, faz um bom trabalho ao capturar as informações da tabela. No entanto, precisamos fazer mais alguns processamentos para torná-la mais fácil de usar. Primeiro, renomearemos as colunas para facilitar o trabalho e removeremos os espaços em branco estranhos na classificação (rank) e no título (title). Faremos isto com select() (ao invés de rename()) para renomear e selecionar apenas essas duas colunas em uma única etapa. Em seguida, removeremos as novas linhas e espaços extras e usaremos separate_wider_regex() (da Seção 15.3.4) para extrair o título, ano e classificação em suas próprias variáveis.\n\nclassificacao &lt;- tabela |&gt;\n  select(\n    classificacao_titulo_ano = `Rank & Title`,\n    nota_imdb = `IMDb Rating`\n  ) |&gt; \n  mutate(\n    classificacao_titulo_ano = str_replace_all(classificacao_titulo_ano, \"\\n +\", \" \")\n  ) |&gt; \n  separate_wider_regex(\n    classificacao_titulo_ano,\n    patterns = c(\n      classificacao = \"\\\\d+\", \"\\\\. \",\n      titulo = \".+\", \" +\\\\(\",\n      ano = \"\\\\d+\", \"\\\\)\"\n    )\n  )\nclassificacao\n#&gt; # A tibble: 250 × 4\n#&gt;   classificacao titulo                   ano   nota_imdb\n#&gt;   &lt;chr&gt;         &lt;chr&gt;                    &lt;chr&gt;     &lt;dbl&gt;\n#&gt; 1 1             The Shawshank Redemption 1994        9.2\n#&gt; 2 2             The Godfather            1972        9.1\n#&gt; 3 3             The Godfather: Part II   1974        9  \n#&gt; 4 4             The Dark Knight          2008        9  \n#&gt; 5 5             12 Angry Men             1957        8.9\n#&gt; 6 6             Schindler's List         1993        8.9\n#&gt; # ℹ 244 more rows\n\nMesmo neste caso, em que a maioria dos dados vêm de células de tabela, ainda vale a pena dar uma olhada no HTML bruto. Se você fizer isso, descobrirá que podemos adicionar alguns dados extras usando um dos atributos. Esse é um dos motivos pelos quais vale a pena gastar um pouco de tempo explorando o código fonte da página; você pode encontrar dados extras ou uma rota de análise um pouco mais fácil.\n\nhtml |&gt; \n  html_elements(\"td strong\") |&gt; \n  head() |&gt; \n  html_attr(\"title\")\n#&gt; [1] \"9.2 based on 2,536,415 user ratings\"\n#&gt; [2] \"9.1 based on 1,745,675 user ratings\"\n#&gt; [3] \"9.0 based on 1,211,032 user ratings\"\n#&gt; [4] \"9.0 based on 2,486,931 user ratings\"\n#&gt; [5] \"8.9 based on 749,563 user ratings\"  \n#&gt; [6] \"8.9 based on 1,295,705 user ratings\"\n\nPodemos combinar isto com os dados tabulares e aplicar novamente separate_wider_regex() para extrair os dados que nos interessam:\n\nclassificacao |&gt;\n  mutate(\n    classificacao_n = html |&gt; html_elements(\"td strong\") |&gt; html_attr(\"title\")\n  ) |&gt; \n  separate_wider_regex(\n    classificacao_n,\n    patterns = c(\n      \"[0-9.]+ based on \",\n      numero_usuarios = \"[0-9,]+\",\n      \" user ratings\"\n    )\n  ) |&gt; \n  mutate(\n    numero_usuarios = parse_number(numero_usuarios)\n  )\n#&gt; # A tibble: 250 × 5\n#&gt;   classificacao titulo                   ano   nota_imdb numero_usuarios\n#&gt;   &lt;chr&gt;         &lt;chr&gt;                    &lt;chr&gt;     &lt;dbl&gt;           &lt;dbl&gt;\n#&gt; 1 1             The Shawshank Redemption 1994        9.2         2536415\n#&gt; 2 2             The Godfather            1972        9.1         1745675\n#&gt; 3 3             The Godfather: Part II   1974        9           1211032\n#&gt; 4 4             The Dark Knight          2008        9           2486931\n#&gt; 5 5             12 Angry Men             1957        8.9          749563\n#&gt; 6 6             Schindler's List         1993        8.9         1295705\n#&gt; # ℹ 244 more rows",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#sites-dinâmicos",
    "href": "webscraping.html#sites-dinâmicos",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.7 Sites dinâmicos",
    "text": "24.7 Sites dinâmicos\nAté agora nos concentramos em sites onde html_elements() retorna o que você vê no navegador e discutimos como processar o que ele retorna e como organizar essas informações em um data frame. Entretanto, algumas vezes você chegará a um site onde html_elements() e companhia não retornam nada parecido com o que você vê no navegador. Em muitos casos, isso ocorre porque você está tentando raspar dados de um site que gera dinamicamente o conteúdo da página com javascript. Atualmente, isso não funciona com o rvest, porque o rvest baixa o HTML bruto e não executa nenhum javascript.\nAinda assim é possível raspar os dados desses tipos de sites, mas o rvest precisa usar um processo mais caro: simular totalmente o navegador da web, incluindo a execução de todo javascript. Esta funcionalidade não estava disponível quando escrevemos este livro, mas é algo em que estamos trabalhando ativamente e pode estar disponível quando você ler isto. Ele usa o pacote chromote que, na verdade, executa um navegador Chrome em segundo plano e oferece ferramentas adicionais para interação com o site, como se fosse uma pessoa digitando o texto ou clicando em botões. Veja maiores informações sobre isto no website do rvest.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#resumo",
    "href": "webscraping.html#resumo",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "\n24.8 Resumo",
    "text": "24.8 Resumo\nNeste capítulo, você aprendeu sobre o porquê, o porque não e como fazer raspagem de dados em páginas da web. Primeiro, você aprendeu sobre o básico de HTML e como usar seletores CSS para se referir a elementos específicos, depois aprendeu como usar o pacote rvest para transferir dados do HTML para o R. Em seguida, demonstramos a raspagem de dados em dois estudos de caso: um cenário mais simples de raspagem de dados do site do pacote rvest com filmes de “Guerra nas Estrelas” e um cenário mais complexo de extração de dados dos 250 melhores filmes do IMDB.\nOs detalhes técnicos da raspagem de dados da web podem ser complexos, especialmente quando se trata de sites, mas as considerações legais e éticas podem ser ainda mais complexas. É importante que você se informe sobre ambos antes de começar a coletar dados.\nIsso nos leva ao final da parte de importação do livro, onde você aprendeu técnicas para obter dados de onde eles residem (planilhas, bancos de dados, arquivos JSON e websites) em um formato organizado (tidy) para o R. Agora é hora de voltarmos para um novo tópico: aproveitar ao máximo do R como linguagem de programação.",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "webscraping.html#footnotes",
    "href": "webscraping.html#footnotes",
    "title": "24  ✅ Raspagem de dados (Web scraping)",
    "section": "",
    "text": "Muitas APIs populares já possuem um pacote no CRAN que as encapsulam, então comece sempre fazendo uma pesquisa antes!↩︎\nObviamente não somos advogados, e este não é um aconselhamento jurídico. Mas este é o melhor resumo que podemos dar depois de ler muito sobre esse assunto.↩︎\nUm exemplo de artigo sobre o estudo do OkCupid foi publicado pela Wired, https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science.↩︎\nEm várias marcações (incluindo &lt;p&gt; e &lt;li&gt;) a marcação de fim não é obrigatória, mas acreditamos ser melhor incluí-la, pois torna a visualização da estrutura HTML mais fácil.↩︎\nEsta classe vem do pacote xml2. xml2 é um pacote de baixo nível a partir do qual o rvest foi criado.↩︎\nrvest também fornece html_text(), porém você deve usar quase sempre html_text2(), já que esta faz um trabalho melhor ao converter HTML anihadas em texto.↩︎",
    "crumbs": [
      "✅ Importar",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>✅ Raspagem de dados (*Web scraping*)</span>"
    ]
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "✅ Programar",
    "section": "",
    "text": "Nessa parte do livro, você irá aprimorar suas habilidades em programação. Programação é uma competência transversal para todo trabalho de ciência de dados: você deve usar o computador para fazer ciência de dados; você não pode fazê-la em sua cabeça, com lápis e papel.\n\n\n\n\n\n\n\nFigura 1: Programação é a água na qual todos os outros componentes nadam.\n\n\n\n\nProgramação produz código, e código é uma ferramenta de comunicação. Obviamente o código diz ao computador o que você quer que ele faça. Mas ele também transmite um significado a outros humanos. Pensar em código como um veículo de comunicação é importante porque todo projeto que você faz é fundamentalmente colaborativo. Mesmo que você não esteja trabalhando com outras pessoas, você definitivamente trabalhará com o você do futuro. Escrever códigos claros é importante para que outras pessoas (como você no futuro) possam entender o porquê de você ter abordado uma análise da forma como fez. Isso significa que melhorar na programação também envolve melhorar na comunicação. Com o tempo, você quer que seu código seja não apenas mais fácil de escrever, mas fácil também para outras pessoas lerem.\nNos próximos três capítulos, você irá desenvolver competências que irão aprimorar suas habilidades em programação.\n\nCopiar e colar é uma ferramenta poderosa, mas você deve evitar usá-la mais que duas vezes. Repetir código é perigoso, pois isto pode facilmente te levar a erros e inconsistências. Em vez disso, no 25  ✅ Funções, você irá aprender como escrever funções que te permitem extrair códigos tidyverse repetidos para que possam ser facilmente reutilizados.\nFunções extraem os códigos repetidos, mas você eventualmente precisa repetir as mesmas ações em diferentes inputs. Você precisa de ferramentas de iteração que te permitem executar as mesmas ações de novo e de novo. Essas ferramentas incluem for loops e programação funcional, que você irá aprender no 26  Iteration.\nQuanto mais você ler códigos escritos por outras pessoas, mais você verá códigos que não utilizam tidyverse. No 27  ✅ Um guia para o R base, você irá aprender algumas das funções mais importantes do R base que você encontrará por aí.\n\nO objetivo desses capítulos é te ensinar o mínimo sobre programação que você precisa para ciência de dados. Quando você dominar esse material, recomendamos fortemente que você continue a investir nas suas habilidades de programação. Nós escrevemos dois livros que você pode achar útil. Hands on Programming with R, de Garrett Grolemund, é uma introdução ao R como linguagem de programação e um ótimo ponto de partida se o R for sua primeira linguagem de programação. Advanced R de Hadley Wickham entra em detalhes na linguagem de programação R; é um ótimo ponto de partida se você já tem experiência em programação e ótimo próximo passo se as ideias desses capítulos forem familiares para você.",
    "crumbs": [
      "✅ Programar"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "25  ✅ Funções",
    "section": "",
    "text": "25.1 Introdução\nUma das melhores maneiras de melhorar sua atuação como cientista de dados é escrever funções. As funções permitem automatizar tarefas comuns de uma forma mais poderosa e geral do que copiar e colar o código. Escrever uma função tem quatro grandes vantagens em relação ao copiar e colar:\nUma boa regra geral é considerar escrever uma função sempre que você copiar e colar um bloco de código mais de duas vezes (ou seja, quando você tiver três cópias do mesmo código). Neste capítulo, você aprenderá sobre três tipos úteis de funções:\nCada uma dessas seções inclui muitos exemplos para ajudá-lo a generalizar esses padrões que você vê. Esses exemplos não seriam possíveis sem a ajuda do pessoal do Twitter, e encorajamos você a seguir os links nos comentários para ver as inspirações originais. Você também pode querer ler os tweets motivacionais originais para funções gerais e funções de plotagem para ver ainda mais funções.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "functions.html#introdução",
    "href": "functions.html#introdução",
    "title": "25  ✅ Funções",
    "section": "",
    "text": "Você pode dar a uma função um nome evocativo que torne seu código mais fácil de entender.\nÀ medida que os requisitos mudam, você só precisa atualizar o código em um local em vez de vários.\nVocê elimina a chance de cometer erros acidentais ao copiar e colar (ou seja, atualizar o nome de uma variável em um lugar, mas não em outro).\nTorna mais fácil reutilizar o trabalho de um projeto em outro, aumentando sua produtividade ao longo do tempo.\n\n\n\nFunções vetoriais que recebem um ou mais vetores como entrada e retornam um vetor como saída.\nFunções de data frames que recebem um data frame como entrada e retornam um data frame como saída.\nFunções de plotagem que recebem um data frame como entrada e retornam um gráfico como saída.\n\n\n\n25.1.1 Pré-requisitos\nResumiremos uma variedade de funções do pacote tidyverse. Também usaremos o pacote dados como fonte de dados familiares para usar em nossas funções.\n\nlibrary(tidyverse)\nlibrary(dados)",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "functions.html#funções-vetoriais",
    "href": "functions.html#funções-vetoriais",
    "title": "25  ✅ Funções",
    "section": "\n25.2 Funções vetoriais",
    "text": "25.2 Funções vetoriais\nComeçaremos com funções vetoriais: funções que recebem um ou mais vetores e retornam um resultado vetorial. Por exemplo, dê uma olhada neste código. O que isso faz?\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(b, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  2.59 0.291 0    \n#&gt; 2 0.880  0    0.611 0.557\n#&gt; 3 0      1.37 1     0.752\n#&gt; 4 0.795  1.37 0     1    \n#&gt; 5 1      1.34 0.580 0.394\n\nVocê pode adivinhar que isso redimensiona cada coluna para pertencer a um intervalo de 0 a 1. Mas você percebeu o erro? Quando Hadley escreveu este código, ele cometeu um erro ao copiar e colar e esqueceu de alterar um a para um b. Prevenir esse tipo de erro é um bom motivo para aprender a escrever funções.\n\n25.2.1 Escrevendo funções\nPara escrever uma função você precisa primeiro analisar seu código repetido para descobrir quais partes são constantes e quais partes variam. Se pegarmos o código acima e o extraimos da função mutate(), será um pouco mais fácil ver o padrão porque cada repetição agora é uma linha:\n\n(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))\n(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))\n(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))\n(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  \n\nPara deixar isso um pouco mais claro, podemos substituir a parte que varia com █:\n\n(█ - min(█, na.rm = TRUE)) / (max(█, na.rm = TRUE) - min(█, na.rm = TRUE))\n\nPara transformar isso em uma função você precisa de três coisas:\n\nUm nome. Aqui usaremos rescala01 porque esta função redimensiona um vetor para ficar entre 0 e 1.\nOs argumentos. Os argumentos variam entre as chamadas e nossa análise acima nos diz que temos apenas um. Chamaremos de x porque este é o nome convencional para um vetor numérico.\nO corpo. O corpo é o código repetido em todas as chamadas.\n\nEntão, você cria uma função seguindo o modelo:\n\nnome &lt;- function(argumentos) {\n  corpo\n}\n\nPara este caso nos leva a:\n\nrescala01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nNeste ponto você pode testar com algumas entradas simples para ter certeza de que capturou a lógica corretamente:\n\nrescala01(c(-10, 0, 10))\n#&gt; [1] 0.0 0.5 1.0\nrescala01(c(1, 2, 3, NA, 5))\n#&gt; [1] 0.00 0.25 0.50   NA 1.00\n\nEntão você pode reescrever a chamada para mutate() como:\n\ndf |&gt; mutate(\n  a = rescala01(a),\n  b = rescala01(b),\n  c = rescala01(c),\n  d = rescala01(d),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\n(No Capítulo 26, você aprenderá como usar across() para reduzir ainda mais a duplicação, então tudo que você precisará é df |&gt; mutate(across(a:d, rescala01))).\n\n25.2.2 Melhorando nossa função\nVocê pode notar que a função rescala01() faz algum trabalho desnecessário — em vez de calcular min() duas vezes e max() uma vez, poderíamos calcular o mínimo e o máximo em uma única etapa com range( ):\n\nrescala01 &lt;- function(x) {\n  intervalo &lt;- range(x, na.rm = TRUE)\n  (x - intervalo[1]) / (intervalo[2] - intervalo[1])\n}\n\nOu você pode tentar esta função em um vetor que inclui um valor infinito:\n\nx &lt;- c(1:10, Inf)\nrescala01(x)\n#&gt;  [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\nEsse resultado não é particularmente útil, então poderíamos pedir a função range() para ignorar valores infinitos:\n\nrescala01 &lt;- function(x) {\n  intervalo &lt;- range(x, na.rm = TRUE, finite = TRUE)\n  (x - intervalo[1]) / (intervalo[2] - intervalo[1])\n}\n\nrescala01(x)\n#&gt;  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#&gt;  [8] 0.7777778 0.8888889 1.0000000       Inf\n\nEssas mudanças ilustram um benefício importante das funções: como movemos o código repetido para uma função, precisamos fazer a mudança em um só lugar.\n\n25.2.3 Funções de mutate\n\nAgora que você tem a ideia básica de funções, vamos dar uma olhada em vários exemplos. Começaremos examinando as funções de “mutate”, ou seja, funções que funcionam bem dentro de mutate() e filter() porque retornam uma saída do mesmo comprimento que a entrada.\nVamos começar com uma variação simples de rescala01(). Talvez você queira calcular o z-score, redimensionando um vetor para ter uma média de zero e um desvio-padrão de um:\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\nOu talvez você queira encerrar um case_when() simples e dar a ele um nome útil. Por exemplo, esta função ajusta_mm() garante que todos os valores de um vetor estejam entre um mínimo ou um máximo:\n\najusta_mm &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\najusta_mm(1:10, min = 3, max = 7)\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\nÉ claro que as funções não precisam trabalhar apenas com variáveis ​​numéricas. Você pode querer fazer alguma manipulação repetida de strings. Talvez você precise deixar o primeiro caractere maiúsculo:\n\nprim_maiusculo &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nprim_maiusculo(\"hello\")\n#&gt; [1] \"Hello\"\n\nOu talvez você queira retirar sinais de porcentagem, vírgulas e cifrões de uma string antes de convertê-la em um número:\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nlimpa_numero &lt;- function(x) {\n  tem_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(tem_pct, num / 100, num)\n}\n\nlimpa_numero(\"$12,300\")\n#&gt; [1] 12300\nlimpa_numero(\"45%\")\n#&gt; [1] 0.45\n\nÀs vezes, suas funções serão altamente especializadas para uma etapa de análise de dados. Por exemplo, se você tiver um monte de variáveis ​​que registram valores ausentes como 997, 998 ou 999, você pode querer escrever uma função para substituí-los por NA:\n\najusta_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\nNós nos concentramos em exemplos que usam um único vetor porque achamos que são os mais comuns. Mas não há razão para que sua função não possa receber múltiplas vetores na entrada.\n\n25.2.4 Funções de resumo\nOutra família importante de funções vetoriais são as funções de sumarização, funções que retornam um único valor para uso em summarize(). Às vezes, isso pode ser apenas uma questão de definir um ou dois argumentos padrão:\n\nvirgulas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" e \")\n}\n\nvirgulas(c(\"gato\", \"cachorro\", \"pomba\"))\n#&gt; [1] \"gato, cachorro e pomba\"\n\nOu você pode fazer um cálculo simples, como o do coeficiente de variação, que divide o desvio padrão pela média:\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n#&gt; [1] 0.5652554\n\nOu talvez você apenas queira tornar um padrão comum mais fácil de lembrar, dando-lhe um nome mais significativo:\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nnum_valores_faltantes &lt;- function(x) {\n  sum(is.na(x))\n} \n\nVocê também pode escrever funções com múltiplos vetores na entrada. Por exemplo, talvez você queira calcular o erro percentual absoluto médio para ajudá-lo a comparar as previsões do modelo com os valores reais:\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nepam &lt;- function(atual, previsto) {\n  sum(abs((atual - previsto) / atual)) / length(atual)\n}\n\n\n\n\n\n\n\nRStudio\n\n\n\nDepois de começar a escrever funções, existem dois atalhos do RStudio que são muito úteis:\n\nPara encontrar a definição de uma função que você escreveu, coloque o cursor sobre o nome da função e pressione F2.\nPara pular rapidamente para uma função, pressione Ctrl + . para abrir o arquivo difuso e o localizador de função e digite as primeiras letras do nome da função. Você também pode navegar para arquivos, seções do Quarto e muito mais, tornando-o uma ferramenta de navegação muito útil.\n\n\n\n\n25.2.5 Exercícios\n\n\nPratique transformar os seguintes trechos de código em funções. Pense no que cada função faz. Como você chamaria cada função? Quantos argumentos são necessários?\n\nmean(is.na(x))\nmean(is.na(y))\nmean(is.na(z))\n\nx / sum(x, na.rm = TRUE)\ny / sum(y, na.rm = TRUE)\nz / sum(z, na.rm = TRUE)\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n\nNa segunda variante de rescala01(), valores infinitos permanecem inalterados. Você pode reescrever rescale01() para que -Inf seja mapeado para 0 e Inf seja mapeado para 1?\nDado um vetor de datas de nascimento, escreva uma função para calcular a idade em anos.\nEscreva suas próprias funções para calcular a variância e a assimetria de um vetor numérico. Você pode procurar as definições na Wikipedia ou em outro lugar.\nEscreva ambos_na(), uma função de resumo que pega dois vetores do mesmo comprimento e retorna o número de posições que possuem um NA em ambos os vetores.\n\nLeia a documentação para descobrir o que as funções a seguir fazem. Por que elas são úteis mesmo sendo tão pequenas?\n\nis_directory &lt;- function(x) {\n  file.info(x)$isdir\n}\nis_readable &lt;- function(x) {\n  file.access(x, 4) == 0\n}",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "functions.html#funções-de-data-frame",
    "href": "functions.html#funções-de-data-frame",
    "title": "25  ✅ Funções",
    "section": "\n25.3 Funções de data frame\n",
    "text": "25.3 Funções de data frame\n\nFunções vetoriais são úteis para extrair código repetido em um verbo dplyr. Mas muitas vezes você também repetirá os próprios verbos, especialmente em um pipeline grande. Ao perceber que você está copiando e colando vários verbos dplyr diversas vezes, você pode pensar em escrever uma função de data frame. As funções de data frame funcionam como verbos dplyr: elas pegam um data frame como primeiro argumento, alguns argumentos extras que dizem o que fazer com ele e retornam um data frame ou um vetor.\nPara permitir que você escreva uma função que use verbos dplyr, primeiro apresentaremos o desafio da indireção (indirection challenge) e como você pode superá-lo usando os sinais de chaves (embracing) { }. Com essa teoria em mãos, mostraremos vários exemplos para ilustrar o que você pode fazer com ela.\n\n25.3.1 Indireção e avaliação organizada\nQuando você começa a escrever funções que usam verbos dplyr, você rapidamente se depara com o problema da indireção. Vamos ilustrar o problema com uma função muito simples: media_agrupada(). O objetivo desta função é calcular a média de var_media agrupada por var_grupo:\n\nmedia_agrupada &lt;- function(df, var_grupo, var_media) {\n  df |&gt; \n    group_by(var_grupo) |&gt; \n    summarize(mean(var_media))\n}\n\nSe tentarmos usá-la, receberemos um erro:\n\ndiamante |&gt; media_agrupada(corte, quilate)\n#&gt; Error in `group_by()`:\n#&gt; ! Must group by variables found in `.data`.\n#&gt; ✖ Column `var_grupo` is not found.\n\nPara tornar o problema um pouco mais claro, podemos usar um data frame mais simples de exemplo:\n\ndf &lt;- tibble(\n  var_media = 1,\n  var_grupo = \"g\",\n  grupo = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; media_agrupada(grupo, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   var_grupo `mean(var_media)`\n#&gt;   &lt;chr&gt;                 &lt;dbl&gt;\n#&gt; 1 g                         1\ndf |&gt; media_agrupada(grupo, y)\n#&gt; # A tibble: 1 × 2\n#&gt;   var_grupo `mean(var_media)`\n#&gt;   &lt;chr&gt;                 &lt;dbl&gt;\n#&gt; 1 g                         1\n\nIndependentemente de como chamamos media_agrupada() ele sempre faz df |&gt; group_by(var_grupo) |&gt; summary(mean(var_media)), em vez de df |&gt; group_by(grupo) |&gt; summary(mean(x) ) ou df |&gt; group_by(grupo) |&gt; summary(mean(y)). Este é um problema de indireção (indirection) e surge porque o dplyr usa avaliação organizada (tidy evaluation) para permitir que você se refira aos nomes das variáveis ​​dentro do seu data frame sem qualquer tratamento especial.\nA avaliação organizada (tidy evaluation) é ótima 95% das vezes porque torna suas análises de dados muito concisas, já que você nunca precisa dizer de qual data frame vem uma variável; é óbvio pelo contexto. A desvantagem da avaliação organizada surge quando queremos agrupar códigos repetidos do tidyverse em uma função. Aqui precisamos de alguma maneira de dizer a group_by() e summarize() para não tratar group_var e mean_var como o nome das variáveis, mas em vez disso procurar dentro delas a variável que realmente queremos usar.\nA avaliação organizada inclui uma solução para esse problema chamada abraçar (embracing) 🤗. Abraçar (embracing) uma variável significa envolvê-la entre chaves para que (por exemplo) var se torne { var }. Abraçar uma variável diz ao dplyr para usar o valor armazenado dentro do argumento, não o argumento como o nome literal da variável. Uma maneira de lembrar o que está acontecendo é pensar em { } como olhar para dentro de um túnel — { var } fará uma função dplyr olhar dentro de var em vez de procurar por uma variável chamada var.\nEntão, para media_agrupada() funcionar, precisamos abraçar var_grupo e var_media com { }:\n\nmedia_agrupada &lt;- function(df, var_grupo, var_media) {\n  df |&gt; \n    group_by({{ var_grupo }}) |&gt; \n    summarize(mean({{ var_media }}))\n}\n\ndf |&gt; media_agrupada(grupo, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   grupo `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\nSucesso!\n\n25.3.2 Quando abraçar?\nPortanto, o principal desafio ao escrever funções de data frame é descobrir quais argumentos precisam ser abraçados (embraced). Felizmente, isso é fácil porque você pode consultar a documentação 😄. Existem dois termos a serem procurados nos documentos que correspondem aos dois subtipos mais comuns de avaliação organizada (tidy evaluation):\n\nMascaramento de dados (data-masking): é usado em funções como arrange(), filter() e summarize() que fazem calculos com variáveis.\nSelecionamento organizado (tidy-selection): é usado para funções como select(), relocate() e rename() que selecionam variáveis.\n\nSua intuição sobre quais argumentos usam avaliação organizada (tidy evaluation) deve ser boa para muitas funções comuns — basta pensar se você pode calcular (por exemplo, x + 1) ou selecionar (por exemplo, a:x).\nNas seções a seguir, exploraremos os tipos de funções úteis que você pode escrever depois de entender como abraçar (embracing) uma variável.\n\n25.3.3 Casos de uso mais comuns\nSe você normalmente executa o mesmo conjunto de sumarização ao fazer a exploração inicial de dados, considere agrupá-los em uma função auxiliar:\n\nsumario6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    media = mean({{ var }}, na.rm = TRUE),\n    mediana = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_faltantes = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamante |&gt; sumario6(quilate)\n#&gt; # A tibble: 1 × 6\n#&gt;     min media mediana   max     n n_faltantes\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;       &lt;int&gt;\n#&gt; 1   0.2 0.798     0.7  5.01 53940           0\n\n(Sempre que você usa summarize() em uma função auxiliar, achamos que é uma boa prática definir .groups = \"drop\" para evitar a mensagem de aviso e deixar os dados em um estado desagrupado.)\nO bom dessa função é que, como ela usa summarize(), você pode usá-la em dados agrupados:\n\ndiamante |&gt; \n  group_by(corte) |&gt; \n  sumario6(quilate)\n#&gt; # A tibble: 5 × 7\n#&gt;   corte       min media mediana   max     n n_faltantes\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;       &lt;int&gt;\n#&gt; 1 Justo      0.22 1.05     1     5.01  1610           0\n#&gt; 2 Bom        0.23 0.849    0.82  3.01  4906           0\n#&gt; 3 Muito Bom  0.2  0.806    0.71  4    12082           0\n#&gt; 4 Premium    0.2  0.892    0.86  4.01 13791           0\n#&gt; 5 Ideal      0.2  0.703    0.54  3.5  21551           0\n\nAlém disso, uma vez que os argumentos da summarize() usam mascaramento de dados (data-masking), isso significa que o argumento var para a função sumario6() também usa mascaramento de dados (data-masking). Isso significa que você também pode sumarizar variáveis ​​calculadas:\n\ndiamante |&gt; \n  group_by(corte) |&gt; \n  sumario6(log10(quilate))\n#&gt; # A tibble: 5 × 7\n#&gt;   corte        min   media mediana   max     n n_faltantes\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;       &lt;int&gt;\n#&gt; 1 Justo     -0.658 -0.0273  0      0.700  1610           0\n#&gt; 2 Bom       -0.638 -0.133  -0.0862 0.479  4906           0\n#&gt; 3 Muito Bom -0.699 -0.164  -0.149  0.602 12082           0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791           0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551           0\n\nPara resumir múltiplas variáveis, você precisará esperar até Seção 26.2, onde aprenderá como usar across().\nOutra função auxiliar usando summarize() popular é uma versão de count() que também calcula proporções:\n\n# https://twitter.com/Diabb6/status/1571635146658402309\nconta_prop &lt;- function(df, var, ordenar = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = ordenar) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamante |&gt; conta_prop(transparencia)\n#&gt; # A tibble: 8 × 3\n#&gt;   transparencia     n   prop\n#&gt;   &lt;ord&gt;         &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1              741 0.0137\n#&gt; 2 SI2            9194 0.170 \n#&gt; 3 SI1           13065 0.242 \n#&gt; 4 VS2           12258 0.227 \n#&gt; 5 VS1            8171 0.151 \n#&gt; 6 VVS2           5066 0.0939\n#&gt; # ℹ 2 more rows\n\nEsta função tem três argumentos: df, var e ordena, e apenas var precisa ser abraçada (embrancing) porque é passada para count() que usa mascaramento de dados (data-masking) para todas as variáveis. Observe que usamos um valor padrão para ordenar para que, se o usuário não fornecer seu próprio valor, o padrão seja FALSE.\nOu talvez você queira encontrar os valores exclusivos ordenados de uma variável para um subconjunto de dados. Em vez de fornecer uma variável e um valor para fazer a filtragem, permitiremos que o usuário forneça uma condição:\n\nunico_onde &lt;- function(df, condicao, var) {\n  df |&gt; \n    filter({{ condicao }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# Procura todos os destinos em Dezembro\nvoos |&gt; unico_onde(mes == 12, destino)\n#&gt; # A tibble: 96 × 1\n#&gt;   destino\n#&gt;   &lt;chr&gt;  \n#&gt; 1 ABQ    \n#&gt; 2 ALB    \n#&gt; 3 ATL    \n#&gt; 4 AUS    \n#&gt; 5 AVL    \n#&gt; 6 BDL    \n#&gt; # ℹ 90 more rows\n\nAqui abraçamos condicao porque é passado para filter() e var porque é passado para distinct() e arrange().\nFizemos todos esses exemplos para usar um data frame como primeiro argumento, mas se você estiver trabalhando repetidamente com os mesmos dados, pode fazer sentido codificá-los. Por exemplo, a função a seguir sempre funciona com o conjunto de dados de voos e sempre seleciona data_hora, companhia_aerea e voo, pois eles formam a chave primária composta (compound primary key) que permite identificar uma linha.\n\nsubconjunto_voos &lt;- function(linhas, colunas) {\n  voos |&gt; \n    filter({{ linhas }}) |&gt; \n    select(data_hora, companhia_aerea, voo, {{ colunas }})\n}\n\n\n25.3.4 Mascaramento de dados vs. seleção organizada\nÀs vezes você deseja selecionar variáveis ​​dentro de uma função que usa mascaramento de dados (data-masking). Por exemplo, imagine que você deseja escrever uma função conta_faltantes() que conte o número de observações faltantes nas linhas. Você pode tentar escrever algo como:\n\nconta_faltantes &lt;- function(df, grupo_vars, x_var) {\n  df |&gt; \n    group_by({{ grupo_vars }}) |&gt; \n    summarize(\n      n_faltantes = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nvoos |&gt; \n  conta_faltantes(c(ano, mes, dia), horario_saida)\n#&gt; Error in `group_by()`:\n#&gt; ℹ In argument: `c(ano, mes, dia)`.\n#&gt; Caused by error:\n#&gt; ! `c(ano, mes, dia)` must be size 336776 or 1, not 1010328.\n\nIsto não funciona, pois group_by() usa mascaramento de dados (data-masking), não seleção organizada (tidy-selection). Podemos contornar esse problema usando a útil função pick(), que permite usar a seleção organizada (tidy-selection) dentro de funções de mascaramento de dados (data-masking):\n\nconta_faltantes &lt;- function(df, grupo_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ grupo_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n  )\n}\n\nvoos |&gt; \n  conta_faltantes(c(ano, mes, dia), horario_saida)\n#&gt; # A tibble: 365 × 4\n#&gt;     ano   mes   dia n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # ℹ 359 more rows\n\nOutro uso conveniente de pick() é fazer uma tabela 2d de contagens. Aqui contamos usando todas as variáveis ​​nas linhas e colunas, então usamos pivot_wider() para reorganizar as contagens em uma grade:\n\n# https://twitter.com/pollicipes/status/1571606508944719876\nconta_wide &lt;- function(data, linhas, colunas) {\n  data |&gt; \n    count(pick(c({{ linhas }}, {{ colunas }}))) |&gt; \n    pivot_wider(\n      names_from = {{ colunas }}, \n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamante |&gt; conta_wide(c(transparencia, cor), corte)\n#&gt; # A tibble: 56 × 7\n#&gt;   transparencia cor   Justo   Bom `Muito Bom` Premium Ideal\n#&gt;   &lt;ord&gt;         &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1            D         4     8           5      12    13\n#&gt; 2 I1            E         9    23          22      30    18\n#&gt; 3 I1            F        35    19          13      34    42\n#&gt; 4 I1            G        53    19          16      46    16\n#&gt; 5 I1            H        52    14          12      46    38\n#&gt; 6 I1            I        34     9           8      24    17\n#&gt; # ℹ 50 more rows\n\nEmbora nossos exemplos tenham se concentrado principalmente no dplyr, a avaliação organizada (tidy-evaluation) também e usada pelo pacote tidyr, e se você olhar a documentação pivot_wider() você pode ver que names_from usa seleção organizada (tidy-selection).\n\n25.3.5 Exercícios\n\n\nUsando os conjuntos de dados “voos” e “clima” do pacote dados, escreva uma função que:\n\n\nEncontra todos os voos que foram cancelados (ou seja, is.na(horario_chegada)) ou atrasados ​​por mais de uma hora.\n\nvoos |&gt; filtra_problematicos()\n\n\n\nConta o número de voos cancelados e o número de voos atrasados por um tempo maior que uma hora.\n\nvoos |&gt; group_by(destino) |&gt; summariza_problematicos()\n\n\n\nEncontra todos os voos que foram cancelados ou atrasados ​​por mais do que o número de horas fornecido pelo usuário:\n\nvoos |&gt; filtra_problematicos(horas = 2)\n\n\n\nResuma o clima para calcular o mínimo, a média e o máximo de uma variável fornecida pelo usuário:\n\nclima |&gt; summariza(temperatura)\n\n\n\nConverte a variável fornecida pelo usuário que usa o horário do relógio (por exemplo, horario_saida, horario_chegada, etc.) em um tempo decimal (ou seja, horas + (minutos/60)).\n\nvoos |&gt; horario_padronizado(saida_programada)\n\n\n\n\nPara cada uma das funções a seguir, liste todos os argumentos que usam avaliação organizada (tidy-evaluation) e descreva se eles usam mascaramento de dados (data-masking*) ou seleção organizada (tidy-selection): distinct(), count(), group_by(), rename_with(), slice_min(), slice_sample().\n\nGeneralize a função a seguir para que você possa fornecer qualquer número de variáveis ​​para a função contar.\n\nconta_prop &lt;- function(df, var, ordenar = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = ordenar) |&gt;\n    mutate(prop = n / sum(n))\n}",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "functions.html#funções-de-plotagem",
    "href": "functions.html#funções-de-plotagem",
    "title": "25  ✅ Funções",
    "section": "\n25.4 Funções de plotagem",
    "text": "25.4 Funções de plotagem\nAo invés de retornar um data frame, você pode querer retornar um gráfico. Felizmente, você pode usar as mesmas técnicas com ggplot2, porque aes() é uma função de mascaramento de dados (data-masking). Por exemplo, imagine que você está fazendo muitos histogramas:\n\ndiamante |&gt; \n  ggplot(aes(x = quilate)) +\n  geom_histogram(binwidth = 0.1)\n\ndiamante |&gt; \n  ggplot(aes(x = quilate)) +\n  geom_histogram(binwidth = 0.05)\n\nNão seria bom se você pudesse agrupar isso em uma função de histograma? Isso é muito fácil quando você sabe que aes() é uma função de mascaramento de dados (data-masking) e você precisa abraçar (embrace):\n\nhistograma &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamante |&gt; histograma(quilate, 0.1)\n\n\n\n\n\n\n\nObserve que histograma() retorna um gráfico ggplot2, o que significa que você ainda pode adicionar componentes adicionais se desejar. Apenas lembre-se de mudar de |&gt; para +:\n\ndiamante |&gt; \n  histograma(quilate, 0.1) +\n  labs(x = \"Tamanho (em quilate)\", y = \"Número de diamantes\")\n\n\n25.4.1 Mais variáveis\nÉ simples adicionar mais variáveis ​​à mistura. Por exemplo, talvez você queira uma maneira fácil de verificar se um conjunto de dados é linear ou não, sobrepondo uma linha suave e uma linha reta:\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nvalida_linearidade &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\ndados_starwars |&gt; \n  filter(massa &lt; 1000) |&gt; \n  valida_linearidade(massa, altura)\n\n\n\n\n\n\n\nOu talvez você queira uma alternativa aos gráficos de dispersão coloridos para conjuntos de dados muito grandes, onde a plotagem excessiva é um problema:\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\ngrafico_hex &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # faz border igual ao preenchimento\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamante |&gt; grafico_hex(quilate, preco, profundidade)\n\n\n\n\n\n\n\n\n25.4.2 Combinando com outros tidyverse\nAlgumas das funções auxiliares mais úteis combinam uma pitada de manipulação de dados com ggplot2. Por exemplo, se você quiser fazer um gráfico de barras verticais onde você classifica automaticamente as barras em ordem de frequência usando a função fct_infreq(). Como o gráfico de barras é vertical, também precisamos inverter a ordem normal para obter os valores mais altos no topo:\n\nbarras_ordenadas &lt;- function(df, var) {\n  df |&gt; \n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt;\n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamante |&gt; barras_ordenadas(transparencia)\n\n\n\n\n\n\n\nTemos que usar um novo operador aqui, := (comumente chamado de “operador morsa”), porque estamos gerando o nome da variável com base nos dados fornecidos pelo usuário. Os nomes das variáveis ​​ficam no lado esquerdo de =, mas a sintaxe do R não permite nada à esquerda de =, exceto um único nome literal. Para contornar este problema, usamos o operador especial := que a avaliação organizada (tidy evaluation) trata exatamente da mesma maneira que =..\nOu talvez você queira facilitar o desenho de um gráfico de barras apenas para um subconjunto de dados:\n\nbarras_condicionais &lt;- function(df, condicao, var) {\n  df |&gt; \n    filter({{ condicao }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamante |&gt; barras_condicionais(corte == \"Bom\", transparencia)\n\n\n\n\n\n\n\nVocê também pode ser criativo e exibir resumos de dados de outras maneiras. Você pode encontrar um aplicativo interessante em https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b; ele usa os rótulos dos eixos para exibir o valor mais alto. À medida que você aprende mais sobre o ggplot2, o poder de suas funções continuará a aumentar.\nTerminaremos com um caso mais complicado: rotular os gráficos que você cria.\n\n25.4.3 Rótulos\nLembra da função de histograma que mostramos anteriormente?\n\nhistograma &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\nNão seria bom se pudéssemos rotular a saída com a variável e a largura do intervalo que foi usada? Para fazer isso, teremos que nos aprofundar na avaliação organizada (tidy evaluation) e usar uma função do pacote sobre a qual ainda não falamos: rlang. rlang é um pacote de baixo nível usado por quase todos os outros pacotes do tidyverse porque implementa a avaliação organizada (tidy evaluation) (bem como muitas outras ferramentas úteis).\nPara resolver o problema de rotulagem podemos usar rlang::englue(). Isso funciona de forma semelhante a str_glue(), então qualquer valor colocado em { } será inserido na string. Mas também entende { }, que insere automaticamente o nome apropriado da variável:\n\nhistograma &lt;- function(df, var, binwidth) {\n  rotulo &lt;- rlang::englue(\"Um histograma da variável {{var}} com agrupamento de {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = rotulo)\n}\n\ndiamante |&gt; histograma(quilate, 0.1)\n\n\n\n\n\n\n\nVocê pode usar a mesma abordagem em qualquer outro lugar onde deseja fornecer uma string em um gráfico ggplot2.\n\n25.4.4 Exercícios\nCrie uma função de plotagem rica implementando gradualmente cada uma das etapas abaixo:\n\nDesenhe um gráfico de dispersão dado o conjunto de dados e as variáveis ​​x e y.\nAdicione uma linha de melhor ajuste (best fit) (ou seja, um modelo linear sem erros padrão).\nAdicione um título.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "functions.html#estilos",
    "href": "functions.html#estilos",
    "title": "25  ✅ Funções",
    "section": "\n25.5 Estilos",
    "text": "25.5 Estilos\nR não se importa com o nome de sua função ou argumentos, mas os nomes fazem uma grande diferença para as pessoas. Idealmente, o nome da sua função será curto, mas evocará claramente o que a função faz. Isso é difícil! Mas é melhor ser claro do que curto, pois o preenchimento automático do RStudio facilita a digitação de nomes longos.\nGeralmente, os nomes das funções devem ser verbos e os argumentos devem ser substantivos. Existem algumas exceções: substantivos são aceitáveis ​​se a função calcular um substantivo muito conhecido (ou seja, media() é melhor que calcular_media()), ou acessar alguma propriedade de um objeto (ou seja, coef() é melhor do que obter_coeficientes()). Use seu bom senso e não tenha medo de renomear uma função se descobrir um nome melhor mais tarde.\n\n# Muito curto\nf()\n\n# Não é verbo, nem descritivo\nminha_funcao_maravilhosa()\n\n# Longo, mas claro\nadicionar_faltantes()\nagrupar_anos()\n\nR também não se importa em como você usa o espaço em branco em suas funções, mas os futuros leitores o farão. Continue seguindo as regras do Capítulo 4. Além disso, funcao() deve sempre ser seguida por chaves ({}), e o conteúdo deve ser recuado por dois espaços adicionais. Isso torna mais fácil ver a hierarquia em seu código, percorrendo a margem esquerda.\n\n# Faltando dois espaços em branco\ndensidade &lt;- function(cor, facetas, agrupamento = 0.1) {\ndiamante |&gt; \n  ggplot(aes(x = quilate, y = after_stat(density), color = {{ cor }})) +\n  geom_freqpoly(binwidth = agrupamento) +\n  facet_wrap(vars({{ facetas }}))\n}\n\n# *Pipe* identado incorretamente\ndensidade &lt;- function(cor, facetas, agrupamento = 0.1) {\n  diamante |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ cor }})) +\n  geom_freqpoly(binwidth = agrupamento) +\n  facet_wrap(vars({{ facets }}))\n}\n\nComo você pode ver, recomendamos colocar espaços extras dentro de { }. Isso torna muito óbvio que algo incomum está acontecendo.\n\n25.5.1 Exercícios\n\n\nLeia o código-fonte de cada uma das duas funções a seguir, descubra o que elas fazem e, em seguida, pense em nomes melhores.\n\nf1 &lt;- function(string, prefixo) {\n  str_sub(string, 1, str_length(prefixo)) == prefixo\n}\n\nf3 &lt;- function(x, y) {\n  rep(y, length.out = length(x))\n}\n\n\nPegue uma função que você escreveu recentemente e gaste 5 minutos pensando em um nome melhor para ela e seus argumentos.\nExplique por que norm_r(), norm_d() etc. seriam melhores que rnorm(), dnorm(). Defenda o contrário. Como você poderia deixar os nomes ainda mais claros?",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "functions.html#resumo",
    "href": "functions.html#resumo",
    "title": "25  ✅ Funções",
    "section": "\n25.6 Resumo",
    "text": "25.6 Resumo\nNeste capítulo, você aprendeu como escrever funções para três cenários úteis: criar um vetor, criar um data frame ou criar um gráfico. Ao longo do caminho, você viu muitos exemplos, que esperamos que tenham começado a estimular sua criatividade, e lhe deram algumas ideias de onde as funções podem ajudar em seu código de análise.\nMostramos apenas o mínimo para começar a usar as funções e há muito mais para aprender. Alguns lugares para aprender mais são:\n\nPara saber mais sobre programação e avaliação organizada (tidy evaluation), veja receitas úteis em programando com dplyr e programando com tidyr e para aprender mais sobre a teoria em O que é mascaramento de dados e por que preciso disso {{?.\nPara saber mais sobre como reduzir a duplicação no código ggplot2, leia o capítulo Programando com ggplot2 do livro ggplot2.\nPara obter mais conselhos sobre estilo de função, consulte o guia de estilo do tidyverse.\n\nNo próximo capítulo, mergulharemos na iteração (iteration), que oferece mais ferramentas para reduzir a duplicação de código.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>✅ Funções</span>"
    ]
  },
  {
    "objectID": "iteration.html",
    "href": "iteration.html",
    "title": "26  Iteration",
    "section": "",
    "text": "26.1 Introduction\nIn this chapter, you’ll learn tools for iteration, repeatedly performing the same action on different objects. Iteration in R generally tends to look rather different from other programming languages because so much of it is implicit and we get it for free. For example, if you want to double a numeric vector x in R, you can just write 2 * x. In most other languages, you’d need to explicitly double each element of x using some sort of for loop.\nThis book has already given you a small but powerful number of tools that perform the same action for multiple “things”:\nNow it’s time to learn some more general tools, often called functional programming tools because they are built around functions that take other functions as inputs. Learning functional programming can easily veer into the abstract, but in this chapter we’ll keep things concrete by focusing on three common tasks: modifying multiple columns, reading multiple files, and saving multiple objects.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#introduction",
    "href": "iteration.html#introduction",
    "title": "26  Iteration",
    "section": "",
    "text": "facet_wrap() and facet_grid() draws a plot for each subset.\n\ngroup_by() plus summarize() computes summary statistics for each subset.\n\nunnest_wider() and unnest_longer() create new rows and columns for each element of a list-column.\n\n\n\n26.1.1 Prerequisites\nIn this chapter, we’ll focus on tools provided by dplyr and purrr, both core members of the tidyverse. You’ve seen dplyr before, but purrr is new. We’re just going to use a couple of purrr functions in this chapter, but it’s a great package to explore as you improve your programming skills.\n\nlibrary(tidyverse)",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#sec-across",
    "href": "iteration.html#sec-across",
    "title": "26  Iteration",
    "section": "\n26.2 Modifying multiple columns",
    "text": "26.2 Modifying multiple columns\nImagine you have this simple tibble and you want to count the number of observations and compute the median of every column.\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nYou could do it with copy-and-paste:\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nThat breaks our rule of thumb to never copy and paste more than twice, and you can imagine that this will get very tedious if you have tens or even hundreds of columns. Instead, you can use across():\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nacross() has three particularly important arguments, which we’ll discuss in detail in the following sections. You’ll use the first two every time you use across(): the first argument, .cols, specifies which columns you want to iterate over, and the second argument, .fns, specifies what to do with each column. You can use the .names argument when you need additional control over the names of output columns, which is particularly important when you use across() with mutate(). We’ll also discuss two important variations, if_any() and if_all(), which work with filter().\n\n26.2.1 Selecting columns with .cols\n\nThe first argument to across(), .cols, selects the columns to transform. This uses the same specifications as select(), Seção 3.3.2, so you can use functions like starts_with() and ends_with() to select columns based on their name.\nThere are two additional selection techniques that are particularly useful for across(): everything() and where(). everything() is straightforward: it selects every (non-grouping) column:\n\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n#&gt; # A tibble: 2 × 5\n#&gt;     grp       a       b     c     d\n#&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1 -0.0935 -0.0163 0.363 0.364\n#&gt; 2     2  0.312  -0.0576 0.208 0.565\n\nNote grouping columns (grp here) are not included in across(), because they’re automatically preserved by summarize().\nwhere() allows you to select columns based on their type:\n\n\nwhere(is.numeric) selects all numeric columns.\n\nwhere(is.character) selects all string columns.\n\nwhere(is.Date) selects all date columns.\n\nwhere(is.POSIXct) selects all date-time columns.\n\nwhere(is.logical) selects all logical columns.\n\nJust like other selectors, you can combine these with Boolean algebra. For example, !where(is.numeric) selects all non-numeric columns, and starts_with(\"a\") & where(is.logical) selects all logical columns whose name starts with “a”.\n\n26.2.2 Calling a single function\nThe second argument to across() defines how each column will be transformed. In simple cases, as above, this will be a single existing function. This is a pretty special feature of R: we’re passing one function (median, mean, str_flatten, …) to another function (across). This is one of the features that makes R a functional programming language.\nIt’s important to note that we’re passing this function to across(), so across() can call it; we’re not calling it ourselves. That means the function name should never be followed by (). If you forget, you’ll get an error:\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median()))\n#&gt; Error in `summarize()`:\n#&gt; ℹ In argument: `across(everything(), median())`.\n#&gt; Caused by error in `median.default()`:\n#&gt; ! argument \"x\" is missing, with no default\n\nThis error arises because you’re calling the function with no input, e.g.:\n\nmedian()\n#&gt; Error in median.default(): argument \"x\" is missing, with no default\n\n\n26.2.3 Calling multiple functions\nIn more complex cases, you might want to supply additional arguments or perform multiple transformations. Let’s motivate this problem with a simple example: what happens if we have some missing values in our data? median() propagates those missing values, giving us a suboptimal output:\n\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA  1.15     5\n\nIt would be nice if we could pass along na.rm = TRUE to median() to remove these missing values. To do so, instead of calling median() directly, we need to create a new function that calls median() with the desired arguments:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b      c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 0.139 -1.11 -0.387  1.15     5\n\nThis is a little verbose, so R comes with a handy shortcut: for this sort of throw away, or anonymous1, function you can replace function with \\2:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\nIn either case, across() effectively expands to the following code:\n\ndf_miss |&gt; \n  summarize(\n    a = median(a, na.rm = TRUE),\n    b = median(b, na.rm = TRUE),\n    c = median(c, na.rm = TRUE),\n    d = median(d, na.rm = TRUE),\n    n = n()\n  )\n\nWhen we remove the missing values from the median(), it would be nice to know just how many values were removed. We can find that out by supplying two functions to across(): one to compute the median and the other to count the missing values. You supply multiple functions by using a named list to .fns:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\nIf you look carefully, you might intuit that the columns are named using a glue specification (Seção 14.3.2) like {.col}_{.fn} where .col is the name of the original column and .fn is the name of the function. That’s not a coincidence! As you’ll learn in the next section, you can use .names argument to supply your own glue spec.\n\n26.2.4 Column names\nThe result of across() is named according to the specification provided in the .names argument. We could specify our own if we wanted the name of the function to come first3:\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\nThe .names argument is particularly important when you use across() with mutate(). By default, the output of across() is given the same names as the inputs. This means that across() inside of mutate() will replace existing columns. For example, here we use coalesce() to replace NAs with 0:\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n#&gt; # A tibble: 5 × 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25   0     1.60 \n#&gt; 2  0     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980  0     1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13 \n#&gt; 5  1.11   0     -0.387 0.704\n\nIf you’d like to instead create new columns, you can use the .names argument to give the output new names:\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n#&gt; # A tibble: 5 × 8\n#&gt;        a      b      c     d a_na_zero b_na_zero c_na_zero d_na_zero\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60      0.434    -1.25      0         1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776     0        -1.43     -0.297     0.776\n#&gt; 3 -0.156 -0.980 NA     1.15     -0.156    -0.980     0         1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13     -2.61     -0.683    -0.785     2.13 \n#&gt; 5  1.11  NA     -0.387 0.704     1.11      0        -0.387     0.704\n\n\n26.2.5 Filtering\nacross() is a great match for summarize() and mutate() but it’s more awkward to use with filter(), because you usually combine multiple conditions with either | or &. It’s clear that across() can help to create multiple logical columns, but then what? So dplyr provides two variants of across() called if_any() and if_all():\n\n# same as df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |&gt; filter(if_any(a:d, is.na))\n#&gt; # A tibble: 4 × 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980 NA     1.15 \n#&gt; 4  1.11  NA     -0.387 0.704\n\n# same as df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |&gt; filter(if_all(a:d, is.na))\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\n26.2.6 across() in functions\nacross() is particularly useful to program with because it allows you to operate on multiple columns. For example, Jacob Scott uses this little helper which wraps a bunch of lubridate functions to expand all date columns into year, month, and day columns:\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n#&gt; # A tibble: 2 × 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nacross() also makes it easy to supply multiple columns in a single argument because the first argument uses tidy-select; you just need to remember to embrace that argument, as we discussed in Seção 25.3.2. For example, this function will compute the means of numeric columns by default. But by supplying the second argument you can choose to summarize just selected columns:\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n#&gt; # A tibble: 5 × 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n#&gt; # A tibble: 5 × 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\n\n26.2.7 Vs pivot_longer()\n\nBefore we go on, it’s worth pointing out an interesting connection between across() and pivot_longer() (Seção 5.3). In many cases, you perform the same calculations by first pivoting the data and then performing the operations by group rather than by column. For example, take this multi-function summary:\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\nWe could compute the same values by pivoting longer and then summarizing:\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n#&gt; # A tibble: 4 × 3\n#&gt;   name   median   mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 a      0.0380 0.205 \n#&gt; 2 b     -0.0163 0.0910\n#&gt; 3 c      0.260  0.0716\n#&gt; 4 d      0.540  0.508\n\nAnd if you wanted the same structure as across() you could pivot again:\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\nThis is a useful technique to know about because sometimes you’ll hit a problem that’s not currently possible to solve with across(): when you have groups of columns that you want to compute with simultaneously. For example, imagine that our data frame contains both values and weights and we want to compute a weighted mean:\n\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\nThere’s currently no way to do this with across()4, but it’s relatively straightforward with pivot_longer():\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n#&gt; # A tibble: 40 × 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a      0.715 0.518\n#&gt; 2 b     -0.709 0.691\n#&gt; 3 c      0.718 0.216\n#&gt; 4 d     -0.217 0.733\n#&gt; 5 a     -1.09  0.979\n#&gt; 6 b     -0.209 0.675\n#&gt; # ℹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n#&gt; # A tibble: 4 × 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a      0.126 \n#&gt; 2 b     -0.0704\n#&gt; 3 c     -0.360 \n#&gt; 4 d     -0.248\n\nIf needed, you could pivot_wider() this back to the original form.\n\n26.2.8 Exercises\n\n\nPractice your across() skills by:\n\nComputing the number of unique values in each column of palmerpenguins::penguins.\nComputing the mean of every column in mtcars.\nGrouping diamonds by cut, clarity, and color then counting the number of observations and computing the mean of each numeric column.\n\n\nWhat happens if you use a list of functions in across(), but don’t name them? How is the output named?\nAdjust expand_dates() to automatically remove the date columns after they’ve been expanded. Do you need to embrace any arguments?\n\nExplain what each step of the pipeline in this function does. What special feature of where() are we taking advantage of?\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#reading-multiple-files",
    "href": "iteration.html#reading-multiple-files",
    "title": "26  Iteration",
    "section": "\n26.3 Reading multiple files",
    "text": "26.3 Reading multiple files\nIn the previous section, you learned how to use dplyr::across() to repeat a transformation on multiple columns. In this section, you’ll learn how to use purrr::map() to do something to every file in a directory. Let’s start with a little motivation: imagine you have a directory full of excel spreadsheets5 you want to read. You could do it with copy and paste:\n\ndata2019 &lt;- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 &lt;- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 &lt;- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 &lt;- readxl::read_excel(\"data/y2022.xlsx\")\n\nAnd then use dplyr::bind_rows() to combine them all together:\n\ndata &lt;- bind_rows(data2019, data2020, data2021, data2022)\n\nYou can imagine that this would get tedious quickly, especially if you had hundreds of files, not just four. The following sections show you how to automate this sort of task. There are three basic steps: use list.files() to list all the files in a directory, then use purrr::map() to read each of them into a list, then use purrr::list_rbind() to combine them into a single data frame. We’ll then discuss how you can handle situations of increasing heterogeneity, where you can’t do exactly the same thing to every file.\n\n26.3.1 Listing files in a directory\nAs the name suggests, list.files() lists the files in a directory. You’ll almost always use three arguments:\n\nThe first argument, path, is the directory to look in.\npattern is a regular expression used to filter the file names. The most common pattern is something like [.]xlsx$ or [.]csv$ to find all files with a specified extension.\nfull.names determines whether or not the directory name should be included in the output. You almost always want this to be TRUE.\n\nTo make our motivating example concrete, this book contains a folder with 12 excel spreadsheets containing data from the gapminder package. Each file contains one year’s worth of data for 142 countries. We can list them all with the appropriate call to list.files():\n\npaths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n\n26.3.2 Lists\nNow that we have these 12 paths, we could call read_excel() 12 times to get 12 data frames:\n\ngapminder_1952 &lt;- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 &lt;- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 &lt;- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n ...,\ngapminder_2007 &lt;- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n\nBut putting each sheet into its own variable is going to make it hard to work with them a few steps down the road. Instead, they’ll be easier to work with if we put them into a single object. A list is the perfect tool for this job:\n\nfiles &lt;- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nNow that you have these data frames in a list, how do you get one out? You can use files[[i]] to extract the ith element:\n\nfiles[[3]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\nWe’ll come back to [[ in more detail in Seção 27.3.\n\n26.3.3 purrr::map() and list_rbind()\n\nThe code to collect those data frames in a list “by hand” is basically just as tedious to type as code that reads the files one-by-one. Happily, we can use purrr::map() to make even better use of our paths vector. map() is similar toacross(), but instead of doing something to each column in a data frame, it does something to each element of a vector.map(x, f) is shorthand for:\n\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n\nSo we can use map() to get a list of 12 data frames:\n\nfiles &lt;- map(paths, readxl::read_excel)\nlength(files)\n#&gt; [1] 12\n\nfiles[[1]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 136 more rows\n\n(This is another data structure that doesn’t display particularly compactly with str() so you might want to load it into RStudio and inspect it with View()).\nNow we can use purrr::list_rbind() to combine that list of data frames into a single data frame:\n\nlist_rbind(files)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\nOr we could do both steps at once in a pipeline:\n\npaths |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind()\n\nWhat if we want to pass in extra arguments to read_excel()? We use the same technique that we used with across(). For example, it’s often useful to peak at the first few rows of the data with n_max = 1:\n\npaths |&gt; \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n  list_rbind()\n#&gt; # A tibble: 12 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Afghanistan Asia         30.3  9240934      821.\n#&gt; 3 Afghanistan Asia         32.0 10267083      853.\n#&gt; 4 Afghanistan Asia         34.0 11537966      836.\n#&gt; 5 Afghanistan Asia         36.1 13079460      740.\n#&gt; 6 Afghanistan Asia         38.4 14880372      786.\n#&gt; # ℹ 6 more rows\n\nThis makes it clear that something is missing: there’s no year column because that value is recorded in the path, not in the individual files. We’ll tackle that problem next.\n\n26.3.4 Data in the path\nSometimes the name of the file is data itself. In this example, the file name contains the year, which is not otherwise recorded in the individual files. To get that column into the final data frame, we need to do two things:\nFirst, we name the vector of paths. The easiest way to do this is with the set_names() function, which can take a function. Here we use basename() to extract just the file name from the full path:\n\npaths |&gt; set_names(basename) \n#&gt;                  1952.xlsx                  1957.xlsx \n#&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#&gt;                  1962.xlsx                  1967.xlsx \n#&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#&gt;                  1972.xlsx                  1977.xlsx \n#&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#&gt;                  1982.xlsx                  1987.xlsx \n#&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#&gt;                  1992.xlsx                  1997.xlsx \n#&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#&gt;                  2002.xlsx                  2007.xlsx \n#&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\nThose names are automatically carried along by all the map functions, so the list of data frames will have those same names:\n\nfiles &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel)\n\nThat makes this call to map() shorthand for:\n\nfiles &lt;- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nYou can also use [[ to extract elements by name:\n\nfiles[[\"1962.xlsx\"]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\nThen we use the names_to argument to list_rbind() to tell it to save the names into a new column called year then use readr::parse_number() to extract the number from the string.\n\npaths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n#&gt; # A tibble: 1,704 × 6\n#&gt;    year country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n#&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n#&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\nIn more complicated cases, there might be other variables stored in the directory name, or maybe the file name contains multiple bits of data. In that case, use set_names() (without any arguments) to record the full path, and then use tidyr::separate_wider_delim() and friends to turn them into useful columns.\n\npaths |&gt; \n  set_names() |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#&gt; # A tibble: 1,704 × 8\n#&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n\n26.3.5 Save your work\nNow that you’ve done all this hard work to get to a nice tidy data frame, it’s a great time to save your work:\n\ngapminder &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n\nNow when you come back to this problem in the future, you can read in a single csv file. For large and richer datasets, using parquet might be a better choice than .csv, as discussed in Seção 22.4.\nIf you’re working in a project, we suggest calling the file that does this sort of data prep work something like 0-cleanup.R. The 0 in the file name suggests that this should be run before anything else.\nIf your input data files change over time, you might consider learning a tool like targets to set up your data cleaning code to automatically re-run whenever one of the input files is modified.\n\n26.3.6 Many simple iterations\nHere we’ve just loaded the data directly from disk, and were lucky enough to get a tidy dataset. In most cases, you’ll need to do some additional tidying, and you have two basic options: you can do one round of iteration with a complex function, or do multiple rounds of iteration with simple functions. In our experience most folks reach first for one complex iteration, but you’re often better by doing multiple simple iterations.\nFor example, imagine that you want to read in a bunch of files, filter out missing values, pivot, and then combine. One way to approach the problem is to write a function that takes a file and does all those steps then call map() once:\n\nprocess_file &lt;- function(path) {\n  df &lt;- read_csv(path)\n  \n  df |&gt; \n    filter(!is.na(id)) |&gt; \n    mutate(id = tolower(id)) |&gt; \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |&gt; \n  map(process_file) |&gt; \n  list_rbind()\n\nAlternatively, you could perform each step of process_file() to every file:\n\npaths |&gt; \n  map(read_csv) |&gt; \n  map(\\(df) df |&gt; filter(!is.na(id))) |&gt; \n  map(\\(df) df |&gt; mutate(id = tolower(id))) |&gt; \n  map(\\(df) df |&gt; pivot_longer(jan:dec, names_to = \"month\")) |&gt; \n  list_rbind()\n\nWe recommend this approach because it stops you getting fixated on getting the first file right before moving on to the rest. By considering all of the data when doing tidying and cleaning, you’re more likely to think holistically and end up with a higher quality result.\nIn this particular example, there’s another optimization you could make, by binding all the data frames together earlier. Then you can rely on regular dplyr behavior:\n\npaths |&gt; \n  map(read_csv) |&gt; \n  list_rbind() |&gt; \n  filter(!is.na(id)) |&gt; \n  mutate(id = tolower(id)) |&gt; \n  pivot_longer(jan:dec, names_to = \"month\")\n\n\n26.3.7 Heterogeneous data\nUnfortunately, sometimes it’s not possible to go from map() straight to list_rbind() because the data frames are so heterogeneous that list_rbind() either fails or yields a data frame that’s not very useful. In that case, it’s still useful to start by loading all of the files:\n\nfiles &lt;- paths |&gt; \n  map(readxl::read_excel) \n\nThen a very useful strategy is to capture the structure of the data frames so that you can explore it using your data science skills. One way to do so is with this handy df_types function6 that returns a tibble with one row for each column:\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#&gt; # A tibble: 6 × 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\nYou can then apply this function to all of the files, and maybe do some pivoting to make it easier to see where the differences are. For example, this makes it easy to verify that the gapminder spreadsheets that we’ve been working with are all quite homogeneous:\n\nfiles |&gt; \n  map(df_types) |&gt; \n  list_rbind(names_to = \"file_name\") |&gt; \n  select(-n_miss) |&gt; \n  pivot_wider(names_from = col_name, values_from = col_type)\n#&gt; # A tibble: 12 × 6\n#&gt;   file_name country   continent lifeExp pop    gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1 1952.xlsx character character double  double double   \n#&gt; 2 1957.xlsx character character double  double double   \n#&gt; 3 1962.xlsx character character double  double double   \n#&gt; 4 1967.xlsx character character double  double double   \n#&gt; 5 1972.xlsx character character double  double double   \n#&gt; 6 1977.xlsx character character double  double double   \n#&gt; # ℹ 6 more rows\n\nIf the files have heterogeneous formats, you might need to do more processing before you can successfully merge them. Unfortunately, we’re now going to leave you to figure that out on your own, but you might want to read about map_if() and map_at(). map_if() allows you to selectively modify elements of a list based on their values; map_at() allows you to selectively modify elements based on their names.\n\n26.3.8 Handling failures\nSometimes the structure of your data might be sufficiently wild that you can’t even read all the files with a single command. And then you’ll encounter one of the downsides of map(): it succeeds or fails as a whole. map() will either successfully read all of the files in a directory or fail with an error, reading zero files. This is annoying: why does one failure prevent you from accessing all the other successes?\nLuckily, purrr comes with a helper to tackle this problem: possibly(). possibly() is what’s known as a function operator: it takes a function and returns a function with modified behavior. In particular, possibly() changes a function from erroring to returning a value that you specify:\n\nfiles &lt;- paths |&gt; \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata &lt;- files |&gt; list_rbind()\n\nThis works particularly well here because list_rbind(), like many tidyverse functions, automatically ignores NULLs.\nNow you have all the data that can be read easily, and it’s time to tackle the hard part of figuring out why some files failed to load and what to do about it. Start by getting the paths that failed:\n\nfailed &lt;- map_vec(files, is.null)\npaths[failed]\n#&gt; character(0)\n\nThen call the import function again for each failure and figure out what went wrong.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#saving-multiple-outputs",
    "href": "iteration.html#saving-multiple-outputs",
    "title": "26  Iteration",
    "section": "\n26.4 Saving multiple outputs",
    "text": "26.4 Saving multiple outputs\nIn the last section, you learned about map(), which is useful for reading multiple files into a single object. In this section, we’ll now explore sort of the opposite problem: how can you take one or more R objects and save it to one or more files? We’ll explore this challenge using three examples:\n\nSaving multiple data frames into one database.\nSaving multiple data frames into multiple .csv files.\nSaving multiple plots to multiple .png files.\n\n\n26.4.1 Writing to a database\nSometimes when working with many files at once, it’s not possible to fit all your data into memory at once, and you can’t do map(files, read_csv). One approach to deal with this problem is to load your data into a database so you can access just the bits you need with dbplyr.\nIf you’re lucky, the database package you’re using will provide a handy function that takes a vector of paths and loads them all into the database. This is the case with duckdb’s duckdb_read_csv():\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\nThis would work well here, but we don’t have csv files, instead we have excel spreadsheets. So we’re going to have to do it “by hand”. Learning to do it by hand will also help you when you have a bunch of csvs and the database that you’re working with doesn’t have one function that will load them all in.\nWe need to start by creating a table that will fill in with data. The easiest way to do this is by creating a template, a dummy data frame that contains all the columns we want, but only a sampling of the data. For the gapminder data, we can make that template by reading a single file and adding the year to it:\n\ntemplate &lt;- readxl::read_excel(paths[[1]])\ntemplate$year &lt;- 1952\ntemplate\n#&gt; # A tibble: 142 × 6\n#&gt;   country     continent lifeExp      pop gdpPercap  year\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n#&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n#&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n#&gt; # ℹ 136 more rows\n\nNow we can connect to the database, and use DBI::dbCreateTable() to turn our template into a database table:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n\ndbCreateTable() doesn’t use the data in template, just the variable names and types. So if we inspect the gapminder table now you’ll see that it’s empty but it has the variables we need with the types we expect:\n\ncon |&gt; tbl(\"gapminder\")\n#&gt; # Source:   table&lt;gapminder&gt; [0 x 6]\n#&gt; # Database: DuckDB v0.10.0 [root@Darwin 21.6.0:R 4.3.3/:memory:]\n#&gt; # ℹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n#&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\nNext, we need a function that takes a single file path, reads it into R, and adds the result to the gapminder table. We can do that by combining read_excel() with DBI::dbAppendTable():\n\nappend_file &lt;- function(path) {\n  df &lt;- readxl::read_excel(path)\n  df$year &lt;- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n\nNow we need to call append_file() once for each element of paths. That’s certainly possible with map():\n\npaths |&gt; map(append_file)\n\nBut we don’t care about the output of append_file(), so instead of map() it’s slightly nicer to use walk(). walk() does exactly the same thing as map() but throws the output away:\n\npaths |&gt; walk(append_file)\n\nNow we can see if we have all the data in our table:\n\ncon |&gt; \n  tbl(\"gapminder\") |&gt; \n  count(year)\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v0.10.0 [root@Darwin 21.6.0:R 4.3.3/:memory:]\n#&gt;    year     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1977   142\n#&gt; 2  1987   142\n#&gt; 3  2007   142\n#&gt; 4  1962   142\n#&gt; 5  1982   142\n#&gt; 6  1967   142\n#&gt; # ℹ more rows\n\n\n26.4.2 Writing csv files\nThe same basic principle applies if we want to write multiple csv files, one for each group. Let’s imagine that we want to take the ggplot2::diamonds data and save one csv file for each clarity. First we need to make those individual datasets. There are many ways you could do that, but there’s one way we particularly like: group_nest().\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n#&gt; # A tibble: 8 × 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 × 9]\n#&gt; 2 SI2            [9,194 × 9]\n#&gt; 3 SI1           [13,065 × 9]\n#&gt; 4 VS2           [12,258 × 9]\n#&gt; 5 VS1            [8,171 × 9]\n#&gt; 6 VVS2           [5,066 × 9]\n#&gt; # ℹ 2 more rows\n\nThis gives us a new tibble with eight rows and two columns. clarity is our grouping variable and data is a list-column containing one tibble for each unique value of clarity:\n\nby_clarity$data[[1]]\n#&gt; # A tibble: 741 × 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # ℹ 735 more rows\n\nWhile we’re here, let’s create a column that gives the name of output file, using mutate() and str_glue():\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 × 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#&gt; # ℹ 2 more rows\n\nSo if we were going to save these data frames by hand, we might write something like:\n\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n\nThis is a little different to our previous uses of map() because there are two arguments that are changing, not just one. That means we need a new function: map2(), which varies both the first and second arguments. And because we again don’t care about the output, we want walk2() rather than map2(). That gives us:\n\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n\n\n26.4.3 Saving plots\nWe can take the same basic approach to create many plots. Let’s first make a function that draws the plot we want:\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\n\n\n\nNow we can use map() to create a list of many plots7 and their eventual file paths:\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\nThen use walk2() with ggsave() to save each plot:\n\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n\nThis is shorthand for:\n\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#summary",
    "href": "iteration.html#summary",
    "title": "26  Iteration",
    "section": "\n26.5 Summary",
    "text": "26.5 Summary\nIn this chapter, you’ve seen how to use explicit iteration to solve three problems that come up frequently when doing data science: manipulating multiple columns, reading multiple files, and saving multiple outputs. But in general, iteration is a super power: if you know the right iteration technique, you can easily go from fixing one problem to fixing all the problems. Once you’ve mastered the techniques in this chapter, we highly recommend learning more by reading the Functionals chapter of Advanced R and consulting the purrr website.\nIf you know much about iteration in other languages, you might be surprised that we didn’t discuss the for loop. That’s because R’s orientation towards data analysis changes how we iterate: in most cases you can rely on an existing idiom to do something to each columns or each group. And when you can’t, you can often use a functional programming tool like map() that does something to each element of a list. However, you will see for loops in wild-caught code, so you’ll learn about them in the next chapter where we’ll discuss some important base R tools.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "iteration.html#footnotes",
    "href": "iteration.html#footnotes",
    "title": "26  Iteration",
    "section": "",
    "text": "Anonymous, because we never explicitly gave it a name with &lt;-. Another term programmers use for this is “lambda function”.↩︎\nIn older code you might see syntax that looks like ~ .x + 1. This is another way to write anonymous functions but it only works inside tidyverse functions and always uses the variable name .x. We now recommend the base syntax, \\(x) x + 1.↩︎\nYou can’t currently change the order of the columns, but you could reorder them after the fact using relocate() or similar.↩︎\nMaybe there will be one day, but currently we don’t see how.↩︎\nIf you instead had a directory of csv files with the same format, you can use the technique from Seção 7.4.↩︎\nWe’re not going to explain how it works, but if you look at the docs for the functions used, you should be able to puzzle it out.↩︎\nYou can print by_clarity$plot to get a crude animation — you’ll get one plot for each element of plots. NOTE: this didn’t happen for me.↩︎",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "base-R.html",
    "href": "base-R.html",
    "title": "27  ✅ Um guia para o R base",
    "section": "",
    "text": "27.1 Introdução\nPara finalizar a seção de programação, faremos uma passagem rápida pelas funções mais importantes do R base que não discutimos de outra forma no livro. Essas ferramentas são particularmente úteis à medida que você programa mais e ajudarão a ler código R que encontrará por aí.\nEste é um bom lugar para lembrar que o tidyverse não é a única maneira de resolver problemas de ciência de dados. Ensinamos o tidyverse neste livro porque os pacotes tidyverse compartilham uma filosofia de design comum, aumentando a consistência entre funções e tornando cada nova função ou pacote um pouco mais fácil de aprender e usar. Não é possível usar o tidyverse sem usar o R base, então na verdade já ensinamos a você muitas funções do R base: de library() para carregar pacotes, até sum() e mean () para sumarizações numéricas, e até fatores, data e POSIXct e, claro, todos os operadores básicos como +, -, /, *, |, &, e !. O que não focamos até agora são os fluxos de trabalho do R base, por isso destacaremos alguns deles neste capítulo.\nDepois de ler este livro, você aprenderá outras abordagens para os mesmos problemas usando o R base, data.table e outros pacotes. Sem dúvida, você encontrará essas outras abordagens quando começar a ler o código R escrito por outras pessoas, principalmente se estiver usando o StackOverflow. É 100% correto escrever código que use uma combinação de abordagens. Não deixe ninguém lhe dizer o contrário!\nNeste capítulo, vamos nos concentrar em quatro grandes tópicos: subconjuntos com [, subconjuntos com [[ e $, a família de funções apply e laços (loops) for. Para finalizar, discutiremos brevemente duas funções essenciais para criação de gráficos.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#introdução",
    "href": "base-R.html#introdução",
    "title": "27  ✅ Um guia para o R base",
    "section": "",
    "text": "27.1.1 Pré-requisitos\nEste capítulo se concentra no R base, portanto não possui nenhum pré-requisito real, mas carregaremos o tidyverse para explicar algumas das diferenças e o pacote dados para o conjunto de dados diamante.\n\nlibrary(tidyverse)\nlibrary(dados)",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-many",
    "href": "base-R.html#sec-subset-many",
    "title": "27  ✅ Um guia para o R base",
    "section": "\n27.2 Selecionando múltiplos elementos com [\n",
    "text": "27.2 Selecionando múltiplos elementos com [\n\n[ é usado para extrair subcomponentes de vetores e data frames e é usado como x[i] ou x[i, j]. Nesta seção, apresentaremos o poder de [, primeiro mostrando como você pode usá-lo com vetores e, em seguida, como os mesmos princípios se estendem de maneira direta a estruturas bidimensionais (2d), como data frames. Em seguida, ajudaremos você a consolidar esse conhecimento, mostrando como vários verbos do pacote dplyr são casos especiais de [.\n\n27.2.1 Subconjuntos de vetores\nExistem cinco tipos principais de coisas com as quais você pode criar subconjuntos de um vetor, ou seja, que podem ser o i em x[i]:\n\n\nUm vetor de inteiros positivos. Extrair um subconjunto com inteiros positivos obtém os elementos dessas posições:\n\nx &lt;- c(\"um\", \"dois\", \"tres\", \"quatro\", \"cinco\")\nx[c(3, 2, 5)]\n#&gt; [1] \"tres\"  \"dois\"  \"cinco\"\n\nAo repetir uma posição, você pode realmente produzir uma saída mais longa do que a entrada, tornando o termo “subconjunto” um pouco impróprio.\n\nx[c(1, 1, 5, 5, 5, 2)]\n#&gt; [1] \"um\"    \"um\"    \"cinco\" \"cinco\" \"cinco\" \"dois\"\n\n\n\nUm vetor de inteiros negativos. Valores negativos descartam os elementos nas posições especificadas:\n\nx[c(-1, -3, -5)]\n#&gt; [1] \"dois\"   \"quatro\"\n\n\n\nUm vetor lógico. Extrair usando um vetor lógico obtém todos os valores correspondentes a um valor verdadeiro TRUE. Isto é mais útil em conjunto com funções de comparação.\n\nx &lt;- c(10, 3, NA, 5, 8, 1, NA)\n\n# Todos os valores não faltantes de x\nx[!is.na(x)]\n#&gt; [1] 10  3  5  8  1\n\n# Todos os valores pares (ou ausentes!) de x\nx[x %% 2 == 0]\n#&gt; [1] 10 NA  8 NA\n\nAo contrário de filter(), os índices NA serão incluídos na saída como NAs.\n\n\nUm vetor de caracteres. Se você tiver um vetor nomeado, poderá extrair um subconjunto com um vetor de caracteres:\n\nx &lt;- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#&gt; xyz def \n#&gt;   5   2\n\nTal como acontece com o subconjunto com números inteiros positivos, você pode usar um vetor de caracteres para duplicar entradas individuais.\n\nVazio. O tipo final de subconjunto é vazio (nothing), x[], que retorna o x completo. Isso não é útil para subconjuntos de vetores, mas como veremos em breve, é útil para subconjuntos de estruturas 2d como tibbles.\n\n27.2.2 Subconjuntos de data frames\n\nExistem algumas maneiras diferentes[^base-r-1] de usar [ com uma tabela de dados, mas a maneira mais importante é selecionar linhas e colunas independentemente com df[linhas, colunas]. Aqui linhas e colunas são vetores conforme descrito acima. Por exemplo, df[linhas, ] e df[, colunas] selecionam apenas linhas ou apenas colunas, usando o subconjunto vazio para preservar a outra dimensão.\nLeia https://adv-r.hadley.nz/subsetting.html#subset-multiple para ver como você também pode criar subconjuntos de um data frame como se fosse um objeto 1d e como você pode subdefini-lo com uma matriz\nAqui estão alguns exemplos:\n\ndf &lt;- tibble(\n  x = 1:3, \n  y = c(\"a\", \"e\", \"f\"), \n  z = runif(3)\n)\n\n# Seleciona a primeira linha e a segunda coluna\ndf[1, 2]\n#&gt; # A tibble: 1 × 1\n#&gt;   y    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a\n\n# Selecione todas as linhas das colunas x e y\ndf[, c(\"x\" , \"y\")]\n#&gt; # A tibble: 3 × 2\n#&gt;       x y    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 a    \n#&gt; 2     2 e    \n#&gt; 3     3 f\n\n# Selecione linhas em que `x` é maior que 1 e todas as colunas\ndf[df$x &gt; 1, ]\n#&gt; # A tibble: 2 × 3\n#&gt;       x y         z\n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2 e     0.834\n#&gt; 2     3 f     0.601\n\nVoltaremos a $ em breve, mas você deve ser capaz de adivinhar o que df$x faz a partir do contexto: ele extrai a variável x de df. Precisamos usá-lo aqui porque [ não usa avaliação tidy, então você precisa ser explícito sobre a origem da variável x.\nHá uma diferença importante entre tibbles e data frames quando se trata de [. Neste livro, usamos principalmente tibbles, que são tabelas de dados, mas eles ajustam alguns comportamentos para tornar sua vida um pouco mais fácil. Na maioria dos lugares, você pode usar “tibble” e “data frame” de forma intercambiável, então quando quisermos chamar atenção especial para o data frame integrado do R base, escreveremos data.frame. Se df for um data.frame, então df[, colunas] retornará um vetor se colunas selecionar uma única coluna e um data frame se selecionar mais de uma coluna. Se df for um tibble, então [ sempre retornará um tibble.\n\ndf1 &lt;- data.frame(x = 1:3)\ndf1[, \"x\"]\n#&gt; [1] 1 2 3\n\ndf2 &lt;- tibble(x = 1:3)\ndf2[, \"x\"]\n#&gt; # A tibble: 3 × 1\n#&gt;       x\n#&gt;   &lt;int&gt;\n#&gt; 1     1\n#&gt; 2     2\n#&gt; 3     3\n\nUma maneira de evitar essa ambiguidade com data.frames é especificar explicitamente drop = FALSE:\n\ndf1[, \"x\" , drop = FALSE]\n#&gt;   x\n#&gt; 1 1\n#&gt; 2 2\n#&gt; 3 3\n\n\n27.2.3 Equivalências do dplyr\nVários verbos dplyr são casos especiais de [:\n\n\nfilter() é equivalente a fazer um subconjunto das linhas com um vetor lógico, tomando cuidado para excluir valores ausentes:\n\ndf &lt;- tibble(\n  x = c(2, 3, 1, 1, NA), \n  y = letters[1:5], \n  z = runif(5)\n)\ndf |&gt; filter(x &gt; 1)\n\n# o mesmo que\ndf[!is.na(df$x) & df$x &gt; 1, ]\n\nOutra técnica comum é usar which() por seu efeito colateral de eliminar valores ausentes: df[which(df$x &gt; 1), ].\n\n\narrange() é equivalente a fazer um subconjunto das linhas com um vetor inteiro, geralmente criado com order():\n\ndf |&gt; arrange(x, y)\n\n# o mesmo que\ndf[order(df$x, df$y), ]\n\nVocê pode usar order(decreasing = TRUE) para classificar todas as colunas em ordem decrescente ou -rank(col) para classificar colunas em ordem decrescente individualmente.\n\n\nAmbos select() e relocate() são semelhantes a fazer subconjuntos das colunas com um vetor de caracteres:\n\ndf |&gt; select(x, z)\n\n# o mesmo que\ndf[, c(\"x\", \"z\")]\n\n\n\nO R base também fornece uma função que combina as características de filter() e select()1 chamada subset():\n\ndf |&gt; \n  filter(x &gt; 1) |&gt; \n  select(y, z)\n#&gt; # A tibble: 2 × 2\n#&gt;   y           z\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a     0.157  \n#&gt; 2 b     0.00740\n\n\n# o mesmo que\ndf |&gt; subset(x &gt; 1, c(y, z))\n\nEsta função foi a inspiração para grande parte da sintaxe do dplyr.\n\n27.2.4 Exercícios\n\n\nCrie funções que recebam um vetor como entrada e retornem:\n\nOs elementos em posições pares.\nCada elemento, exceto o último valor.\nSomente valores pares (e nenhum valor ausente).\n\n\nPor que x[-which(x &gt; 0)] não é o mesmo que x[x &lt;= 0]? Leia a documentação de which() e faça alguns experimentos para descobrir..",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#sec-subset-one",
    "href": "base-R.html#sec-subset-one",
    "title": "27  ✅ Um guia para o R base",
    "section": "\n27.3 Selecionando um único elemento com $ e [[\n",
    "text": "27.3 Selecionando um único elemento com $ e [[\n\n[, que seleciona muitos elementos, é similar a [[ e $, que extraem um único elemento. Nesta seção, mostraremos como usar [[ e $ para extrair colunas de data frames, discutiremos mais algumas diferenças entre data.frames e tibbles e enfatizaremos algumas diferenças importantes entre [ e [[ quando usado com listas.\n\n27.3.1 Data frames\n[[ e $ podem ser usados ​​para extrair colunas de um data frame. [[ pode acessar por posição ou por nome, e $ é especializado para acesso por nome:\n\ntb &lt;- tibble(\n  x = 1:4,\n  y = c(10, 4, 1, 21)\n)\n\n# por posição\ntb[[1]]\n#&gt; [1] 1 2 3 4\n\n# por nome\ntb[[\"x\"]]\n#&gt; [1] 1 2 3 4\ntb$x\n#&gt; [1] 1 2 3 4\n\nEles também podem ser usados ​​para criar novas colunas, o equivalente em R base a mutate():\n\ntb$z &lt;- tb$x + tb$y\ntb\n#&gt; # A tibble: 4 × 3\n#&gt;       x     y     z\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1    10    11\n#&gt; 2     2     4     6\n#&gt; 3     3     1     4\n#&gt; 4     4    21    25\n\nExistem várias outras abordagens do R base para criar novas colunas, incluindo transform(), with() e within(). Hadley coletou alguns exemplos em https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf.\nUsar $ diretamente é conveniente ao realizar resumos rápidos. Por exemplo, se você deseja apenas encontrar o tamanho do maior diamante ou os possíveis valores de corte, não há necessidade de usar summarize():\n\nmax(diamante$quilate)\n#&gt; [1] 5.01\n\nlevels(diamante$corte)\n#&gt; [1] \"Justo\"     \"Bom\"       \"Muito Bom\" \"Premium\"   \"Ideal\"\n\ndplyr também fornece um equivalente a [[/$ que não mencionamos no Capítulo 3: pull(). pull() pega um nome de variável ou uma posição de variável e retorna apenas a coluna correspondente. Isso significa que poderíamos reescrever o código acima para usar o pipe:\n\ndiamante |&gt; pull(quilate) |&gt; max()\n#&gt; [1] 5.01\n\ndiamante |&gt; pull(corte) |&gt; levels()\n#&gt; [1] \"Justo\"     \"Bom\"       \"Muito Bom\" \"Premium\"   \"Ideal\"\n\n\n27.3.2 Tibbles\nExistem algumas diferenças importantes entre tibbles e data.frames quando se trata de $. Os *data frames acessam o prefixo de qualquer nome de variável (chamado de correspondência parcial** ou partial matching) e reclamam se uma coluna não existir:\n\ndf &lt;- data.frame(x1 = 1)\ndf$x\n#&gt; [1] 1\ndf$z\n#&gt; NULL\n\nTibbles são mais rigorosos: eles apenas retornam os nomes das variáveis exatos ​​e gerarão um aviso se a coluna que você está tentando acessar não existir:\n\ntb &lt;- tibble(x1 = 1)\n\ntb$x\n#&gt; Warning: Unknown or uninitialised column: `x`.\n#&gt; NULL\ntb$z\n#&gt; Warning: Unknown or uninitialised column: `z`.\n#&gt; NULL\n\nPor esta razão, às vezes brincamos que os tibbles são preguiçosos e grosseiros: fazem menos e reclamam mais.\n\n27.3.3 Listas\n[[ e $ também são muito importantes para trabalhar com listas, e é importante entender como eles diferem de [. Vamos ilustrar as diferenças com uma lista chamada l:\n\nl &lt;- list(\n  a = 1:3, \n  b = \"uma string\", \n  c = pi, \n  d = list(-1, -5)\n)\n\n\n\n[ extrai uma sublista. Não importa quantos elementos você extraia, o resultado sempre será uma lista.\n\nstr(l[1:2])\n#&gt; List of 2\n#&gt;  $ a: int [1:3] 1 2 3\n#&gt;  $ b: chr \"uma string\"\n\nstr(l[1])\n#&gt; List of 1\n#&gt;  $ a: int [1:3] 1 2 3\n\nstr(l[4])\n#&gt; List of 1\n#&gt;  $ d:List of 2\n#&gt;   ..$ : num -1\n#&gt;   ..$ : num -5\n\nAssim como acontece com os vetores, você pode extrair um subconjunto com um vetor lógico, inteiro ou de caracteres.\n\n\n[[ e $ extraem um único componente de uma lista. Eles removem um nível de hierarquia da lista.\n\nstr(l[[1]])\n#&gt;  int [1:3] 1 2 3\n\nstr(l[[4]])\n#&gt; List of 2\n#&gt;  $ : num -1\n#&gt;  $ : num -5\n\nstr(l$a)\n#&gt;  int [1:3] 1 2 3\n\n\n\nA diferença entre [ e [[ é particularmente importante para listas porque [[ acessa um elemento da lista enquanto [ retorna uma lista nova e menor. Para te ajudar a lembrar a diferença, dê uma olhada no pimenteiro incomum mostrado na Figura 27.1. Se este pimenteiro for sua lista pimenteiro, então pimenteiro[1] é um pimenteiro contendo um único pacote de pimenta. pimenteiro[2] teria a mesma aparência, mas conteria o segundo pacote. pimenteiro[1:2] seria um pimenteiro contendo dois pacotes de pimenta. pimenteiro[[1]] extrairia o próprio pacote de pimenta.\n\n\n\n\n\n\n\nFigura 27.1: (Esquerda) Um pimenteiro que Hadley encontrou uma vez em seu quarto de hotel. (Meio) pimenteiro[1]. (Direita) pimenteiro[[1]]\n\n\n\n\nEste mesmo princípio se aplica quando você usa 1d [ com um data frame: df[\"x\"] retorna um data frame de uma coluna e df[[\"x\"]] retorna um vetor.\n\n27.3.4 Exercícios\n\nO que acontece quando você usa [[ com um número inteiro positivo maior que o tamanho do vetor? O que acontece quando você cria um subconjunto com um nome que não existe?\nO que seria pimenteiro[[1]][1]? E quanto a pimenteiro[[1]][[1]]?",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#a-família-apply",
    "href": "base-R.html#a-família-apply",
    "title": "27  ✅ Um guia para o R base",
    "section": "\n27.4 A família Apply",
    "text": "27.4 A família Apply\nNo Capítulo 26, você aprendeu técnicas do tidyverse para iteração como dplyr::across() e a família de funções map. Nesta seção, você aprenderá sobre seus equivalentes básicos, a família apply. Neste contexto, apply (aplicar) e map (mapear) são sinônimos porque outra maneira de dizer “mapear uma função sobre cada elemento de um vetor” é “aplicar uma função sobre cada elemento de um vetor”. Aqui lhe daremos uma rápida visão geral desta família de funções para que você possa reconhecê-la por aí.\nO membro mais importante desta família é lapply(), que é muito semelhante a purrr::map()2. Na verdade, como não usamos nenhum dos recursos mais avançados de map(), você pode substituir cada chamada de map() na Capítulo 26 por lapply().\nNão existe no R base um função exatamente equivalente a across(), mas você pode chegar perto usando [ com lapply(). Isso funciona porque, nos bastidores, os data frames são listas de colunas, portanto, chamar lapply() em um data frame aplica a função a cada coluna.\n\ndf &lt;- tibble(a = 1, b = 2, c = \"a\", d = \"b\", e = 4)\n\n# Encontre a primeira coluna numérica\ncoluna_numerica &lt;- sapply(df, is.numeric)\ncoluna_numerica\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\n# Em seguida, transforme cada coluna com lapply() e substitua os valores originais\ndf[, coluna_numerica] &lt;- lapply(df[, coluna_numerica, drop = FALSE], \\(x) x * 2)\ndf\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b c     d         e\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1     2     4 a     b         8\n\nO código acima usa uma nova função, sapply(). É semelhante a lapply() mas sempre tenta simplificar o resultado, daí o s em seu nome, produzindo aqui um vetor lógico em vez de uma lista. Não recomendamos usá-lo para programação, porque a simplificação pode falhar e fornecer um tipo inesperado, mas geralmente é adequado para uso interativo. purrr tem uma função semelhante chamada map_vec() que não mencionamos no Capítulo 26.\nO R base fornece uma versão mais estrita de sapply() chamada vapply(), abreviação de vector apply. É necessário um argumento adicional que especifica o tipo esperado, garantindo que a simplificação ocorra da mesma forma, independentemente da entrada. Por exemplo, poderíamos substituir a chamada sapply() acima por vapply() onde especificamos que esperamos que is.numeric() retorne um vetor lógico de tamanho 1:\n\nvapply(df, is.numeric, logical(1))\n#&gt;     a     b     c     d     e \n#&gt;  TRUE  TRUE FALSE FALSE  TRUE\n\nA distinção entre sapply() e vapply() é muito importante quando eles estão dentro de uma função (porque faz uma grande diferença na robustez da função para entradas incomuns), mas geralmente não importa na análise de dados.\nOutro membro importante da família apply é tapply() que calcula um único resumo agrupado (grouped summary):\n\ndiamante |&gt; \n  group_by(corte) |&gt; \n  summarize(preco = mean(preco))\n#&gt; # A tibble: 5 × 2\n#&gt;   corte     preco\n#&gt;   &lt;ord&gt;     &lt;dbl&gt;\n#&gt; 1 Justo     4359.\n#&gt; 2 Bom       3929.\n#&gt; 3 Muito Bom 3982.\n#&gt; 4 Premium   4584.\n#&gt; 5 Ideal     3458.\n\ntapply(diamante$preco, diamante$corte, mean)\n#&gt;     Justo       Bom Muito Bom   Premium     Ideal \n#&gt;  4358.758  3928.864  3981.760  4584.258  3457.542\n\nInfelizmente tapply() retorna seus resultados em um vetor nomeado que requer alguma ginástica se você quiser coletar múltiplos resumos e agrupar variáveis ​​em um data frame (é certamente possível não fazer isso e apenas trabalhar com vetores livres, mas em nossa experiência isso apenas atrasa o trabalho). Se você quiser ver como pode usar tapply() ou outras técnicas básicas para realizar outros resumos agrupados, Hadley reuniu algumas técnicas neste resumo.\nO membro final da família apply é o titular apply(), que trabalha com matrizes e arrays. Em particular, tome cuidado com apply(df, 2, alguma_coisa), que é uma forma lenta e potencialmente perigosa de fazer lapply(df, alguma_coisa). Isso raramente aparece na ciência de dados porque geralmente trabalhamos com tabelas de dados e não com matrizes.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#loops-for",
    "href": "base-R.html#loops-for",
    "title": "27  ✅ Um guia para o R base",
    "section": "\n27.5 Loops for\n",
    "text": "27.5 Loops for\n\nLoops for são o alicerce fundamental da iteração que as famílias apply e map usam nos bastidores. Os loops for são ferramentas poderosas e gerais que são importantes para aprender à medida que você se torna um programador R mais experiente. A estrutura básica de um loop for é semelhante a esta:\n\nfor (elemento in vetor) {\n  # faça algo com elemento\n}\n\nO uso mais direto dos loops for é obter o mesmo efeito que walk(): chamar alguma função que atuará em cada elemento de uma lista. Por exemplo, na Seção 26.4.1 em vez de usar walk():\n\ncaminhos |&gt; walk(anexar_arquivo)\n\nPoderíamos ter usado um loop for:\n\nfor (caminho in caminhos) {\n  anexar_arquivo(path)\n}\n\nAs coisas ficam um pouco mais complicadas se você quiser salvar a saída do loop for, por exemplo, lendo todos os arquivos Excel em um diretório como fizemos na Capítulo 26:\n\ncaminhos &lt;- dir(\"data/gapminder\", pattern = \"\\\\.xlsx$\", full.names = TRUE)\narquivos &lt;- map(caminhos, readxl::read_excel)\n\nExistem algumas técnicas diferentes que você pode usar, mas recomendamos ser explícito sobre como será o resultado desde o início. Neste caso, vamos querer uma lista do mesmo comprimento que caminhos, que podemos criar com vector():\n\narquivos &lt;- vector(\"list\", length(caminhos))\n\nEntão, em vez de iterar sobre os elementos de caminhos, iremos iterar sobre seus índices, usando seq_along() para gerar um índice para cada elemento de paths:\n\nseq_along(caminhos)\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\nUsar os índices é importante porque nos permite vincular cada posição na entrada com a posição correspondente na saída:\n\nfor (i in seq_along(caminhos)) {\n  arquivos[[i]] &lt;- readxl::read_excel(caminhos[[i]])\n}\n\nPara combinar a lista de tibbles em um único tibble você pode usar do.call() + rbind():\n\ndo.call(rbind, arquivos)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\nEm vez de fazer uma lista e salvar os resultados à medida que avançamos, uma abordagem mais simples é construir o data frame parte por parte:\n\nsaida &lt;- NULL\nfor (caminho in caminhos) {\n  saida &lt;- rbind(saida, readxl::read_excel(caminho))\n}\n\nRecomendamos evitar esse padrão porque ele pode ficar muito lento quando o vetor é muito longo. Esta é a fonte do boato persistente de que os loops for são lentos: eles não são, mas o crescimento iterativo de um vetor é.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#gráficos",
    "href": "base-R.html#gráficos",
    "title": "27  ✅ Um guia para o R base",
    "section": "\n27.6 Gráficos",
    "text": "27.6 Gráficos\nMuitos usuários de R que não usam o tidyverse preferem ggplot2 para criação de gráficos devido a recursos úteis como padrões sensatos, legendas automáticas e uma aparência moderna. No entanto, as funções gráficas do R base ainda podem ser úteis porque são muito concisas – é preciso muito pouca digitação para fazer um gráfico exploratório básico.\nExistem dois tipos principais de gráficos básicos que você verá: gráficos de dispersão e histogramas, produzidos com plot() e hist() respectivamente. Aqui está um exemplo rápido do conjunto de dados diamante do pacote dados:\n# Esquerda\nhist(diamante$quilate)\n\n# Direita\nplot(diamante$quilate, diamante$preco)\n\n\n\n\n\n\n\n\n\n\nObserve que as funções gráficas básicas funcionam com vetores, então você precisa extrair colunas do data frame usando $ ou alguma outra técnica.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#resumo",
    "href": "base-R.html#resumo",
    "title": "27  ✅ Um guia para o R base",
    "section": "\n27.7 Resumo",
    "text": "27.7 Resumo\nNeste capítulo mostramos uma seleção de funções do R base úteis para subconjuntos e iterações. Em comparação com as abordagens discutidas em outras partes do livro, essas funções tendem a ter mais um sabor de “vetor” do que de “data frames”, porque as funções do R base tendem a usar vetores individuais, em vez de um data frame e alguma especificação de coluna. Isso geralmente facilita a vida da programação e se torna mais importante à medida que você escreve mais funções e começa a escrever seus próprios pacotes.\nEste capítulo conclui a seção de programação do livro. Você teve um início sólido em sua jornada para se tornar não apenas um cientista de dados que usa R, mas um cientista de dados que pode programar em R. Esperamos que esses capítulos tenham despertado seu interesse em programação e que você esteja com bastante de empolgação para aprender mais fora deste livro.",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "base-R.html#footnotes",
    "href": "base-R.html#footnotes",
    "title": "27  ✅ Um guia para o R base",
    "section": "",
    "text": "Mas ele não lida com data frames agrupados (grouped) de maneira diferenciada e não suporta funções auxiliares de seleção como starts_with().↩︎\nFaltam apenas recursos convenientes, como barras de progresso e relatórios de qual elemento causou o problema se houver um erro.↩︎",
    "crumbs": [
      "✅ Programar",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>✅ Um guia para o R base</span>"
    ]
  },
  {
    "objectID": "communicate.html",
    "href": "communicate.html",
    "title": "✅ Comunicar",
    "section": "",
    "text": "Até agora, você aprendeu as ferramentas para importar seus dados no R, organizá-los em uma forma conveniente para análise e, posteriormente, compreendê-los por meio de transformações e visualização. Contudo, não importa o quão boa é sua análise se você não conseguir explicá-la para outras pessoas: você precisa comunicar seus resultados.\n\n\n\n\n\n\n\nFigura 1: Comunicação é a parte final do processo de ciência de dados; se você não conseguir comunicar seus resultados para outros humanos, não importa o quão boa é sua análise.\n\n\n\n\nComunicação é o tema dos dois capítulos seguintes:\n\nNo 28  ✅ Quarto, você irá aprender sobre o Quarto, uma ferramenta para integrar texto, código e resultados. Você pode usar o Quarto tanto para comunicação entre analistas, quanto para comunicação entre analistas e pessoas tomadoras de decisão. Graças ao poder dos formatos do Quarto, você pode até usar o mesmo documento para ambos os propósitos.\nNo 29  ✅ Formatos para Quarto, você irá aprender um pouco sobre as muitas outras variedades de outputs possíveis de serem produzidos usando o Quarto, incluindo dashboards, websites e livros.\n\nEsses capítulos focam principalmente na parte técnica da comunicação, não nos problemas realmente difíceis de comunicar seus pensamentos para outros humanos. Entretanto, há vários outros ótimos livros sobre comunicação, os quais iremos indicar no final de cada capítulo.",
    "crumbs": [
      "✅ Comunicar"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "28  ✅ Quarto",
    "section": "",
    "text": "28.1 Introdução\nO Quarto fornece uma estrutura (framework) unificada para autoria em ciência de dados, combinando seu código, seus resultados e seu texto. Documentos Quarto são plenamente reprodutíveis e suportam muitos formatos de saída como PDF, arquivos Word, apresentações e mais.\nArquivos Quarto foram projetados para serem usados de três maneiras:\nQuarto é uma feerramenta de linha de comando, não é um pacote do R. Isso significa que ajuda, via de regra, não está disponível via ?. Em vez disso, enquanto você trabalhar neste capítulo e usar o Quarto no futuro, você deve procurar a documentação para Quarto.\nSe você for uma pessoa que usa R Markdown, você deve estar pensando “Quarto parece muito com R Markdown”. Isso não está errado! Quarto une a funcionalidade de muitos pacotes do ecosistema do R Markdown (rmarkdown, bookdown, distill, xaringan, etc.) em um sistema único e consistente, mas também extende o ecosistema com apoio nativo para múltiplas linguagens de programação como Python e Julia, além do próprio R. De certa forma, o Quarto reflete tudo que foi aprendido na expansão e no suporte ao ecossistema do R Markdown em uma década.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#introdução",
    "href": "quarto.html#introdução",
    "title": "28  ✅ Quarto",
    "section": "",
    "text": "Para se comunicar com pessoas tomadoras de decisão, que querem focar nas conclusões e não no código por trás da análise.\nPara colaborar com outras pessoas cientistas de dados (incluindo você no futuro!) que estejam interessadas tanto em suas conclusões quanto em como você as alcançou (isto é, o código).\nComo um ambiente em que se faz ciência de dados, como um caderno (notebook) de laboratório moderno em que se pode capturar não apenas o que você fez, como também o que você estava pensando.\n\n\n\n\n28.1.1 Pré-requisitos\nVocê precisa da interface de linha de comando do Quarto (Quarto CLI – command line interface), mas não é necessário instalá-la ou carregá-la explicitamente. Seu RStudio o fará automaticamente quando for necessário.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#básico-de-quarto",
    "href": "quarto.html#básico-de-quarto",
    "title": "28  ✅ Quarto",
    "section": "\n28.2 Básico de Quarto",
    "text": "28.2 Básico de Quarto\nIsso é um arquivo Quarto – um arquivo de texto simples que possui a extensão .qmd:\n\n---\ntitle: \"Tamanhos de diamante\"\ndate: 2022-09-12\nformat: html\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\nlibrary(dados)\n\nmenores &lt;- diamante |&gt; \n  filter(quilate &lt;= 2.5)\n```\n\nTemos dados sobre `r nrow(diamante)` diamantes. \nApenas `r nrow(diamante) - nrow(menores)` são maiores que 2.5 quilates. \nA distribuição dos demais é exibida a seguir:\n\n```{r}\n#| label: grafico-diamantes-menores\n#| echo: false\n\nmenores |&gt; \n  ggplot(aes(x = quilate)) + \n  geom_freqpoly(binwidth = 0.01)\n```\n\nO arquivo contém três tipos importantes de conteúdo:\n\nUm cabeçalho YAML (opcional) envolto por ---.\n\nBlocos (ou chunks) de código R envoltos por ```.\nTexto misturado com formatação simples de texto como # título/subtítulo e _itálico_.\n\nFigura 28.1 mostra um documento .qmd no RStudio com interface de notebook, no qual código e saída são intercalados. Você pode executar cada bloco de código clicando no ícone Executar – Run (triângulo verde que parece com o botão de play no canto superior direito do bloco de código), ou pressionando Cmd/Ctrl + Shift + Enter. O RStudio executará o código e mostrará os resultados juntamente com o código.\n\n\n\n\n\n\n\nFigura 28.1: Um documento Quarto no RStudio. Código e saída intercalados no documento, com a saída do gráfico aparecendo logo abaixo do código.\n\n\n\n\nSe você não gosta de ver seus gráficos e saída dos códigos no documento e prefere usar os painéis do console e gráfico (aba plot), é possível clicar no ícone de engrenagem próximo ao botão “Render” e selecionar “Chunk Output in Console” (ou seja, mostrar resultados do chunk no console), conforme mostrado em Figura 28.2.\n\n\n\n\n\n\n\nFigura 28.2: Um documento Quarto no RStudio com a saída de gráfico no painel Plots.\n\n\n\n\nPara produzir um relatório completo contendo todo o texto, código e resultados, clique em “Render” or pressione Cmd/Ctrl + Shift + K. Você também pode fazer isso programaticamente, em linha de código, com quarto::quarto_render(\"diamond-sizes.qmd\"). Isso exibirá o relatório no painel de visualização, como exibido em Figura 28.3, e criará um arquivo HTML.\n\n\n\n\n\n\n\nFigura 28.3: Um documento Quarto no RStudio com o documento renderizado no painel Viewer.\n\n\n\n\nQuando se gera ou renderiza o documento, Quarto envia o arquivo .qmd para o knitr, https://yihui.org/knitr/, que executa todos os blocos de código e cria um novo arquivo markdown (.md) que inclui o código e seus resultados. O arquivo markdown gerado pelo knitr é então processado pelo pandoc, https://pandoc.org, que é responsável por criar a versão final do arquivo. Esse processo é ilustrado em Figura 28.4. A vantagem desse fluxo de trabalho em duas etapas é que é possível criar uma ampla variedade de formatos de arquivo, como você verá em Capítulo 29.\n\n\n\n\n\n\n\nFigura 28.4: Diagrama do fluxo de trabalho Quarto de qmd a knitr, md, pandoc para saída nos formatos PDF, MS Word ou HTML.\n\n\n\n\nPara iniciar seu próprio arquivo .qmd, selecione File &gt; New File &gt; Quarto Document… na barra de menu. O RStudio abrirá uma janela em que você poderá preencher informações para preencher seu arquivo com conteúdos úteis que lembra como os principais recursos do Quarto funcionam.\nAs seções a seguir aprofundam os três componentes de um documento Quarto em mais detalhes: o texto em markdown, os blocos de código e o cabeçalho YAML.\n\n28.2.1 Exercícios\n\nCrie um novo documento Quarto usando File &gt; New File &gt; Quarto Document. Leia as instruções. Pratique a execução dos blocos de código individualmente. Depois, renderize o documento clicando no botão designado e depois usando o atalho do teclado. Verifique se consegue alterar o código, rodá-lo novamente e ver o novo documento modificado.\nCrie um novo documento Quarto para cada um dos três formatos disponibilizados: HTML, PDF e Word. Renderize cada um dos três documentos. Qual é a diferença entre as saídas (outputs)? Qual é a diferença entre as entradas (inputs)? (É possível que seja necessário instalar o LaTeX para construir o arquivo PDF — O RStudio avisará se isso for necessário.)",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#editor-visual",
    "href": "quarto.html#editor-visual",
    "title": "28  ✅ Quarto",
    "section": "\n28.3 Editor Visual",
    "text": "28.3 Editor Visual\nO editor Visual no RStudio utiliza uma interface WYSIWYM para autoria de documentos Quarto. Por trás das cortinas, os textos em documentos Quarto (arquivos .qmd) são escritos em Markdown, um conjunto leve de convenções para formatação de arquivos de texto simples. Na verdade, o Quarto usa o markdown do Pandoc (uma versão um pouco extendida de Markdown que é interpretável pelo Quarto), incluindo tabelas, citações, referências cruzadas, notas de rodapé, divs/spans, listas de definição, atributos, HTML/TeX crus, entre outros, assim como suporta execução de células de código e a visualização de seus resultados em linha. Enquanto Markdown é desenhado para ser simples de ler e de escrever, como você verá em Seção 28.4, ainda é necessário aprender uma nova sintaxe. Assim, se documentos computacionais como arquivos .qmd são novos para você, mas você tem experiência com Google Docs ou MS Word, o jeito mais fácil de começar a usar Quarto no RStudio é pelo editor visual.\nNo editor visual, você pode tanto usar botões na barra de menu para inserir imagens, tabelas, referências cruzadas, etc. quanto usar o atalho geral ⌘ / para inserir qualquer coisa. Se você estiver no começo de uma linha (como ilustrado em Figura 28.5), você pode apenas digitar / para usar o atalho.\n\n\n\n\n\n\n\nFigura 28.5: Editor visual Quarto.\n\n\n\n\nInserir e personalizar como os conteúdos são exibidos também é mais fácil com o uso do editor visual. Você pode colar uma imagem diretamente da sua área de transferência no editor visual (e o RStudio colocará uma cópia daquela imagem no diretório do projeto e montarará um link para ela) ou usar o menu Insert &gt; Figure / Image do editor visual para navegar até a imagem desejada para inserir ou colar sua URL. Além disso, usando o mesmo menu você pode redimensionar a imagem e adicionar uma legenda, texto alternativo e um link.\nO editor visual tem muito mais recursos que não enumeramos aqui que podem ser úteis a você na medida em que você ganha experiência em escrever com a ferramenta.\nMais importante, enquanto o editor visual exibe o conteúdo do documento com formatação, por trás ele salva o conteúdo em Markdown, permitindo transitar entre o editor visual e de código (source) para visualizar e editar o documento usando qualquer uma das ferramentas.\n\n28.3.1 Exercícios\n\nCrie novamente o documento em Figura 28.5 usando o editor visual.\nUsando o editor visual, insira um bloco de código usando o menu Insert e depois faça o mesmo usando qualquer ferramenta.\nUsando o editor visual, descubra como:\n\nAdicionar uma nota de rodapé.\nAdicionar uma linha horizontal.\nAdicionar um bloco de citação.\n\n\nUsando o editor visual, vá em Insert &gt; Citation e insira a citação para o artigo cujo título é Welcome to the Tidyverse usando o DOI (digital object identifier), que é 10.21105/joss.01686. Renderize o documento e observe como a referência aparece no documento. Que alteração você consegue identificar no YAML do seu documento?",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-source-editor",
    "href": "quarto.html#sec-source-editor",
    "title": "28  ✅ Quarto",
    "section": "\n28.4 Editor Source",
    "text": "28.4 Editor Source\nTambém é possível editar documentos Quarto usando o editor Source no RStudio, sem a assistência do editor visual. Enquanto o editor Visual será familiar para aqueles com experiência em escrita com ferramentas como Google docs, o editor Source será familia para aqueles com experiência escrevendo scripts R ou documentos R Markdown. O editor Source também pode ser útil para procurar erros (debugging) de sintaxe Quarto, já que muitas vezes é mais fácil achar esses erros em texto simples.\nO guia abaixo mostra como usar o Markdown do Pandoc para escrever documentos Quarto em seu editor fonte.\n\n## Formatação de texto\n\n*itálico* **negrito** ~~taxado~~ `código`\n\nsobrescrito^2^ subscrito~2~\n\n[sublinhado]{.sublinhado} [small caps]{.smallcaps}\n\n## Títulos\n\n# Título Nível 1\n\n## Título Nível 2\n\n### Título Nível 3\n\n## Listas\n\n-   Item de lista não enumerada 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n\n1.  Item de lista enumerada 1\n\n2.  Item 2.\n    Os números são incrementados automaticamente na saída.\n\n## Links e imagens\n\n&lt;http://example.com&gt;\n\n[frase com link](http://example.com)\n\n![texto de legenda opcional](quarto.png){fig-alt=\"Logomarca Quarto com a palavra quarto escrita em letras minúsculas\"}\n\n## Tabelas\n\n| Primeiro título    | Segundo título     |\n|--------------------|--------------------|\n| Célula de conteúdo | Célula de conteúdo |\n| Célula de conteúdo | Célula de conteúdo |\n\nA melhor forma de aprender essas coisas é simplesmente tentar. Isso levará alguns dias, mas em pouco tempo se tornam algo automático e não será necessário pensar tanto sobre elas. Se você se esquecer, pode buscar uma boa folha de referência em Help &gt; Markdown Quick Reference.\n\n28.4.1 Exercícios\n\nPratique o que você aprendeu criando um currículo (CV) breve. O título deve ser o seu nome e você deve incluir cabeçalhos para pelo menos sua educação ou trabalho. Cada uma das seções deve incluir uma lista em tópicos de trabalhos/títulos. Destaque o ano em negrito.\n\nUsando o editor source e a referência rápida para Markdown, descubra como:\n\nAdicionar uma nota de rodapé.\nAdicionar uma linha horizontal.\nAdicionar um bloco de citação.\n\n\nCopie e cole o conteúdo de diamond-sizes.qmd a partir de https://github.com/cienciadedatos/pt-r4ds/tree/main/quarto para um arquivo R Quarto local. Verifique se você consegue executá-lo, então adicione texto depois do polígono de frequências que descreve suas características mais chamativas.\nCrie um documento em Google doc ou MS Word (ou use um documento que você tenha criado previamente) que contenha títulos, hiperlinks, texto formatado, etc. Copie os conteúdos desse documento e cole-os em um documento quarto no editor visual. Em seguida, troque para o editor source e inspecione o código fonte.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#blocos-de-código",
    "href": "quarto.html#blocos-de-código",
    "title": "28  ✅ Quarto",
    "section": "\n28.5 Blocos de Código",
    "text": "28.5 Blocos de Código\nPara executar código em um documento Quarto, é necessário incluir um bloco de código. Há três maneiras de fazer isso:\n\nO atalho de teclado Cmd + Option + I / Ctrl + Alt + I.\nO botão “Insert” na barra de ferramentas do editor.\nEscrevendo manualmente os limitadores de bloco ```{r} e ```.\n\nRecomendamos que você aprenda o atalho de teclado. Isso economizará muito tempo no longo prazo!\nÉ possível prosseguir para a execução do código usando o atalho que agora (temos fé!) que você conhece e ama:Cmd/Ctrl + Enter. No entanto, blocos de código recebem um novo atalho: Cmd/Ctrl + Shift + Enter, que executa todo o código no bloco. Pense no bloco de código como uma função. Um bloco de código deve ser relativamente autocontido, focado em realizar uma única tarefa.\nAs seções a seguir descrevem o cabeçalho do bloco de código, que consiste em ```{r}, seguido de um rótulo opcional e diversas outras opções de bloco, cada uma em sua própria linha, marcada por #|.\n\n28.5.1 Rótulo do bloco de código\nBlocos de código podem receber um rótulo opcional, por exemplo\n\n```{r}\n#| label: adicao-simples\n\n1 + 1\n```\n#&gt; [1] 2\n\nHá três vantagens nisso:\n\nÉ possível navegar mais facilmente para blocos de código específicos usando o navegador em lista no canto inferior esquerdo do editor do script:\n\n\n\n\n\n\n\n\n\n\nGráficos produzidos pelos blocos de código terão nomes úteis para reutilizá-los em outros lugares. Mais sobre isso em Seção 28.6.\nÉ possível organizar redes de bloco de código em cache para evitar múltiplas execuções de computações caras em toda execução. Mais sobre isso em Seção 28.8.\n\nOs rótulos dos seus blocos de código devem ser curtos, mas evocativos e não devem conter espaços. Recomendamos o uso de traços (-) para separar palavras (em vez de sublinhados, _) e evitar o uso de outros caracteres especiais nos rótulos de código.\nEm geral, você é livre para rotular o bloco de código como quiser, mas há um bloco cujo nome indica um coportamento especial: setup. Quando você está no modo notebook, o bloco de código com nome setup será executado automaticamente uma vez antes que todo o seu código seja executado.\nAlém disso, rótulos não podem ser duplicados. Cada rótulo de bloco de código deve ser único.\n\n28.5.2 Opções de bloco de código (chunk options)\nSaídas de blocos de código podem ser personalizadas com campos de opções (options) fornecidos para o cabeçalho do bloco. Quase 60 opções para personalização dos seus blocos de código são fornecidas pelo Knitr. Aqui cobriremos as opções mais importantes, que você utilizará com frequência. É possível verificar a lista completa em https://yihui.org/knitr/options.\nO conjunto mais importante de opções controla se seu código será executado e que resultados serão exibidos no relatório final:\n\neval: false previne o código de ser avaliado. (E obviamente, se o código não é executado, nenhum resultado será gerado). Isso é útil para exibir um código de exemplo ou para desabilitar um grande bloco de código sem comentar cada uma de suas linhas.\ninclude: false executa o código, mas não o mostra nem inclui seus resultados no documento final. Use isso para códigos de configurações cujos resultados você não quer que dêem uma aparência de desordem no seu relatório.\necho: false evita o código mas permite a exibição dos resultados no arquivo finalizado. Use isso quando estiver escrevendo relatórios direcionados a pessoas que não querem ver o código por trás dos resultados.\nmessage: false ou warning: false previne o aparecimento de mensagens ou avisos no arquivo final.\nresults: hide esconde os resultados; fig-show: hide esconde gráficos.\nerror: true permite que a renderização do seu documento continue mesmo que ocorra um erro. Você raramente precisará incluir isso na versão final do seu relatório, mas pode ser útil se você precisa corrigir um erro específico dentro do seu .qmd. Também é útil se você está ensinando R e quer incluir um erro deliberadamente. O padrão, error: false impede a renderização caso exista qualquer erro no documento.\n\nCada uma dessas opções de bloco de código é adicionada ao cabeçalho do bloco, seguindo #|, por exemplo, no bloco a seguir o resultado não é impresso, já que eval está marcado como false.\n\n```{r}\n#| label: multiplicacao-simples\n#| eval: false\n\n2 * 2\n```\n\nA tabela a seguir resume que tipos de saída cada opção suprime:\n\n\n\n\n\n\n\n\n\n\n\nOpção\nExecuta código\nMostra código\nResultados\nGráficos\nMensagens\nAvisos\n\n\n\neval: false\nX\n\nX\nX\nX\nX\n\n\ninclude: false\n\nX\nX\nX\nX\nX\n\n\necho: false\n\nX\n\n\n\n\n\n\nresults: hide\n\n\nX\n\n\n\n\n\nfig-show: hide\n\n\n\nX\n\n\n\n\nmessage: false\n\n\n\n\nX\n\n\n\nwarning: false\n\n\n\n\n\nX\n\n\n\n28.5.3 Opções Globais\nNa medida em que você trabalhar mais com o knitr, você descobrirá que algumas das opções padrão dos blocos não satisfazem a sua necessidade e será preciso alterá-las.\nÉ possível fazer isso adicionando suas opções preferidas no YAML do documento em execute. Por exemplo, se você estiver preparando um relatório para uma audiência que não precisa ver seu código, mas apenas seus resultados e narrativa, pode ser que seja desejável configurar echo: false no nível do documento. Isso esconderá o código por padrão e só exibirá blocos de código que você escolha mostrar ( com echo: true). Você pode configurar message: false e warning: false, mas isso tornará difícil a resolução de problemas de execução porque nenhuma das mensagens serão exibidas no final do documento.\ntitle: \"My report\"\nexecute:\n  echo: false\nComo o Quarto foi desenhado para ser multi-línguas (funciona com R mas também com outras linguagens como Python, Julia, etc.), nem todas as opções do knitr estão disponíveis no nível de documento. Algumas das opções funcionam com knitr mas não com outros motores (engines) que o Quarto usa para executar código em outras linguagens (por exemplo, Jupyter). No entanto é possível ajustar essas como opções globais para o seu documento dentro do campo knitr em opts_chunk. Por exemplo, quando escrevemos livros ou tutoriais, configuramos:\ntitle: \"Tutorial\"\nknitr:\n  opts_chunk:\n    comment: \"#&gt;\"\n    collapse: true\nIsso faz com que nossa formatação para comentários preferida seja usada e garante que o código e seu resultado sejam exibidos próximos um do outro.\n\n28.5.4 Código em linha\nExiste outra maneira de inserir código R em um documento Quarto: diretamente no texto com `r `. Isso pode ser muito útil se você for citar propriedades dos seus dados no texto. Por exemplo, o documento modelo usado no começo do capítulo tinha:\n\nTemos dados sobre `r nrow(diamonds)` diamantes. Apenas `r nrow(diamonds) - nrow(smaller)` são maiores que 2.5 quilates. A distribuição dos restantes é exibida abaixo:\n\nQuando o relatório é renderizado, os resultados dessas computações são inseridas no texto:\n\nTemos dados sobre 53940 diamantes. Apenas 126 são maiores que 2.5 quilates. A distribuição dos restantes é exibida abaixo:\n\nAo inserir números no texto, format() é seu amigo. A função permite configurar o número de digits (casas decimais) para que você não imprima o número com um grau de precisão que chega a ser ridículo e big.mark para facilitar a leitura dos números. Você pode combiná-las em uma função auxiliar:\n\ncomma &lt;- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#&gt; [1] \"3,452,345\"\ncomma(.12358124331)\n#&gt; [1] \"0.12\"\n\n\n28.5.5 Exercícios\n\nAdicione uma seção que explore como o tamanho de diamantes varia de acordo com corte, cor e transparência. Considere que você está escrevendo um relatório para alguém que não sabe R e em vez de usar echo: false em cada bloco, configure como uma opção global.\nFaça o download de diamond-sizes.qmd de https://github.com/hadley/r4ds/tree/main/quarto. Adicione uma seção que descreva os 20 maiores diamantes, incluindo uma tabela que mostre seus atributos mais importantes.\nModifique diamonds-sizes.qmd para usar label_comma() e produzir um resultado bem formatado. Inclua também a percentagem de diamantes que são maiores que 2.5 quilates.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-figures",
    "href": "quarto.html#sec-figures",
    "title": "28  ✅ Quarto",
    "section": "\n28.6 Figuras",
    "text": "28.6 Figuras\nAs figuras em um documento Quarto podem ser integradas (como um arquivo PNG ou JPEG) ou geradas como resultado de um bloco de código.\nPara integrar uma imagem a partir de um arquivo externo, é possível usar o menu Insert no editor Visual no RStudio e selecionar Figure / Image. Isso abrirá um menu em que é possível buscar a imagem que você deseja inserir, assim como adicionar um texto alternativo ou legenda e ajustar seu tamanho.\nNo editor visual também é possível simplesmente colar uma imagem da sua área de transferência no documento, então o RStudio inserirá uma cópia daquela imagem na pasta do seu projeto.\nSe você incluir um bloco de código que gera uma figura (como uma chamada a ggplot()), a imagem resultante será automaticamente incluída no seu documento Quarto.\n\n28.6.1 Tamanho de figura\nO maior desafio ao trabalhar com imagens no Quarto é fazer com que elas fiquem do tamanho e no formato corretos. Há cinco opções principais que controlam o tamanho da figura: fig-width, fig-height, fig-asp, out-width e out-height. Ajustar o tamanho é desafiador porque há dois tamanhos (aquele da figura criada pelo R e aquele que é inserido no documento final) e múltiplas formas de especificar tamanho (isto é, altura, largura e aspect ratio - proporcional: escolha dois dos três).\nRecomendamos três das cinco opções:\n\nGráficos tendem a ser esteticamente mais agradáveis se têm largura consistente. Para garantir isso, configure fig-width: 6 (6 polegadas) e fig-asp: 0.618 (a razão áurea) nas definições padrão. Nos blocos individuais, ajuste apenas fig-asp.\n\nControle o tamanho da saída com out-width e configure como uma percentagem da largura do corpo do documento. Sugerimos out-width: \"70%\" e fig-align: center.\nIsso dá espaço para os gráficos respirarem, sem tomar espaço demais.\n\nPara inserir múltiplos gráficos na mesma linha, configure layout-ncol em 2 para dois gráficos, 3 para três gráficos, etc. Isso efetivamente ajusta out-width para “50%” para cada gráfico se layout-ncol for 2, “33%” se layout-ncol for 3, etc. Dependendo do que você está tentando ilustrar (por exemplo, mostrar dados ou variações de gráficos), você pode experimentar ajustar também fig-width conforme a discussão a seguir.\n\nSe você perceber que está precisando apertar os olhos para enxergar o texto no seu gráfico, você precisa ajustar o fig-width. Se fig-width é maior que o tamanho da figura renderizada no documento final, o texto ficará muito pequeno; se fig-width for menor, o texto ficará grande demais. Frequentemente será necessário alguma experimentação para acertar a razão entre fig-width e a largura do seu documento. Para ilustrar, os três gráficos a seguir têm fig-width de 4, 6, e 8 respectivamente:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe você quiser garantir que o tamanho da fonte seja consistente em todas as suas figuras, será necessário ajustar sempre o out-width com o fig-width para manter a mesma razão com o out-width padrão. Por exemplo, se seu fig-width padrão é 6 e o out-width está em “70%”, será necessário configurar fig-width a 4.3 (6 * 0.5 / 0.7) quando ajustar out-width: \"50%\".\nEntender dimensionamento é uma arte e uma ciência e acertar essas coisas pode requerer uma abordagem de tentativa e erro. Você pode aprender mais sobre isso no post de blog tomando controle de dimensionamento de gráficos.\n\n28.6.2 Outras opções importantes\nQuando estamos trabalhando com código e texto, como neste livro, é possível ajustar fig-show: hold de modo que os gráficos sejam exibidos após o código. Isso rende o efeito agradável de nos forçar a quebrar blocos de código grandes em menores com suas explicações.\nPara adicionar uma legenda ao gráfico, use fig-cap. No Quarto isso mudará a figura de inline (no meio do texto) para “floating”.\nSe você está produzindo PDF, o tipo de gráfico padrão é PDF. Isso é um bom padrão porque PDFs são gráficos vetoriais de alta qualidade. No entanto, isso pode gerar gráficos muito grandes e lentos se você está exibindo milhares de pontos. Nesse caso, ajuste fig-format: \"png\" para forçar o uso de PNGs. Esses têm qualidade ligeiramente menor, mas são muito mais compactos.\nÉ uma boa ideia dar rótulos a blocos de código que produzam figuras, mesmo que você rotineiramente não faça isso. O rótulo do bloco é usado para gerar o nome de arquivo do gráfico salvo em disco, então nomear seus blocos facilita muito a identificação dos gráficos e reutilizá-los em outras circunstâncias (por exemplo, quando é necessário pegar um único gráfico para enviar um email).\n\n28.6.3 Exercícios\n\nAbra diamond-sizes.qmd no editor visual, ache uma imagem de diamante, copie e cole no documento. Clique duas vezes na imagem e adicione uma legenda. Redimensione a imagem e renderize o documento. Observe como a imagem é salva no seu diretório de trabalho.\nEdite o rótulo do bloco de código em diamond-sizes.qmd que gera um gráfico para que comece com o prefixo fig- e adicione uma legenda à figura com a opção de bloco fig-cap. Em seguida, edite o texto acima do bloco de código e adicione uma referência cruzada para a figura com Insert &gt; Cross Reference.\n\nMude o tamanho da figura com as seguintes opções de bloco, uma por vez, renderize o documento e descreva como a figura muda.\n\nfig-width: 10\nfig-height: 3\nout-width: \"100%\"\nout-width: \"20%\"",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#tabelas",
    "href": "quarto.html#tabelas",
    "title": "28  ✅ Quarto",
    "section": "\n28.7 Tabelas",
    "text": "28.7 Tabelas\nSemelhante ao apresentado para figuras, é possível incluir dois tipos de tabelas em um documento Quarto. Elas podem ser tabelas markdown que você pode criar diretamente em seu documento Quarto (usando o menu Insert Table) ou podem ser geradas como resultado de um bloco de código. Nesta seção focaremos na segunda, tabelas geradas via computação.\nPor padrão, Quarto imprime data frames e matrizes como você as veria no console:\n\nmtcars[1:5, ]\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\nSe voce preferir que os dados sejam expostos com formatação adicional, você pode usar a função knitr::kable(). O código abaixo gera Tabela 28.1.\n\nknitr::kable(mtcars[1:5, ], )\n\n\nTabela 28.1: Uma tabela feita com knitr (kable).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\n\n\nLeia a documentação para ?knitr::kable para ver de que outras formas você pode personalizar a sua tabela. Para uma personalização ainda mais profunda, considere os pacotes gt, huxtable, reactable, kableExtra, xtable, stargazer, pander, tables, e ascii. Cada um fornece um conjunto de ferramentas para retornar tabelas formatadas a partir de código R.\n\n28.7.1 Exercícios\n\nAbra diamond-sizes.qmd no editor visual, insira um bloco de código e adicione uma tabela com knitr::kable() que mostre as 5 primeiras linhas do data frame diamonds.\nExiba a mesma tabela com gt::gt().\nAdicione um rótulo de bloco de código que comece com o prefixo tbl- e adicione a legenda para a tabela com a opção de bloco tbl-cap. Depois edite o texto acima do bloco de código para adicionar a referência cruzada para a tabela com Insert &gt; Cross Reference.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#sec-caching",
    "href": "quarto.html#sec-caching",
    "title": "28  ✅ Quarto",
    "section": "\n28.8 Salvando em cache",
    "text": "28.8 Salvando em cache\nNormalmente, cada renderização do documento começa de uma folha em branco. Isso é ótimo para reprodutibilidade porque garante que você capturou toda computação importante em código. No entanto, pode ser doloroso refazer computações que tomam um tempo longo. A solução para isso é cache: true.\nÉ possível habilitar o cache do knitr no nível do documento para guardar em cache os resultados de todas as computações em um documento usando as opções padrão de YAML:\n---\ntitle: \"Meu documento\"\nexecute: \n  cache: true\n---\nTambém é possível permitir caching no nível de bloco para guardar os resultados da computação de um bloco específico em cache.\n\n```{r}\n#| cache: true\n\n# código para uma computação longa...\n```\n\nQuando configurado, isso salvará os resultados do bloco para um arquivo de nome especial em seu disco de armazenamento. Em execuções subsequentes, o knitr verificará se houve alguma alteração no código e caso isso não tenha acontecido os resultados em cache serão reutilizados.\nO sistema de cache deve ser usado com cuidado porque, por padrão, é usado apenas no código, e não em suas dependências. Por exemplo, aqui o bloco dados_processados depende do bloco dados-crus:\n``` {{r}}\n#| label: dados-crus\n#| cache: true\n\ndadoscrus &lt;- readr::read_csv(\"um_arquivo_enorme.csv\")\n```\n``` {{r}}\n#| label: dados_processados\n#| cache: true\n\ndados_processados &lt;- dadoscrus |&gt; \n  filter(!is.na(var_importante)) |&gt; \n  mutate(nova_variavel = transformacao_complicada(x, y, z))\n```\nGuardar o bloco processed_data em cache signigica que ele será executado novamente se o pipeline de dplyr for alterado, mas não se a chamada de read_csv() mudar. Esse problema pode ser evitado com a opção dependson:\n``` {{r}}\n#| label: dados-processados\n#| cache: true\n#| dependson: \"dados-brutos\"\n\ndados_processados &lt;- dadoscrus |&gt; \n  filter(!is.na(var_importante)) |&gt; \n  mutate(nova_variavel = transformacao_complicada(x, y, z))\n```\ndependson deve conter um vetor de caracteres em todos os blocos de que o bloco em cache depende. O knitr atualizará os resultados para o bloco em cache sempre que detectar que uma de suas dependências mudou.\nNote que os blocos não serão atualizados se um_arquivo_enorme.csv mudar, já que o cache do knitr só monitora alterações no arquivo .qmd. Se você quiser também monitorar mudanças naquele arquivo, é possível usar a opção cache.extra. Essa é uma expressão de R arbitrária que invalida o cache toda vez que há alteração. Uma boa função neste caso é file.mtime(): a função retorna quando foi a última alteração. Você pode então escrever:\n``` {{r}}\n#| label: raw-data\n#| cache: true\n#| cache.extra: !expr file.mtime(\"um_arquivo_enorme.csv\")\n\ndadoscrus &lt;- readr::read_csv(\"um_arquivo_enorme.csv\")\n```\nSeguimos o conselho de David Robinson para nomear esses blocos: cada um é nomeado de acordo com o objeto primário que é criado. Isso facilita a compreensão da especificação de dependson.\nNa medida em que suas estratégias de cache vão complicando, é uma boa ideia limpar todo o seu cache com knitr::clean_cache().\n\n28.8.1 Exercícios\n\nAjuste uma sequência de blocos em que d depende de c e b e os dois últimos dependem de a. Faça com que cada bloco imprima lubridate::now(), ajuste cache: true e verifique o que você entendeu sobre caching.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#resolução-de-problemas",
    "href": "quarto.html#resolução-de-problemas",
    "title": "28  ✅ Quarto",
    "section": "\n28.9 Resolução de problemas",
    "text": "28.9 Resolução de problemas\nResolver problemas em documentos Quarto pode ser desafiador porque você não está mais em um ambiente interativo de R, então você precisará aprender uns truques novos. Além disso, o erro pode ter ocorrido devido a problemas no documento de Quarto ou mesmo devido ao código em R no documento.\nUm erro comum em documentos com blocos de código é haver rótulos de blocos duplicados, o que tem certa ocorrência se o seu fluxo de trabalho envolve copiar e colar de blocos de código. Para abordar esse problema, tudo que você precisa fazer é mudar o nome de um dos seus rótulos duplicados.\nSe os erros ocorrem por causa do código em R no documento, a primeira coisa que você deveria fazer sempre é tentar recriar o problema em uma sessão interativa. Reinicie o R, depois execute todos os blocos (Run all chunks) via Run region no menu Code ou com o atalho Ctrl + Alt + R. Se estiver com sorte, isso recriará o problema e você descobrirá o que está acontecendo interativamente.\nSe isso não ajudar, deve haver algo diferente entre o seu ambiente interativo e o seu ambiente Quarto. Será necessário explorar as opções sistematicamente. A diferença mais comum é o diretório de trabalho: o diretório de trabalho de um documento Quarto é aquele em que o documento vive. Verifique se o diretório é o que você espera usando getwd() em um bloco.\nA seguir, tente listar todas as coisas que poderiam causar o bug. Será necessário verificar sistematicamente se essas coisas são as mesmas na sua sessão R e na sua sessão Quarto. A forma mais fácil de fazer isso é ajustar error: true no bloco causando o problema e usar print() e str() para verificar que as configurações são o que você espera.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#cabeçalho-yaml",
    "href": "quarto.html#cabeçalho-yaml",
    "title": "28  ✅ Quarto",
    "section": "\n28.10 Cabeçalho YAML",
    "text": "28.10 Cabeçalho YAML\nÉ possível controlar muitas outras configurações de “documento inteiro” ajustando os parâmetros do cabeçalho YAML. Você pode estar pensando no que significa YAML: é “YAML Ain’t Markup Language” ou “YAML não é linguagem Markup” – mas não carrega a sigla em português. A linguagem foi projetada para representar dados hierárquicos de uma forma que seja fácil para humanos lerem e escreverem. Quarto usa isso para controlar muitos detalhes da saída. Aqui discutiremos três: documentos autocontidos, parâmetros de documentos e bibliografias.\n\n28.10.1 Documentos Autocontidos\nDocumentos HTML tipicamente têm uma série de dependências externas (por exemplo imagens, guias de estilo CSS, JavaScript, etc.) e, por padrão, o Quarto coloca essas dependências em uma pasta _files no mesmo diretório que o seu arquivo .qmd. Se você publicar o arquivo HTML em uma plataforma (por exemplo, QuartoPub, https://quartopub.com/), as dependências desse diretório são publicadas com o documento e então estarão disponíveis no relatório publicado. No entanto, se você quer enviar o relatório para um colega por email, é possível que prefira ter um único documento HTML autocontido que tem suas dependências todas embutidas. Você pode fazer isso especificando a opção embed-resources.\nformat:\n  html:\n    embed-resources: true\nO arquivo resultante será autocontido, de modo que não necessitará de qualquer arquivo interno nem de acesso à internet para ser exibido corretamente por um navegador.\n\n28.10.2 Parâmetros\nDocumentos Quarto podem incluir um ou mais parâmetros cujos valores podem ser ajustados quando se renderiza o relatório. Parâmetros são úteis quando se quer executar mais vezes o mesmo relatório com valores diferentes para vários inputs chave. Por exemplo, pode ser que seja necessário produzir relatórios de vendas por filial, resultados de provas por aluno ou mesmo resumos demográficos por país. Para declarar um ou mais parâmetros, use o campo params.\nEsse exemplo usa o parâmetro my_class para determinar que classe de carros será exibida:\n\n---\nformat: html\nparams:\n  minha_classe: \"suv\"\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\nlibrary(dados)\n\nclasse &lt;- milhas |&gt; filter(classe == params$minha_classe)\n```\n\n# Economia de combustível para `r params$minha_classe`\n\n```{r}\n#| message: false\n\nggplot(classe, aes(x = cilindrada, y = rodovia)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\n\nComo se pode ver, parâmetros estão disponíveis dentro dos blocos de código como uma lista chamada params com permissão apenas de leitura.\nÉ possível escrever vetores atômicos diretamente no cabeçalho YAML. É possível ainda executar expressões arbitrárias em R prefixando o valor do parâmetro com !expr. Essa é uma boa forma de especificar parâmetros de data/tempo.\nparams:\n  start: !expr lubridate::ymd(\"2015-01-01\")\n  snapshot: !expr lubridate::ymd_hms(\"2015-01-01 12:30:00\")\n\n28.10.3 Bibliografias e citações\nBibliografia e citações podem ser automaticamente geradas pelo Quarto em uma série de estilos. A forma mais direta de adicionar citações e bibliografias no seu documento Quarto é usando o editor visual no RStudio.\nPara adicionar a citação no editor visual, vá em Insert &gt; Citation. Citações podem ser inseridas a partir de uma variedade de fontes:\n\nReferências DOI (Digital Object Identifier).\nBibliotecas particulares ou de grupo do Zotero.\nPesquisas na Crossref, DataCite, ou na PubMed.\nSeu documento de bibliografia (um arquivo .bib no diretório do seu documento).\n\nInternamente, o editor visual usa a representação padrão para citações do markdown Pandoc (por exemplo, [@citation]).\nSe você inserir uma citação usando um dos primeiros três métodos, o editor visual automaticamente criará um arquivo bibliography.bib para você e adicionará a sua referência a ele. Isso também adicionará um campo bibliography ao YAML do documento. À medida em que você insere mais referências, esse arquivo é povoado com as citações. Também é possivel editar diretamente esse arquivo usando muitos formatos comuns como BibLaTeX, BibTeX, EndNote, Medline.\nPara criar a citação dentro do seu arquivo .qmd no editor source, use a chave composta de ‘@’ + identificador da citação do seu arquivo de bibliografia. Em seguida, coloque a citação entre colchetes. Seguem alguns exemplos:\nSepare múltiplas citações com `;`: Blah blah [@smith04; @doe99].\n\nÉ possível inserir comentários arbitrários nos colchetes: \nBlah blah [veja @doe99, pp. 33-35; também @smith04, cap. 1].\n\nRemova os colchetes para criar uma citação direta: @smith04 diz blah, ou @smith04 [p. 33] diz blah.\n\nAdicione um `-` antes da citação para suprimir o nome do autor:\nSmith diz blah [-@smith04].\nQuando o Quarto renderiza o seu arquivo, a bibliografia será construída e adicionada ao final do seu documento. A bibliografia conterá cada uma das citações do seu arquivo de bibliografia, mas não é criado um título no documento para ela. Como resultado, é uma prática comum finalizar o seu documento com um título de seção para a bibliografia como # Referências ou # Bibliografia.\nÉ possível alterar o estilo das suas citações e bibliografia fazendo referência a um arquivo CSL (citation style language – ou linguagem de estilo de citação) no campo csl:\nbibliography: rmarkdown.bib\ncsl: apa.csl\nAssim como no campo de bibliografia, seu arquivo csl deve conter um caminho para o arquivo. Aqui assumimos que o arquivo CSL está no mesmo diretório que o arquivo .qmd. Um bom lugar para encontrar arquivos de estilo CSL para sua bibligrafia é em: https://github.com/citation-style-language/styles.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#fluxo-de-trabalho",
    "href": "quarto.html#fluxo-de-trabalho",
    "title": "28  ✅ Quarto",
    "section": "\n28.11 Fluxo de trabalho",
    "text": "28.11 Fluxo de trabalho\nAnteriormente discutimos um fluxo de trabalho básico para executar seu código R, trabalhando interativamente no console, e depois salvar o que funciona no editor de script. O Quarto junta o console e o editor de script, deixando menos clara a linha que separa a exploração interativa e captura de código para longo prazo. Você pode trabalhar interativamente dentro de um bloco, editando e executando novamente com Cmd/Ctrl + Shift + Enter. Quando o trabalho estiver bom, você pode continuar e criar um novo bloco de código.\nO Quarto também é importante porque integra estreitamente texto e código. Isso faz do Quarto um ótimo caderno de análise (analysis notebook), porque permite desenvolver código e registrar seus pensamentos. Um caderno de análise compartilha muitos dos mesmos objetivos de um caderno de laboratório clássico nas ciências exatas. O caderno:\n\nPermite gravar o que você fez e por que você fez. Independentemente de quão boa é a sua memória, se você não registrar o que fez, chegará um momento em que você esquecerá os detalhes importantes. Escreva para não se esquecer!\nApoia o pensamento rigoroso. É mais provável que você desenvolva uma análise robusta se você registrar seus pensamentos enquanto trabalha, depois pode continuar a refletir sobre eles. Isso também economiza tempo quando você eventualmente organizar sua análise para compartilhar com outras pessoas.\nAjuda outras pessoas a entenderem o seu trabalho. É raro fazer análise de dados sozinho e você frequentemente fará parte de uma equipe. Um caderno de laboratório ajuda a compartilhar com seus colegas não apenas o que você fez, mas também porque você fez o que fez.\n\nMuitos dos bons conselhos sobre o uso efetivo de cadernos de laboratórios podem também ser traduzidos para cadernos de análise. Tiramos de nossa própria experiência e dos conselhos de Collin Purrington sobre cadenos de laboratório (https://colinpurrington.com/tips/lab-notebooks) para desenvolver essas dicas:\n\nGaranta que cada caderno tem um título descritivo, um nome evocativo e um primeiro parágrafo que descreve brevemente os objetivos de análise.\n\nUse o campo de data do cabeçalho YAML para registrar a data em que você começou a trabalhar no caderno:\ndate: 2016-08-23\nUse ISO8601 YYYY-MM-DD para não haver ambiguidade. Use mesmo que você não escreva datas desse jeito!\n\nSe você passa muito tempo em uma ideia de análise e no final parece que não vai dar em nada, não apague! Faça uma breve anotação sobre o motivo de a análise ter falhado e deixe no caderno. Isso ajudará você a não cair na mesma rota quando voltar à análise no futuro.\nGeralmente é melhor registrar dados fora do R. Se você precisa registrar um pequeno trecho dos dados, faça isso de forma explícita usando tibble::tribble().\nSe você descobrir um erro no arquivo de dados, nunca o modifique diretamente. Em vez disso, escreva código para corrigir o valor. Escreva o motivo do reparo.\nAntes de finalizar os trabalhos do dia, garanta que é possível renderizar o caderno. Se está usando caching, limpe os caches. Isso permitirá a correção de problemas enquanto o código ainda está fresco na memória.\nSe você quiser que seu código seja reprodutível a longo prazo (por exemplo, para voltar a trabalhar nele no mês ou ano seguinte), pode ser necessário registrar as versões dos pacotes que seu código usa. Uma abordagem rigorosa é usar renv, https://rstudio.github.io/renv/index.html, que guarda os pacotes no seu diretório do projeto. Um macete é incluir um bloco que execute sessionInfo() — isso não permite facilmente recriar seus pacotes em seu estado atual, mas pelo menos ajuda a saber em que estado estavam.\nVocê criará muitos, muitos cadernos de análise no decorrer da sua carreira. Como você os organizará de modo que consiga achá-los no futuro? Recomendamos guardá-los em projetos individuais e criar um bom esquema de nomes.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#resumo",
    "href": "quarto.html#resumo",
    "title": "28  ✅ Quarto",
    "section": "\n28.12 Resumo",
    "text": "28.12 Resumo\nNeste capítulo apresentamos o Quarto para escrita e publicação reprodutível de documentos computacionais que incluam seu código e seu texto no mesmo lugar. Você aprendeu sobre escrever em documentos Quarto no RStudio com o editor fonte ou visual, como blocos de código funcionam e como personalizar opções para cache de computações. Além disso, você aprendeu sobre ajustes no cabeçalho YAML para criar documentos autocontidos ou parametrizados, assim como incluir citações e bibliografia. Também demos dicas de fluxo de trabalho e de resolução de problemas.\nEnquanto essa introdução deve ser suficiente para iniciar seu trabalho com Quarto, ainda há muito a aprender. Quarto ainda é relativamente jovem e ainda está crescendo rapidamente. O melhor lugar para se atualizar das últimas inovações é o site oficial: https://quarto.org.\nHá dois tópicos importantes que não cobrimos aqui: colaboração e detalhes para comunicar sua ideia com precisão para outros humanos. Colaboração é uma parte vital da ciência de dados moderna e você pode facilitar muito a sua vida usando ferramentas de controle de versão, como Git e GitHub. Recomendamos o livro “Happy Git with R”, uma introdução amigável ao Git e ao GitHub para quem programa em R, escrito pela Jenny Bryan. O livro está disponível online com acesso livre: https://happygitwithr.com.\nTambém não comentamos sobre o que você deveria realmente escrever para comunicar seus resultados da sua análise com clareza. Para melhorar sua escrita, recomendamos muito a leitura de Style: Lessons in Clarity and Grace por Joseph M. Williams & Joseph Bizup, ou The Sense of Structure: Writing from the Reader’s Perspective por George Gopen. Ambos os livros ajudarão a entender a estrutura de frases e parágrafos e darão ferramentas para tornar sua escrita mais clara. (esses livros são um tanto caros, mas são muito usados em cursos de inglês, então há muitas cópias baratas de segunda mão). George Gopen também tem uma série de artigos curtos sobre escrita em https://www.georgegopen.com/the-litigation-articles.html. Esses são direcionados a advogados, mas quase tudo se aplica a cientistas de dados também.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>✅ Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html",
    "href": "quarto-formats.html",
    "title": "29  ✅ Formatos para Quarto",
    "section": "",
    "text": "29.1 Introdução\nAté agora você viu o Quarto sendo usado para produzir documentos HTML. Este capítulo dá uma visão geral de alguns dos muitos outros tipos de saída (output) que você pode produzir com Quarto.\nHá duas formas de configurar a saída do documento:",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#introdução",
    "href": "quarto-formats.html#introdução",
    "title": "29  ✅ Formatos para Quarto",
    "section": "",
    "text": "Permanentemente, modificando o cabeçalho YAML:\ntitle: \"Tamanhos de diamante\"\nformat: html\n\n\nPontualmente, executando quarto::quarto_render() manualmente:\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"docx\")\n\nIsso é útil quando se deseja programaticamente produzir múltiplos tipos de saída ja que o argumento output_format também pode receber uma lista de valores.\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = c(\"docx\", \"pdf\"))",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#opções-de-saída",
    "href": "quarto-formats.html#opções-de-saída",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.2 Opções de saída",
    "text": "29.2 Opções de saída\nO Quarto oferece uma ampla variedade de formatos de saída. É possível achar a lista completa em https://quarto.org/docs/output-formats/all-formats.html. Muitos formatos compartilham configurações de seu resultado (por exemplo, toc: true para incluir um sumário), mas outros têm configurações que são específicas do formato (por exemplo, code-fold: true colapsa os blocos de código em uma tag HTML &lt;details&gt; de modo que o usuário possa exibí-lo quando quiser, e não é aplicável a um documento PDF ou Word).\nPara sobrescrever as opções padrão, é necessário usar um campo format extendido. Por exemplo, se quiser renderizar um html com um sumário flutuante, é necessário usar:\nformat:\n  html:\n    toc: true\n    toc_float: true\nÉ possível ainda renderizar múltiplas saídas fornecendo uma lista de formatos:\nformat:\n  html:\n    toc: true\n    toc_float: true\n  pdf: default\n  docx: default\nNote a sintaxe especial (pdf: default) caso não queira sobrescrever nenhuma das opções padrão.\nPara renderizar todos os formatos especificados no YAML do documento, use output_format = \"all\".\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"all\")",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#documentos",
    "href": "quarto-formats.html#documentos",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.3 Documentos",
    "text": "29.3 Documentos\nO foco do capítulo anterior era a saída padrão html. Existem diversas variações básicas nesse tema, gerando diferentes tipos de documentos. Por exemplo:\n\npdf produz um PDF com LaTeX (um systema de diagramação/layout de código aberto/open-source), que precisará ser instalado. O RStudio emitirá um aviso se ainda não estiver instalado.\ndocx para um documento Microsoft Word (.docx).\nodt para um documento OpenDocument Text (.odt).\nrtf para um documento Rich Text Format (.rtf).\ngfm para um documento GitHub Flavored Markdown (.md).\nipynb para um caderno Jupyter (.ipynb).\n\nLembre-se que ao gerar um documento para compartilhar com tomadores de decisão é possível inativar a exibição padrão de código configurando opções globais no YAML do documento:\nexecute:\n  echo: false\nPara documentos html, outra opção é fazer com que os blocos de código fiquem escondidos por padrão, mas visíveis se clicados:\nformat:\n  html:\n    code: true",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#apresentações",
    "href": "quarto-formats.html#apresentações",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.4 Apresentações",
    "text": "29.4 Apresentações\nTambém é possível usar o Quarto para produzir apresentações. O controle visual é menor do que se teria usando uma ferramenta como Keynote ou Powerpoint, mas inserir automaticamente resultados do seu código em R nas apresentações pode economizar muito tempo. Em apresentações o conteúdo do trabalho é dividido em slides, com um novo slide começando em cada marcador de título de nível 2 (##). Além disso, títulos de nível 1 (#) indicam o começo de uma nova seção com um slide de título de seção que, por padrão, fica centralizado no meio do slide.\nUma variedade de formatos de apresentação têm suporte em Quarto, incluindo:\n\nrevealjs - apresentações HTML com revealjs\npptx - apresentações PowerPoint\nbeamer - apresentações PDF com LaTeX Beamer.\n\nLeia mais sobre a criação de apresentações com Quarto em https://quarto.org/docs/presentations.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#interatividade",
    "href": "quarto-formats.html#interatividade",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.5 Interatividade",
    "text": "29.5 Interatividade\nAssim como em qualquer documento HTML, documentos nesse formato criados com Quarto podem conter elementos interativos também. Aqui introduzimos duas opções para incluir interatividade em seus documentos Quarto: htmlwidgets e Shiny.\n\n29.5.1 htmlwidgets\nHTML é um formato interativo e é possível aproveitar essa qualidade com htmlwidgets, funções de R que produzem visualizações interativas em HTML. Por exemplo, veja o mapa leaflet abaixo. Se você está vendo essa página na internet, é possível mover o mapa, aumentar ou diminuir o zoom, etc. Obviamente isso não é possível em um livro, entao uma visualização estática é automaticamente inserida pelo Quarto.\n\nlibrary(leaflet)\nleaflet() |&gt;\n  setView(174.764, -36.877, zoom = 16) |&gt; \n  addTiles() |&gt;\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") \n\n\n\n\n\nUma ótima notícia sobre htmlwidgets é que você não precisa saber nada de HTML ou de JavaScript para usá-las. Todos os detalhes são incluídos no pacote, então não precisa se preocupar sobre isso.\nHá muitos pacotes que fornecem htmlwidgets, incluindo:\n\ndygraphs para visualizações de séries temporais interativas.\nDT para tabelas interativas.\nthreejs para gráficos 3D interativos.\nDiagrammeR para diagramas (como diagramas de fluxo ou diagramas simples de nó e aresta – grafos).\n\nPara aprender mais sobre htmlwidgets e ver uma lista completa de pacotes que os fornecem, visite https://www.htmlwidgets.org.\n\n29.5.2 Shiny\nhtmlwidgets fornecem interatividade client-side (do lado do cliente ou, em liguagem comum, do usuário) — toda a interatividade ocorre no navegador, independente do R. Por um lado, isso é ótimo porque é possível distribuir o arquivo HTML sem qualquer conexão com R. No entanto, isso limita fundamentalmente o que se pode fazer ao que foi implementado em HTML e JavaScript. Uma abordagem alternativa é usar shiny, um pacote que permite criar interativamente usando R em vez de JavaScript.\nPara fazer chamadas de código Shiny em um documento Quarto, inclua server: shiny no cabeçalho YAML:\ntitle: \"Shiny Web App\"\nformat: html\nserver: shiny\nDepois você pode usar as funções “input” para adicionar componentes interativos ao documento:\n\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\n\n\n\n\n\n\n\n\n\nÉ necessário também um bloco de código com a opção context: server que contém o código que precisa ser executado em um servidor Shiny.\nVocê pode fazer referência aos valores com input$name e input$age, fazendo com que o código que os usa seja novamente executado toda vez que são alterados.\nNão podemos mostrar um app shiny sendo executado porque as interações ocorrem no server-side (do lado do servidor). Isso significa que é possível escrever apps interativos sem saber JavaScript, mas é necessário um servidor para hospedá-los. Isso introduz um problema logístico: aplicativos Shiny precisam de um servidor Shiny para serem executados online. Quando se executa aplicativos Shiny em seu próprio computador, um servidor Shiny é automaticamente configurado para você, mas é necessário um servidor de acesso público se quiser publicar esse tipo de interatividade on-line. Essa é a troca fundamental de shiny: qualquer coisa que você faria em R você pode fazer em um documento shiny, mas isso requer alguém executando R.\nPara aprender mais sobre Shiny, recomendamos a leitura do livro Mastering Shiny por Hadley Wickham, https://mastering-shiny.org.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#sites-e-livros",
    "href": "quarto-formats.html#sites-e-livros",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.6 Sites e livros",
    "text": "29.6 Sites e livros\nCom um pouco de infraestrutura adicional é possível usar o Quarto para gerar um site completo ou um livro:\n\nColoque seus arquivos .qmd em um único diretório. index.qmd se tornará a página principal — a home page.\n\nAdicione um arquivo YAML chamado _quarto.yml que fornece a navegação para o site. Nesse arquivo, ajuste o tipo de project para book ou website para livro ou site respectivamente:\nproject:\n  type: book\n\n\nPor exemplo, o arquivo _quarto.yml a seguir cria um site a partir de três arquivos: index.qmd (a página inicial), viridis-colors.qmd, e terrain-colors.qmd.\n\nproject:\n  type: website\n\nwebsite:\n  title: \"A website on color scales\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: viridis-colors.qmd\n        text: Viridis colors\n      - href: terrain-colors.qmd\n        text: Terrain colors\n\nO arquivo _quarto.yml necessário para um livro é estruturado de forma muito similar. O exemplo a seguir mostra como é possível criar um livro com quatro capítulos que renderizam três tipos diferentes de output (html, pdf, e epub). Mais uma vez os arquivos fonte são arquivos .qmd.\n\nproject:\n  type: book\n\nbook:\n  title: \"A book on color scales\"\n  author: \"Jane Coloriste\"\n  chapters:\n    - index.qmd\n    - intro.qmd\n    - viridis-colors.qmd\n    - terrain-colors.qmd\n\nformat:\n  html:\n    theme: cosmo\n  pdf: default\n  epub: default\n\nRecomendamos que você use um projeto do RStudio para seus sites e livros. Baseado no arquivo _quarto.yml o RStudio reconhecerá o tipo de projeto em que está trabalhado, adicionará uma aba Build à IDE que você pode usar para renderizar e visualizar prévias de seus sites e livros. Tanto sites como livros também podem ser renderizados usando quarto::render().\nLeia mais em https://quarto.org/docs/websites sobre sites Quarto e em https://quarto.org/docs/books sobre livros.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#outros-formatos",
    "href": "quarto-formats.html#outros-formatos",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.7 Outros formatos",
    "text": "29.7 Outros formatos\nQuarto oferece ainda mais formatos de output:\n\nVocê pode escrever artigos usando Quarto Journal Templates: https://quarto.org/docs/journals/templates.html.\nVocê pode transformar documentos Quarto em formato de notebooks do Jupyter com format: ipynb: https://quarto.org/docs/reference/formats/ipynb.html.\n\nVeja https://quarto.org/docs/output-formats/all-formats.html para uma lista com ainda mais formatos.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#resumo",
    "href": "quarto-formats.html#resumo",
    "title": "29  ✅ Formatos para Quarto",
    "section": "\n29.8 Resumo",
    "text": "29.8 Resumo\nNeste capítulo apresentamos uma variedade de opções para comunicar seus resultados com Quarto, de documentos estáticos e interativos a apresentações, sites e livros.\nPara aprender mais sobre comunicação efetiva nesses diferentes formatos, recomendamos os seguintes recursos:\n\nPara melhorar suas habilidades de apresentação, experimente Presentation Patterns por Neal Ford, Matthew McCollough, e Nathaniel Schutta. O recurso fornece um conjunto de padrões efetivos (de alto e baixo nível) que você pode adotar para melhorar suas apresentações.\nSe você dá palestras acadêmicas, você pode gostar de Leek group guide to giving talks.\nNão experimentamos pessoalmente, mas ouvimos coisas boas sobre o curso online de Matt McGarrity’s sobre apresentação ao público: https://www.coursera.org/learn/public-speaking.\nSe você está criando muitos painéis (dashboards), leia Information Dashboard Design: The Effective Visual Communication of Data de Stephen Few. Isso ajudará a criar painéis que são realmente úteis, não apenas agradáveis de olhar.\nConhecimento sobre design gráfico muitas vezes beneficia a comunicação efetiva das suas ideias. The Non-Designer’s Design Book de Robin Williams é um ótimo lugar para começar.",
    "crumbs": [
      "✅ Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>✅ Formatos para Quarto</span>"
    ]
  }
]